# 字节
[字节后端日常实习一面_笔经面经_牛客网 (nowcoder.com)](https://www.nowcoder.com/discuss/821404?source_id=profile_create_nctrack&channel=-1)
1. JVM内存区域，垃圾回收过程，怎么查看垃圾回收过程
```markdown
内存区域以线程共享和独占来入手

垃圾回收过程以垃圾回收算法入手,再介绍CMS垃圾回收过程

查看垃圾回收算法:java  -XX:+PrintCommandLineFlags  -version, 最后一个 -XX:+UseParallelGC 新生代使用ParallerGC，老年代使用Serial Old
```

2. 线程池参数，拒绝策略，工作流程
```markdown


```


3. 线程同步方法，创建线程方法，Runable和Callable区别

```markdown
同步方法:(得补补)
1.synchronized
2.volatile
3.ThreadLocal


创建线程方法:
1.继承Thread类
2.实现Runnable接口
3.实现Callable接口,通过Future拿到返回值

区别:
从使用角度来看: 后者能返回值,前者不能
从构造角度来看: Runnable方法的执行可以看做是Thread来执行的,而Callable的call方法的执行是FutureTask来执行的,中间加了一层,使得我们能通过一系列方法改进原本run方法不能返回值的问题
```

4. volatile作用
```markdown
从java关键字使用的层面看,volatile关键字保证了内存可见性,这点synchronized也同样具备

从JMM层面看, java内存模型是共享内存模型,对变量的处理都是对工作内存中的变量进行处理,若变量不在工作内存,则去主内存读取.这使得一个变量可能存在多个线程的工作内存中,volatile就是使得一个线程对该变量的修改可以使得其他线程工作内存中该变量的副本失效,若需要读取该变量就只能重新去主内存读取

再往下看,volatile做了什么操作来实现这个功能:答案就是volatile,volatile修饰的变量赋值后汇编层面的指令加上了lock前缀,使得其他处理器若存在该变量则对应的block失效.

再往下看,MESI缓存一致性协议如果严格执行的话缓存一致性是没问题的,但效率太低了,每次修改变量时总得通知其他cpu当前要对某个变量修改,然后等待其他cpu回应ack,这期间要修改的cpu是空闲的,而其他cpu得判断自己高速缓存是否存在该变量,有就将该block失效,再返回ack.为了提高效率映入了写存储区和失效队列.这就导致了一个线程对一个变量的修改结果其他线程并不能马上看到,出现线程安全问题
```


5. MySQL索引结构，联合索引，隔离级别(RC和RR区别），mvcc原理
```markdown

MySQL索引分为聚合索引和非聚合索引,



隔离级别: 1.读未提交 2.读已提交 3.可重复读 4.串行化

RC 和 RR 的区别就是 关于读视图是每一次 select 生成 还是 第一次select 生成

对于快照读 都是 用 MVCC + undo log 链来完成
对于当前读, RC 用 行锁 , RR使用 next-key lock

MVCC原理就是每一次select 创建一个读视图
```

6. Redis 基本数据结构，怎么存储对象
```markdown
基本数据结构:
	1.SDS
	2.字典
	3.压缩列表
	4.quickList
	5.skipList


```


7. Spring IOC 和 AOP


8. LRU





```MARKDOWN

字节大数据基础架构部门的实习生

字节面经 一面 2.17 
1. 自我介绍
2. 接口和抽象类的区别
3. 了解过啥设计模式
4. 单例模式是啥
5. 工厂模式的作用，为什么要用工厂模式？
	解耦, 把对象的创建和使用的过程分开(就是Class A 想调用Class B,那么只是调用B的方法，而至于B的实例化，就交给工厂类)
6. 建造者模式的实现方式
7. 在设计模式中你使用抽象类还是接口比较多
8. 了解哪些Java锁
9. 死锁的必要条件
10. Mysql索引了解吗(那时候不会就直接说不会了)
11. MySql事务隔离级别
12. 说一下你用过的Java框架
	(说了Spring 的 ioc/aop 还没说aop就下一问了)
13. 项目中如何使用git和maven的
代码题:
 	1. 写一个快排
 	 	1. 快排是否稳定
 	 	2. 什么情况下会退化
 	 	3. 如何优化
 	 	4. 时间复杂度
 	2. 写一个二分查找
 	 	1. 复杂度
代码题写的太快了, 然后他说时间还没到在问几个问题
14. 了解分布式吗(NO)
15. 说一下Java基础类型
16. 为什么int是2的31次方
17. 了解Docker吗(NO)
13. 什么是Java同步和异步

反问:
	1. 部门的业务
	2. 对我的评价
	
字节跳动二面 2.18
1. 进程之间的通信
 1. 管道通信
 2. 命名管道通信
 3. 消息队列
 4. 共享内存
 5. 信号量
 6. 套接字
 7. 信号
 3. 说一下你了解的锁
2. 说一下synchronized 和 reentranlock
3. 介绍一下Reentrantlock
4. 单例模式中变量前加的关键字(volatile)
5. 单例模式并发下实现方式
 1. 双重检查锁(DCL)
 2. 内部类
 3. 枚举类
6. volatile的作用是什么
 1. 防止 JVM 的指令重排 ，还有一个重要的作用就是保证变量的可见性
 2. 会主动刷新存储 
7. 聚集索引和非聚集索引的区别
  1.聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。**
  2.非聚集索引即索引结构和数据分开存放的索引。二级索引属于非聚集索引**
8. mysql三大范式说一个你了解的
9. mysql的ACID是什么
10. Maven包冲突怎么解决
11. 介绍一下HashMap
12. HashMap扩容了解吗?说一下扩容因子(loadFactor)
13. 红黑树的特点, 为啥红黑树比较二叉树快
  - 每条路上黑节点的数量是固定的, 高度限制搜索快
  - 红黑树特点 :
   1. 每个节点非红即黑；
   2. 根节点总是黑色的；
   3. 每个叶子节点都是黑色的空节点（NIL节点）；
   4. 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）；
   5. 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。
14. Redis为什么快?
	直接操作内存 单线程没有多线程创建销毁的开销 IO多路复用
15. Redis缓存机制(我觉得应该是处理流程)
算法题:
	LeetCode 25 困难
	K个一组反转链表改版(最后n个不足也反转)
	
字节面经 三面Leader面 - 2.21(挂)

1. Object类里有什么方法
2. 有用过Object类中相关锁的方法吗
  1. wait
  2. notify
  3. notifyAll
3. Java垃圾回收的方法新生代和老年代的不同的算法
4. 设计模式中有用到锁的模式
5. 如果没有使用两个锁单例会有什么问题
6. MySQL使用还是对他的原理有什么了解
7. 使用JavaEE开发过一些项目吗
8. 在开发项目中有什么问题吗, 然后最后解决了的
算法题:
LeetCode 101简单
​	1. 对称二叉树
还是题刷的不够多,没写到这题也没多写二叉树,我居然用BFS写的
```



https://www.nowcoder.com/discuss/840270





## 操作系统
#### 产生死锁的条件
	互斥，占有并保持，不可剥夺，循环等待
#### 进程通信
	管道：匿名管道（半双工），有名管道
	信号量
	信号
	消息队列
	内存映射
	套接字

#### 线程通信
	线程间的通信目的主要是用于线程同步。所以线程没有像进程通信中的用于数据交换的通信机制。
	锁机制，信号量机制，信号机制
#### 进程同步
	进程同步的基础是通信，从通信中找到能设置状态变化并且其他进程能感知到。只要都共享的读取某个东西，就可以通过修改这个东西的状态实现同步。临界区，信号量，事件对象
	临界区，信号量，事件对象


### 虚拟内存管理
#### 页面调度算法
	先进先出，最佳置换，最近最久未使用，Clock，改进Clock

#### 分段和分页
	离散内存分配是实现虚拟内存的基础。对内存进行分页和分段，目的都是为了更好的利用内存资源。分页服务于操作系统，为了更好的管理内存回收与分配；分段服务于用户，为了更好的根据开发逻辑关系，使用内存
	分段是一种连续内存分配策略，不存在缺页中断；而分页是将进程逻辑地址空间分为若干大小相等的页面，将物理地址空间分为若干大小相等的物理块，物理块大小等于页面大小，当程序执行时将用到的页面映射到物理块上，实现内存的离散分配
	
	一次查询流程：cpu发出一个虚拟地址，MMU翻译出一个物理地址（物理块号）并添加到TLB中，cpu先去内存中查页表，根据查出的物理块号在根据业内偏移量拼出物理内存地址，再去对应的物理内存访问真实数据
	
	页表管理着页号对应的物理块号的映射

#### 虚拟内存
	虚拟内存管理让每个进程认为自己独占了整个地址空间，其实这个地址空间是主存和磁盘地址空间的抽象，目的是逻辑上扩充内存容量，逻辑容量等于主存容量与磁盘容量之和。同时，让每个进程拥有一致的虚拟内存空间简化了内存的管理，不同进程的同一个虚拟地址可以被内存管理单元（MMU）映射到同一个物理地址上。而且保证了进程之间不会被互相干扰，无需考虑内存冲突的问题。
	
	如何实现的：
	虚拟存储器中，进程的内存映射是推迟到运行时，
	
	缺页中断细节：首先什么是缺页中断？分页系统中，通过查询页表发现页面没有驻留内存，则触发缺页中断，引起OS将页面调入内存的行为。
	官方点：虚拟地址没有和物理地址产生映射关系时，通知OS调入缺失页面的信号
	当程序进行地址映射时，MMU查询页表发现页表项存在位为0，则发出缺页中断。CPU响应中断信号，保存上下文后转入执行进程内核态。分析中断原因后转入具体的中断处理程序。如果内存中没有足够的物理块，则根据页面置换程序选出某个页面，如果页表项的修改为1，则将页面刷新到外存，并将物理块释放。当有足够的内存资源时，则启动磁盘IO，根据目标页面的页表项查出页面所在的外存地址，将副本调入内存。IO完成后，操作系统修改页表项存在位为1，并且写入物理块号。还需要刷新TLB（全刷新还是局部刷新看具体OS实现）。恢复上下文，重新执行引起缺页中断的命令（会再次查询页表）。（快表刷新了，没有命中，再次查询页表）
	系统抖动是频繁缺页中断的表现，如果抛开操作系统层面，服务器抖动通常是由于**内存不够用，（运行的程序）进程（线程）太多**。过多的缺页导致很多进程等待磁盘IO将页面调入的内存而主动放弃CPU，CPU利用率很低。可以考虑主动暂停一部分进程的运行（暂时从内存中取得一些进程）或者限制进程的创建


### IO多路复用

#### select和poll
	select 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。
	所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。
	
#### epoll
	epoll优化了数据从用户到内核再由内核到用户反复拷贝的问题，具体方案：在内存开辟一块名为epoll的空间，存储需要拷贝的数据 epoll没有文件描述符的限制
	第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删查一般时间复杂度是 O(logn)，通过对这棵黑红树进行操作，这样就不需要像 select/poll 每次操作时都传入整个 socket 集合，只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。
	第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。

##### 为何支持百万并发
	-   不用重复传递事件集合
	-   epoll初始化时，内核开辟了epoll缓冲区，缓冲区内事件以epitem结点挂载到红黑树上，通过epoll_ctl的任何操作都是O(logN)
	-   epoll_wait调用仅需观察rdlist是否为空，若非空则拷贝rdlist到用户空间并返回触发事件数量，无需遍历
	-   向内核中断处理注册回调，一旦关心的事件触发，回调自动将socket对应的epitem添加到rdlist中

-   ET边沿触发：无论事件是否处理完毕，仅触发一次
-   LT水平触发：只要事件没有处理完毕，每一次epoll_wait都触发该事件

## 计算机网络
#### 一次完整的请求响应
	地址栏一敲，浏览器需要对输入进行检查，生成一个正确的URL，那这个时候可能有两个工作还没做，一个是域名解析，另一个是传输层建立连接
	先走域名解析流程，两支线，一个拿到ip，一个拿到CNAME。
	域名解析完成后，操作系统和服务器端点3次握手建立连接，连接完成后又分为两个支线，一个是浏览器构造一个请求报文就可以委托OS发出去，另一个是基于HTTPS协议还得再进行安全层的握手
	数据成功发出后，服务器进程收到浏览器的请求，一般浏览器会为每个客户单独分配一个线程，并将请求包装成request对象，服务器根据用户的请求从服务器路径中找到可以处理服务请求的处理器，并将处理得到的结果封装为一个reponse对象返回。最终服务器返回的结果会基于http响应的形式达到客户端，浏览器拿到响应报文后，解析响应头，渲染响应体

### 传输层
	传输层为应用提供端到端的数据传输服务，使得应用层不用关心数据传输的细节，只需要关心对数据内容的封装。另一方面，传输层不关心运输层报文的路由，这由下面的网络层负责，在传输层开来，两端的数据传输就好像在同一台主机进行的一样。
	而TCP和UDP只是具体规定了：报文格式是什么，报文丢了怎么办，传输出错等传输细节问题，他们本身也是对数据传输这个概念作进一步的规范，本身也还是协议
	
	横向比较TCP和UDP:
		TCP是面向连接，提供可靠传输服务的传输层协议，而UDP是面向无连接，不提供可靠传输的传输层协议
		TCP将应用层的数据包看作是有序，无结构的字节流，并且保证这些字节流有序，不丢失，不重复，不出错的到达对端，而UDP是面向数据报的，他对上层传递的数据包既保留边界，也不拆分和合并，加上控制首部就直接发出去
		TCP报文基于5元组分用，而UDP基于3元组分用
		TCP报文大小由TCP协议决定，通常体现在流量控制和拥塞控制上，受确认报文窗口值和网络拥塞情况影响，不会超过mss大小，一般不会在IP层分片，而UDP则不提供拥塞控制和流量控制，UDP报文的数据部分通常由用户决定，一般会在IP层分片
		
		mtu是网络传输最大报文包，mss是网络传输数据最大值

#### 为什么TCP可靠 和 UDP为什么不可靠
	TCP有3次握手确人双方具备正常的收发能力，4次挥手关闭连接的机制，此外还有流量控制和拥塞控制算法，最关键的是保留重传机制来确保tcp报文交予对方。对于每份报文也存在校验，保证报文的可靠性。从报文大小方面来看，一般在传输层分片而不会在ip层分配，避免一个ip报文丢失使得整个传输层报文作废
	而UDP是面向数据包无连接的，数据包发出去，就不保留数据备份，仅加个控制首部就交由网络层，一般会在网络层分片，若某段报文丢失则整个报文就失效了
	
	那啥是可靠传输：
	
	
	
	流量控制：传输层面的流量
	

### HTTP
#### HTTP演变
	1.0是短链接：每次请求都要进行一次tcp三握四挥
	1.1变为流水线式长连接：多个请求可以在未收到前一个请求的响应前就发出去，串行复用同一个tcp连接，但应用层存在队头阻塞问题。问题就是头部信息不压缩，占用额外带宽传输效率低，无法定义优先级，服务器只能进行响应
	2.0支持头部压缩，客户端和服务端同时维护一张头信息表，使用索引代替字段，传输效率提升；不再使用文本格式，使用二进制格式避免转换的开销。多个请求可非串行复用同一个tcp连接，使得并发的处理多个请求成为现实，具体是，每个请求/响应的所有数据包称为一个数据流，每个数据流都拥有独一无二的标记。服务器还可以主动向客户端发送消息，减少延时的等待。还支持指定数据流的优先级
	3.0 2.0多条数据流复用同一个tcp连接，在tcp看来就是普通的数据流，一旦丢包就会发生重传机制，这样所有的HTTP请求都必须等待丢失的包被重传。为了解决这个问题，HTTP3将传输层协议更换为UDP，因为UDP不关系顺序和丢包，因此解决了队头阻塞问题。为了保证可靠性，使用了基于QUIC协议，当某个数据发送丢包时，阻塞这个流而不影响其他流。QUIC实际上相当于：支持可靠传输UDP + TLS + HTTP2/的多路复用协议

#### HTTP细节
	请求报文，响应报文，头部字段，响应码
	
	
	头部字段：
	host：服务器域名
	accept-encoding，content-Encoding：什么压缩格式
	contentType：指示资源所属类型
	connect：close和keep—alive短长连接
	
	响应码：200 OK  301 永久重定向 302 临时重定向 404 资源未找到 500 内部错误 502 代理服务器收到源服务器无效响应

#### Cookie，Session，Token
	cookie：HTTP的请求头，在request中是cookie，response中是set-Cookie
	当客户端（浏览器）访问某个服务器时，服务器根据已保存cookie的domain和path决定捎带哪些cookie信息，传送给服务器。而服务器拿到cookie集合一般会遍历这个每一个cookie，并且找到感兴趣的cookie进行身份验证——可以看作是上下文加载。而如果没有找到感兴趣的cookie，则大概有两种可能：这是个新的用户，或者用户的cookie被清除或已经过期了。那么就在response中addCookie，浏览器收到后保存这个cookie
	cookie的属性项除了最常见的 name/value，还有过期时间expires和最长存活时间max-age。如果不指定这两个，那会话结束就会被销毁，浏览器不会将其持久化到本地
	cookie可以看作是token，也可以是指针，这指针可以指向session
	
	会话信息存在cookie中和存在session中，从资源利用看，cookie存放会话信息造成大量带宽浪费，而且直接将会话信息存放在报文中，不安全，而且由于cookie是存放在客户端，服务器就失去了对会话信息的控制权，为了防止不安全的cookie，服务端必然要进行某种检查，校验机制（数字签名，时间戳等，基本就是token的思想）
	另一方面，不可能将所有的会话信息保存在服务端，因为服务器内存有限，如果服务器是分布式部署的，那么session对象可能无法及时同步，导致一个持有sessionId的用户总是无法正常自动登录
	
	cookie放什么？一些指针信息（如sessionId）、一些视频小网站没有登录业务但是也要保存用户的浏览记录，那么观看历史记录、搜索历史记录都可以保存到cookie中（可能就是一个名字，也可能是一条记录的id）、自定义设置（背景图片、个性栏等）、一些不重要的临时信息（例如浏览器型号、手机型号）。  
	还可以实现一些小功能如拿到用户上一次访问时间、统计用户访问总数、拿到用户上一次登录的ip地址等等。（说白了就是读取上下文相关的功能）
	至于token，它可以保存到URL传递，也可以保存到cookie或其他的头部，它是一个字符串，看作一个凭证，通常由用户标识符+时间戳+签名组成，服务器使用私钥对它签名并且保存在客户端，当客户端回传token时，服务器再次计算签名，如果没错则视为当前用户通过验证并放行，对于要求状态的页面，浏览器总是需要携带这个服务器签发的token。一般将基于token的验证看作无状态的，服务器不记录哪些用户已经登录，它的唯一职责就是**签发token**以及**验证token**，每个token都是独立的。  
	token更适合用于权限管理的系统，如：一个网站的业务就是普通用户看普通内容，VIP看普通内容+VIP内容，那么服务器唯一要做的就是拦截普通用户和为氪金用户签发token，这里面不需要太多上下文信息去保存，只需要做好访问控制即可。（session也能做，但是如果业务就是单纯访问控制，还是token做比较好：服务器压力小、逻辑简单、安全性高一些…）
	一般说HTTP实现有状态（保存和用户会话的上下文）**的具体方案，无非就是cookie+session或者cookie+token和cookie+session+token，当然取决于程序员如何使用cookie这个工具去实现会话状态。

## redis

#### 个人理解
	先从写代码时这个角度看redis，它是一个具有多种数据结构集合的类库；角度再往上升，它这个集合类库可以单独抽离出来，成为单个应用，或者说是进程，同时方便可水平扩展，基于该特性，它活跃的场景应该是分布式场景，多个程序需要共享某些数据，就可以从该数据中提取。接着角度再往上升，就涉及到redis的特性，其高可用特性，请求处理快，数据可持久化，服务可靠。
#### 内存淘汰策略
	8种：1种不淘汰 7种淘汰 4种在设置了过期时间的数据中进行淘汰，3种在所有数据范围内进行淘汰

#### 缓存污染
	先给出定义：访问次数非常少的数据占用着内存资源
	如何解决：那得靠内存淘汰策略了，选啥内存淘汰策略得看场景：
	
	若是明确知道数据随后再次被访问的情况，ttl可以有效避免缓存污染
	
	LRU:单个维度：数据访问的时效性，扫描式单词查询会造成缓存污染，但好处就是保留最近访问的数据
	
	LRU关注时效性，而LFU关注访问频次
	
	LFU：从两个维度：数据访问的时效性，数据的被访问次数。淘汰掉访问次数最低的数据。相同再淘汰访问时效性。数据被读取到缓存中，计数值为5，防止刚被写入缓存就被淘汰

#### 过期建删除策略
	惰性删除，定期删除

#### 数据结构
##### SDS
	主要成员：一个是字符串长度，一个char[]数组，一个字符数组中未使用的字节数，还有一个flags，用来表示不同类型的 SDS，节省内存

##### 字典
	两个哈希表，渐进式rehash

##### 跳表
	多层有序链表，链表的每个节点除了第一个节点外，都存储着层，前进指针，后退指针，成员值，分值，其中第一个节点有32层，不存储分值和成员值。其他节点随机在1到32层之间生成层数，层与层之间使用前进指针连接。这个链表封装在一个结构体中，这个结构体成员变量有：指向头部节点的指针，指向尾部节点的指针，存储节点数量的变量，存储节点中的最高层数。
	寻找节点的过程：从头节点开始的最高层开始遍历，根据前进指针向前寻找，如果前一个元素大于或等于待查找的元素或者遇到尾节点，则下移层次继续寻找；如果下一个元素不大于待查找的元素，则前进指针继续向前寻找，继续比较，直到在第一层遇到前一个节点的值大于当前待查找的值，在这个位置生成一个带随机层数的节点，然后插入值

##### 整数集合
	不会出现重复元素，是redis用于保存整数值的集合抽象数据结构，可以保存16，32，64位的整数值


##### 压缩列表
	当一个列表只包含少量列表项，并且都是小的整数值和短字符串，那么它便适合使用压缩列表进行实现，因此其特点是节省内存，减少内存碎片的产生
	组成：整个列表占用的字节数，表尾节点到起始地点的偏移量，节点数量，各个节点，用于标识末尾的标志符号
	节点组成：前一个节点的长度，节点编码，节点值
	若前一个节点小于254，则prelen为1字节，否则5字节


#### 数据类型
	字符串对象：int，embstr，row(sds)
	列表对象：quicklist（多个ziplist通过前后节点的指针连接起来）
	哈希对象：ziplist或dict
	集合对象：intset或dict
	有序集合对象：ziplist，skiplist&dict(O1获取成员的分值，Olongn进行范围排序操作)


#### 事务
	怎么开始事务？
	multi命令，然后声明多条操作指令，提交exec命令。
	
	redis中的事务看起来更像是打包命令的执行
	其原子性需要两个角度看： 如果代码出现语法问题如使用了不存在的命令，那么事务中的所有命令都不会执行；如果运行时出现错误比如命令和操作的数据类型不匹配，那么出错的指令不会影响其他的指令的执行
	
	还有 watch和unwatch指令，在exec执行时，如果至少一个被监视的键值被修改，那么服务器就会拒绝执行队列中的命令
	
	ACID思考：原子性看作残破的，隔离级别由于单线程所以没有，持久性看开不开AOF，因为RDB只和时间事件有关，只有在AOF模式下，才可以保障持久性；由于前面3种的欠缺，一致性也是没有
	
	使用redis事务其实Lua脚本更优，因为可以写逻辑关系运算if/else，不过该方式也是不能支持回滚，得自己写补偿代码）
	Lua脚本的好处：
	1.相对于redis事务，减少请求的带宽
	2.原子操作
	3.脚本可以复用



## Java
#### List，Set，Map接口
	set和List都是Collection的子接口，是对集合行为的进一步划分。set规范不重复，不要求有序的集合行为；List则规范允许重复，有序的线性表行为。
	Map接口规范了映射类型应具有的行为，一个键对应一个值，键是唯一的，但值可以不唯一

##### List
	ArrayList：初始容量是10，加载因子0.5，扩容前的数组长度右移一位 + 扩容前的数组长度
	Vector：初始容量为10，加载因子1，扩容为原来的2倍
	
	ArrayList和LinkedList：
	都是List接口的实现类，都具有线性表的行为。其中ArrayList底层是基于数组实现，而LinkedList则是基于双向链表实现
	ArrayList扩容时需要创建新的数组并将原数据拷贝进新数组
	而LinkedList不需要考虑扩容，理论上是无界的
	
	对比：两者最基本的不同就是底层数据结构的不同，增删元素方面（这里只考虑在中间操作）：ArrayList时间复杂度On，而LinkedList为O1，但随机访问方面：ArrayList为O1，Linkedlist为0n，此外ArrayList能利用到局部性原理，而LinkedList不能
	LinkedList不会浪费空间，但每个节点占用空间更大；ArrayList。。。



##### Set
	HashSet：初始容量为16，加载因子0.75，扩容为原来的2倍

##### Map
	HashMap：初始容量16，加载因子0.75；扩容为原来的2倍


### 异常
#### 分类
	两大子类：error和exception
	error：OOM,StackOverflow
	exception：运行时异常和编译期异常
		RuntimeException及其子类都是非受检异常，无论是主动抛出这个异常还是调用了声明该异常的方法都可以不去处理，交由JVM来处理。
		而其他异常都是受检异常，必须进行try-catch处理或者throws向上抛出。常见受检异常包括:IO异常，文件无法找到异常，空指针异常

#### 处理机制
	一个异常的执行顺序：
		1.new出一个异常对象
		2.中止当前正在执行的程序
		3.弹出异常对象的引用
		4.异常处理机制接管被中止的程序
		5.进入异常处理程序的catch代码块继续执行
		
		每个方法调用栈的catch结构可以看到当前栈帧的异常处理器，如果找不到就会栈帧出栈，寻找上一调用级别的异常处理器。最终main方法栈帧出栈后，交给JVM的未捕获异常处理器进行处理。如果没有则执行默认行为：
		1.调用异常对象的printStackTrace方法，打印方法调用栈的异常信息
		2.如果该线程不是主线程，则终止这个线程，其他线程正常运行，如果是主线程，则整个应用程序被终止


### finally
	如果finally和try/catch都有返回语句，那么后者return的内容将会被覆盖点，前者返回之前执行finally的内容
	存在异常丢失情况


### JVM如何判断两个类相同
	1.根据类的全限定名进行判断是否相等
	2.判断类对应的类加载器

### 为什么反射效率低
java反射之所以慢，根本原因是编译器没法对反射相关的代码做优化。
Java 的编译期是一段不确定的操作过程。因为它可能是一个前端编译器（如 Javac）把 \*.java 文件编译成 \*.class 文件的过程；也可能是程序运行期的即时编译器（JIT 编译器，Just In Time Compiler）把字节码文件编译成机器码的过程；还可能是静态提前编译器（AOT 编译器，Ahead Of Time Compiler）直接把 \*.java 文件编译成本地机器码的过程。
其中即时编译器（JIT）在运行期的优化过程对于程序运行来说更重要，Java虚拟机在编译阶段的代码优化就在这里进行，由于反射涉及动态解析的类型，因此无法执行某些Java虚拟机优化。因此，反射操作的性能要比非反射操作慢，因此应该避免在对性能敏感的应用程序中频繁使用Java反射来创建对象。


### 枚举类
	有穷对象集合，枚举类型中的构造器默认私有化，只能添加private修饰或者不添加
	使用枚举方式创建单例的好处：
	1.  避免反射攻击
	2.  避免序列化问题

### 接口和抽象类

### 什么叫同步异步，什么叫阻塞非阻塞
	线程之间的同步：使得各个线程按照可预期的方式去执行

### 值传递和引用传递
	java中的所有参数传递都是值传递，对于基本类型就是字面量，而对于引用类型就是地址值。
	JVM的执行引擎是基于栈的，一旦方法被调用就需要创建一个栈帧，而调用方法的对象会将参数值复制一份（dup指令）压入被调用函数的操作数栈中。也就是说地址值和字面量都会被复制一份传入一个方法中。
	但是地址值指向的是一个堆中对象，它是一个地址。而字面量就是一个纯数值。一旦方法执行结束，栈帧出栈销毁。地址值变量和值变量都作为栈帧的局部变量被释放了，但是地址值指向的对象仍然存活在堆中。
	也就是说，虽然地址值变量是一个局部变量，但是它指向的堆中对象是堆内存共享的，它的内容被永久的改变了。
	总之，解释这个问题的下手点：传递的是什么——地址值和字面量，而且都是拷贝的。使用不同——字面量只能进行值的读写，而地址值可以用于访问堆中对象。改变——传入的字面量和地址值不会改变，该指向谁还指向谁，但是指向的对象被改变了。

### JMM


### 两大规则
	as-if-serial原则：cpu重排序在可以保证程序线性执行结果准确性的前提，对性能进行优化。但在多线程情况下就无法保证了
	happens-before（先行发生）原则：JMM的设计基于一种原则：先保证正确性，再考虑执行效率的问题，happens-before用来指定两个操作之间的执行顺序，这两个操作可以在一个线程之内，也可以在不同线程中，所以这种对操作顺序的关系的界定可以为程序员提供内存可见性的保证，具体happen-before定义如下：
	1.如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，并且第一个操作的执行顺序排在第二个操作之前
	2.两个操作之间存在happends-before关系，并不意味着java平台的具体实现必须按照happens-before关系指定的顺序来执行，比如i = 2，j = 3,虽然存在 happens-before关系，但两条指令之间没有任何影响，可以进行重排序
	而 i = 1， j = i + 1 之间有依赖关系而不会重排序
	落实到具体就是8条规则：程序顺序规则，监视器锁规则，volatile变量规则，传递性，线程start规则，线程中止规则，线程中断规则，对象终结规则

### volatile
	使用volatile的变量对其进行操作时在汇编层面的指令会多出lock前缀，该前缀目的是禁掉MESI缓存一致性提高效率的优化措施，让写存储区和失效队列失效。
	往上一层就是对volatile变量进行读取的时候，会加上读屏障，保证读到的共享变量值是最新的。而对其进行修改时会加上写屏障，保证该共享变量会马上对其他cpu暴露
	读写屏障前面的代码无法排序到后面，同样后面的代码也无法排序到前面


### 同步
	线程以我们可预期的方式执行就是同步


## JUC

#### 为什么Java只有Runnable状态
	操作系统层面，处于running状态的线程如果放弃CPU则进入runnable状态，而java为我们屏蔽了线程切换（CPU调度）的细节，我们只需要知道创建一个线程，然后调用start()方法该线程进入runnable状态即可。如果将runnable拆分为两个状态，那么就相当于打破了操作系统和虚拟机之间的隔离性，违背了jvm设计的初衷，本末倒置了。
	java线程执行的过程中，总是不断的发生CPU调度，但是对于用户是透明的，因为java屏蔽了这一切的细节，对于用户来说，一旦一个线程被start()调用，那么它便是runnable的。

#### 创建线程的方式
Java 线程调用 start->start0 这个本地方法，实际上会调用到 JVM_StartThread 方法，而 JVM_StartThread方法中会创建与平台相关的本地线程，该线程执行 Java 线程的 run 方法。

	先看Thread类的run方法,如果target为空就什么也不做，否则就执行runnable成员的run方法。由此引申出 传入run对象，或者重写Thread的run方法
	
	第三种，实现callable接口的call方法，通过FutureTask获得其返回值或异常。FutureTask间接继承Runnable接口，当启动Thread.start时，就会创建出另一线程调用run方法，而FutureTask的run方法又会去调用Callable实现类的call方法，讲返回值和异常对象保存在成员字段outcome中，在get()中判断outcome的类型，如果是结果就返回，否则抛出异常。
	同一个Callable实例对应的任务只会执行一次，不会执行第二遍。为什么呢？因为每个futureTask实例都有状态，没当一个futureTask被实例化后，状态为NEW，而执行完毕状态就变为normal。只有当futureTask状态为NEW时run方法才会执行

**总结：**
callable/call()计算出结果，而通过futureTask/get()向外暴露/公布结果。futureTask表示一个异步运算的结果，对这个异步运算的任务可以等待获取、判断是否完成以及取消任务

实现接口和继承Thread比较
推荐使用实现runnable接口的方式，因为实现runnable接口本质上是完成“布置任务”的行为，可以减少“线程细节”与“任务”本身的耦合度——线程是载体，任务是主要关注点，**不是让某类线程绑定某个任务，而是产生一个任务后创建一个线程实例去执行**


#### 线程池
	


## JVM
#### 多态
```markdown
首先给出定义，接着使用上区别，再底层上区别，方法调用原理，虚方法表出现的原因

多态分两种：编译期多态和运行时多态，前者是重载，后者是重写

### 什么是重载：同一个实例拥有多个同名方法，根据方法签名的不同，编译期可以唯一确定载入的版本，横向选择

### 什么是重写：存在继承关系的基础上，子类对父类的方法进行重新实现，纵向选择

方法调用的本质就是将符号引用解析为直接引用的过程，直接引用指向方法对应的字节码指令的地址。对于非虚方法，这个过程在类加载的解析阶段完成，而对于虚方法，这个过程在运行时完成

### 什么是非虚方法：不能被重写，编译器可以确定唯一的调用版本。

eg:
1. static方法(invokeStatic)
2. super.XX() 即调用父类方法（invokeSpecial）
3. final修饰的方法（invokeVirtual）
4. private修饰的方法（invokeSpecial）
5. 构造器（invokeSpecial）


### 什么是虚方法：实例方法，特点是可以被重写，这就是为什么重载虽然能在编译期确认某一个方法的重载版本，但并不一定能确认它的调用入口，可能父类重载的方法给子类重写了。

### 使用上区别：
重写一个方法时，**参数列表不能改变**，返回值要么不变，要么是可以兼容的类型（被重写方法返回值的子类、实现类、子接口等“小类型”），异常也同理，不能抛出更宽泛的异常类型，同时也不能做更严格的访问权限。  
重载一个方法时，**参数列表一定要变**，异常、修饰符、返回值不做要求

### 底层上
当一个类被编译后，它的某一个方法的信息将被保存在方法表和常量池中，其中方法的各个参数的符号引用集合将作为特征签名将被保存在常量池中，而返回值不会作为特征签名的成员。因此无法仅仅依靠返回值确认重载版本。


重写是运行时多态的体现，方法调用的本质就是将符号引用转换（解析）为直接引用，直接引用指向方法对应的字节码指令（的地址）。对于非虚方法，这个过程在类加载的解析阶段完成，而对于虚方法，这个过程在运行时完成（即执行引擎真正开始执行该方法调用代码时才进行解析）。
而对重写方法调用的解析，就是将符号引用指向重写方法执行入口的过程，运行时执行动态分派的动作，**取决于变量对应的真实类型**（变量指向的对象类型，而不是变量类型），只有虚方法才会执行动态分派


### 方法调用原理
如果调用一个实例方法（非final），对应的是invokeVirtual指令。
【1】引用入操作数栈，这个引用指向的对象的对象头中具有一个执行真实类型的指针（类型指针）
【2】栈帧中有一个动态连接结构，保存了一个指（向运行时常量池中）当前栈帧所属方法的引用。（虚方法中，此时动态连接指针指向的还是方法的符号引用）
【3】在真实类型（方法表）中寻找是否存在相应的重写方法，如果存在则进行权限认证，通过后则将动态连接的符号引用，指向当前方法的入口（直接引用）
【4】否则按照继承关系向上搜索，如果始终未成功解析，则抛出异常：abstractMethodError

多态在于invokeVirtual的调用，因此非虚方法和字段不会展现“多态”


如果继承的层次比较深，要调用的方法位于比较上层的父类，则调用的效率是比较低的，因为每次调用都要经过很多次查找。这时候大多系统会采用一种称为**虚方法表**的方法来优化调用的效率。


所谓虚方法表，就是在类加载的时候，为每个类创建一个表，这个表包括该类的对象所有动态绑定的方法及其地址，包括父类的方法，但一个方法只有一条记录，子类重写了父类方法后只会保留子类的。当通过对象动态绑定方法的时候，只需要查找这个表就可以了，而不需要挨个查找每个父类。

虚方法表会在类加载的链接阶段被创建并开始初始化，类的变量的初始值准备完成之后，JVM会把该类的方法表也初始化完毕

```
[[JVM#重写与重载]]

## MySQL
### MySQL架构
	MySQL服务器可以分为server层和存储引擎层，其中server包含连接器，查询缓存，分析器，优化器，执行器。而存储引擎最大的特点就是基于表和插件式，可以根据不同的应用建立不同的存储引擎表，MySQL默认使用InnoDB
	一个连接进程和MySQL数据库实例通信本质上就是两个进程在通信
	其中连接层负责将数据库实例与客户端程序建立TCP连接，并且完成一些认证，校验的工作
	服务层完成sql解析，分析，优化，缓存以及所有的内置函数。所有跨存储引擎的功能也都在这一层实现：存储过程，触发器，视图等
	存储引擎负责mySQL中数据的存储和提取，存储引擎是基于表的，而且是以插件的形式存在，可以根据不同的表更换不同的存储引擎（存储引擎就是管理如何操作数据的一种方法，数据最终需要存储在磁盘上）
	存储层主要是将数据存储在运行于裸设备的文件系统之上，并完成与存储引擎的交互，这才是数据真正落地的地方，需要os和硬件的支持（如磁盘）
	每个客户端连接都会在服务器进程中拥有一个线程，每个查询都会在单独的线程中执行，对应一个cpu核心中执行，服务器会负责线程的分配和撤销（线程池），因此不需要为每一个新建的连接创建或者销毁线程

### MySQL执行流程
	1.mysql客户端首先与MySQL服务器经tcp3次握手建立连接后，服务器需要对客户端进行认证，一旦认证成功，服务器还会继续验证该客户端是否具有执行某个特定查询的权限
	2.对于select语句，在解析sql之前，服务器会先检查查询缓存，如果能够在其中找到对应的sql，服务器就会返回查询缓存中的结果集（这部分在MySQL8中被移除，因为一旦进行任何一个更新操作，整个缓存都会被清空）
	3.分析器对查询语句进行扫描，词法分析和语法分析，如果SQL语句有误，那么就会收到 you have an error in your SQL 的错误提示
	之后还会对合法的查询语句进行语义检查，检查语句中的数据库对象如关系名，属性名是否存在。还会对用户的存取权限进行检查
	4.优化器生成执行计划，并且选择合适的索引，为字段选择合适的查询位置，为多表确定正确的连接顺序
	5.根据优化器生成的执行计划，由代码生成器生成执行这个查询计划的代码加以执行并回送查询结果，执行器根据表的引擎定义，去调用相应引擎提供的读取接口，最终得到接口返回的结果

### InnoDB引擎

### 两阶段提交
	prepare阶段：修改事务对应的undo页面，将当前事务状态设置为prepare，当然修改undo页面前要记录下redo日志。修改完后将redo日志刷盘
	commit阶段：将事务执行过程中产生的binlog刷新到硬盘，再执行存储引擎的提交工作
	
	当崩溃恢复时，首先按照已经刷新到磁盘的redo日志修改页面，把系统恢复到崩溃前的状态，然后依照各个undo页面链表查看对应事务的状态，若是active状态，直接按照undo日志回滚。
	若是prepare状态，则是否回滚取决于binlog，若binlog已经在硬盘，就将该事务提交，没有就回滚

### 事务
	什么是事务？原子性，一致性，隔离性，持久性

## MyBatis

### 简述mybatis框架
	持久层框架，底层是对JDBC的封装，基于ORM（对象和关系表的映射）思想对结果集进行了封装
	ORM思想：把数据库表和javaBean对应起来，使得java操作实体类最终映射到对数据库表的操作

### 简述原理

### 两个占位符和SQL注入
	${} 属于静态的文本替换,生成的sql语句会将占位符的内容直接替换为传入的参数(打印日志可以看到完整的语句)
	#{} 会将占位符替换为?. 然后执行sql前使用preparedStatement将?替换为具体的参数,可以防止注入攻击(打印日志时,参数都被?占位)
	#{}是先编译好sql语句再替换，而${}将参数先替换再编译sql语句。  如果使用拼接字符串作为参数，那么#{}将其看作一个单独的参数，相当于是一个无效的参数。  
	总之，**应该使用 #{}**
	
	在使用PreparedStatement执行SQL命令时，命令会带着占位符被数据库进行编译和解析，并放到命令缓冲区。然后，每当执行同一个PreparedStatement语句的时候，由于在缓冲区中可以发现预编译的命令，虽然会被再解析一次，但不会被再次编译。
	而SQL注入只对编译过程有破坏作用，执行阶段只是把输入串作为数据处理，不需要再对SQL语句进行解析，因此解决了注入问题。
	因为SQL语句编译阶段是进行词法分析、语法分析、语义分析等过程的，也就是说编译过程识别了关键字、执行逻辑之类的东西，编译结束了这条SQL语句能干什么就定了。而在编译之后加入注入的部分，就已经没办法改变执行逻辑了，这部分就只能是相当于输入字符串被处理。
	
	背这个：#{}是先编译好sql语句再替换，而${}将参数先替换再编译sql语句
	编译结束了这条SQL语句能干什么就定了。而在编译之后加入注入的部分，就已经没办法改变执行逻辑了，这部分就只能是相当于输入字符串被处理
	SQL注入只对编译过程有破坏作用，执行阶段只是把输入串作为数据处理，不需要再对SQL语句进行编译，因此解决了注入问题
	
	



## JDBC
### 理解JDBC及其流程

### SPI
	SPI:服务提供接口,为某个接口寻找服务的实现
	出现的原因是,spi接口是由bootstrap启动类加载器来进行加载,而spi实现类是由application系统类加载器来加载类.因此在双亲委派模型下,启动类加载器无法委托系统类加载器去加载类
	
	线程上下文类加载器是java对双亲委派模式与实现SPI之间的妥协.Java应用运行的线程的上下文类加载器是系统类加载器,在线程中运行的代码可以通过此类加载器来加载类和资源
	
	总结就是:JDK提供SPI接口,第三方提供实现类,第三方按照约定将以服务接口命名的文件放到META-INF/services/目录下,内容就是实现类的全限定类名列表,按照约定jdk会去扫描jar包中符合约定的类名,然后依次调用forName加载,但由于SPI接口是由启动类加载器加载,该类加载器无法加载第三方类型,因此将这个任务委托给当前执行线程的线程上下文加载器




# 琐碎记录
## 数据结构：
-   给一个场景：有很多图片，然后我们需要对图片进行存储，以及查找，有什么数据结构比较适合？
-   如果我要加速查询的速率，你要怎么设计？


## 架构设计
-   如果一台服务器，然后要对单机进行拓展，你要怎么设计后续的拓展工作？