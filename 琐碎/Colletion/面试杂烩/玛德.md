# 字节
[字节后端日常实习一面_笔经面经_牛客网 (nowcoder.com)](https://www.nowcoder.com/discuss/821404?source_id=profile_create_nctrack&channel=-1)
1. JVM内存区域，垃圾回收过程，怎么查看垃圾回收过程
```markdown
内存区域以线程共享和独占来入手

垃圾回收过程以垃圾回收算法入手,再介绍CMS垃圾回收过程

查看垃圾回收算法:java  -XX:+PrintCommandLineFlags  -version, 最后一个 -XX:+UseParallelGC 新生代使用ParallerGC，老年代使用Serial Old
```

2. 线程池参数，拒绝策略，工作流程
```markdown


```


3. 线程同步方法，创建线程方法，Runable和Callable区别

```markdown
同步方法:(得补补)
1.synchronized
2.volatile
3.ThreadLocal


创建线程方法:
1.继承Thread类
2.实现Runnable接口
3.实现Callable接口,通过Future拿到返回值

区别:
从使用角度来看: 后者能返回值,前者不能
从构造角度来看: Runnable方法的执行可以看做是Thread来执行的,而Callable的call方法的执行是FutureTask来执行的,中间加了一层,使得我们能通过一系列方法改进原本run方法不能返回值的问题
```

4. volatile作用
```markdown
从java关键字使用的层面看,volatile关键字保证了内存可见性,这点synchronized也同样具备

从JMM层面看, java内存模型是共享内存模型,对变量的处理都是对工作内存中的变量进行处理,若变量不在工作内存,则去主内存读取.这使得一个变量可能存在多个线程的工作内存中,volatile就是使得一个线程对该变量的修改可以使得其他线程工作内存中该变量的副本失效,若需要读取该变量就只能重新去主内存读取

再往下看,volatile做了什么操作来实现这个功能:答案就是volatile,volatile修饰的变量赋值后汇编层面的指令加上了lock前缀,使得其他处理器若存在该变量则对应的block失效.

再往下看,MESI缓存一致性协议如果严格执行的话缓存一致性是没问题的,但效率太低了,每次修改变量时总得通知其他cpu当前要对某个变量修改,然后等待其他cpu回应ack,这期间要修改的cpu是空闲的,而其他cpu得判断自己高速缓存是否存在该变量,有就将该block失效,再返回ack.为了提高效率映入了写存储区和失效队列.这就导致了一个线程对一个变量的修改结果其他线程并不能马上看到,出现线程安全问题
```


5. MySQL索引结构，联合索引，隔离级别(RC和RR区别），mvcc原理
```markdown

MySQL索引分为聚合索引和非聚合索引,



隔离级别: 1.读未提交 2.读已提交 3.可重复读 4.串行化

RC 和 RR 的区别就是 关于读视图是每一次 select 生成 还是 第一次select 生成

对于快照读 都是 用 MVCC + undo log 链来完成
对于当前读, RC 用 行锁 , RR使用 next-key lock

MVCC原理就是每一次select 创建一个读视图
```

6. Redis 基本数据结构，怎么存储对象
```markdown
基本数据结构:
	1.SDS
	2.字典
	3.压缩列表
	4.quickList
	5.skipList


```


7. Spring IOC 和 AOP


8. LRU





```MARKDOWN

字节大数据基础架构部门的实习生

字节面经 一面 2.17 
1. 自我介绍
2. 接口和抽象类的区别
3. 了解过啥设计模式
4. 单例模式是啥
5. 工厂模式的作用，为什么要用工厂模式？
	解耦, 把对象的创建和使用的过程分开(就是Class A 想调用Class B,那么只是调用B的方法，而至于B的实例化，就交给工厂类)
6. 建造者模式的实现方式
7. 在设计模式中你使用抽象类还是接口比较多
8. 了解哪些Java锁
9. 死锁的必要条件
10. Mysql索引了解吗(那时候不会就直接说不会了)
11. MySql事务隔离级别
12. 说一下你用过的Java框架
	(说了Spring 的 ioc/aop 还没说aop就下一问了)
13. 项目中如何使用git和maven的
代码题:
 	1. 写一个快排
 	 	1. 快排是否稳定
 	 	2. 什么情况下会退化
 	 	3. 如何优化
 	 	4. 时间复杂度
 	2. 写一个二分查找
 	 	1. 复杂度
代码题写的太快了, 然后他说时间还没到在问几个问题
14. 了解分布式吗(NO)
15. 说一下Java基础类型
16. 为什么int是2的31次方
17. 了解Docker吗(NO)
13. 什么是Java同步和异步

反问:
	1. 部门的业务
	2. 对我的评价
	
字节跳动二面 2.18
1. 进程之间的通信
 1. 管道通信
 2. 命名管道通信
 3. 消息队列
 4. 共享内存
 5. 信号量
 6. 套接字
 7. 信号
 3. 说一下你了解的锁
2. 说一下synchronized 和 reentranlock
3. 介绍一下Reentrantlock
4. 单例模式中变量前加的关键字(volatile)
5. 单例模式并发下实现方式
 1. 双重检查锁(DCL)
 2. 内部类
 3. 枚举类
6. volatile的作用是什么
 1. 防止 JVM 的指令重排 ，还有一个重要的作用就是保证变量的可见性
 2. 会主动刷新存储 
7. 聚集索引和非聚集索引的区别
  1.聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。**
  2.非聚集索引即索引结构和数据分开存放的索引。二级索引属于非聚集索引**
8. mysql三大范式说一个你了解的
9. mysql的ACID是什么
10. Maven包冲突怎么解决
11. 介绍一下HashMap
12. HashMap扩容了解吗?说一下扩容因子(loadFactor)
13. 红黑树的特点, 为啥红黑树比较二叉树快
  - 每条路上黑节点的数量是固定的, 高度限制搜索快
  - 红黑树特点 :
   1. 每个节点非红即黑；
   2. 根节点总是黑色的；
   3. 每个叶子节点都是黑色的空节点（NIL节点）；
   4. 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）；
   5. 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。
14. Redis为什么快?
	直接操作内存 单线程没有多线程创建销毁的开销 IO多路复用
15. Redis缓存机制(我觉得应该是处理流程)
算法题:
	LeetCode 25 困难
	K个一组反转链表改版(最后n个不足也反转)
	
字节面经 三面Leader面 - 2.21(挂)

1. Object类里有什么方法
2. 有用过Object类中相关锁的方法吗
  1. wait
  2. notify
  3. notifyAll
3. Java垃圾回收的方法新生代和老年代的不同的算法
4. 设计模式中有用到锁的模式
5. 如果没有使用两个锁单例会有什么问题
6. MySQL使用还是对他的原理有什么了解
7. 使用JavaEE开发过一些项目吗
8. 在开发项目中有什么问题吗, 然后最后解决了的
算法题:
LeetCode 101简单
​	1. 对称二叉树
还是题刷的不够多,没写到这题也没多写二叉树,我居然用BFS写的
```



https://www.nowcoder.com/discuss/840270





## 操作系统
#### 产生死锁的条件
	互斥，占有并保持，不可剥夺，循环等待
#### 进程通信
	管道：匿名管道（半双工），有名管道
	信号量
	信号
	消息队列
	内存映射
	套接字

#### 线程通信
	线程间的通信目的主要是用于线程同步。所以线程没有像进程通信中的用于数据交换的通信机制。
	锁机制，信号量机制，信号机制
#### 进程同步
	进程同步的基础是通信，从通信中找到能设置状态变化并且其他进程能感知到。只要都共享的读取某个东西，就可以通过修改这个东西的状态实现同步。临界区，信号量，事件对象
	临界区，信号量，事件对象


### 虚拟内存管理
#### 页面调度算法
	先进先出，最佳置换，最近最久未使用，Clock，改进Clock

#### 分段和分页
```markdown
离散内存分配是实现虚拟内存的基础。对内存进行分页和分段，目的都是为了更好的利用内存资源。分页服务于操作系统，为了更好的管理内存回收与分配；分段服务于用户，为了更好的根据开发逻辑关系使用内存,分段更易实现信息共享和保护，因为一个共享代码区可以涉及多个页面，分页实现相对困难。
分段是一种连续内存分配策略，不存在缺页中断；而分页是将进程逻辑地址空间分为若干大小相等的页面，将物理地址空间分为若干大小相等的物理块，物理块大小等于页面大小，当程序执行时将用到的页面映射到物理块上，实现内存的离散分配
	
一次查询流程：①CPU给出逻辑地址，由MMU算得页号、页内偏移量，将页号与快表中的所有页号进行比较。

②如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若快表命中，则访问某个逻辑地址仅需一次访存即可。

③如果没有找到匹配的页号，则需要访问内存中的页表，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此,若快表未命中，则访问某个逻辑地址需要两次访存(注意:在找到页表项后，应同时将其存入快表,以便后面可能的再次访问。但若快表已满，则必须按照-定的算法对旧的页表项进行替换)
	
页表管理着页号对应的物理块号的映射

联想到redis的写时复制机制,共享数据页

```

#### 虚拟内存
```markdown
虚拟内存管理让每个进程认为自己独占了整个地址空间，其实这个地址空间是主存和磁盘地址空间的抽象，目的是逻辑上扩充内存容量，逻辑容量等于主存容量与磁盘容量之和。同时，让每个进程拥有一致的虚拟内存空间简化了内存的管理，不同进程的同一个虚拟地址可以被内存管理单元（MMU）映射到同一个物理地址上。而且保证了进程之间不会被互相干扰，无需考虑内存冲突的问题。
	
	如何实现的：
	虚拟存储器中，进程的内存映射是推迟到运行时的，也就是说，一个程序三行代码，只有第一行代码经过地址映射了，执行到第二行时就执行不到了。CPU拿到虚拟地址，然后委托MMU芯片进行地址转换，当MMU查询页表时发现 **存在位是false**，页面没有驻留内存，这时会发出缺页中断（缺页异常 page fault），CPU陷入内核转去处理中断，最终缺页从外存调入内存。物理块不够用则会执行页面置换策略，将低优先级页面换出内存，并将物理块与目标页面进行映射（其实就是修改页表）
	
	缺页中断细节：首先什么是缺页中断？分页系统中，通过查询页表发现页面没有驻留内存，则触发缺页中断，引起OS将页面调入内存的行为。
	官方点：虚拟地址没有和物理地址产生映射关系时，通知OS调入缺失页面的信号
	当程序进行地址映射时，MMU查询页表发现页表项存在位为0，则发出缺页中断。CPU响应中断信号，保存上下文后转入执行进程内核态。分析中断原因后转入具体的中断处理程序。如果内存中没有足够的物理块，则根据页面置换策略选出某个页面，如果页表项的修改为1，则将页面刷新到外存，并将物理块释放。当有足够的内存资源时，则启动磁盘IO，根据目标页面的页表项查出页面所在的外存地址，将副本调入内存。IO完成后，操作系统修改页表项存在位为1，并且写入物理块号。还需要刷新TLB（全刷新还是局部刷新看具体OS实现）。恢复上下文，重新执行引起缺页中断的命令（会再次查询页表）。（快表刷新了，没有命中，再次查询页表）
	系统抖动是频繁缺页中断的表现，如果抛开操作系统层面，服务器抖动通常是由于**内存不够用，（运行的程序）进程（线程）太多**。过多的缺页导致很多进程等待磁盘IO将页面调入的内存而主动放弃CPU，CPU利用率很低。可以考虑主动暂停一部分进程的运行（暂时从内存中取得一些进程）或者限制进程的创建
```


### IO多路复用

#### select和poll
	select 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。
	所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。
	
#### epoll
	epoll优化了数据从用户到内核再由内核到用户反复拷贝的问题，具体方案：在内存开辟一块名为epoll的空间，存储需要拷贝的数据 epoll没有文件描述符的限制
	第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述符，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删查一般时间复杂度是 O(logn)，通过对这棵黑红树进行操作，这样就不需要像 select/poll 每次操作时都传入整个 socket 集合，只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。
	第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。

##### 为何支持百万并发
	-   不用重复传递事件集合
	-   epoll初始化时，内核开辟了epoll缓冲区，缓冲区内事件以epitem结点挂载到红黑树上，通过epoll_ctl的任何操作都是O(logN)
	-   epoll_wait调用仅需观察rdlist是否为空，若非空则拷贝rdlist到用户空间并返回触发事件数量，无需遍历
	-   向内核中断处理注册回调，一旦关心的事件触发，回调自动将socket对应的epitem添加到rdlist中

-   ET边沿触发：无论事件是否处理完毕，仅触发一次
-   LT水平触发：只要事件没有处理完毕，每一次epoll_wait都触发该事件

## 计算机网络

### OSI七层模型
物理层：实现相邻计算机节点比特流的透明传输，尽可能屏蔽掉传输介质和物理设备的差异

数据链路层：管理相邻节点直接的数据通信，将网络层传递下来的ip数据报封装成帧，在两个相邻节点之间的链路上传送，通过MAC地址来找到下一个节点

网络层：网络层的任务就是选择合适的网间路由和交换结点，确保数据及时传送到对方的计算机。 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称数据报。

传输层：负责向两台主机进程之间的通信提供通用的数据传输服务。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务

会话层：建立，维护，重连应用程序之间的会话
表示层：数据处理，如数据编解码，加密解密，压缩解压缩

应用层：定义的是应用进程间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议，如域名系统DNS，支持万维网应用的 HTTP协议，支持电子邮件的 SMTP协议等等。我们把应用层交互的数据单元称为报文。 我们寄快递的时候，只需要把包裹交给快递员，由他负责运输快递，我们不需要关心快速是如何被运输的。


### 为什么既要IP地址又要MAC地址

IP地址决定了网络中数据包如何通过路由器的转发到达目的地，而MAC地址则唯一标识了接受这个数据包的主机。或者换种说法，IP是快递地址，MAC是收件人

### 应用层
#### 一次完整的请求响应
	地址栏一敲，浏览器需要对输入进行检查，生成一个正确的URL，那这个时候可能有两个工作还没做，一个是域名解析，另一个是传输层建立连接
	先走域名解析流程，两支线，一个拿到ip，一个拿到CNAME。
	域名解析完成后，操作系统和服务器端点3次握手建立连接，连接完成后又分为两个支线，一个是浏览器构造一个请求报文就可以委托OS发出去，另一个是基于HTTPS协议还得再进行安全层的握手
	数据成功发出后，服务器进程收到浏览器的请求，一般浏览器会为每个客户单独分配一个线程，并将请求包装成request对象，服务器根据用户的请求从服务器路径中找到可以处理服务请求的处理器，并将处理得到的结果封装为一个reponse对象返回。最终服务器返回的结果会基于http响应的形式达到客户端，浏览器拿到响应报文后，解析响应头，渲染响应体

### 传输层
传输层为应用提供端到端的数据传输服务，使得应用层不用关心数据传输的细节，只需要关心对数据内容的封装。另一方面，传输层不关心运输层报文的路由，这由下面的网络层负责，在传输层开来，两端的数据传输就好像在同一台主机进行的一样。
而TCP和UDP只是具体规定了：报文格式是什么，报文丢了怎么办，传输出错等传输细节问题，他们本身也是对数据传输这个概念作进一步的规范，本身也还是协议



#### 横向比较TCP和UDP:
TCP是面向连接，提供可靠传输服务的传输层协议，而UDP是面向无连接，不提供可靠传输,通过校验和尽最大努力交付报文的传输层协议
TCP将应用层的数据包看作是有序，无结构的字节流，并且保证这些字节流有序，不丢失，不重复，不出错的到达对端，而UDP是面向数据报的，他对上层传递的数据包既保留边界，也不拆分和合并，加上控制首部就直接发出去
TCP报文基于5元组分用，而UDP基于3元组分用
TCP报文大小由TCP协议决定，通常体现在流量控制和拥塞控制上，受确认报文窗口值和网络拥塞情况影响，不会超过mss大小，一般不会在IP层分片，而UDP则不提供拥塞控制和流量控制，UDP报文的数据部分通常由用户决定，一般会在IP层分片
TCP仅支持单播，而UDP支持单播、多播和组播。

UDP如何进行一对多、多对多
发送方可以使用单播或多播地址作为目标ip地址，同时允许接收方对一台或多台发送方主机开放，实现对应效果
mtu是网络传输最大报文包，mss是网络传输数据最大值


#### 如何理解面向连接和无连接
面向连接就是双方在数据传输前都要确认对方的数据收发能力,并为该通信分配系统资源,数据传输具有可靠性特点

无连接就是数据一旦发出,不需要做备份,也不需要接收方做响应,特点是可靠性低,不能防止丢失的报文,重复或失序.通信迅速,灵活

[[计算机网络#传输层]]

#### 为什么TCP可靠 和 UDP为什么不可靠

%%TCP的可靠主要体现在几方面：有序（序号和确认机制）、不丢失（序号是基础，其次是重传机制）、无差错（校验和）、不重复（确认机制，不接收已确认序号的报文中的数据）%%


%%TCP有3次握手确人双方具备正常的收发能力，此外还有流量控制和拥塞控制算法，最关键的是保留重传机制来确保tcp报文交予对方。对于每份报文也存在校验，保证报文的可靠性。从报文大小方面来看，一般在传输层分片而不会在ip层分配，避免一个ip报文丢失使得整个传输层报文作废%%

1. TCP有3次握手确认双方具备正常的收发能力
2. 保留重传机制确保tcp报文交于对方，确认机制保证不接受重复的报文
3. 对每份报文存在着校验,保证报文的可靠性
4. 从报文大小方面来看，一般在传输层分片而不会在ip层分配，避免一个ip报文丢失使得整个传输层报文作废

而UDP是面向数据包无连接的，数据包发出去，就不保留数据备份，仅加个控制首部就交由网络层，若报文过长则会导致网络层对其分片，若某段报文丢失则整个报文就失效了


可靠传输？这里的可靠没有加任何限定词，那么请自问一下：绝对的可靠，或者说理想的可靠传输是一个怎么样的传输过程？一句话：字节流从一端发出，一模一样的到达另一端。
再拆解一下，从两端发出去的肯定不能是一条长字节，字节组合为分组，分组加上控制首部作为报文段。绝对的可靠：报文有序到达、报文无差错、报文不重复、报文不丢失

我们不是神，只能尽量让报文传输达到“可靠”。
1. 报文有序到达可能保证（ARQ），但是吞吐量太低了。我们可以退一步，不要求传输过程的有序，只要求有序的接收——序号机制+累加确认
2. 我们无法做到传输过程中无差错，但是我们让接收方主动丢弃出错的包，然后发送方重传出错报文，就可以达到“接收无差错”——校验和+重传机制
3. 同理，对于不重复、我们无法做到传输的过程不产生重复的包，但是我们可以保证不接收重复的包——序号机制
4. 我们无法保证过程中不丢包，但是我们通过超时重传或者冗余ACK让发送方感知丢包事件，从而触发重传行为，另一方面，通过滑动窗口机制保证如果发送方已发送的包未被确认就不能向右滑动，必须保存包的副本。——超时/快 重传机制 + 滑动窗口的滑动策略

我们通过先分析绝对的可靠传输是什么样的，然后提出具体的TCP实现策略对其相对的实现，来展示我们对可靠传输的思考。如果可以具体结合例子具体解释那么就更好了。如果可以的话， 可还有举例ARQ/GBN/SR是如何实现可靠传输的。





#### 滑动窗口，流量控制，拥塞控制

##### 滑动窗口
滑动窗口是传输层进行流量控制的一种措施，接收方通过通告发送方自己的窗口大小，从而控制发送方的发送速度，防止发送方发送速度过快而导致自己被淹没。


为什么会有窗口的概念，因为TCP不允许发送方一次发送太多数据，这个“窗口”的概念，在TCP中通过“窗口字段”来表示。**从这个角度看，滑动窗口协议像是用来控制发送流量的。**
滑动？什么时候滑动？TCP滑动窗口协议中把窗口具体分为发送方窗口和接收方窗口，发送方窗口中又可以分为已发送但未确认和未发送的数据（字节），接收方窗口表示可以接收但是未达到的数据。一旦数据全部发送完毕，那么发送方必须等待接收方的确认报文。而一旦发送方报文到达接收方，接收方将接收报文中的数据，存入接收缓冲区并给出确认，此时接收方的接收窗口左边界右移。而当发送方接收到接收方的确认报文，他将释放相应的缓冲区，同时发送窗口左边界右移。 **从这个角度来看，滑动窗口协议有具有一定可靠传输的意义。（保存未确认分组不滑动，是为了进行重传）**


[对TCP ，GBN，SR的一点理解总结 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/126312611)
**停止等待ARQ**
基于超时重传、一单位窗口、一应一答模式的，也称为停等协议，每个报文都有序列号，确认号只需要0和1，提供校验和。ARQ可以实现可靠传输，但是吞吐量太小了。

**连续ARQ**

GBN(回退N帧）和SR（选择重传）则是基于多单位窗口的，流水线式发送报文，累加确认序号，其中确认号为期待对方下一个报文段的第一个数据字节的序号。其中GBN不保存失序分组，则SR保存，同时GBN总是重传整个发送窗口的分组，而SR只选择重传某个缺失分组。
TCP的重传可以按照GBN实现，也可以按照SR实现，TCP是可以保存无序分组的。如果TCP在建立连接时声明了SACK选项（任意一方），则基于SR的重传机制。
同时TCP具有流量控制和拥塞控制的功能，它的滑动窗口不是固定的，而是可变的，TCP发送方窗口的右边界滑动方向和大小取决于接收方报文的窗口值字段。

##### 流量控制
流量控制：这里的流量指的是传输层层面的流量，接收方以某种方式通告对端，调整发送速率（要求对端发送速率慢一点）。这里强调的对端，也就是说中间的网络节点是感受不到的，TCP接收方通过窗口字段通告TCP发送方的发送窗口。

==流量控制的目的==，要避免的情况——接收方缓存暂时无法接受新到达的分组，导致分组被抛弃，因而出现大量的丢失重传。
当发送方发出的报文段到达接收方时，接收方返回一个确认报文并且给出窗口值。当发送方收到确认报文后，根据确认号移动发送窗口的左边界，根据窗口值移动发送窗口的右边界。

当接受方给出的窗口值为0时，那么发送方就不能发送任何数据了，只能等待接收方缓存空出位置。但这里有个问题就是接收方缓存空出位置后并不会主动通知发送方，这样一来双方就陷入死等状态。
因此TCP引入了**持续计时器**，这个计时器是一直启动的，因此某种程度上也是一种资源上的开销。
>持续计时器基于指数退避计算超时时间，而且一旦超时就会发生**零窗口探测报文**（强制对端返回包含窗口值的ACK报文），探测报文包含一字节的数据，因此它是可以被重传的。如果收到的确认报文中窗口值仍然为0，将重置计时器，如果探测报文丢失，就将超时时间加倍（2/4/8…超过设置的阈值，就单方面断开连接，异常断开情况）


%%一旦发送窗口大小为0，那么发送方就不能发送任何数据了，必须等待对端确认报文中窗口值的通告。如果确认报文丢失，那么双方将陷入死等。因此TCP引入了**持续计时器**，这个计时器是一直启动的，因此某种程度上也是一种资源上的开销。
>持续计时器基于指数退避计算超时时间，而且一旦超时就会发生**零窗口探测报文**（强制对端返回包含窗口值的ACK报文），探测报文包含一字节的数据，因此它是可以被重传的。如果收到的确认报文中窗口值仍然为0，将重置计时器，如果探测报文丢失，就将超时时间加倍（2/4/8…超过设置的阈值，就单方面断开连接，异常断开情况）%%

**糊涂窗口综合症**：如果接收⽅腾出⼏个字节并告诉发送⽅现在有⼏个字节的窗⼝，⽽发送⽅会义⽆反顾地发送这⼏个字节， 这就是糊涂窗⼝综合症
我们的 TCP + IP 头有 40 个字节，为了传输那⼏个字节的数据，要达上这么⼤的开销，这太不经济 了

解决办法：
接收⽅通常的策略如下: 
当「窗⼝⼤⼩」⼩于 min( MSS，缓存空间/2 ) ，也就是⼩于 MSS 与 1/2 缓存⼤⼩中的最⼩值时，就会向发送⽅通 告窗⼝为 0 ，也就阻⽌了发送⽅再发数据过来。 等到接收⽅处理了⼀些数据后，窗⼝⼤⼩ >= MSS，或者接收⽅缓存空间有⼀半可以使⽤，就可以把窗⼝打开让发 送⽅发送数据过来。


发送⽅通常的策略: 
使⽤ Nagle 算法，该算法的思路是延时处理，它满⾜以下两个条件中的⼀条才可以发送数据： 
1. 要等到窗⼝⼤⼩ >= MSS 或是 数据⼤⼩ >= MSS 
2. 收到之前发送数据的 ack 回包 


只要没满⾜上⾯条件中的⼀条，发送⽅⼀直在囤积数据，直到满⾜上⾯的发送条件。 另外，Nagle 算法默认是打开的，如果对于⼀些需要⼩数据包交互的场景的程序，⽐如，telnet 或 ssh 这样的交互 性⽐较强的程序，则需要关闭 Nagle 算法。 可以在 Socket 设置 TCP_NODELAY 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应⽤ ⾃⼰的特点来关闭）


_谈论流量控制，首先要知道什么是流量控制，重点区别拥塞控制，而且要通过窗口值说明TCP如何进行流量控制。然后通过使用一个报文的发送与确认分析发送窗口的变化，来说明流量控制的具体表现。最后还可以说明一下窗口值为0的特殊情况如何处理。_



##### 拥塞控制

拥塞控制：拥塞就是堵，你可以认为这里的堵指的是“传输通道”这个抽象的隧道堵住了。这个抽象的“通道”下具体可以表现为路由器的接收缓存不够用了、链路过载等。说白了，网络中注入的数据报文太多了，路由器的缓存装不下、链路的带宽不够分，结果要么是数据包中途被丢弃，要么是数据报因为延迟无法及时达到对端，对端不知道中间发送了什么，它只知道这个包没有及时到达（丢包了）。
**因此流量控制关注的是传输层的两端，要求发送方的发送速率能够匹配接收方的接收速率。而拥塞控制关注的是两端中间的“传输通道”（或者说下层网络和链路的承受能力），要求发送方调节发送速率，顾及中间通道的承受能力。**（这里的传输通道不仅是两端之间的通道，是整个传输层通信共用的抽象通道）
在TCP的具体实现中（这里指对拥塞控制的进一步具体化），**（发送窗口）窗口字段的值取决于拥塞窗口和接收窗口的最小值。**


拥塞是指一个或者多个交换点的数据报超载，TCP又会有重传机制，导致过载。为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量.

当cwnd < ssthresh 时，使用慢开始算法。当cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。当cwnd = ssthresh 时，即可使用慢开始算法，也可使用拥塞避免算法。

慢开始：由小到大逐渐增加拥塞窗口的大小，每接一次报文，cwnd指数增加。

拥塞避免：cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1。

快恢复之前的策略：发送方判断网络出现拥塞，就把ssthresh设置为出现拥塞时发送方窗口值的一半，继续执行慢开始，之后进行拥塞避免。

快恢复：发送方判断网络出现拥塞，就把 cwnd设置为原来的一半，，ssthresh等于cwnd，之后进行拥塞避免。

###### 重传

TCP拥塞控制中，以丢包作为“网络拥塞”的标志，而丢包又可以通过“超时”和“大量失序报文到达”来表现，因此TCP拥塞控制的算法和丢包重传的时机紧密相关。

TCP的重传方式分为**超时重传**和**快重传**。
其中超时重传时间的设置参考报文**往返时间RTT**，这个值通过时间戳选项计算出来，超时重传的时间是基于**二进制指数回退策略**（超时时间第一次R，再次超时2R，再次超时4R…）。发生超时重传的场景通常是网络拥塞十分严重（总是发生路由器丢包）或者断网情况（报文压根无法发出去）。（一旦收到确认报文就重置超时时间为R）

如果在超时重传定时器溢出之前，接收到连续的三个重复冗余ACK，发送端便知晓哪个报文段在传输过程中丢失了，于是重发该报文段，不需要等待超时重传定时器溢出再发送该报文。
>发送一个新的数据报时，设置一个计时器，如果及时接收则取消，之后发送方再发送新的数据报时，再重新设置新的计时器。这在停等协议是非常容易理解的，但是对于流水线式的非停等协议，计时器可能是基于窗口的，因此一旦重传就是以窗口为单位的就不奇怪了。TCP有各种各样的实现，目前我的理解是：TCP超时重传的范围是窗口，但是有SACK选项使得其可以仅重传部分分组。

而对于网络拥塞不是那么严重时，通常基于快重传策略。TCP收到一个报文后，总是对接收缓存中最后一个有序字节的序号给出确认，而且发送方一次可以发出多个报文段，当发送方收到了若干个（默认3个）重复确认的ACK报文时，将快速重传丢失的报文。（若干个冗余报文总是在超时之前到达发送方）
TCP虽然是基于累积确认的，因此TCP允许接收方**延迟确认**。但是**前提是按序接收分组**。一旦接收方收到了一个失序分组，它必须立即给出重复确认。如果是SACK，重复确认报文还包含了“空缺的是那个报文”的信息。
使用SACK可以更快的填补空缺，而且可以减少不必要的重传，因为一个RTT不再是仅仅快速重传冗余ACK希望重传的报文，而是重传具体的几个缺口报文。而且SACK还可以避免伪重传（刚收到3个重复ACK，那边就到达了）

总结：超时重传是基于时间驱动的，而快重传是基于事件驱动的。
>当超时重传时到底重传所有发送窗口的分组，还是重传某个分组和具体的TCP实现有关，如果TCP创建连接的时候声明了SACK选项，那么TCP便是基于选择重传的，其中SACK在正式传输时，包含了接收方已经成功接收的数据块的序列号范围，发送方可以更加精确的重传“缺口”分组，同时快重传也会参考SACK，这个选项一般是默认开启的

>纯ACK（不包含任何数据的ACK报文）不会被重传，因此如果三次握手丢失了第三个报文，而且不含任何数据，则超时重传的总是第二个SYN+ACK报文，其中SYN占一个序列号。
>重传计时器对任何占用序列号的报文都会计时，超时时间RTO，通常是RTT的两倍。重传计时器是方法方维护的（两端都有发送方的角色），因此如果一个报文丢失，两边都有可能重传，只不过谁先重传不得而知。




_谈论拥塞控制，首先要知道拥塞控制的关注点，以及与流量控制的区别，然后谈TCP中的具体体现。另外就是简单谈谈拥塞控制的四种算法。_




### HTTP

#### 怎么理解Http无状态
因为它的每个请求都是完全独立的,每个请求包含了处理这个请求所需的完整的数据。如果第一个请求出错了,后面的请求一般也能够继续处理


**无状态的缺点**：
单个请求需要的所有信息都必须要包含在请求中一次发送到服务端，这导致单个消息的结构需要比较复杂，必须能够支持大量元数据，因此HTTP消息的解析要比其他许多协议都要复杂得多。  
同时，这也导致了相同的数据在多个请求上往往需要反复传输，例如同一个连接上的每个请求都需要传输Host、Authentication、Cookies、Server等往往是完全重复的元数据，一定程度上降低了协议的效率。

  
  
[HTTP无状态协议的理解 - 简书 (jianshu.com)](https://www.jianshu.com/p/9aeca6b1448c)

**为什么不改进http协议使之有状态**
最初的http协议只是用来浏览静态文件的,无状态协议已经足够,这样实现的负担也很轻(相对来说,实现有状态的代价是很高的,要维护状态,根据状态来操作。)。随着web的发展,它需要变得有状态,但是不是就要修改http协议使之有状态呢?是不需要的。因为我们经常长时间逗留在某一个网页,然后才进入到另一个网页,如果在这两个页面之间维持状态,代价是很高的。其次,历史让http无状态,但是现在对http提出了新的要求,按照软件领域的通常做法是,保留历史经验,在http协议上再加上一层实现我们的目的(“再加上一层,你可以做任何事”)。所以引入了其他机制来实现这种有状态的连接。



HTTP 协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都**不做持久化处理**。 不保留之前一切的请求或响应报文的信息，每当有新的请求发送时，就会有对应的新响应产生，**这是为了更快地处理大量事务，确保协议的可伸缩性。**

HTTP2 应该看作是有状态的，因为两端都维护一个头信息表，用索引代替字段

**如何解决无状态的问题**

```markdown
[http无状态和解决认证的方法 - 爵士灬 - 博客园 (cnblogs.com)](https://www.cnblogs.com/sunnycc/p/14801678.html)
_cookie有两种：1.存放在浏览器进程中。2存放在硬盘中。是可以选择被设置的。_

_单体服务解决服务器无状态和用户鉴权：_

_单体系统中不存在cookie跨域和session服务器共享问题。_

__使用浏览器会话cookie和session可以得到解决。__

_微服务_解决服务器无状态和用户鉴权：__

_微服务要考虑_cookie跨域和session服务器共享问题。__

__域名相同的情况下：__

__spring-session+redis：当用户登录的时候我们会存放session到服务端和浏览器单，同时session一部分信息也会被存放到redis，当我们拦截认证时就可以去redis取session进行验证判断。__

_redis+token：_当用户登录成功时生成token，将sessionId或者用户信息做key，token做value存放到redis，每次请求时拦截验证。__

　　　　　　用户信息+token可以实现一个用户同时只能登录一次。

__jwt生成token方式：当用户登录成功时生成token，token返回给用户，客户端每次请求时携带token，然后服务端验证token是否正确。  token必须要在每次请求时发送给服务器，它应该保存在请求头中，另外，服务器要支持CORS（跨来源资源共享）策略，一般我们在服务端这么做就可以了 Access-Control-Allow-Origin：*。__

__域名不相同的情况下：__

____redis+token：______当用户登录成功时生成token，将sessionId或者用户信息做key，token做value存放到redis，每次请求时拦截验证。__

　　　　　　用户信息+token可以实现一个用户同时只能登录一次。

SSO单点登录：需要一个独立的注册中心，用户第一次登录被拦截到认证中心进行登录，认证中心给用户办法token，用户每次登录都携带token，每次请求验证token是否正确。
```
1. cookie
cookie的传递会经过下边这4步:

Client 发送 HTTP 请求给 Server
Server响应,并附带Set-Cookie的头部信息
Client保存 Cookie, 之后请求 Server 会附带Cookie的头部信息
Server从 Cookie 知道 Client是谁了,返回相应的响应

2. session
如果把用户名、密码等重要隐私都存到客户端的Cookie中,还是有泄密风险。为了更安全,把机密信息保存到服务器上,这就是 Session Session是服务器上维护的客户档案,可以理解为服务器端数据库中有一张user表,里面存放了客户端的用户信息。SessionID就是这张表的主键ID
Session信息存到服务器,必然占用内存。用户多了以后,开销必然增大。为了提高效率,需要做分布式,做负载均衡。因为认证的信息保存在内存中,用户访问哪台服务器,下次还得访问相同这台服务器才能拿到授权信息,这就限制了负载均衡的能力。而且 SeesionID存在 Cookie,还是有暴露的风险,比如SCRF(Cross-Site Request Forgery,跨站请求伪造)

如何解决这些问题呢? 基于 Token令牌鉴权。


3. Token
首先, Token不需要再存储用户信息,节约了内存。其次,由于不存储信息,客户端访问不同的服务器也能进行鉴权,增强了扩展能力。然后, Token可以采用不同的加密方式进行签名,提高了安全性。
Token就是一段字符串, Token传递的过程跟 Cookie类似,只是传递对象变成了 Token。用户使用用户名、密码请求服务器后,服务器就生成 Token,在响应中返给客户端,客户端再次请求时附带上 Token, 服务器就用这个 Token进行认证鉴权。

Token虽然很好的解决了 Session的问题,但仍然不够完美。服务器在认证 Token的时候,仍然需要去数据库查询认证信息做校验。为了不查库,直接认证,JWT出现了。


4. JWT
JWT的英文全称是 JSON Web Token。JWT把所有信息都存在自己身上了,包括用户名密码、加密信息等,且以JSON对象存储的。  
JWT长相是xxxxx.yyyyy.zzzzz,极具艺术感。包括三部分内容

-   Header包括 token类型和加密算法(HMAC SHA256 RSA)
 `{ "alg": "HS256", "typ": "JWT" }`


-   Payload  
    传入内容
    {"sub":1234567890","name":"John Doe, "admin": true}


-   Signature  
    签名, 把 header 和 payload 用 base64 编码后 “.” 拼接, 加盐 secret(服务器私钥)
     HMACSHA256(base64UrLEncode(header)+"." + base64UrlEncode(payload),secret);

最终的 token就是这样一个字符串
	 eyJhbGci0iJIUzI11Ni9
 	.eyJzdWIi0iIxMjMONTY30DkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ
 	.yK0B4jkGWu7twu8Ts9zju01E10_CPedLJkoJFCan5J4;

给 Token穿个外套
 Authorization: Bearer;
 
这就是我们在请求 Header里面看到的内容格式了。


##### 长连接
[http长连接(http长连接什么时候断开)-前端基础-前端这点事 (ltonus.com)](https://www.ltonus.com/web-basic/http-link.html)


TCP 连接的重复建⽴和断开所造成的额外开销，减轻了服务器端的负载
持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态

如果客户端的请求头中的connection为close，则表示客户端需要关掉长连接，如果为keep-alive，则客户端需要打开长连接，如果客户端的请求中没有connection这个头，那么根据协议，如果是http1.0，则默认为close，如果是http1.1，则默认为keep-alive。如果结果为keepalive，那么，nginx在输出完响应体后，会设置当前连接的keepalive属性，然后等待客户端下一次请求。

![[Pasted image 20220416175305.png]]
上图中的Keep-Alive: timeout=20，表示这个TCP通道可以保持20秒。另外还可能有max=XXX，表示这个长连接最多接收XXX次请求就断开。对于客户端来说，如果服务器没有告诉客户端超时时间也没关系，服务端可能主动发起四次握手断开TCP连接，客户端能够知道该TCP连接已经无效；另外TCP还有心跳包来检测当前连接是否还活着，方法很多，避免浪费资源。


使用长连接之后，客户端、服务端怎么知道本次传输结束呢？两部分：1是判断传输数据是否达到了Content-Length指示的大小；2动态生成的文件没有Content-Length，它是分块传输（chunked），这时候就要根据chunked编码来判断，chunked编码的数据在最后有一个空chunked块，表明本次传输数据结束
#### HTTP演变
	1.0是短链接：每次请求都要进行一次tcp三握四挥
	1.1变为流水线式长连接：多个请求可以在未收到前一个请求的响应前就发出去，串行复用同一个tcp连接，但应用层存在队头阻塞问题。问题就是头部信息不压缩，占用额外带宽传输效率低，无法定义优先级，服务器只能进行响应
	2.0支持头部压缩，客户端和服务端同时维护一张头信息表，使用索引代替字段，传输效率提升；不再使用文本格式，使用二进制格式避免转换的开销。多个请求可非串行复用同一个tcp连接，使得并发的处理多个请求成为现实，具体是，每个请求/响应的所有数据包称为一个数据流，每个数据流都拥有独一无二的标记。服务器还可以主动向客户端发送消息，减少延时的等待。还支持指定数据流的优先级
	3.0 2.0多条数据流复用同一个tcp连接，在tcp看来就是普通的数据流，一旦丢包就会发生重传机制，这样所有的HTTP请求都必须等待丢失的包被重传。为了解决这个问题，HTTP3将传输层协议更换为UDP，因为UDP不关系顺序和丢包，因此解决了队头阻塞问题。为了保证可靠性，使用了基于QUIC协议，当某个数据发送丢包时，阻塞这个流而不影响其他流。QUIC实际上相当于：支持可靠传输UDP + TLS + HTTP2/的多路复用协议

#### HTTP细节
	请求报文，响应报文，头部字段，响应码
	
	
	头部字段：
	host：服务器域名
	accept-encoding，content-Encoding：什么压缩格式
	contentType：指示资源所属类型
	connect：close和keep—alive短长连接
	
	响应码：200 OK  301 永久重定向 302 临时重定向 404 资源未找到 500 内部错误 502 代理服务器收到源服务器无效响应

#### Cookie，Session，Token
	cookie：HTTP的请求头，在request中是cookie，response中是set-Cookie
	当客户端（浏览器）访问某个服务器时，服务器根据已保存cookie的domain和path决定捎带哪些cookie信息，传送给服务器。而服务器拿到cookie集合一般会遍历这个每一个cookie，并且找到感兴趣的cookie进行身份验证——可以看作是上下文加载。而如果没有找到感兴趣的cookie，则大概有两种可能：这是个新的用户，或者用户的cookie被清除或已经过期了。那么就在response中addCookie，浏览器收到后保存这个cookie
	cookie的属性项除了最常见的 name/value，还有过期时间expires和最长存活时间max-age。如果不指定这两个，那会话结束就会被销毁，浏览器不会将其持久化到本地
	cookie可以看作是token，也可以是指针，这指针可以指向session
	
	会话信息存在cookie中和存在session中，从资源利用看，cookie存放会话信息造成大量带宽浪费，而且直接将会话信息存放在报文中，不安全，而且由于cookie是存放在客户端，服务器就失去了对会话信息的控制权，为了防止不安全的cookie，服务端必然要进行某种检查，校验机制（数字签名，时间戳等，基本就是token的思想）
	另一方面，不可能将所有的会话信息保存在服务端，因为服务器内存有限，如果服务器是分布式部署的，那么session对象可能无法及时同步，导致一个持有sessionId的用户总是无法正常自动登录
	
	cookie放什么？一些指针信息（如sessionId）、一些视频小网站没有登录业务但是也要保存用户的浏览记录，那么观看历史记录、搜索历史记录都可以保存到cookie中（可能就是一个名字，也可能是一条记录的id）、自定义设置（背景图片、个性栏等）、一些不重要的临时信息（例如浏览器型号、手机型号）。  
	还可以实现一些小功能如拿到用户上一次访问时间、统计用户访问总数、拿到用户上一次登录的ip地址等等。（说白了就是读取上下文相关的功能）
	至于token，它可以保存到URL传递，也可以保存到cookie或其他的头部，它是一个字符串，看作一个凭证，通常由用户标识符+时间戳+签名组成，服务器使用私钥对它签名并且保存在客户端，当客户端回传token时，服务器再次计算签名，如果没错则视为当前用户通过验证并放行，对于要求状态的页面，浏览器总是需要携带这个服务器签发的token。一般将基于token的验证看作无状态的，服务器不记录哪些用户已经登录，它的唯一职责就是**签发token**以及**验证token**，每个token都是独立的。  
	token更适合用于权限管理的系统，如：一个网站的业务就是普通用户看普通内容，VIP看普通内容+VIP内容，那么服务器唯一要做的就是拦截普通用户和为氪金用户签发token，这里面不需要太多上下文信息去保存，只需要做好访问控制即可。（session也能做，但是如果业务就是单纯访问控制，还是token做比较好：服务器压力小、逻辑简单、安全性高一些…）
	一般说HTTP实现有状态（保存和用户会话的上下文）**的具体方案，无非就是cookie+session或者cookie+token和cookie+session+token，当然取决于程序员如何使用cookie这个工具去实现会话状态。

## redis

#### 个人理解
	先从写代码时这个角度看redis，它是一个具有多种数据结构集合的类库；角度再往上升，它这个集合类库可以单独抽离出来，成为单个应用，或者说是进程，同时方便可水平扩展，基于该特性，它活跃的场景应该是分布式场景，多个程序需要共享某些数据，就可以从该数据中提取。接着角度再往上升，就涉及到redis的特性，其高可用特性，请求处理快，数据可持久化，服务可靠。
#### 内存淘汰策略
	8种：1种不淘汰 7种淘汰 4种在设置了过期时间的数据中进行淘汰，3种在所有数据范围内进行淘汰

#### 缓存污染
	先给出定义：访问次数非常少的数据占用着内存资源
	如何解决：那得靠内存淘汰策略了，选啥内存淘汰策略得看场景：
	
	若是明确知道数据随后再次被访问的情况，ttl可以有效避免缓存污染
	
	LRU:单个维度：数据访问的时效性，扫描式单词查询会造成缓存污染，但好处就是保留最近访问的数据
	
	LRU关注时效性，而LFU关注访问频次
	
	LFU：从两个维度：数据访问的时效性，数据的被访问次数。淘汰掉访问次数最低的数据。相同再淘汰访问时效性。数据被读取到缓存中，计数值为5，防止刚被写入缓存就被淘汰

#### 过期建删除策略
	惰性删除，定期删除

#### 数据结构
##### SDS
	主要成员：一个是字符串长度，一个char[]数组，一个字符数组中未使用的字节数，还有一个flags，用来表示不同类型的 SDS，节省内存

##### 字典
	两个哈希表，渐进式rehash

##### 跳表
	多层有序链表，链表的每个节点除了第一个节点外，都存储着层，前进指针，后退指针，成员值，分值，其中第一个节点有32层，不存储分值和成员值。其他节点随机在1到32层之间生成层数，层与层之间使用前进指针连接。这个链表封装在一个结构体中，这个结构体成员变量有：指向头部节点的指针，指向尾部节点的指针，存储节点数量的变量，存储节点中的最高层数。
	寻找节点的过程：从头节点开始的最高层开始遍历，根据前进指针向前寻找，如果前一个元素大于或等于待查找的元素或者遇到尾节点，则下移层次继续寻找；如果下一个元素不大于待查找的元素，则前进指针继续向前寻找，继续比较，直到在第一层遇到前一个节点的值大于当前待查找的值，在这个位置生成一个带随机层数的节点，然后插入值

##### 整数集合
	不会出现重复元素，是redis用于保存整数值的集合抽象数据结构，可以保存16，32，64位的整数值


##### 压缩列表
	当一个列表只包含少量列表项，并且都是小的整数值和短字符串，那么它便适合使用压缩列表进行实现，因此其特点是节省内存，减少内存碎片的产生
	组成：整个列表占用的字节数，表尾节点到起始地点的偏移量，节点数量，各个节点，用于标识末尾的标志符号
	节点组成：前一个节点的长度，节点编码，节点值
	若前一个节点小于254，则prelen为1字节，否则5字节


#### 数据类型
	字符串对象：int，embstr，row(sds)
	列表对象：quicklist（多个ziplist通过前后节点的指针连接起来）
	哈希对象：ziplist或dict
	集合对象：intset或dict
	有序集合对象：ziplist，skiplist&dict(O1获取成员的分值，Olongn进行范围排序操作)


#### 事务
	怎么开始事务？
	multi命令，然后声明多条操作指令，提交exec命令。
	
	redis中的事务看起来更像是打包命令的执行
	其原子性需要两个角度看： 如果代码出现语法问题如使用了不存在的命令，那么事务中的所有命令都不会执行；如果运行时出现错误比如命令和操作的数据类型不匹配，那么出错的指令不会影响其他的指令的执行
	
	还有 watch和unwatch指令，在exec执行时，如果至少一个被监视的键值被修改，那么服务器就会拒绝执行队列中的命令
	
	ACID思考：原子性看作残破的，隔离级别由于单线程所以没有，持久性看开不开AOF，因为RDB只和时间事件有关，只有在AOF模式下，才可以保障持久性；由于前面3种的欠缺，一致性也是没有
	
	使用redis事务其实Lua脚本更优，因为可以写逻辑关系运算if/else，不过该方式也是不能支持回滚，得自己写补偿代码）
	Lua脚本的好处：
	1.相对于redis事务，减少请求的带宽
	2.原子操作
	3.脚本可以复用

### 持久化及AOF重写


### 缓存异常

```markdown

### 缓存穿透
要查询的数据既不在缓存中,也不在数据库中,导致每次对该数据的请求都会越过缓存直接打在数据库上,若并发量上来,数据库容易承受不住导致宕机

解决方案:
1.对不存在的用户，缓存保存一个空对象进行标记（例如使用 K - null 键值对临时存储），防止对相同id的请求再次访问数据库，相当于“**特殊的命中**”，防止大量请求透过redis进入DB。但是这个方法可能使得redis中存储大量无用数据，占用内存资源。（设置过期时间长了占用内存，时间短了可能会被攻击者趁虚而入）  
2.**布隆过滤器**，存在性检测。对某个id的请求**经过多组哈希函数最终会对应一个值**，布隆过滤器可以保证如果布隆过滤器中存在某个key的计算值，那么可能存在，也可能不存在，但是如果没有则一定不存在。（通过数据结构和算法快速判断出key是否存在于数据库可以缩小过滤密度）  
3.接口的调用层面增加校验，对应一定不会被响应的请求，直接在缓存之前就拦截住,比如请求参数不合理、请求参数是非法值、请求字段不存在.不让这些请求访问后端缓存和数据库
4.网关层Nginx设防，将当个IP每秒访问超过阈值的ip拉入黑名单


### 缓存击穿
缓存击穿是指，**针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理**，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时

解决方案：  
1.热点数据设置永不过期（定时查询redis的记账信息，如果查询某个键超过一个阈值就使用persist命令解除过期时间）  
2.读操作中，线程如果拿到数据发现已经过期，则**先申请互斥锁，然后再更新缓存（涉及一个调用DAO接口的操作）**。可以防止多个线程同时从数据库中读数据，然后同时更新缓存。  
3.避免多个热点数据同时失效，将数据放入缓存的时候使用**固定时间加上一个小的随机数**，**避免大量热点key同一时刻失效**。  
4.使用随机退避方式，数据失效时tryLock，如果没有获取到锁就随机sleep一小段时间，然后重新调用接口，此时的数据已经被其他线程更新为有效数据了，此时可以拿到数据。


### 缓存雪崩
缓存雪崩是更加严重的缓存击穿，往往是某一时间点，大量的热点key失效，从而导致大量请求打入数据源，即使数据库重新启动后仍然会被新到来的请求击垮。缓存中间件失效。还要一种情况就是Redis 缓存实例发生故障宕机了，无法处理请求，这就会导致大量请求一下子积压到数据库层，从而发生缓存雪崩

解决策略和缓存击穿类似。  
1.我们应该避免缓存key的失效时间集中在一个时间段，可以在存入key的时候，加入随机数  
2.**快速失败的熔断策略**，减少数据源瞬间压力。**服务降级、限流**，牺牲此时一部分用户的体验保证系统的稳定性。

限流组件可以设置每秒能通过多少请求，没有通过的请求走降级路线。通过系统部分用户的体验换取服务器的安全。

3.使用主从模式和集群模式保证缓存的高可用，将热点数据均分在不同的集群服务器上


解决方案：

1.我们应该避免缓存key的失效时间集中在一个时间段，可以在存入key的时候，加入随机数  
2.若redis缓存层无法发挥其作用,则走服务降级,限流路线,减少数据源压力,牺牲此时一部分用户的体验保证系统的稳定性。在损失业务吞吐量的代价下，在时间的作用下，随着过期key慢慢填充，Redis实例可以自行恢复缓存层作用。

3.若是redis实例挂了引起的,则使用主从模式和集群模式保证缓存的高可用，将热点数据均分在不同的集群服务器上
```

## Java

### 理解面向对象
对于面向过程，解决问题的思路是先干什么，后干什么。而面向对象解决问题的思路是先把问题拆分成几个对象，然后考虑每个对象可以提供哪些方法。

**三大特性：**
面向对象的思想：使用一组数据结构和处理它们的方法组成对象，把具有相同行为的对象归纳为类，通过类的封装隐藏内部细节，通过类的继承实现类的重用与扩展，通过多态实现基于对象的动态分派。

封装是面向对象最重要的特征，封装就是屏蔽细节，只保留调用的接口。（属性也通过方法暴露），就好像手机通过屏幕（展示）输出，通过按键进行输入，其中计算的细节被手机外壳屏蔽。用户只需要关注三点即可：输入、接口提供的功能、输出
而屏蔽细节的最好方式，就是寻找共同点，提取出一个抽象的上层模板，模板与具体实现的功能可以通过继承来体现。而通过同一个模板实现出的不同的类又可以表现出不同的行为，这便是多态。


#### List，Set，Map接口
	set和List都是Collection的子接口，是对集合行为的进一步划分。set规范不重复，不要求有序的集合行为；List则规范允许重复，有序的线性表行为。
	Map接口规范了映射类型应具有的行为，一个键对应一个值，键是唯一的，但值可以不唯一

##### List
	ArrayList：初始容量是10，加载因子0.5，扩容前的数组长度右移一位 + 扩容前的数组长度
	Vector：初始容量为10，加载因子1，扩容为原来的2倍
	
	ArrayList和LinkedList：
	都是List接口的实现类，都具有线性表的行为。其中ArrayList底层是基于数组实现，而LinkedList则是基于双向链表实现
	ArrayList扩容时需要创建新的数组并将原数据拷贝进新数组
	而LinkedList不需要考虑扩容，理论上是无界的
	
	对比：两者最基本的不同就是底层数据结构的不同，增删元素方面（这里只考虑在中间操作）：ArrayList时间复杂度On，而LinkedList为O1，但随机访问方面：ArrayList为O1，Linkedlist为0n，此外ArrayList能利用到局部性原理，而LinkedList不能
	LinkedList不会浪费空间，但每个节点占用空间更大；ArrayList。。。



##### Set
	HashSet：初始容量为16，加载因子0.75，扩容为原来的2倍

##### Map
	HashMap：初始容量16，加载因子0.75；扩容为原来的2倍


### 异常
#### 分类
	两大子类：error和exception
	error：OOM,StackOverflow
	exception：运行时异常和编译期异常
		RuntimeException及其子类都是非受检异常，无论是主动抛出这个异常还是调用了声明该异常的方法都可以不去处理，交由JVM来处理。
		而其他异常都是受检异常，必须进行try-catch处理或者throws向上抛出。常见受检异常包括:IO异常，文件无法找到异常，空指针异常

#### 处理机制
	一个异常的执行顺序：
		1.new出一个异常对象
		2.中止当前正在执行的程序
		3.弹出异常对象的引用
		4.异常处理机制接管被中止的程序
		5.进入异常处理程序的catch代码块继续执行
		
		每个方法调用栈的catch结构可以看到当前栈帧的异常处理器，如果找不到就会栈帧出栈，寻找上一调用级别的异常处理器。最终main方法栈帧出栈后，交给JVM的未捕获异常处理器进行处理。如果没有则执行默认行为：
		1.调用异常对象的printStackTrace方法，打印方法调用栈的异常信息
		2.如果该线程不是主线程，则终止这个线程，其他线程正常运行，如果是主线程，则整个应用程序被终止
		
		未捕获异常处理器：


### finally
	如果finally和try/catch都有返回语句，那么后者return的内容将会被覆盖点，前者返回之前执行finally的内容
	存在异常丢失情况


### JVM如何判断两个类相同
	1.根据类的全限定名进行判断是否相等
	2.判断类对应的类加载器

### 反射
#### 什么是反射
反射，**就是在运行时，拿到一个类型的元信息**。从哪里拿到这些元信息？JVM的元信息统一保存在方法区，类加载阶段，class文件被载入内存，并且转换为了保存在方法区的数据结构中。同时向堆中放入一个class实例，用作元信息访问的入口。我们可以通过class.forName(）、实例.getClass()、或者类型.class这三种方法拿到这个class实例。（8大基本类型和void关键字都具有class实例）

> 拿到class实例，可以直接使用newInstance方法通过空参构造器创建对象，或者也可以使用getConstructor（）根据参数数量、类型拿到具体的构造器实例，当找到需要调用的方法时，都会复制一份而不是使用原来的实例，保证数据隔离。反射是线程安全的。

一旦我们拿到这个class实例，就找到了访问类型元数据的入口，我们可以通过这个class实例拿到构造器实例、方法实例、字段实例、注解实例等，进而我们还可以拿到字段类型、方法参数类型等。反射技术通常用于实现各种框架包括注解的解析、依赖注入、占位符替换、动态代理等。

反射的特点可以用于实现类型之间的**解耦**，提供系统灵活性，**例如输入全限定类名，反射创建一个实例（动态加载）**，避免大量if/else条件（静态加载）。包括spring的依赖注入、切面编程以及解析配置文件都离不开反射特性的支持。  
但是反射的性能比较低（一般配合缓存使用）、JVM无法对某些动态加载的类型进行优化，而且一定程度上破坏了Java的封装语义。另一方面，反射技术可能减低代码可读性，使得代码难以维护。



JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象。
#### 为什么反射效率低
java反射之所以慢，根本原因是编译器没法对反射相关的代码做优化。
Java 的编译期是一段不确定的操作过程。因为它可能是一个前端编译器（如 Javac）把 \*.java 文件编译成 \*.class 文件的过程；也可能是程序运行期的即时编译器（JIT 编译器，Just In Time Compiler）把字节码文件编译成机器码的过程；还可能是静态提前编译器（AOT 编译器，Ahead Of Time Compiler）直接把 \*.java 文件编译成本地机器码的过程。
其中即时编译器（JIT）在运行期的优化过程对于程序运行来说更重要，Java虚拟机在编译阶段的代码优化就在这里进行，由于反射涉及动态解析的类型，因此无法执行某些Java虚拟机优化。因此，反射操作的性能要比非反射操作慢，因此应该避免在对性能敏感的应用程序中频繁使用Java反射来创建对象。


**一方面是由于JIT无法对其进行优化，另一方面java反射调用方法是比较“重”的操作，要经过一系列的权限验证、通过native方法请求jvm去方法区查找方法定义、以及最后的invoke仍然可能要通过JNI调用native方法**


#### 什么时候该用反射
1.  不能明确接口调用哪个函数，需要根据传入的参数在运行时决定。
2.  不能明确传入函数的参数类型，需要在运行时处理


### 注解
注解本质上是一个接口，它需要被第三方识别并使用包括编译器、框架、甚至是注解本身  
注解的作用：生成文档、被框架反射读取（如依赖注入）、编译时格式检查如override。

**元注解，是被注解识别的注解**。  
【1】@Target用来约束注解的修饰位置。使用枚举类型ElementType，取值包括type、field、method、parameter等  
【2】@Retention用于约束注解的声明周期，使用枚举类型RetentionPolicy，取值包括runtime、class、source。只有runtime会保留到运行期，被反射技术读取到，而class只会被保留在class文件中，运行时被擦除，通常用于编译器检查如@Override、@Deprecated和@SuppressWarnning  
【3】@Document用于生成文档。  
【4】@Inherited允许子类继承父类的注解

注解支持的元素包括8大基本类型以及对应数组类型、枚举、注解、Class、字符串。但是不支持包装类型以及其他引用类型。

注解通过和反射技术配合使用，以@value为例，用户为 name字段 修饰@value(“mike”)，spring框架注入值的时候首先拿到字段集合fields，遍历每一个field，如果存在@value，那么就可以拿到这个值。此时根据field还可以拿到字段名、字段的类型type。最终spring读取value，并解析为type类型，反射注入到bean对象的name字段中。（反射的性能，一定程度上依赖类型的规模）

#### 原理

注解底层使用到了**动态代理技术**。  
因为注解本质上是一个接口（继承自java.lang.annotio的子接口），但是我们可以通过**Class对象的getAnnotation方法获得一个annotation的实例**（这就是一个代理对象，调用自定义方法的时候，最终调用的是invocationHandler的invoke方法）。

该方法会从memberValue这个string-object的map中取值（k是注解属性名称，v是具体的赋值），所有生命周期在runtime的注解都会加载进这个map，并且通过引用传递给invocationHandler实例。而invoke的执行核心就是——**通过方法名返回注解的属性值**

> 进行反射获取注解（调用getAnnotations（）方法）的时候，JVM会将所有生命周期在RUNTIME的注解取出来，放入一个map中，并创建一个AnnotationInvocationHandler实例，并将注解map传递给它，最后JVM **通过动态代理的方式生成目标注解的代理类**，并初始化好处理器

```
my annotation = review.class.getAnnotation(my.class);

    
```

**my是自定义注解的代理实例，有一个AnotationInvocationHandler类型的成员h，h的成员memberValues是一个map，key是注解中的方法名（注解的属性名），value是属性的值。value或是缺省值或者用户传入的值**

> 注解@my的实例annotation是一个代理对象的实例，这个代理对象的类型是$Proxy1 extends Proxy implements my ，并且持有AnotationInvocationHandler类型的引用。

```
class AnnotationInvocationHandler implements InvocationHandler, Serializable 

    
```

一个注解实例本质上是一个代理类实例，通过方法名返回注解的属性。（使用这个代理类的newProxyInstance方法的时候，传入接口和AnotationInvocationHandler，最终返回一个代理实例）


### 枚举类
	有穷对象集合，枚举类型中的构造器默认私有化，只能添加private修饰或者不添加
	使用枚举方式创建单例的好处：
	1.  避免反射攻击
	2.  避免序列化问题

### 接口和抽象类的区别

### 什么叫同步异步，什么叫阻塞非阻塞
	线程之间的同步：使得各个线程按照可预期的方式去执行

### 值传递和引用传递
	java中的所有参数传递都是值传递，对于基本类型就是字面量，而对于引用类型就是地址值。
	JVM的执行引擎是基于栈的，一旦方法被调用就需要创建一个栈帧，而调用方法的对象会将参数值复制一份（dup指令）压入被调用函数的操作数栈中。也就是说地址值和字面量都会被复制一份传入一个方法中。
	但是地址值指向的是一个堆中对象，它是一个地址。而字面量就是一个纯数值。一旦方法执行结束，栈帧出栈销毁。地址值变量和值变量都作为栈帧的局部变量被释放了，但是地址值指向的对象仍然存活在堆中。
	也就是说，虽然地址值变量是一个局部变量，但是它指向的堆中对象是堆内存共享的，它的内容被永久的改变了。
	总之，解释这个问题的下手点：传递的是什么——地址值和字面量，而且都是拷贝的。使用不同——字面量只能进行值的读写，而地址值可以用于访问堆中对象。改变——传入的字面量和地址值不会改变，该指向谁还指向谁，但是指向的对象被改变了。
	
	基本类型或者引用类型，到底存储在什么地方要根据变量的类型来讨论。栈、堆都是动态的内存，其中栈用来实现方法的调用，因此栈帧中存储的都是作为局部变量的值或引用，而且在标量替换下，栈中也可以通过成员打散的方式存放对象。堆中则是对象存放的主要场所，如果某个变量作为对象的成员，那么不管它是什么类型，它都同对象存放在堆中。虽然堆和栈都是运行时的内存区域，但是栈帧和对象的生命周期是不一样的。
	
	值传递:方法调用时,实际参数把它的值传递给对应的形式参数,形式参数只是用实际参数的值初始化自己的存储单元的内容,这两者是两个不同的存储单元.所以方法执行中形式参数值的改变不影响实际参数的值
	引用传递:对形式参数的操作实际是对实际参数的操作,这个结果在方法结束后,被保留下来,所以方法执行中形式参数的改变将会影响实际参数

### JMM


### 两大规则
	as-if-serial原则：cpu重排序在可以保证程序线性执行结果准确性的前提，对性能进行优化。但在多线程情况下就无法保证了
	happens-before（先行发生）原则：JMM的设计基于一种原则：先保证正确性，再考虑执行效率的问题，happens-before用来指定两个操作之间的执行顺序，这两个操作可以在一个线程之内，也可以在不同线程中，所以这种对操作顺序的关系的界定可以为程序员提供内存可见性的保证，具体happen-before定义如下：
	1.如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，并且第一个操作的执行顺序排在第二个操作之前
	2.两个操作之间存在happends-before关系，并不意味着java平台的具体实现必须按照happens-before关系指定的顺序来执行，比如i = 2，j = 3,虽然存在 happens-before关系，但两条指令之间没有任何影响，可以进行重排序
	而 i = 1， j = i + 1 之间有依赖关系而不会重排序
	落实到具体就是8条规则：程序顺序规则，监视器锁规则，volatile变量规则，传递性，线程start规则，线程中止规则，线程中断规则，对象终结规则

### volatile
	使用volatile的变量对其进行操作时在汇编层面的指令会多出lock前缀，该前缀目的是禁掉MESI缓存一致性提高效率的优化措施，让写存储区和失效队列失效。
	往上一层就是对volatile变量进行读取的时候，会加上读屏障，保证读到的共享变量值是最新的。而对其进行修改时会加上写屏障，保证该共享变量会马上对其他cpu暴露
	读写屏障前面的代码无法排序到后面，同样后面的代码也无法排序到前面


### 同步
	线程以我们可预期的方式执行就是同步

### 多态及其原理
```markdown

首先重载是横向选择的,而重写是纵向选择

重载:同一个实例可以有多个重名方法,根据方法签名的不同,编译期可以确定唯一载入的版本,但无法确认方法的调用入口。重载是编译期的多态

重写:存在继承关系的基础上,子类对父类方法的重新实现,在运行时确认，所以是运行时多态。

重载为什么编译期可以确定唯一的载入版本却无法确认方法的调用入口？
因为存在子类的父类方法的重写

什么情况下才能确认？
该方法无法被重写就能确认，这些方法统称为非虚方法。其方法的符号引用在类加载的解析阶段就转换为直接引用

### 两者使用上的区别
重写一个方法时，**参数列表不能改变**，返回值要么不变，要么是可以兼容的类型（被重写方法返回值的子类、实现类、子接口等“小类型”），异常也同理，不能抛出更宽泛的异常类型，同时也不能做更严格的访问权限。  
重载一个方法时，**参数列表一定要变**，异常、修饰符、返回值不做要求


### 底层区别
当一个类被编译后，它的某一个方法的信息将被保存在方法表和常量池中，其中方法的各个参数的符号引用集合将作为特征签名将被保存在常量池中，而返回值不会作为特征签名的成员。因此无法仅仅依靠返回值确认重载版本。


重写是运行时多态的体现，方法调用的本质就是将符号引用转换（解析）为直接引用，直接引用指向方法对应的字节码指令（的地址）。对于非虚方法，这个过程在类加载的解析阶段完成，而对于虚方法，这个过程在运行时完成（即执行引擎真正开始执行该方法调用代码时才进行解析）。
而对重写方法调用的解析，就是将符号引用指向重写方法执行入口的过程，运行时执行动态分派的动作，取决于变量对应的真实类型（变量指向的对象类型，而不是变量类型），只有虚方法才会执行动态分派

动态分派：运行时根据实际类型确认方法执行的版本
### 方法调用原理
动态分派，重写都是基于虚方法而言，与动态分派相对的就是静态分派，或者说是解析。

如果调用一个静态方法，对应的是invokeStatic指令，其中静态方法的符号引用在解析阶段就已经指向Father实现的方法了，因此调用的Father提供的方法。（类加载之后就已经确认唯一调用版本了，和创建什么实例已经没有关系了，由静态类型决定）

如果调用一个实例方法（非final），对应的是invokeVirtual指令。
1.引用入操作数栈，这个引用指向的对象的对象头中具有一个指向真实类型的指针（类型指针）
2.栈帧中有一个动态链接结构，保存了一个指向当前栈帧所属方法的引用
3.在真实类型的方法表中寻找是否存在相应的重写方法，如果存在则进行权限认证，通过后则将动态链接的符号引用指向当前方法的入口，也就是符号引用转为直接引用
4.在当前真实类型的方法表中找不到就按照继承关系向上搜索，如果始终未能成功解析，则抛出异常：abstractMethodError

### 优化
如果继承的层次比较深，要调用的方法位于比较上层的父类，则调用的效率是比较低的，因为每次调用都要经过很多次查找。这时候大多系统会采用一种称为**虚方法表**的方法来优化调用的效率。


所谓虚方法表，就是在类加载的时候，为每个类创建一个表，这个表包括该类的对象所有动态绑定的方法及其地址，包括父类的方法，但一个方法只有一条记录，子类重写了父类方法后只会保留子类的。当通过对象动态绑定方法的时候，只需要查找这个表就可以了，而不需要挨个查找每个父类。

虚方法表会在类加载的链接阶段被创建并开始初始化，类的变量的初始值准备完成之后，JVM会把该类的方法表也初始化完毕
```


### 垃圾回收


### 深拷贝和浅拷贝
```markdown
首先要明白变量都是一个指针，只不过指向的是字面量还是其他对象

java浅拷贝就是当前地址上保存的是一个指针，我就拷贝这个指针就返回

而深拷贝则是，如果这个位置的指针指向的是字面量，那我就返回，如果该指针指向的仍然是一个指针，那就进行一个递归的解析，直到所有位置的指针都被解析为字面量
```


### hello world执行流程
[java Hello world 源码执行流程详解 - 简书 (jianshu.com)](https://www.jianshu.com/p/8753649b6be2?utm_campaign=haruki)


### 在java中如何一次跳出多层循环
**在Java中，要想跳出多重循环，可以在外层的循环前定义一个标号，然后在内层循环体中使用带有标号的break 语句，即可跳出外层循环。**

```java

public static void main(String[] args) {
    ok:
    for (int i = 0; i < 10; i++) {
        for (int j = 0; j < 10; j++) {
            System.out.println("i=" + i + ",j=" + j);
            if (j == 5) {
                break ok;
            }

        }
    }
}


```

### 为什么Int类型的取值范围是2的31次方减1
最大存储2^32次方,但32位的第一位是符号位。所以是2^31次方
最后的减一操作是 因为从零开始的，0被划到了正数的范畴

### 容器
#### hashMap
##### HashMap扩容为什么是2的倍数
	通过位运算达到取余的效果，找到元素在数组中的下标，位运算可以提高速度, hash & (n - 1)


**为什么高16位与低16位做异或**
hashMap的hash()使用hashCode的低16位和高16位进行了异或操作，其实就是一个扰动计算——让所有位都参与计算，这样每一位不同都可以对应一个新的hash计算值，降低hash冲突的概率（如果直接使用原始hashCode，可能出现过多高位相同低位不同的hash值，使得取模后存放过于集中）。说白了，就是通过**不同的高位影响相似的低位，让总体的hash值更加平均**。

hashCode（）本质上就是一个hash函数，将对象的地址空间映射为一个整形值

##### 解决哈希冲突的办法

两个不同的输入，经过hash函数得到同一个输出，我们需要解决这个冲突。  
1. 开发定址法  
当前位置已经被占用了，就继续向后面找，直到找到另外一个空位置。  
JDK的threadLocalMap就是这么解决hash冲突的，通过线性探测法解决。  
2. 链地址法  
最常见的，hashMap就是基于该方式  
3. 再哈希法  
再使用另外一个hash函数进行一次计算，那再冲突了呢？可能继续找新的hash函数，或者搭配另外一种方式，看具体实现吧  
4. 公共溢出区  
将哈希表分为基本表与溢出表，冲突数据往溢出区存放。小坑放不下扔进大坑

##### 扩容原理

hashMap默认大小是16，默认扩容因子是0.75，因此一旦检测到节点数量达到12就会触发resize函数进行扩容，数组的新容量变成旧容量的二倍（32），并且重新计算阈值。本质上是一个数组中的节点向另一个数组转移的过程。

1.7中，遍历旧数组中每一个节点，遍历的同时计算新数组的索引位置，并且**头插**进入新数组（因为只需要计算数组索引）

1.8中，不再是边遍历边移动了，而是使用两个辅助链表节点——维护两个链表（两对头尾节点），高位链表和低位链表，每一个桶都对应两个辅助链表。遍历旧桶的时候将节点放入高位链表或低位链表，当某一个桶被遍历完毕，就将这两个链表保存到新桶中、清空链表、然后重复这个过程直到所有的节点被移动完毕（低位链表最终保存在新数组的index，高位链表存入oldCap+index位置）。因为两个链表都是保存了尾结点的，因此节点插入是**尾插**的。

> 新容量大小 = oldCap + oldCap ，因此原桶中的元素实际被划分为了两部分，一部分存入【0，oldCap】的index，另一部分存入【oldCap,2oldCap】的oldCap+index中。

（1.7每个节点移动前都需要计算一次index。而1.8每个桶只计算一次index即可，更主要关注的是去往哪一个链表）

> 1.7是先判断扩容后插入，而1.8是先插入然后判断扩容。先扩容后插入其实是可以避免一定的空间浪费的（防止扩容后就不再使用了），这里为什么1.8先插入后扩容真的不知道，以后看能填上坑不能吧。

使用`e.hash & oldCap==0` 表示是低位链表，否则就是高位链表。



**为什么1.8要先插入后扩容**


下面就举例频繁转变临界点的情况 ,根据频繁转变临界点的情况对比来说明原因,假设插入的节点刚好都在当前的链表或者红黑树的索引位置上

没为什么，当前链表7个节点，你看着办，先插入树化再扩容转变概率小点  


##### 链表树化

为什么链表树化需要同时满足链表长度>=8和数组长度>=64两个条件

因为当 table 数组容量比较小时，键值对节点 hash 的碰撞率可能会比较高，进而导致链表长度较长。这个时候应该优先扩容，而不是立马树化。

为什么要大于等于8转化为红黑树，而不是7或9？
树节点的比普通节点更大，在链表较短时红黑树并未能明显体现性能优势，反而会浪费空间，在链表较短是采用链表而不是红黑树。在理论数学计算中（装载因子=0.75），链表的长度到达8的概率是百万分之一；把7作为分水岭，大于7转化为红黑树，小于7转化为链表。红黑树的出现是为了在某些极端的情况下，抗住大量的hash冲突，正常情况下使用链表是更加合适的。


如果 hashCode的分布离散良好的话，那么红黑树是很少会被用到的，因为各个值都均匀分布，很少出现链表很长的情况。在理想情况下，链表长度符合泊松分布，各个长度的命中概率依次递减，注释中给我们展示了1-8长度的具体命中概率，当长度为8的时候，概率概率仅为0.00000006，这么小的概率，HashMap的红黑树转换几乎不会发生，因为我们日常使用不会存储那么多的数据，你会存上千万个数据到HashMap中吗？



##### 死链循环的产生
jdk7在多线程环境下扩容可能会导致死循环，主要是由头插法导致元素在桶中的相对位置发送改变，破坏了稳定性。jdk1.8基于尾插，扩容完毕后元素的相对位置没有改变，不会造成死循环。

因为如果两个线程同时执行扩容，那么肯定都是各种拿着公共的元素往自己数组中放，假设某个链表A->B,其中一个线程完成扩容，且顺序变成B->A，而另一个线程醒来后局部变量e为A，next为B。A头插进入另一个线程开辟的数组newTable[i]，然后e迭代给next即e为B，下一轮循环重新为局部变量next赋值，而next=e.next，此时next又回到了A，这时如果再进行一次头插A将指向B，此时就已经成为环了。


##### 阈值问题

loadfactor负载因子是hashMap扩容的一个参考因子，hashMap使用loadfactor和当前容量计算出扩容的阈值。存在阈值的原因是因为hashMap是基于hash值与数组容量取余来计算节点的数组索引，因此设置阈值可以减少hash冲突的产生。  
**设置阈值是空间换时间的考虑**。  
如果阈值设置太大，那么可能出现hash冲突，无法保证O（1）的访问时间复杂度，严重的情况下可能退化为链表。如果设置太小又会造成不必要的空间浪费，而且扩容的行为可能是否频繁，影响整体性能，同时扩容本身也带来了时延和内存占用（申请数组和移动元素）。  
0.75是一个经验值，是空间和时间上的折中。

> 根据源码注释，节点在桶中的位置遵循泊松分布，当加载因子为0.75时，桶中元素超过8的几率非常小。

jdk8之后的底层数据结构是数组+链表+红黑树。其中如果某个桶中的链表节点数量超过8个，则在插入第8个节点后进行树化操作。而节点数量小于等于6个时又会重新变成链表节点。其中7相当于是一个缓冲节点，防止节点类型频繁的转换。  
树节点比链表节点占用更多的空间，因为实际上树节点继承了linkedHashMap定义的entry节点，而这个entry节点又继承了Node节点





##### 为啥要二次幂
首先，length为2的整数次幂的话，h&(length-1)就相当于对length取模，这样便保证了散列的均匀，同时也提升了效率；其次，length为2的整数次幂的话，为偶数，这样length-1为奇数，奇数的最后一位是1，这样便保证了h&(length-1)的最后一位可能为0，也可能为1（这取决于h的值），即与后的结果可能为偶数，也可能为奇数，这样便可以保证散列的均匀性，而如果length为奇数的话，很明显length-1为偶数，它的最后一位是0，这样h&(length-1)的最后一位肯定为0，即只能为偶数，这样任何hash值都只会被散列到数组的偶数下标位置上，这便浪费了近一半的空间，因此，length取2的整数次幂，是为了使不同hash值发生碰撞的概率较小，这样就能使元素在哈希表中均匀地散列。


#####  put与get方法的实现

（这里以1.8为例）  
put和get实际上逻辑是非常简单的。  
put方法底层调用的是putVal方法，调用之前会使用hash()函数对hashCode进行二次哈希计算，得到一个计算值hash。hashMap的数组默认是懒创建的，因此一开始会先判断数组是否存在，不存在就创建。然后就拿到刚才计算的hash值，和数组长度取模得到当前键值对在数组中的索引位置。  
如果对应位置没有元素直接放入，如果存在元素则比较hash值（粗略当成hashCode也可以）和equals方法，只有二者都相同才会认为当前元素与待插入元素是同一个元素，这种情况进行节点覆盖，否则就接着往下判断。  
判断一下是否属于树节点，如果属于就委托插入树节点的方法去插入。如果不是树节点，说明存在哈希冲突。于是沿着当前元素这个链表往后遍历，边遍历边计数，计数结果超过7则进行树化后插入。否则继续找，最终只有两个结果：覆盖了某一个链表节点，或者尾插入链表。  
如果插入新节点会返回null，如果覆盖节点则会返回旧节点。1.7在插入前会判断扩容，而1.8则是先插入再判断扩容。

get就更简单了，不需要扩容判断，同样是根据hashCode进行二次哈希计算出hash值，然后与数组长度取模得到数组索引，根据hash值和key的equals方法进行对比，是就返回，没有就顺着链表向后找，没有找到就返回null，如果是一个树节点则委托查找树节点的函数去执行。


#### hashTable
hashTable是线程安全的hashMap，但是锁的粒度比较大，是基于synchronized加锁的，锁对象就是全局的this，严格来说，应该是this对象头mark word锁指针指向monitor对象。（这里不考虑锁升级，如果考虑锁升级，这个“锁”可能是monitor、或者线程id、lock record，这里不展开了）。说白了和vector一样，全局共同使用一把锁。  
hashTable是不允许存放null值的，事实上所有并发容器都不允许存放null值，因为并发容器一开始就打算应用在并发环境，一个key如果是一个null，那么它到达一开始是个null，还是被其他线程remove了呢？


hashTable是直接使用hashCode与数组长度取模计算索引位置的，默认大小是11，而扩容是2N+1的，扩容因子默认仍然为0.75.  
为什么是11？因为除以（近似的）质数求余数的分散效果更好，2N+1可以保证每次容量都是一个奇数（接近质数）。


### hashcode和equals， == 和equals的区别,String

[[Java基础# ==和 equals 的区别]]

[[Java基础#hashCode 和 equals]]


[[Java基础#String 、 StringBuffer 和 StringBuilder 的区别]]
## JUC
#### 线程的状态


#### 为什么Java只有Runnable状态
	操作系统层面，处于running状态的线程如果放弃CPU则进入ready状态，而java为我们屏蔽了线程切换（CPU调度）的细节，我们只需要知道创建一个线程，然后调用start()方法该线程进入runnable状态即可。如果将runnable拆分为两个状态，那么就相当于打破了操作系统和虚拟机之间的隔离性，违背了jvm设计的初衷，本末倒置了。
	java线程执行的过程中，总是不断的发生CPU调度，但是对于用户是透明的，因为java屏蔽了这一切的细节，对于用户来说，一旦一个线程被start()调用，那么它便是runnable的。

#### 创建线程的方式
Java 线程调用 start->start0 这个本地方法，实际上会调用到 JVM_StartThread 方法，而 JVM_StartThread方法中会创建与平台相关的本地线程，该线程执行 Java 线程的 run 方法。

	先看Thread类的run方法,如果target为空就什么也不做，否则就执行runnable成员的run方法。由此引申出 传入run对象，或者重写Thread的run方法
	
	第三种，实现callable接口的call方法，通过FutureTask获得其返回值或异常。FutureTask间接继承Runnable接口，当启动Thread.start时，就会创建出另一线程调用run方法，而FutureTask的run方法又会去调用Callable实现类的call方法，并用一个成员变量保持call方法的返回值，get方法会判断此时callable任务的状态，如果没有完成，那么阻塞当前线程，等待完成，如果处于已经取消状态直接抛出异常，如果已经执行完毕，将结果返回。
	同一个Callable实例对应的任务只会执行一次，不会执行第二遍。为什么呢？因为每个futureTask实例都有状态，每当一个futureTask被实例化后，状态为NEW，而执行完毕状态就变为normal。只有当futureTask状态为NEW时run方法才会执行
	
	

**总结：**
callable/call()计算出结果，而通过futureTask/get()向外暴露/公布结果。futureTask表示一个异步运算的结果，对这个异步运算的任务可以等待获取、判断是否完成以及取消任务

实现接口和继承Thread比较
推荐使用实现runnable接口的方式，因为实现runnable接口本质上是完成“布置任务”的行为，可以减少“线程细节”与“任务”本身的耦合度——线程是载体，任务是主要关注点，**不是让某类线程绑定某个任务，而是产生一个任务后创建一个线程实例去执行**


#### 线程池
合理利用线程池能够带来三个好处。第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。第三：提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。但是要做到合理的利用线程池，必须对其原理了如指掌。


建议使用有界队列，有界队列能增加系统的稳定性和预警能力，可以根据需要设大一点，比如几千。有一次我们组使用的后台任务线程池的队列和线程池全满了，不断的抛出抛弃任务的异常，通过排查发现是数据库出现了问题，导致执行SQL变得非常缓慢，因为后台任务线程池里的任务全是需要向数据库查询和插入数据的，所以导致线程池里的工作线程全部阻塞住，任务积压在线程池里。如果当时我们设置成无界队列，线程池的队列就会越来越多，有可能会撑满内存，导致整个系统不可用，而不只是后台任务出现问题。当然我们的系统所有的任务是用的单独的服务器部署的，而我们使用不同规模的线程池跑不同类型的任务，但是出现这样问题时也会影响到其他任务。

**线程池的监控**
通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用

-   taskCount：线程池需要执行的任务数量。
-   completedTaskCount：线程池在运行过程中已完成的任务数量。小于或等于taskCount。
-   largestPoolSize：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过。如等于线程池的最大大小，则表示线程池曾经满了。
-   getPoolSize:线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以这个大小只增不+ getActiveCount：获取活动的线程数。

通过扩展线程池进行监控。通过继承线程池并重写线程池的beforeExecute，afterExecute和terminated方法，我们可以在任务执行前，执行后和线程池关闭前干一些事情。如监控任务的平均执行时间，最大执行时间和最小执行时间等。这几个方法在线程池里是空方法。如：

protected void beforeExecute(Thread t, Runnable r) { }



##### 线程池参数
1. corePoolSize：核心线程数，也就是常驻线程池的线程最大数量  
2. maximumPoolSize：最大线程数，线程池的最大线程数，包含核心线程与非核心线程  
3. keepAliveTime:非核心线程的最大存活时间  
4. timeUnit：单位，是一个枚举，可以指定keepAliveTime的单位  
5. workQueue：工作队列，通常是阻塞队列  
6. threadFactory：线程工厂，通过工厂模式创建线程，一般使用executors提供的默认工厂，可以指定线程命名规则等  
7. rejectedExecutionHandler：拒绝策略，当任务无法被处理的处理方案，一般使用ThreadPoolExecutor提供的静态内部类

##### 拒绝策略

-   **AbortPolicy**：默认策略，在需要拒绝任务时抛出RejectedExecutionException；
-   **CallerRunsPolicy**：直接在 execute 方法的调用线程中运行被拒绝的任务，如果线程池已经关闭，任务将被丢弃；
-   **DiscardPolicy**：直接丢弃任务；
-   **DiscardOldestPolicy**：丢弃队列中等待时间最长的任务，并执行当前提交的任务，如果线程池已经关闭，任务将被丢弃


##### 工作流程
核心线程数 10 1010 , 最大小成熟 20 2020 , 非核心线程数 10 1010 , 非核心线程空闲存活时间 60 6060 秒 , 阻塞队列大小 10 1010 个 ;

当有 Runnable 任务进入线程池后 ;

先查看 " 核心线程 " , 如果没有核心线程 , 先 创建核心线程 ;

如果有核心线程 , 则 查看核心线程是否有空闲的 ;

如果有空闲的核心线程 , 直接将该任务分配给该空闲核心线程 ;

如果没有空闲核心线程 , 则 查看核心线程数有没有满 ;

如果核心线程没有满 , 则 创建一个核心线程 , 然后执行该任务 ;

如果核心线程满了 , 将该任务放入 " 阻塞队列 " 中 , 查看阻塞队列是否已满 ;

如果阻塞队列没有满 , 直接 将任务放入阻塞队列中 ;

如果阻塞队列满了 , 则 查看是否能创建 " 非核心线程 " ;

如果能创建非核心线程 , 则 创建非核心线程 , 并执行该任务 ;

如果不能创建非核心线程 , 则 执行 " 拒绝策略 " ;



##### 线程池队列满了处理方案
[[JUC#线程池思考]]

##### SynchronousQueue
线程间要交换数据一般都是用一个通过公共变量或者一个同步阻塞队列，生产者线程设置变量或者往队列中put值，消费者线程则读取变量或者从队列中take。

而SynchronousQueue则不需要存储线程间交换的数据，它的作用更像是一个匹配器，使生产者和消费者一一匹配。

比如当一个线程调用了put方法时，发现队列中没有take线程，那么put线程就会阻塞，当take线程进来时发现有阻塞的put线程，那么他们两个就会匹配上，然后take线程获取到put线程的数据，两个线程都不阻塞。

反之一个线程调用take方法也会阻塞线程，当一个调用put方法的线程进来后也会与之匹配。

如果一个take或者put线程进来发现有同类的take或者put线程在阻塞中，那么线程会排到后面，直到有不同类的线程进来然后匹配其中一个线程。

#### 锁升级

### 锁

#### 公平锁和非公平锁

按照先来先到的规则获取锁，就是公平的

使用公平锁时，恢复挂起的线程到线程获取锁需要一定时间，而非公平锁不需要恢复挂起线程这一操作，直接就能获取锁，效率更高。但可能引发锁饥饿现象

使用哪种锁？
为了更高的吞吐量，使用非公平锁，节省线程切换的时间

### java线程同步方法
什么是线程同步?
多个线程并发访问共享数据时,保证共享数据在同一时刻只能被规定个数的线程使用(一般一条,信号量一些).互斥是实现同步的一种手段
临界区,互斥量,信号量都是互斥的实现方式

1. 互斥同步方法
   synchronized和reentranlock
2. 非阻塞同步方法
   乐观锁
3. 无同步方法
   采用线程本地存储ThreadLocal：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行完，如果能保证，就可以把共享数据的可见范围限制在同一个线程之内，这样，无需同步也能保证线程之间不出现数据争用




### ThreadLocal

作用：
提供线程内的 **局部变量**，**不同的线程** 之间 **不会相互干扰**  
这种变量在 **线程的生命周期内** 起作用，  
减少 **同一个线程** 内 **多个函数或组件** 之间一些 **公共变量** 的 **传递复杂度**


1.  **`线程并发`**:  
    在 **多线程并发** 的场景下
2.  **`传递数据`**:  
    我们可以通过ThreadLocal在 **同一线程**，**不同组件** 中传递 **公共变量**
3.  **`线程隔离`**:  
    每个线程的变量都是 **独立** 的，**不会相互影响**

1.  传递数据 ： 保存每个线程绑定的数据，在需要的地方可以直接获取, 避免参数直接传递带来的代码耦合问题
   
2.  线程隔离 ： 各线程之间的数据相互隔离却又具备并发性，避免同步方式带来的性能损失


## JVM
#### 多态
```markdown
首先给出定义，接着使用上区别，再底层上区别，方法调用原理，虚方法表出现的原因

多态分两种：编译期多态和运行时多态，前者是重载，后者是重写

### 什么是重载：同一个实例拥有多个同名方法，根据方法签名的不同，编译期可以唯一确定载入的版本，横向选择

### 什么是重写：存在继承关系的基础上，子类对父类的方法进行重新实现，纵向选择

方法调用的本质就是将符号引用解析为直接引用的过程，直接引用指向方法对应的字节码指令的地址。对于非虚方法，这个过程在类加载的解析阶段完成，而对于虚方法，这个过程在运行时完成

### 什么是非虚方法：不能被重写，编译器可以确定唯一的调用版本。

eg:
1. static方法(invokeStatic)
2. super.XX() 即调用父类方法（invokeSpecial）
3. final修饰的方法（invokeVirtual）
4. private修饰的方法（invokeSpecial）
5. 构造器（invokeSpecial）


### 什么是虚方法：实例方法，特点是可以被重写，这就是为什么重载虽然能在编译期确认某一个方法的重载版本，但并不一定能确认它的调用入口，可能父类重载的方法给子类重写了。

### 使用上区别：
重写一个方法时，**参数列表不能改变**，返回值要么不变，要么是可以兼容的类型（被重写方法返回值的子类、实现类、子接口等“小类型”），异常也同理，不能抛出更宽泛的异常类型，同时也不能做更严格的访问权限。  
重载一个方法时，**参数列表一定要变**，异常、修饰符、返回值不做要求

### 底层上
当一个类被编译后，它的某一个方法的信息将被保存在方法表和常量池中，其中方法的各个参数的符号引用集合将作为特征签名将被保存在常量池中，而返回值不会作为特征签名的成员。因此无法仅仅依靠返回值确认重载版本。


重写是运行时多态的体现，方法调用的本质就是将符号引用转换（解析）为直接引用，直接引用指向方法对应的字节码指令（的地址）。对于非虚方法，这个过程在类加载的解析阶段完成，而对于虚方法，这个过程在运行时完成（即执行引擎真正开始执行该方法调用代码时才进行解析）。
而对重写方法调用的解析，就是将符号引用指向重写方法执行入口的过程，运行时执行动态分派的动作，**取决于变量对应的真实类型**（变量指向的对象类型，而不是变量类型），只有虚方法才会执行动态分派


### 方法调用原理
如果调用一个实例方法（非final），对应的是invokeVirtual指令。
【1】引用入操作数栈，这个引用指向的对象的对象头中具有一个执行真实类型的指针（类型指针）
【2】栈帧中有一个动态连接结构，保存了一个指（向运行时常量池中）当前栈帧所属方法的引用。（虚方法中，此时动态连接指针指向的还是方法的符号引用）
【3】在真实类型（方法表）中寻找是否存在相应的重写方法，如果存在则进行权限认证，通过后则将动态连接的符号引用，指向当前方法的入口（直接引用）
【4】否则按照继承关系向上搜索，如果始终未成功解析，则抛出异常：abstractMethodError

多态在于invokeVirtual的调用，因此非虚方法和字段不会展现“多态”


如果继承的层次比较深，要调用的方法位于比较上层的父类，则调用的效率是比较低的，因为每次调用都要经过很多次查找。这时候大多系统会采用一种称为**虚方法表**的方法来优化调用的效率。


所谓虚方法表，就是在类加载的时候，为每个类创建一个表，这个表包括该类的对象所有动态绑定的方法及其地址，包括父类的方法，但一个方法只有一条记录，子类重写了父类方法后只会保留子类的。当通过对象动态绑定方法的时候，只需要查找这个表就可以了，而不需要挨个查找每个父类。

虚方法表会在类加载的链接阶段被创建并开始初始化，类的变量的初始值准备完成之后，JVM会把该类的方法表也初始化完毕

```
[[JVM#重写与重载]]

#### 内存区域
```markdown
线程私有：程序计数器，虚拟机栈，本地方法栈
线程共享：堆，方法区


```


### 类加载流程

#### 加载
将一个class文件从硬盘上载入内存，将class文件映射到JVM的内存地址范围内

1. 通过一个类的全限定名获取定义该类的二进制字节流
2. 将字节流包含的信息转换为方法区的运行时数据结构
3. 在堆内存生成一个该class文件的映射对象——java.lang.Class对象，作为外部访问该类元数据的入口
   >加载的结果：class文件载入内存，堆内存创建了一个class对象，方法区为该class文件保存了一个class对象引用和一个classLoader引用。通过这两个引用可以判断两个类是否是一个类型


JVM加载类的信息到内存之后，使用字节码执行引擎去执行我们写的代码编译出来的代码指令，在执行代码的时候需要程序计数器来记录当前执行的字节码指令的位置的，也就是记录目前执行到了哪一条字节码指令。


```java
public class Load {

    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {
        MyClassLoader myClassLoader = new MyClassLoader();
        Class<?> myMap1 = myClassLoader.loadClass("MyMap");
        Class<?> myMap2 = myClassLoader.loadClass("MyMap");

        MyClassLoader myClassLoader1 = new MyClassLoader();
        Class<?> myMap3 = myClassLoader1.loadClass("MyMap");

        //myMap1 == myMap2  != myMap3
//        Object instance = myMap.newInstance();
    }
}

class MyClassLoader extends ClassLoader{

    @Override
    protected Class<?> findClass(String name) throws ClassNotFoundException {
        String path = "e:\\myclassPath\\" + name + ".class";

        try{

            ByteArrayOutputStream os = new ByteArrayOutputStream();
            Files.copy(Paths.get(path),os);

            //得到字节数组
            byte[] bytes = os.toByteArray();

            //byte[] -> *.class
            return defineClass(name,bytes,0,bytes.length);

        }catch (IOException e){
            e.printStackTrace();
            throw new ClassNotFoundException("类文件未加载到");
        }
    }
}


```

##### 双亲委派模型

##### 打破双亲模式

DriverManager它是rt,jar包中定义的类，因此它的类加载器是bootstrap，而Driver是各个厂商提供的类，属于application加载的范畴，因此不能使用driverManager的类加载器直接去加载Driver。

双亲委派模型并不是一个强制性的约束模型，而是java设计者推荐给开发者使用的一种类加载器实现模型，它虽然解决了**类的唯一性问题（防止内存中存在多个同名类型）**：使用不同类加载器加载的类最终都会被同一个类加载器加载——也就是说，用户要使用DriverManager，那么使用时DriverManager会被bootstrap加载，但是现在DriverManager相应根据用户传入的String去加载这个Driver，就加载不了了，因为DriverManager只能使用bootstrap加载，它没有更高一级的领导，更不可能往下委托，这就是双亲模型的缺陷——**上层类无法回调下层类的代码**（下层类需要使用上层类代码时，可以直接new或者反射调用，反正肯定能将上层类加载入内存，但是上层类没法这么做，因为它没法加载一个下层类）

**什么是打破双亲**？
本来按照双亲委派的规则，上层类（启动）无法加载下层类（应用），但是我通过某种方式达到这个目的——主动违背委派模型。

driverManager使用的是调用类的类加载器或者线程上下文类加载器去加载的Driver。


*为什么不选择从下往上加载*
	因为这样的话就写死了，每一个父加载器都要知道它的子加载器是谁，写死，不方便扩展
	而双亲委派父类不必知道子类，找不到就抛异常，由子类catch后自己尝试加载


#### 连接
连接和加载阶段是可以一起进行的，连接就是“link：链在一起”，可以细分为：
1. 验证：文件格式、元数据、字节码、符号引用验证
2. 准备：为静态变量分配内存（堆）并设置零值。如果存在constantValue属性，通常就是在准备阶段进行赋值。（否则在初始化阶段，在\<clinit\>()中赋值）
3. 解析：符号引用解析为直接引用。非虚方法就是在这个阶段完成


#### 初始化
为静态字段赋初值。将为静态变量赋值的语句、static块收敛到\<clinit\>方法中执行。JVM保证子类的\<clinit\>执行前，父类的\<clinit\>已经完成调用。
>不管是\<clinit\>还\<init\>，多线程环境下都是可以保证互斥调用的，jvm提供初始化锁。如果多个线程同时初始化一个类或实例，那么只有一个线程可以成功执行该方法，其他线程必须阻塞


### 主动使用问题
一个类被加载，但是不一定会触发初始化行为，以下情况则一定会触发类的初始化（有且仅有）
1. new关键字（触发了构造器）
2. 读取/修改静态变量（除了静态常量）
3. 执行静态方法
4. Class.forName()
5. loadClass(），且第二个参数为true（初始化=true）
6. 初始化一个类的子类
7. 包含main方法的类（主类）


### static
静态创建，被static修饰的字段或者方法都是属于类的，不依赖于任何一个实例。
一旦类加载完毕，堆中便存在一个class实例，类的实例成员与方法可以看作与class实例绑定。
class文件中，static修饰的方法和字段与实例字段、方法一样存放在class文件的字段表和方法表。不同的是，访问标志ACC_static为true。

对于static修饰的方法，在类解析阶段便可以确定唯一调用版本。对于static修饰的字段，在类准备阶段就已经分配好内存空间并赋零值了。初始化阶段使用\<clinit\>()初始化。

### this与static无法共存的本质
static方法和实例方法的执行都是基于栈的，区别不多，一个是invokeVirtual/invokestatic，另一个是static方法栈帧的局部变量表中没有参数this，而实例方法中的局部变量表中，第一个参数总是预留给this的。这也是为什么static方法中为什么不能出现this的原因。
语义上：static属于类，this代表当前实例，二者生命周期不一致
实现上：static方法栈帧的局部变量表没有保存this的引用，因此无法使用this。（除非你把this作为一个引用类型，通过参数的形式传入方法中）


### 对象

#### 对象内存
 对象存放在堆内存，一个对象可以划分为三个部分：
1. 对象头：对象元信息
2. 实例数据：对象存储的有效信息
3. 对齐填充：保证对象是8的整数倍，因此最小的对象也会占用8字节
   
对象头主要包含两类信息：对象本身的运行时数据（mark word）和类型指针
通过类型指针，可以指定这个对象的真实类型是什么（属于哪个的实例）。如果是数组还会保存一个用于标记长度的数据。

>java的数组类型是jvm运行时基于newarray指令动态创建的，长度字段直接维护在底层的对象结构中

mark word包含了各种运行时数据，包含hashCode值、锁标记、对象分代年龄、GC标记等


#### 对象的创建过程

1. 查找类在常量池中的引入，如果不是直接引用则说明类还未必加载，则会对类进行加载、连接和初始化。
2. 为对象分配内存空间，并且置零值，此时一个空对象创建完毕。
	>如果内存规整，则使用指针碰撞的方式分配内存：把空闲与非空闲内存使用一个指针隔开，分配内存移动指针实现  
	 如果内存不规整，则使用空闲列表管理内存  
	 更新基于CAS保证原子性，如内存分配
	 
3. 设置对象头，完成对象的构造
4. 执行\<init\>()进行初始化（实例属性和构造块按照顺序收敛，最后是构造函数）
5. 将堆中对象的首地址赋值给引用变量，入栈

##### 对象存放位置
除了在堆存放，还可以在栈和TLAB（TLAB本质也是在堆，只不过避免了CAS）

#### 对象的创建方式

1. new：通过构造函数创建
2. 反射，动态创建：借助java.lang.Class类的newInstance（）方法（调用无参构造器）
3. 使用java.lang.reflectConstructor类的newInstance（）方法（反射调用某个构造器）
4. 使用对象克隆方法clone（）
5. 先进行序列化，然后在调用反序列化（objectInputStream）的readObject方法。（深拷贝）
>静态创建：创建哪个对象编译后JVM就知道了，类已经被载入常量池了。  
>动态创建：JVM仅知道需要加载反射相关的类，但是要创建什么对象只有运行到反射方法才知道，类可能也是运行时载入内存的。（编译后类的符号引用可能没有被放入常量池）


#### new关键字做了什么

通过反编译，可以指定new对应四个指令  
1. new  
在堆中开辟内存空间，并将一个引用类型(this)入栈。
>OS管理内存，jvm向OS申请内存，并且为堆划分出一部分内存，类加载更多的是向jvm方法区申请内存，而创建任意对象则是向jvm的堆区申请内存

2. dup
把栈顶的this拷贝一份，因为之后需要调用（构造器）方法也需要这个引用

3. invokeSpecial
执行构造器方法，参数是一个类的常量池引用，这会触发类的加载。而子类的加载又会触发父类的加载，而且编译器为\<init\>方法首行自动调用父类的\<init\>方法，最终的效果：
执行父\<clinit\>()——> 子\<clinit\>()——>父 \<init\>()——>子\<init\>()
> 我的理解，代码块和变量赋值的动作优先级高于\<init\>()，编译器会默认在构造函数第一句执行空的父构造器，也可以指定。如果没有写构造器则编译器生成默认的空构造器，否则不生成默认空构造器，因此父 \<init\>()中执行的是子\<init\>()指定调用的构造器或者默认构造器。

4. 引用出栈，存入局部变量表（astore）


### this的本质
因此，this本质上就是一个引用，它指向的就是当前实例对象，我们使用this和使用其他的引用无本质区别。
另一方面，new指令的本质就是触发构造器的调用。构造器的写法上是不加返回值的，但是它其实是有返回值的，返回的就是this这个引用。而this引用指向的就是创建完成的对象。

而**实例方法中可以直接使用this，是因为实例方法的局部变量表中总是在第一个位置存放this引用（slot_0）,static则没有this这个隐式参数。**

### super的本质
super代表当前实例从父类继承而来**信息域**的引用（地址）  
也就是说super并不是一个完整的对象，他只是一个内存范围，因此使用super可以访问有限的信息，但是却不能把super当做一个引用
`        Program cur = this;`
`        Object o = super;  报错`
子类字节码中有父类索引，因此可以直接找到父类的各种信息（元信息、方法指令），父类定义的内存全部在子类的内存范围，new开辟的内存空间中，不仅含有子类的数据，也包含父类拿到的数据，子类是父类的延伸，因此子类对象往往比父类对象更占用内存空间。

### 能否访问？
子类能否访问父类的字段和方法由标准ACC_FLAG决定，而且这在编译阶段和类检验阶段已经可以保证这条语义的正确性了。用户看似“没有继承”或者“看不见”，其实是“继承”下来的，同样占用内存空间，这也就解释为什么通过反射暴力破解能够访问到相应的值了——不是拿不到，而是私有字段或方法对应的内存地址禁止访问，这在编译期是可以检查出来的。

总结：
this和super本质上都是指向一段内存（new出来的内存空间）的指针，但是super只能访问该空间的部分数据（专门存储父类信息的内存数据），调用父类构造函数是为这段空间的成员初始化/填充数据。通过super调用方法对应invokeSpecial指令，调用版本编译期确认，就是父类的方法，解析阶段将常量池中的引用解析为直接引用。而this调用的方法对应invokeVirtual，运行时分派，无法确认方法是否被子类重写。

### 什么时候需要自定义类加载器
1. 加密解密：众所周知，java代码很容易被反编译，如果你需要把自己的代码进行加密，可以先将编译后的代码用某种加密算法加密，然后实现自己的类加载器，负责将这段加密后的代码还原。

2. 从非标准的来源加载代码：例如你的部分字节码是放在数据库中甚至是网络上的，就可以自己写个类加载器，从指定的来源加载类。

3. 隔离加载类：作用是运行同一个类的不同版本


## JMM

#### final关键字作用及内存语义
>[this引用逃逸 - JJian - 博客园 (cnblogs.com)](https://www.cnblogs.com/jian0110/p/9369096.html)

[Java内存模型JMM之五final内存语义 - 莫待樱开春来踏雪觅芳踪 - 博客园 (cnblogs.com)](https://www.cnblogs.com/txmfz/p/14755661.html)
```markdown
1.修饰任何变量,都使得**为该变量开辟的内存空间仅能存放一次值，且不可以修改**.这个值可以是一个字面量，也可以是一个地址值。（如果更具体一点：基本类型变量的值不能变，引用类型指向的对象不能变,但其属性可变）

2.修饰方法：方法不能被重写。显然方法被修饰为**final具有意义的前提是继承**。
priate修饰方法使得该方法不能被子类对象使用，而final使得子类对象只能使用父类继承下来的方法而不可以重写。private final中final就没什么必要了，final具有意义的前提是存在继承关系！

3.修饰类：该类不能被继承。显然final和abstract是冲突的，二者如果同时出现是无法通过编译的。
如果把final变量定义在循环中，那么final语义起作用的范围仅仅是当前循环上下文，下一次循环时，此final就非彼final了。（如果把final变量定义在循环外，则仍然有效）

final的不可变语义是编译器保证的，如果对final变量进行二次赋值，则在编译期就可以检查出来。


final还可以保证内存可见性
编译器为final写（初始赋值）操作之后插入写屏障，在读操作之前插入读屏障。

final提供的内存语义  
**保证了一个线程在读取final变量之前必须首先获取包含这个变量的对象的引用（先拿到引用，再读final）。同时，还保证了对象引用被任何线程获取之前，final变量的初始值已经被正确的写入了。（先写final，再拿到引用）**

总结：final保证了对象引用对任意线程线程可见之前，对象的final域已经被初始化。线程在读到一个对象的final域之前，一定先读到该对象的引用。保证了线程不会读取到final域未初始化之前的默认值,**一旦构造器把“this”的引用传递出去，就无法保证了**

 public static void reader () {       //读线程B执行 
        FinalExample object = obj;       //读对象引用 
        int a = object.i;                //读普通域 
         int b = object.j;                //读final域 
 }
```

## MySQL
### MySQL架构
	MySQL服务器可以分为server层和存储引擎层，其中server包含连接器，查询缓存，分析器，优化器，执行器。而存储引擎最大的特点就是基于表和插件式，可以根据不同的应用建立不同的存储引擎表，MySQL默认使用InnoDB
	一个连接进程和MySQL数据库实例通信本质上就是两个进程在通信
	其中连接层负责将数据库实例与客户端程序建立TCP连接，并且完成一些认证，校验的工作
	服务层完成sql解析，分析，优化，缓存以及所有的内置函数。所有跨存储引擎的功能也都在这一层实现：存储过程，触发器，视图等
	存储引擎负责mySQL中数据的存储和提取，存储引擎是基于表的，而且是以插件的形式存在，可以根据不同的表更换不同的存储引擎（存储引擎就是管理如何操作数据的一种方法，数据最终需要存储在磁盘上）
	存储层主要是将数据存储在运行于裸设备的文件系统之上，并完成与存储引擎的交互，这才是数据真正落地的地方，需要os和硬件的支持（如磁盘）
	每个客户端连接都会在服务器进程中拥有一个线程，每个查询都会在单独的线程中执行，对应一个cpu核心中执行，服务器会负责线程的分配和撤销（线程池），因此不需要为每一个新建的连接创建或者销毁线程

### MySQL执行流程
	1.mysql客户端首先与MySQL服务器经tcp3次握手建立连接后，服务器需要对客户端进行认证，一旦认证成功，服务器还会继续验证该客户端是否具有执行某个特定查询的权限
	2.对于select语句，在解析sql之前，服务器会先检查查询缓存，如果能够在其中找到对应的sql，服务器就会返回查询缓存中的结果集（这部分在MySQL8中被移除，因为一旦进行任何一个更新操作，整个缓存都会被清空）
	3.分析器对查询语句进行扫描，词法分析和语法分析，如果SQL语句有误，那么就会收到 you have an error in your SQL 的错误提示
	之后还会对合法的查询语句进行语义检查，检查语句中的数据库对象如关系名，属性名是否存在。还会对用户的存取权限进行检查
	4.优化器生成执行计划，并且选择合适的索引，为字段选择合适的查询位置，为多表确定正确的连接顺序
	5.根据优化器生成的执行计划，执行前验证用户有无对应的操作权限,若无直接返回错误信息。由代码生成器生成执行这个查询计划的代码加以执行并回送查询结果，执行器根据表的引擎定义，去调用相应引擎提供的读取接口，最终得到接口返回的结果

### InnoDB引擎

### 两阶段提交
	prepare阶段：修改事务对应的undo页面，将当前事务状态设置为prepare，当然修改undo页面前要记录下redo日志。修改完后将redo日志刷盘
	commit阶段：将事务执行过程中产生的binlog刷新到硬盘，再执行存储引擎的提交工作
	
	当崩溃恢复时，首先按照已经刷新到磁盘的redo日志修改页面，把系统恢复到崩溃前的状态，然后依照各个undo页面链表查看对应事务的状态，若是active状态，直接按照undo日志回滚。
	若是prepare状态，则是否回滚取决于binlog，若binlog已经在硬盘，就将该事务提交，没有就回滚

```markdown
Mysql在存储引擎与插件之间的事务或存储引擎之间的事务，可以看作内部XA事务。最常见的分布式事务就是binlog和innoDB存储引擎之间的事务，由于主从复制的需要，绝大多数的数据库开启binlog。

Mysql的分布式事务指的是内部的多个事务之间的“分布式”，Mysql innoDB支持XA事务，需要定义一个全局唯一的XID，并告知每个事务分支要进行的操作。

这个XA事务最开始作为mysql innodb中binlog 和 redo log之间的事务保障，其中binlog是需要发给从服务器进行重放操作的。Binlog 中记录了XID，用来表示binlog是否成功调用sync。此时Binlog属于XA事务的协调器，以binlog是否成功调用sync作为事务提交的标志。崩溃恢复后，将redo log中的xid与binlog的xid进行比较，如果binlog存在对应的xid则说明完整，redo log提交事务（redo log在prepare阶段已经调用了redo log的sync调用，并且保存了binlog的最后一个xid），否则回滚事务。

在innoDB的事务提交阶段，引入XA事务的目的，是为了保证binlog写入和redo log写入是一个原子操作（**为bin log与redo log开启事务保证**）

引入prepare状态之前，事务只有提交与未提交两种状态，而且事务是基于存储引擎层面实现的。
如果没有prepare状态，mysql恢复后只有两种可能
【1】事务已提交，啥事情没有。
【2】事务未提交，那么就会回滚事务，但是这时有可能binlog已经落盘。这时候slave和master就会数据不一致。（innoDB的事务并没有保证binlog和redo log能够原子更新，因此需要引入XA事务）
引入prepare后，mysql恢复后会多一个判断，如果处于prepare且binlog数据落盘，则事务直接提交。否则回滚（因为提交失败了）

XA事务的崩溃恢复：
【1】扫描最后一个binlog，提取xid（标识binlog的第几个event，xid标准标志着事务已经完成）
【2】xid也会写入redo，将redo 中prepare状态的xid和最后一个binlog的xid进行比较，如果存在则提交。（事务是不会跨binlog的）

```


执行一条UPDATE语句过程中都发生了什么事情。当优化器分析出成本最小的执行计划后，就开始对执行计划中的各个扫描扫描区间中的记录进行更新。具体更新一条记录的流程如下：

1. 先在B+树中定位到该记录（这个过程也被称作加锁读），如果该记录所在的页面不在buffer pool里，先将其加载到buffer pool里再读取。
2. 读取到记录后判断记录更新前后是否一样，一样的话就跳过该记录，否则进行后续步骤。
3. 首先更新聚簇索引记录。更新聚簇索引记录时：①先向Undo页面写undo日志。不过由于这是在更改页面，所以修改Undo页面前需要先记录一下相应的redo日志。②真正的更新记录。不过在真正更新记录前也需要记录相应的redo日志。
4. 更新其他的二级索引记录。

至此，一条记录就更新完了。

然后开始记录该语句对应的binlog日志，此时记录的binlog并没有刷新到硬盘上的binlog日志文件，在事务提交时才会统一将该事务运行过程中的所有binlog日志刷新到硬盘。


下面就是两阶段提交

**内部XA**

对于一台服务器来说，即使客户端使用`BEGIN/START TRANSACTION`语句开启的普通事务，该事务所包含的语句也有可能涉及多个存储引擎。此时MySQL内部采用XA规范来保证所有支持事务的存储引擎要么全部提交，要么全部回滚，这也被称作MySQL的`内部XA`。

另外有一点值得注意的是，`内部XA`除了解决这种设计多个存储引擎的事务之外，还解决保证binlog和存储引擎所做的修改是一致的问题。我们稍后重点展开一下这个问题。

在MySQL内部执行一个事务时，存储引擎会修改相应的数据，server层会记录语句对应的binlog。这是两个要么都完成，要么都不完成的事情。否则的话：

•如果存储引擎修改了相应数据并且提交了事务，而server层却未写入binlog。在有主从复制的场景中，意味着这个事务不会在从库中得以执行，从而造成主从之间的数据不一致。

•如果server层写入了binlog，但存储引擎却回滚了事务。在有主从复制的场景中，意味着这个事务会在从库中得以执行，从而造成主从之间的数据不一致。

那我们需要保证：**如果存储引擎提交了事务，server层的binlog日志必须也被写入到硬盘上；如果存储引擎回滚了事务，server层的binlog日志必须不能被写入到硬盘上**。

MySQL采用`内部XA`来实现上述内容，下边以Innodb存储引擎为例，具体讨论一下Innodb事务的提交和binlog日志写入的过程。

当客户端执行`COMMIT`语句或者在自动提交的情况下，MySQL内部开启一个XA事务，分两阶段来完成XA事务的提交：

- Prepare阶段：存储引擎将该事务执行过程中产生的redo日志刷盘，并且将本事务的状态设置为`PREPARE`。binlog啥也不干。

prepare阶段会将事务对应的undo页面状态修改为prepare，还会记录下本次内部XA事务的xid，这些对undo页面的操作也会记录到相应的redo日志，随后跟记录数据页修改的redo日志一起刷盘


  
- Commit阶段：先将事务执行过程中产生的binlog刷新到硬盘，再执行存储引擎的提交工作。
会把本次更新对应的binlog文件名称和这次 更新的binlog日志在文件里的位置，都写入到redo log日志文件里去，同时在redo log日志文件里写入一个commit标 记。 在完成这个事情之后，才算最终完成了事务的提交

对于处于PREPARE状态的事务，存储引擎既可以提交，也可以回滚，这取决于目前该事务对应的binlog是否已经写入硬盘。这时就会读取最后一个binlog日志文件，从日志文件中找一下有没有该PREPARE事务对应的xid记录，如果有的话，就将该事务提交，否则就回滚好了。




commit意义：用来保持redo log日志与binlog日志一致的。

两阶段提交是为了**保证redo log和bin log的数据一致性**。

commit阶段之前的崩溃，都是通过undo log进行回滚的。而如果是commit阶段崩溃，需要考虑binlog的状态：  
【1】如果binlog的记录是完整的，那么使用redo log对页面数据进行重新更新  
【2】如果binlog的记录是不完整的，那么使用undo log进行数据回滚。





**另一版本**：
更新语句update、insert等都是默认开启自动提交事务的，因此当一条记录被更新后，缓冲池中的页面必然会变脏。但是一般不会同步刷新页面，而是通过后台线程异步刷新页面。当事务提交时，默认情况下会将redo log的内容同步到磁盘，当完成这个操作的时候（redo log更新成功（这里仅考虑redo log）），整个更新操作就算完成了。因为redo log是实现原子性和持久性的关键元素，如果日志被成功更新，那么即使脏页发生丢失，也可以通过redo log进行恢复操作  
核心就是WAL（write ahead log）——**先同步日志，再将数据写入磁盘**

innoDB的redo log是固定大小，如果满了就会覆盖开头，循环写入。

两个重要参数（其实就是双指针）：**write pos（当前记录的位置）**和**checkpoint（当前要擦除的位置）**  
一边写一边后移，擦除记录前需要将记录更新到数据文件中，【w,c】之间都是可以使用的空间，如果w追上c则表示redo log满了，暂时不能执行新的更新。  
有了redolog，innoDB可以保证**即使数据库发送异常重启，之前提交的记录都不会丢失**，被称为crash-safe崩溃安全。

Redo log是innoDB独有的日志。Server的日志叫binlog（归档日志/二进制日志），所有引擎都可以使用。Redo log是物理日志，记录“某个页面上做了什么修改”，而binlog是逻辑日志，记录的是语句级别的（statement）或者行的逻辑修改级别的（row）。而且Binlog是追加写入的，达到一定大小后会切换下一个文件，不会覆盖以前的日志。

> Redolog不是记录数据页更新之后的状态，而是记录某个页面、某个偏移量做了什么改动，是物理数据层面的。  
> Binlog有两种模式，statement模式记录SQL语句，row模式记录行的内容（两条，更新前和更新后）

binLog记录了数据库执行更改的所有逻辑操作（如SQL语句），用于做数据规定、数据恢复和数据复制。**不具备崩溃恢复功能**。  
**两阶段提交**  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fdf2b9af4ef4945919ea8cfa51214c16a.png)【1】执行器先调用引擎接口取得ID=2的这行记录，如果数据页存在于内存直接返回给执行器，否则先从磁盘读入内存，然后再返回。（简单概况：**从磁盘或缓冲池中读取（拷贝）目标数据行，放入目标内存区域**）  
【2】记录undo log（事务开启前的数据版本）  
【3】执行器得到记录，将c字段值加一，得到新的记录，再调用引擎接口写入新数据  
【4】**引擎将新数据更新到内存**中（缓冲池中的页面变脏）  
【5】同时**将redo log写入内存**（执行整个事务的过程中，redo log就不断被保存进内存），此时redo log处于**prepare准备状态**。（写入redo log缓冲区，表示预提交）  
【6】执行器生成该操作的binlog，并将binlog写入磁盘（这里的写是广义概念，是否同步到磁盘看具体参数，**默认是不同步磁盘，仅仅从应用程序的binlog cache写入操作系统缓存**）  
【7】执行器调用引擎的提交事务接口，（默认情况下）将redo log写入磁盘，此时redo log处于提交阶段。

会把本次更新对应的binlog文件名称和这次 更新的binlog日志在文件里的位置，都写入到redo log日志文件里去，同时在redo log日志文件里写入一个commit标 记。 在完成这个事情之后，才算最终完成了事务的提交


### 事务及其实现原理
	什么是事务？原子性，一致性，隔离性，持久性

```markdown

先来一发什么是事务:事务保证了数据库将从一种一致性状态转移到另一种一致性状态，事务一般对于一组操作，这组操作的执行是原子的，要么全部完成要么全部失败，而且一旦提交必然能够保证对数据库永久性的改变，即使数据库发生故障也可以恢复数据。而且事务之间应该是独立。  
事务具体体现在ACID四个特性。

A: 一个是事务中的操作要么全部成功,要么全部失败,不存在第三种情况
C:一致性,对数据库的操作总是使得数据库从一个一致性状态变为另一个一致性状态,转钱的例子
I:隔离性,针对不同事务之间相互影响的程度,通常使用锁机制保证两个写事务之间的隔离性,而采用MVCC机制保证读写事务之间的隔离性
D:持久性,事务一旦提交,那么对数据库中数据的修改就是永久性的,不管之后是否发生宕机


原子性:通过undo log和锁实现(若是其他事务发现当前记录被上锁就不能对其上锁,特制互斥锁),如果执行事务的过程中回滚或者mysql实例崩溃,可通过undo log回滚到事务开始前的一致性状态

undo log:分为两种格式:1.insert undo log记录插入操作产生的undo log，只有在事务回滚时需要，事务提交后被丢弃。  
					 2.update undo log记录update和delete操作产生的undo log，**不能在提交事务后进行删除，因为可能被快照读需要（MVCC），提交后加入undo log链表，等待purge线程进行删除**。只有当快照读或者事务回滚不涉及该事务时，对应的日志才会被purge线程同一清除

隔离性:锁机制保证两个写事务之间的隔离性,而采用MVCC机制保证读写事务之间的隔离性

一致性:编不出来,

持久性:由两阶段提交协议保障,而两阶段提交协议就是 redo log 和 bin log,只要bin log 到磁盘上,redo log就随便了

下面来一发日志介绍:

**bin log**:Server层日志,是对mysql操作记录的归档日志,记录的格式有两种:1.statement格式(基于SQL语句记录) 2.row格式(对表数据,结构,索引等的变更操作)

具体设置:当以启动选项 --binlog-format=STATEMENT 启动MySQL服务器时，生成的binlog称作`基于语句的日志`
		当以启动选项 --binlog-format=ROW 启动MySQL服务器时，生成的binlog称作`基于行的日志`。此时会将该语句所改动的记录的全部信息都记录上。

注意:在有主从复制的场景中，使用`基于语句的日志`可能会造成主服务器和从服务器维护的数据不一致的情况。

执行事务的时候，会将binlog写入bin log cache（写入cache比较快，事务通常涉及多个操作，避免每个操作都直接写磁盘造成性能下降），事务最终提交的时候才会将缓存内容同步到磁盘（事务提交的默认行为，syn_binlog参数决定）  
当开始一个事务时，mysql会自动分配一个大小为 binlog cache size的缓存，如果日志内容超过缓存大小，则会把缓存中的日志写入一个临时文件。

同步时机:
1.Syn_binlog=0 ,提交事务时不会马上将binlog cache同步到磁盘，而是写到操作系统的page cache（内核缓存），操作系统崩溃有丢失日志的风险（默认 0）
默认值。事务提交后，将二进制日志从缓冲写入磁盘，但是不进行刷新操作（fsync()），此时只是写入了操作系统缓冲，若操作系统宕机则会丢失部分二进制日志。

2.Syn_binlog=1 每次提交事务都会执行fsync调用，将文件刷新到磁盘
事务提交后，将二进制文件写入磁盘并立即执行刷新操作，相当于是同步写入磁盘，不经过操作系统的缓存

3.Syn_binlog>1 每次提交都写入到page cache，N表示**写缓存的次数**，写缓存次数积累到N次之后才会fsync写入磁盘，mysql崩溃有丢失N个日志的风险


**重做日志redo log**:重做日志用来保证事务的持久性，由重做日志缓存与重做日志文件组成。
WAL技术即**write ahead log**。在一个事务中，数据库实例执行的修改操作将同时对内存中的redo log 与page（内存没有就先读到内存）进行修改。当事务提交时，将**内存中的redo log**持久化（fsync()）到硬盘中即可返回，内存中的脏页将按照一定频率刷入硬盘中。

Redo log **顺序写**，节省了随机写磁盘的IO消耗，循环写。写指针指向当前记录的位置，**检查点指针**指向当前要擦除的位置。当写指针追上检查点指针的时候，就需要暂停所有的更新操作，并将一部分记录进行擦除（redo log内存满了后执行覆盖写，刷新对应脏页）。
对比change buffer:节省随机读的开销


**redo log 的写入磁盘时机**是可以配置的。除了主线程会每秒的写入外 
1.**innodb_flush_log_at_trx_commit=1是默认情况**，事务提交时，强制fsync（阻塞操作）将文件系统缓冲区的数据刷新入磁盘。【值为1的基本都是同步操作】
`写入重做日志文件的操作不是直接写，而是先写入重做日志缓存，再按照一定顺序写入日志文件。默认情况下，属于强制同步写入（没写完就等着），而其他两个选项相当于把同步操作中的若干步骤采用异步操作替换，使得提交可以更快返回。`

2.若为0,提交事务的时候，不立即把 redo log buffer 里的数据刷入磁盘文件的，而是依靠 InnoDB 的主线程每秒执行一次刷新到磁盘。此时可能你提交事务了，结果 mysql 宕机了，然后此时内存里的数据全部丢失

3.若为2,则提交时，将redo cache中的数据全部刷入**文件系统的缓冲区 page cache**，而不是直接进入磁盘文件

刷盘的其他情况:
1.定时处理：后台线程master thread每隔一秒进行同步操作
2.redo log buffer大小占用到 innoDB log buffer size的一半时，进行同步操作

总结下三种:上面两种加上默认策略

重做日志文件的大小对innoDB存储引擎的性能有很多影响，如果设置过大，则恢复需要很长时间，设置太小又可能使得写指针与检查点指针重合，导致频繁异步刷新

从操作日志缓存往磁盘写入时，按照512字节写入（一个扇区的大小、写入的最小单位）。


讲得有点多,开下一页总结,O(∩_∩)O哈哈~
```

```markdown
对比redo log 和 bin log:

Redo日志是物理日志，记录的是对某个数据页做了什么修改，binlog（二进制日志）记录的是语句的逻辑(分两种格式)
Redo是循环写，空间用完会覆盖写。Binlog是追加写，不会覆盖，空间不够用会切换到下一个日志  
二进制日志仅在**事务提交时写入**，只写磁盘一次（默认行为是仅提交时仅写入操作系统缓冲区）。而重做日志可以在**事务进行的过程中被后台线程异步写入磁盘**
Redo log用于崩溃恢复。而binlog用于基于时间点的恢复，还可以用于主从复制

redo log 为什么具有crash-safe能力:
`Mysql将某一页的数据进行同步磁盘操作的时候，将数据刷新到底层磁盘的多个扇区，这个过程无法保证原子性，逻辑日志binlog无法保证崩溃恢复能力，因为它记录的太“抽象”，没有redo log具体。`

本质原因就是 binlog是写前日志,无法判断追加写后在BufferPool 中的 page有没有刷到磁盘
而redo log中存储的是没有刷入磁盘的数据,只要刷入磁盘,数据就会从redo中被删除

crash后,如何恢复未刷盘的数据到内存中:
根据 redo log 和 binlog 的两阶段提交，未持久化的数据分为几种情况：

change buffer 写入，redo log 虽然做了 fsync 但未 commit，binlog 未 fsync 到磁盘，这部分数据丢失。
change buffer 写入，redo log fsync 未 commit，binlog 已经 fsync 到磁盘，先从 binlog 恢复 redo log，再从 redo log 恢复 change buffer。
change buffer 写入，redo log 和 binlog 都已经 fsync，直接从 redo log 里恢复。


每当系统重启时，都会先进入恢复过程。

此时首先按照已经刷新到磁盘的redo日志修改页面，把系统恢复到崩溃前的状态。

然后在表空间中找一下各个`Undo页面链表`的首个页面的页号，然后就可以读取该页面的各种信息。通过这个页面，我们可以知道该`Undo页面链表`对应的事务状态是什么：
1.如果是`TRX_UNDO_ACTIVE`状态，也就是活跃状态，直接按照undo日志里记载的内容将其回滚就好了。
2.如果是`TRX_UNDO_PREPARE`状态，那么是提交还是回滚就取决于binlog的状态了，我们稍后再说。
3.如果是其他状态，就将该事务提交即可。
对于处于PREPARE状态的事务，存储引擎既可以提交，也可以回滚，这取决于目前该事务对应的binlog是否已经写入硬盘。这时就会读取最后一个binlog日志文件，从日志文件中找一下有没有该PREPARE事务对应的xid记录，如果有的话，就将该事务提交，否则就回滚好了。
```


#### 事务隔离级别及实现原理
```markdown
脏读,读已提交,可重复读,串行化

脏读:一个事务还没提交,他做的变更能被其他事务看见
读已提交:一个事务提交之后,他做的变更才能被其他事务看见
可重复读:一个事务执行过程中看到的数据,总是跟这个事务启动时看到的一样
串行化:通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超 时现象和锁竞争。


**读已提交如何解决脏读问题? || 可重复读如何解决幻读?**

快照读全依赖MVCC,而MVCC机制是由版本链和读视图来实现的.区别就是读视图什么时候形成
这样来看MVCC就是避免读写冲突

而当前读的话,区别就是 间隙锁加不加的问题



**版本链作用就是记录着数据的历史版本,而读视图就是判断版本链中哪个版本对当前事务是可见的**

首先讲下**版本链**:InnoDB存储引擎的表,其聚簇索引记录中都包含两个必要的列,一个是trx_id,代表对该条数据进行修改的事务id;另一个是roll_pointer,每次对某条聚簇索引记录进行改动时,都会把旧的版本写入undo日志中,然后这个隐藏列就相当于一个指针,通过他来找到该记录前改签的信息.这些旧的版本通过roll_pointer属性连接起来,就串成一个链表,这就是版本链

**读视图**:记录着当前系统中还有哪些活跃的读写事务,将它们的事务id放到一个列表中,这样在访问某条记录时,按照规则就可以判断记录的那个版本对当前事务可见,另外还会存储两个值,一个代表生成读视图时列表中的最小值,另一个代表生成读视图时系统应该分配给下一个事物的id值:
1.若是记录的trx_id 列小于 min_trx_id,可见
2.若是记录的...大于 max_trx_id,不可见
3.>= min_trx_id && <= max_trx_id,就需要判断下trx_id在不在m_ids中,在就不可见,不在可见

如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本，如果最后一个版本也不可见的话，那么就意味着该条记录对该事务不可见，查询结果就不包含该记录。




```


### 索引

#### 索引的意义
索引就是书签，有了索引可以对内容进行快速定位，实现**加速读**。  
如果把一张表看作一个内容线性表，没有索引的表可能就是一个普通的链表结构，我们只能从头读到尾，而具备索引结构，它就可以看作一个跳表结构，可以支持部分随机读取的行为。  
具体的谈论索引，我们必须具体到某一种实现。


#### 索引优缺点
索引具有以下优点：  
1. 提高查询速度、表连接速度  
2. 避免额外的内存或临时文件排序，减少排序和分组的时间  
3. 唯一索引保证每一行数据的唯一性

维护索引的数据结构，也需要付出以下代价：  
1. 维护、创建、**页合并**、**页分裂**等操作耗时  
2. 创建索引时，需要**对表进行加锁**，可能会其他事务的影响正常操作（锁其实就是基于索引实现的）  
3. 索引缓存和各种索引文件需要额外占用内存和磁盘资源（需要有额外的文件和内存去存放索引）  
4. 修改数据时会触发索引的维护，降低性能


#### 索引的建立

##### 索引设计原则
1. 主键自动建立唯一索引  
2. **频繁作为查询条件的字段**应该建立索引  
3. **被驱动表关联的字段**，**外键关系建立索引**  
4. 频繁更新的字段不适合建立索引（因为每次更新不仅仅更新数据还要更新索引）  
5. Where条件中用不到的字段不创建索引  
6. 高并发下倾向创建联合索引  
7. 查询中**排序的字段**，若通过索引去访问排序字段将大大提高排序速度  
8. 查询中统计或者**分组字段**  
9. **写多读少**的字段，如果要键索引则应该建立**普通非唯一索引**


不适合建立索引的情况：  
1. 表记录太少（少于一千）  
2. 经常增删改的表  
3. **区分度不高**的字段不适合建立索引，如性别等(数据重复且分布平均的表字段（例如性别，如果一个表中男女各半，则每次根据性别查询都需要回表查出50%的数据，性能远不如全表扫描）)
4. **参与列计算**的列不适合建索引


维护索引不但需要在磁盘上维护索引文件，还需要在内存中维护存放索引页的内存区。另一方面，B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。不免涉及到数据的移动和数据页的增加和删减。  
一个数据页满了，按照B+Tree算法需要新增加一个数据页进行数据分散，需要进行**页分裂**，会导致性能下降。空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做数据**页合并**，合并的过程是分裂过程的逆过程


##### InnoDB的索引
mysql具有许多需要遍历元素的场景：范围查询、全表查询、关联子查询等，因此B+树是更合适的，而B树更适合于单条记录的查询。innoDB使用B+树索引模型，所以数据都是存储在B+树中的，每一个索引在innoDB中对应一颗B+树。索引文件和数据文件存放在表空间中，而且mysql为每一个索引分配两个段去存放叶子节点和非叶子节点。


**索引创建**
索引可以分为三类：  
1. 单值索引：一个索引只包含单个列，一个表可以有多个单列索引  
2. 唯一索引：索引列的值必须唯一，但允许有空值  
3. 复合索引:即一个索引包含多个列

创建方式：
1. 创建表的时候创建索引：
```sql
create table testTable(  
    id int not null,   
    username varchar(16) not null,  
    index [indexName] (username(length))  -- 为字符类型创建索引可以指定前缀
); 
```


2. 创建表之后创建索引：（index前面可以加上unique前缀表示唯一索引，否则默认普通索引）
```sql
CREATE INDEX idx_ceo_deptnam ON dept(ceo,deptname)
CREATE INDEX idx_deptnam ON dept(deptname)
CREATE INDEX idx_deptid ON emp(deptid)
```

**CREATE INDEX** 索引名称 **ON** 表名（字段名）  
（mysql会默认对主键创建一个索引——主键索引）

展示索引：**SHOW INDEX FROM** 表名  
删除索引：**DROP INDEX** 索引名 **ON** 表名


#### 索引的数据结构
索引本质上就是一种数据结构，它支持快速查找

1. 有序数组  
查询效率很高，因为**有序数组结构适合通过二分查找算法**，但是插入删除可能会造成整体拷贝，因此更加适合**静态存储引擎**或者**只读的数据类型存储**。例如：历史记录，用户可以通过日期快速从有序数组中找到历史记录。  
2. 哈希表  
哈希表的效率一定程度上依赖哈希函数（桶映射函数）和解决哈希冲突的方案。  
输入待查找的值作为key，通过对key进行哈希计算得到一个桶的索引，一般通过链表法解决哈希冲突，因此**查询效率高，增删效率也高**。  
但是由于元素在桶内的分布是无序的，因此做区间查询的时候很慢，仅适合做**等值查询**的场景，如nosql的redis数据库。  
**哈希表实现索引的限制**：  
a.只能包含哈希值和行指针，无法存储字段值或数据行，因此**无法避免回表**  
b.不支持部分索引匹配查找，因为hash索引始终使用索引列的全部内容计算hash值的，**不能更好的利用联合索引**

> 如果索引使用哈希表实现，则一个索引对应一颗哈希表。默认会对主键建立一个索引（哈希表）。假如对name字段建立索引，则磁盘上至少存在两个索引文件。Where name = ‘123’，首先查询name索引文件，通过hash(‘123’)得到键值对的存放位置，得到‘123’-主键id，然后再查询一次主键索引哈希表得到最终的记录。

c.hash索引不是按照索引值顺序存储的，**天生无序**。  
d.仅支持等值查询  
e.存在哈希冲突问题

innoDB会在系统自动生成**自适应索引**，由于哈希表是离散存储的，因此无法排序，也不支持最左前缀索引，而且存储哈希冲突的问题，不支持范围查询。

3. 平衡二叉树/红黑树

> 搜索二叉树、平衡二叉树和红黑树都是二叉树，其中平衡二叉树解决了搜索二叉树“在一定情况下会退化成单向链表”的问题，而平衡二叉树的约束过多且实现复杂，红黑树可以看作平衡二叉树的一种“弱平衡性”的一种实现方案。

平衡二叉树的查询速度是log2(N)，每次查找都是一次二分，但是每一层分叉过少的代价就是树的高度过高，每一层查找都是一次磁盘I/O，**平衡二叉树的查询成本随着树高升高而增加**，因此平衡二叉树不适合作为数据库的索引结构。

> 每次查找都会将索引页面读入内存，然后确定下一个需要读入的索引页面，因为页面本身也是有序的，因此在内存中的查找是很快的（可以基于二分查找算法），而这时的瓶颈就在于它是二叉还是二十叉了，而是在于I/O导致的时间开销，因为每读入一次节点都至少需要一次I/O，而一层中不管几个节点都是对应一次I/O，**树高过高导致I/O次数上升才是正在的瓶颈**，因此**二叉树更多用于内存结果对象的查找，比如在内存中维护一个treeMap作为作为内存索引结构**。

4. B树/B+树（多叉平衡树）  
B树是专门为磁盘设备设计的平衡查找树，它相对于二叉平衡树有了更适合磁盘I/O的特点，如：**树的节点可以存放多个元素**，这样树的高度就得到了压缩，查询某个节点可以进行更少的I/O次数。B树的节点单位通常与磁盘的存储单位是对应的，**数据库设计者通常利用磁盘预读原理，将一个节点的大小设计等于一个页的大小，这样每个节点只需要一次I/O便可以完全载入**，因此每次读入内存的其实是一个数据块或索引块。  
另一方面，B数节点中的元素数据行都是有序的，这就**降低了排序成本，将随机I/O转换为了顺序I/O**，避免为排序分配临时内存或临时中间文件。



##### B树和B+树

感觉还是key值,指针和数据行较好

一颗M叉的B树是一颗平衡的M路搜索树，**所有叶子节点都在同一层，每个节点中即存放key值又存放指针**。  
而B+树是B树的变种，**B+树的叶子节点用于保存key值的信息，而所有的非叶子节点都可以看作是搜索目标叶子节点的索引部分**。  
B+树的所有叶子节点都新增了**链表指针**，这使得所有数据在B+数叶子节点中按照key排序。

**B树通过压缩高度虽然解决了“磁盘IO次数较多的问题”，但是未能解决遍历查找效率低下的问题**

B+树索引每次加载出的都是一个页，页中包含多个数据行。根据索引字段可以定位数据行所在的数据页，将数据页加载进入内存。在内存值通过对索引的key值进行二分查找可以取出对应数据行。  
B+树非叶子节点可以看作索引节点，不存储数据行，所有数据行存在于叶子节点。这使得**B+树搜索可以更加稳定**（因此连接查询时总是将小表做主表），**每个叶子节点可以存储的元素更多**，查询所需的IO次数也会更少，一个数据页可以包含更多的数据行。

**B+树更适合进行范围查找**，因为遍历一个范围的元素，只需要遍历叶子节点。而B树的不同页面之间不连续，如果要进行范围扫描，B+树以链表的形式扫描聚簇索引叶子节点进行优化，而**B树需要同时在多个节点之间切换**，因为B树节点内部的数据行虽然是有序的，但是从节点之间看，则是不连续的。

而**B树更加适合等值查找**，因为B树的key不像B+树全部存储在叶子节点，因此如果对B树查询某个key，很可能在某个距离根很近的位置就能找到，而最坏的情况才是在叶子结点找到。另一方，B树不适合大范围的搜索，如果仅仅是小范围的搜索并不影响性能，如果需要大范围遍历，顺序I/O将退化为随机I/O（不断回旋查找），从而导致I/O次数上升，性能下降。**B+树含有数据行的节点都是叶子结点，有序且相连，直接对叶子节点遍历即可，查找较稳定，遍历元素效率高**

B+树的非叶子节点会冗余一份在叶子节点中（所有的非叶子节点key都保存一份key/value到叶子节点），并且叶子节点之间使用指针相连。B树一个叶子节点可以存储多个元素，相当于完全平衡二叉树整体的树高降低了，磁盘IO效率提升了。而**B+树只是通过叶子节点冗余非叶子节点，提升了范围查找的效率，B+树同时也具有B树的一切优点**。

> 树的路数也不是无限延伸的， 如果树的路数无限延伸则会**退化成一个有序数组**，如果数据量过大**无法一次性载入内存，会进行多次IO**，效率会下降。**因为树高下降，索引的粒度（叉数）就会变大，节点装入的内容变多，会多于一页**，这样读入一个页面可能需要至少两次I/O

总结：  
B+数的单一节点存放更多数据，IO效率高。由于每次都是从叶子节点载入页面，查找更稳定。天然有序，便于范围查询和排序。  
B树比较适合单值查询，因为如果所在页靠近根结点，那么可以很快锁定目标页。



#### (非)聚簇索引和辅助索引

聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页(而MySQL也确实是以数据页为单位进行读取,淘汰)。这个特性决定了索引组织表中数据也是索引的一部分，每张表只能拥有一个聚簇索引。

**主键索引**的叶子节点存的是**key所在的数据行**。在InnoDB里，主键索引也被称为**聚簇索引**  
**非主键索引**的叶子节点内容是**主键的值**。在InnoDB里，非主键索引也被称为**辅助索引**  
而搜索辅助索引的B+树，最终拿到的也只是一个主键的ID值罢了，必须再一次通过这个主键id搜索聚簇索引对应的B+树，拿到最终的页面载入内存，因此其实搜索了两次B+树，这种行为就叫做**回表**。


MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址
MyISAM引擎使用B+Tree作为索引结构，叶节点的**data域存放的是数据记录的地址**

非聚簇索引：主键索引和辅助索引存储都是存储一个指向真正表数据的地址，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。


#### 索引查找规则

```markdown
1.索引覆盖:查询的列被所建的索引覆盖.select的数据列可以从辅助索引的叶子节点中就可以取得,不必通过回表再次读取数据行,如果索引不能覆盖查询的所有列,则不得不每扫描记录就进行一次回表,这属于随机IO,这种情况下,按照索引顺序读取数据可能比全表扫描慢,这时优化器可能放弃走索引而选择全表扫描
2.最左前缀:列的排列顺序决定了可命中的索引列数,最左前缀原则帮助用户更好的设计联合索引，通过复用联合索引减少创建单独索引的开销
创建一个联合索引的时候如（name,age,sex），逻辑上其实创建了三个索引（name）、（name,age）和（name,age,sex）。联合索引的最左N个字段，也可以是字符串索引的最左N个字符。因为B+树对数据行的存储依照（name,age,sex）三个关键字进行排序（先按照name排序，name相同按照age，age相同按照sex）。

3.索引下推(下沉):索引下推可以在索引遍历过程中对**索引中包含的字段**先进行判断，过滤到不满足的条件，**减少回表的次数**
注意：参与索引下沉的过滤项，一定要是**索引中的字段**。

```

#####  最左前缀 

基于B+树结构的组合索引的基础上,查询条件字段能按从左到右的顺序,连续的命中组合索引的列数,决定了能使用组合索引的前多少个字段实现加速读的效果,查询条件得是 等值, 若是范围查询,就会停止匹配,组合索引后面的字段无法参与加速读

本质就是mysql按从左到右的顺序进行查找

对`(a,b,c)`建立索引，查询条件使用 a/ab/abc 会走索引，使用 bc 不会走索引。

对`(a,b,c,d)`建立索引，查询条件为`a = 1 and b = 2 and c > 3 and d = 4`，那么a、b和c三个字段能用到索引，而d无法使用索引。因为遇到了范围查询。

如下图，对(a, b) 建立索引，a 在索引树中是全局有序的，而 b 是全局无序，局部有序（当a相等时，会根据b进行）。直接执行`b = 2`这种查询条件无法使用索引。

![最左前缀](https://uploadfiles.nowcoder.com/files/20211030/8683776_1635580314321/%E6%9C%80%E5%B7%A6%E5%89%8D%E7%BC%80.png)

当a的值确定的时候，b是有序的。例如`a = 1`时，b值为1，2是有序的状态。当`a = 2`时候，b的值为1，4也是有序状态。 当执行`a = 1 and b = 2`时a和b字段能用到索引。而执行`a > 1 and b = 2`时，a字段能用到索引，b字段用不到索引。因为a的值此时是一个范围，不是固定的，在这个范围内b值不是有序的，因此b字段无法使用索引。



#### 关联查询优化

LEFT JOIN 条件用于确定如何从右表搜索行,左边一定都有,所以**右边是关键点,一定需要建立索引**，相当于是一个双循环，外循环遍历所有行，而对于外循环的每一行，如果不进行任何优化则是O（n）复杂度，而如果建立索引则可以优化到O（logm(n)）。

1. 能够直接多表关联的，**尽量直接关联，不使用子查询**  
2. 尽量减少join语句中的循环总次数，不用join过多或嵌套，永远使用小结果集驱动大结果集【内循环使用B+索引查询，很稳定，因此决定于外循环，外循环结果集越小越好】

**当B表的数据集必须小于A表数据集时，in 优于exists**  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F6eab2f77691743a4854c73e431e49c47.png)被驱动表 in (驱动表)  
**当A表的数据集必须小于B表数据集时，exists优于in**  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F120006eb05bd4c648953e8c878b34822.png)驱动表 exists （被驱动表）

> Exists——将主查询的数据，放入子查询中做条件验证，根据返回值（true或false）来决定主查询的数据结果是否得以保留

**被驱动表需要在相应字段建立索引**

```SQL
SELECT * from student
where student.SId in 
(SELECT sc.sid from sc)

    
```

效果上等价于

```SQL
SELECT * from student
where EXISTS (SELECT 1 from sc WHERE sc.sid=student.sid)

    
```

内连接时，mysql优化器会自动帮你把小结果集选为驱动表，因为驱动表无论如何都会被全表扫描，所以扫描次数越少越好。  
子查询生成的子表尽量作为驱动表，因为如果作为被驱动表可能不能被选择索引

#### 分组与排序优化
Order by满足两种情况时，会基于索引方式排序：  
1. order by语句使用索引的最左前列  
2. **使用where子句与order by子句条件列组合满足索引最左前列**  
尽可能在索引列上完成排序操作，遵循索引键的最佳左前缀

使用索引的排序，不需要开辟额外排序内存或者临时文件，通过索引依次按照顺序扫描一组主键id，然后通过回表取出数据行并拼装结果集（如果select的内容直接可以从叶子节点拿到，那直接走覆盖索引，可以避免回表）。

注意：order by时，select * 是一个大忌

**Group by 使用索引的原则几乎和order by一致，唯一区别是group by即使没有过滤条件使用索引，也可以直接使用索引**

> 当范围条件和group by或者order by的字段出现二选一的时候，优先观察条件字段的过滤数量，如果过滤数量足够多，而需要排序的数据并不多的时候，优先把索引放在范围字段上。

**Group by实质是先排序后分组**，按照索引建的最佳左前缀。Where优先于having，能写在where限定的条件就不要去having限定了


#### limit优化
Limit语法由偏移量offset和取值数量size组成，其中偏移量默认从0开始，其中limit 10000，10代表从第10001条数据开始取，取size个。注意这里是扫描到10001条数据后，开始往后拿数据，而前面这些数据都被抛弃了，因此offset特别大的时候，效率非常低

```sql
Select * from Student limit 1000,10

    
```

可以被改造为：

```sql
Select * from Student 
Join (Select id  from Student limit 1000,10 ) as stu
On student.id = stu.id

    
```

子查询id是主键，本身就是一个索引结构，因此外部进行关联时能够很快取出对应的数据行。内部查询是id，其效率高于*，相当于内部查询到10个id，然后外部通过id拿到对应数据行。


### 索引失效分析和解决方案


#### 范围过大

【1】使用不等号!=或<>、not in 、is not null 的时候优化器使用全表扫描  
【2】like 以通配符开头如(’%a’)，可以使用**覆盖索引**解决。  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F6184dabe3ad148088c480869c97ce0e1.png)使用覆盖索引的情况：  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fb3e551a28455480d9183340d2ea7979c.png)【3】使用or进行连接

#### 隐式转型

【1】在索引列一则执行计算等操作，如计算、函数、类型转换。例如 where a+1=3  
【2】字符串不加单引号导致索引失效（例如：name=张三 会导致失效）  
【3】隐式编码格式转换也会导致失效，应该使两个表的字符集相同

> 如果对索引字段做函数操作，可能破坏索引值的有序性，这种情况下，优化器放弃走索引树的搜索，而是全索引表扫描（只是放弃了通过非叶子节点定位，而是直接遍历叶子节点）。同理where id + 1 =99不可以 where id =99-1可以

#### 其他

【1】搜索引擎不能使用索引中**范围条件右边的列**。  
【2】错误使用最左前缀法则。  
【3】**如果对主键进行删除或者重建，会导致整个表的重建**

> 例如index(a,b,c),where b=3 不可以。where a=3 and c=5 使用了a，但是c不可以（找到aXX节点对应的id叶子节点）（因为抛开a，单独看b或者c，它们并不是全局有序的，不能作为扫描使用的标志，仅能用作一些过滤和优化）  
> where a=3 and b>2 and c=5 使用了a b,但是c不能用在范围之后。（找到abX节点对应的所有id叶子节点）

注意，如果where的内容是四个const。建立的索引如index（a,b,c,d）,查询顺序为d,c,b,a或者a,b,d,c。Mysql的查询优化器会最终调整为a,b,c,d的形式后再进行查询

### 索引的选择

#### change buffer
>[(59条消息) 写缓冲(change buffer)，这次彻底懂了！！！_58沈剑的博客-CSDN博客](https://blog.csdn.net/shenjian58/article/details/93691224)

参数：innodb_change_buffer_max_size

介绍：配置写缓冲的大小，占整个缓冲池的比例，默认值是25%，最大值是50%。

画外音：写多读少的业务，才需要调大这个值，读多写少的业务，25%其实也多了。

参数：innodb_change_buffering

介绍：配置哪些写操作启用写缓冲，可以设置成all/none/inserts/deletes等。





change buffer指的是对“写操作”的缓存，推迟更新的行为。  
需要同时满足两个添加：辅助索引 和 非唯一索引

如果**非唯一普通索引页**不在缓冲池（内存）中，则对页进行写操作时，不会先去加载磁盘，而是**直接将修改操作记录在changeBuffer上**，等到未来数据页被读取时，再将数据合并恢复到缓冲池中。  
后台线程也会时不时地进行合并操作，正常退出mysql时也会合并，其他如重写日志不可用、内存中的changeBuffer超过缓冲池1/2  
**事务提交的时候，changeBuffer的操作已经记录到redo log中了，因此崩溃恢复时可以找回**

changeBuffer适合于==“写多读少”==的场景，如果读操作很频繁，那么写缓存就没有意义了，反而是记录与合并的操作显得很多余。

changeBuffer和数据页一样，是物理页的一个组成部分，**底层是一颗B+树**，负责**对索引表的辅助索引的更新操作进行缓存**，存放于共享表空间。changeBuffer在内存中有缓存，同时也可以持久化到磁盘中。  
changeBuffer在内存的部分占用了缓冲池的内存，默认最大可用占用缓冲池的1/2.

changeBuffer的目的是**降低对磁盘的随机读次数**（更新时不用将页面读入内存，而是更新处于内存中的change buffer结构），磁盘IO是数据库操作中成本最高的一部分，同时数据页不用调入缓冲池，节省了内存空间。而**数据页缓存则是减少了随机写磁盘的IO次数**（每次写内存中的页面，而不是直接写磁盘中的页面，直到redo log失效、后台线程同步等时间发生才会将脏页面更新磁盘）。

如果要修改的字段是唯一索引或者主键，还需要加载数据页，**判断是否违反唯一性约束**，从而导致changeBuffer没有了意义。

总结：  
**读多写少**的场景适合定义**唯一索引**，如果使用普通索引进行等值搜索，搜索到第一个记录后不会停止，因为可能有值重复的记录，会继续搜索直到碰到不相等的记录才会退出。而唯一索引字段在遇到第一个满足条件的记录后，就会自动停止检索。  
由于引擎一次读出一页，因此对于普通索引，引擎需要多做一次指针寻址和判断，如果第一个记录在数据页的最后一条记录，还必须读取下一个数据页。

**写多读少**适合定义**普通（非唯一）索引**，因为普通非唯一索引字段的修改会在写缓存中进行（如果页面不再内存的前提下），不需要频繁的加载页面

普通索引和唯一索引在查询方面区别不大，但是**更新唯一索引字段更加消耗性能**，因此建议使用普通索引。

Redo log主要节省的是随机写磁盘的IO消耗（将随机写入脏页的行为，记录在redo log日志文件中，某一时间点将redo log同步到磁盘，只要redo log成功同步，就不担心脏页更新丢失），而changebuffer主要节省的是随机读磁盘的IO消耗。

#### 索引与约束

约束是一种逻辑上的概念，用于保证数据的完整性，它更像是一种检查机制。而索引是一个数据结构，在数据库中通常有对应的物理存储，而且它具体的功能如加速读取。

#### 自增

> MYLSAM 引擎的自增长值保存在数据文件中  
> innoDB 5.7之前,自增长值保存在内存中，mysql 8将自增长值的变更保存在redo log中，重启时依靠redo log恢复重启之前的值。

插入新数据而进行平衡调整可能会引起**页分裂**（数据页满了，申请新的数据页，移动部分数据），这个过程不但影响性能，还会降低页的利用率。删除操作可能会引发**页合并**。  
**自增主键的插入模式符合递增插入的场景**，不涉及平衡的调整，不会触发叶子节点分裂。同时，**主键长度越小**，**普通索引的叶子节点越小**，普通索引所**占用的空间也就越小**。

> 修改时机：前提是字段被声明为**auto_increment**  
> 【1】插入数据时id没有指定或者被指定为0或者null  
> 【2】使用了具体值X，就使用指定的值。如果要插入的值小于自增值，则表的自增值不变，否则自增计时器的值被更新为X+1。  
> 新的自增值生成算法：从auto_increment_offset开始，以auto_increment_increment为步长，持续叠加，直到找到第一个大于插入值X的值，作为新的自增值。

**唯一键冲突（插入失败）**和**事务回滚**都会导致**自增主键id不连续**，另一个不连续的原因是由于**mysql对批量插入语句分配自增id策略**导致的。

> 如果自增主键用完了，再尝试插入新的数据就会导致主键冲突报错（根据自增主键类型不同，范围也不同）



### InnoDB和MyISAM的数据分布对比

MyISAM的数据分布：按照**数据插入顺序**存储在磁盘上（数据和索引分开存储，通常内存缓存索引数据，而数据由操作系统/文件系统（磁盘）缓存，因此访问数据需要一次系统调用），**叶子节点存储的是“行号”**，这种分布方式很容易创建索引，**且二级索引和主键索引的存储方式相同**

InnoDB的数据分布：聚簇索引的每一个叶子节点都包含了**主键值**，**事务ID**，用于事务和MVCC的**回滚指针**以及所有剩余**数据列**，二级索引和聚簇索引很不同，叶子节点存储的是主键值，这种策略**减少了当出现行移动或者数据页分裂时二级索引的维护工作**。





### 存储结构
innoDB存储引擎中，表都是根据**主键顺序**进行存放的，这种存储方式的表称为索引组织表。  
如果创建一张表的时候没有显示指定主键，则使用**非空的唯一索引**作为主键（如果有多个，则寻找定义索引顺序的第一个非空唯一索引），若不存在则innoDB存储引擎自动创建一个指针结构作为隐式主键。

所有数据都存放在表空间中，表空间由各个段组成，其中数据段存储B+树的叶子节点，索引段存储B+树的非叶子节点。段由若干个区组成，区由连续的页组成，区的对象固定为1MB，默认情况下，innoDB存储引擎页的大小为16KB（一个区中一共有64个连续的页面）。而页面则是innoDB磁盘管理的最小单位，页中的数据按行存放。  
数据库每次读取的就是页中存放的行记录。


### 锁的类型
从对**数据结构的操作类型**分类  
**读锁(共享锁)** 针对同一份数据，多个读操作可以同时进行而不会互相影响。  
**写锁(排它锁)** 当前写操作没有完成前，它会阻断其他写锁和读锁。

从**粒度**分类：表锁和行锁  
MySQL常用的两种引擎MyISAM和InnoDB，MyISAM默认使用表锁，InnoDB默认使用行锁。  
注意：使用InnoDB引擎，如果筛选条件里面没有索引字段，就会锁住整张表，否则的话，锁住相应的行

> Mysql行锁由引擎层实现，mylsam不支持行锁。  
> Mysql也支持lock tables和unlock tables语句，这时服务器层实现的，和存储引擎无关  
> 意向锁是innoDB自己加的，如果要对某个元组加锁，那么需要对上层节点加意向锁。

innoDB采用的是**两阶段锁定协议**。在事务执行的过程中，**随时都可以执行锁定，锁只有在执行commit或者rollback的时候才会释放**，并且所有的锁都是在同一时刻被释放的。**innoDB会根据隔离级别在需要的时候为被事务访问的数据自动加上隐式锁**。

意向锁  
innoDB支持**多粒度锁定**，运行事务在行级和表级的锁同时存在。意向锁将锁定的对象分为多个层次，意向锁表明事务希望在更细粒度上进行上锁。  
假设事务A对某一行加入写锁，事务B希望对该表加入加锁。事务表加锁之前必须对表中的每一行进行遍历，这样效率很低。而**有了意向锁，A加行锁之前，先申请意向锁，申请成功后再申请一行的行锁。而如果事务B希望加表锁，它发现该表存在意向锁，那么申请锁的行为就会被阻塞。**  
**申请意向锁的行为由数据库完成，当事务申请某一行的行锁的时候，数据库会自动该表的意向锁。**

### 数据库的三大范式
[数据库三大范式 - 夏小皮 - 博客园 (cnblogs.com)](https://www.cnblogs.com/xiaxiaopi/p/14373342.html)

```markdown
第一范式:数据项不可以再分,每个字段都应该是原子的,不可分割的.eg: 学号+姓名合在一起当一个字段
第二范式:第一范式基础上,其他数据项完全依赖主键,eg:(学分,学号)当主键
第三范式:第二范式基础上,非主键字段不传递依赖于主键,也不部分依赖于主键,每一列数据和主键直接相关,不能间接相关(也就是不能出现冗余数据,如电影表中增加一列票房统计字段,而这个字段通过观众表与电影表间接相关)

```

### select语句的执行顺序

select的机读流程：  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fa0bd66262d434719b9c296f7bd20af1f.png%3Fx-oss-process%3Dimage%2Fwatermark%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NzkzOTkz%2Csize_16%2Ccolor_FFFFFF%2Ct_70)每一个步骤都会生成一个虚表，并且下一步生成的虚表都是在某一个虚表的基础上生成的，这些中间生成的表对用户不可用，只有最后一步生成的表才会返回给调用者。  
【1】from：对两个表执行笛卡尔积（类比双循环），生成虚表A  
【2】对虚表A进行ON筛选，只有满足条件的行才会被连接并插入虚表B  
【3】外连接（外部行连接）：**保留主表，找到未匹配的、主表一侧的行**添加到B，生成C，如果from子句中多于两个表则重复以上步骤，直到生成唯一的虚拟表。其中从表中与主表没有对应的字段（主表有值，从表没有值）将被赋值为NULL  
【4】对C进行where筛选，符合条件的行插入虚表D  
【5】按照group by字段对D进行分组（先通过临时表排序再分组），生成虚表E  
【6】having子句对E进行筛选，将符合条件的语句插入F  
【7】select从F中选取目标列，生成G  
【8】distinct语句去除重复的行，生成H

> 如果指定了distinct子句，则会创建一张内存临时表（内部不够，使用文件排序），这张临时表的表结构和G表一样，但是**distinct列被增加了唯一索引**

【9】将H中的数据行按照order by字段进行排序，并生成一个游标。注意，**此时select执行完毕，因此可以使用select指定的别名**。

> 这一步返回的是游标。由于SQL是基于**集合**的，因此**不存在预先排序**，对表进行排序的查询可以返回一个对象，包含按特定物理顺序组织的行，这种对象就是游标。

【10】从游标的开始处选择指定数量或者比例的行(例如进行limit操作)，生成结果集返回调用者。

> Limit n,m 从第n条记录（0开始）选择m条记录，但是数据量很大的时候非常低效，因为limit每次从头开始扫描（移动游标对象扫描记录，不走索引，因为走到这个位置时索引的作用已经发挥完毕了，这里返回的游标就是一个迭代器的指针）。

使用了Order by子句的查询不能用作表 表达式（视图、子查询、派生表）  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F0ba979a42a164a17a9bc5908f45dfae5.png)上面这种写法会保存，因为from子句的内容中不是一张表（**带有排序作用的order by子句的查询**），而是一个**对象**，其中的行按特定的顺序组织在一起，这种对象就是游标。

### update语句的执行流程

更新语句update、insert等都是默认开启自动提交事务的，因此当一条记录被更新后，缓冲池中的页面必然会变脏。但是一般不会同步刷新页面，而是通过后台线程异步刷新页面。当事务提交时，默认情况下会将redo log的内容同步到磁盘，当完成这个操作的时候（redo log更新成功（这里仅考虑redo log）），整个更新操作就算完成了。因为redo log是实现原子性和持久性的关键元素，如果日志被成功更新，那么即使脏页发生丢失，也可以通过redo log进行恢复操作  
核心就是WAL（write ahead log）——**先同步日志，再将数据写入磁盘**

innoDB的redo log是固定大小，如果满了就会覆盖开头，循环写入。

两个重要参数（其实就是双指针）：**write pos（当前记录的位置）**和**checkpoint（当前要擦除的位置）**  
一边写一边后移，擦除记录前需要将记录更新到数据文件中，【w,c】之间都是可以使用的空间，如果w追上c则表示redo log满了，暂时不能执行新的更新。  
有了redolog，innoDB可以保证**即使数据库发送异常重启，之前提交的记录都不会丢失**，被称为crash-safe崩溃安全。

Redo log是innoDB独有的日志。Server的日志叫binlog（归档日志/二进制日志），所有引擎都可以使用。Redo log是物理日志，记录“某个页面上做了什么修改”，而binlog是逻辑日志，记录的是语句级别的（statement）或者行的逻辑修改级别的（row）。而且Binlog是追加写入的，达到一定大小后会切换下一个文件，不会覆盖以前的日志。

> Redolog不是记录数据页更新之后的状态，而是记录某个页面、某个偏移量做了什么改动，是物理数据层面的。  
> Binlog有两种模式，statement模式记录SQL语句，row模式记录行的内容（两条，更新前和更新后）

binLog记录了数据库执行更改的所有逻辑操作（如SQL语句），用于做数据规定、数据恢复和数据复制。**不具备崩溃恢复功能**。  
**两阶段提交**  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fdf2b9af4ef4945919ea8cfa51214c16a.png)【1】执行器先调用引擎接口取得ID=2的这行记录，如果数据页存在于内存直接返回给执行器，否则先从磁盘读入内存，然后再返回。（简单概况：**从磁盘或缓冲池中读取（拷贝）目标数据行，放入目标内存区域**）  
【2】记录undo log（事务开启前的数据版本）  
【3】执行器得到记录，将c字段值加一，得到新的记录，再调用引擎接口写入新数据  
【4】**引擎将新数据更新到内存**中（缓冲池中的页面变脏）  
【5】同时**将redo log写入内存**（执行整个事务的过程中，redo log就不断被保存进内存），此时redo log处于**prepare准备状态**。（写入redo log缓冲区，表示预提交）  
【6】执行器生成该操作的binlog，并将binlog写入磁盘（这里的写是广义概念，是否同步到磁盘看具体参数，**默认是不同步磁盘，仅仅从应用程序的binlog cache写入操作系统缓存**）  
【7】执行器调用引擎的提交事务接口，（默认情况下）将redo log写入磁盘，此时redo log处于提交阶段。

两阶段提交是为了**保证redo log和bin log的数据一致性**。

commit阶段之前的崩溃，都是通过undo log进行回滚的。而如果是commit阶段崩溃，需要考虑binlog的状态：  
【1】如果binlog的记录是完整的，那么使用redo log对页面数据进行重新更新  
【2】如果binlog的记录是不完整的，那么使用undo log进行数据回滚。



### MySQL查询比较慢的话，通过什么方式来优化
(情况①：偶尔很慢，可能是数据库在查询脏页，或者没拿到锁  
情况②：一直很慢，可能是没有索引，或者有索引但没走索引，或者表数据量太大需要分库分表)


### 删除表里的所有数据有哪些方法

### 数据库连接池

为什么需要数据库连接池？



## MyBatis

### 简述mybatis框架
	持久层框架，底层是对JDBC的封装，基于ORM（对象和关系表的映射）思想对结果集进行了封装
	ORM思想：把数据库表和javaBean对应起来，使得java操作实体类最终映射到对数据库表的操作

### 简述原理

### 两个占位符和SQL注入
	${} 属于静态的文本替换,生成的sql语句会将占位符的内容直接替换为传入的参数(打印日志可以看到完整的语句)
	#{} 会将占位符替换为?. 然后执行sql前使用preparedStatement将?替换为具体的参数,可以防止注入攻击(打印日志时,参数都被?占位)
	#{}是先编译好sql语句再替换，而${}将参数先替换再编译sql语句。  如果使用拼接字符串作为参数，那么#{}将其看作一个单独的参数，相当于是一个无效的参数。  
	总之，**应该使用 #{}**
	
	在使用PreparedStatement执行SQL命令时，命令会带着占位符被数据库进行编译和解析，并放到命令缓冲区。然后，每当执行同一个PreparedStatement语句的时候，由于在缓冲区中可以发现预编译的命令，虽然会被再解析一次，但不会被再次编译。
	而SQL注入只对编译过程有破坏作用，执行阶段只是把输入串作为数据处理，不需要再对SQL语句进行解析，因此解决了注入问题。
	因为SQL语句编译阶段是进行词法分析、语法分析、语义分析等过程的，也就是说编译过程识别了关键字、执行逻辑之类的东西，编译结束了这条SQL语句能干什么就定了。而在编译之后加入注入的部分，就已经没办法改变执行逻辑了，这部分就只能是相当于输入字符串被处理。
	
	背这个：编译结束了这条SQL语句能干什么就定了。而在编译之后加入注入的部分，就已经没办法改变执行逻辑了，这部分就只能是相当于输入字符串被处理
	
	SQL注入只对编译过程有破坏作用，执行阶段只是把输入串作为数据处理，不需要再对SQL语句进行编译，因此解决了注入问题
	
	#{}是先编译好sql语句再替换，而${}将参数先替换再编译sql语句



## JDBC
### 理解JDBC及其流程

jdbc本质上是java官方定义的一组接口（Drive/Connect/Statement/ResultSet等），然后让各个数据库厂商去向用户提供各自的接口实现类，这些接口规定了一种行为——java语言如何操作数据库实例。用户可以基于这套接口去面向接口编程，作为用户的程序员只需要注册相应的驱动即可。  
而一个JDBC打开的连接，最终也会映射为一条数据库连接（mysql客户端与mysql服务器之间建立的TCP连接）


#### statement

Statement接口规范了执行sql语句，返回结果的行为。  
statement直接对参数的处理，是直接将sql语句与参数进行字符串拼接的，容易被sql注入攻击（例如 and 1 = 1恒成立，进行全表扫描）。preparedStatement是statement的子接口，可以防止SQL注入攻击，会对SQL进行预编译，效率很高，而且参数使用?进行占位，通过set方法给占位符赋值（这里谈论的都是具体的实现类行为）  
callableStatement继承自preparedStatement，用于调用存储过程，不过一般不使用JDBC创建存储过程。


#### JDBC流程

JDBC的流程可以概括为：  
1. 注册数据库驱动  
2. 拿到连接connect对象  
3. 拿到执行sql语句的statement对象  
4. 执行sql语句得到结果集resultSet对象
   
```java
        Class.forName("com.mysql.cj.jdbc.Driver");
        Connection root = DriverManager.getConnection("jdbc:mysql://localhost:3306/mysql?useSSL=false", "root", "123456");
        String sql ="select * from user";
        Statement statement = root.createStatement();
        ResultSet resultSet = statement.executeQuery(sql);
        statement.close();
        root.close();

    
```


获取connect对象的方式有两种，一种是直接new对应的Driver对象，然后使用driver对象的connect方法去获得，而另一种更加常用的方式是使用DriverManager的静态方法getConnection去获取

###### 注册驱动原理

注册注册，听着很玄乎，其实说白了就是driverManager这个类维护了一个集合，这个集合装载的是Driver对象（DriverInfo是对Driver的封装，内部组合了DrIver对象，内部还维护了一个DriverAction类型，可以指定取消注册的逻辑）。而注册说白了就是往这个容器中添加Driver的过程

```java
    private final static CopyOnWriteArrayList<DriverInfo> registeredDrivers = new CopyOnWriteArrayList<>();
```

当我们forName主动将一个类加载如内存，就会触发类初始化，执行该类的static块。这个块内执行的逻辑其实就是new一个对象，然后注册进driverManager的Driver集合中。

```java
    static {
        try {
            DriverManager.registerDriver(new Driver());
        } catch (SQLException var1) {
            throw new RuntimeException("Can't register driver!");
        }
    }
```

Driver类还会有一个无参构造器，我们也可以直接使用这个无参构造器new一个driver对象，但是这样就属于硬编码了，而第一种方式完全可以写在配置文件中，然后读入properties对象。

```java
    public Driver() throws SQLException {
    }
```

driverManager设计的目的就是代替用户管理驱动（Driver），也算是一种控制反转吧…  
一旦将Driver委托给driverManager后，获得连接时，需要遍历集合找到合适的驱动对象（依次尝试connect，如果返回的连接对象不为null就返回），并且调用其对应的connect方法。



### SPI
	SPI:服务提供接口,为某个接口寻找服务的实现
	出现的原因是,spi接口是由bootstrap启动类加载器来进行加载,而spi实现类是由application系统类加载器来加载类.因此在双亲委派模型下,启动类加载器无法委托系统类加载器去加载类
	
	线程上下文类加载器是java对双亲委派模式与实现SPI之间的妥协.Java应用运行的线程的上下文类加载器是系统类加载器,在线程中运行的代码可以通过此类加载器来加载类和资源
	
	总结就是:JDK提供SPI接口,第三方提供实现类,第三方按照约定将以服务接口命名的文件放到META-INF/services/目录下,内容就是实现类的全限定类名列表,按照约定jdk会去扫描jar包中符合约定的类名,然后依次调用forName加载,但由于SPI接口是由启动类加载器加载,该类加载器无法加载第三方类型,因此将这个任务委托给当前执行线程的线程上下文加载器


##  Linux
### Linux怎么杀死进程，kill -9 .. 9是什么意思， 15是什么意思



## 多线程练习
### 三个线程交替打印1,2,3

```java

package javabase;
/**
 @Description
 @author ZJF
 @create 2022-04-16-20:17
 @version */

import java.util.concurrent.Semaphore;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

/**
 *
 *@author:ZJF
 *@Date 2022-04-16-20:17
 *@description:
 */
public class Dayin123 {

    private static Lock lock = new ReentrantLock();
    private static int count = 0;
    private static Semaphore A = new Semaphore(1);
    private static Semaphore B = new Semaphore(1);
    private static Semaphore C = new Semaphore(1);
    public static void main(String[] args){
        // write your code here
        final Dayin123 demo2 = new Dayin123();
        Thread t1 = new Thread(demo2::print1);
        Thread  t2 = new Thread(demo2::print2);
        Thread t3 = new Thread(demo2::print3);
        try {
            B.acquire();
            C.acquire();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        t2.start();
        t3.start();
        t1.start();
    }

    public void print1()  {
        for (int i = 1; i <= 100; i += 3) {
            try {
                A.acquire();
                if((i+3)%3==1)
                {

                    System.out.println("print1:"+i);
                }
                B.release();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }


        }
    }
    public  void print2()  {
        for (int i = 2; i <= 100; i += 3) {

            try {
                B.acquire();
                if((i+3)%3==2)
                {
                    System.out.println("print2:"+i);
                }
                C.release();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }


        }
    }
    public void print3()  {
        for (int i = 3; i <= 100; i += 3) {

            try {
                C.acquire();
                if((i+3)%3==0)
                {
                    System.out.println("print3:"+i);

                }
                A.release();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }

        }
    }

}

```

# 琐碎记录
## 数据结构：
-   给一个场景：有很多图片，然后我们需要对图片进行存储，以及查找，有什么数据结构比较适合？
-   如果我要加速查询的速率，你要怎么设计？


## 架构设计
-   如果一台服务器，然后要对单机进行拓展，你要怎么设计后续的拓展工作？