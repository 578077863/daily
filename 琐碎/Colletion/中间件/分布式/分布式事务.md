
## 理论
分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上，相对的，传统事务也称之为单机事务。在单机事务时代，我们通常可以使用数据库的事务操作来解决数据的一致性问题；那么在微服务越来越流行的当下，我们应该如何保证不同服务器上数据的一致性？本文先从CAP理论和BASE理论说起，之后从一致性强弱的角度梳理当前主流的强一致性方案、最终一致性方案和弱一致性方案，最后总结一下各个方案的特点和适用场景，希望对你有所帮助。


### CAP理论
CAP理论可以说是分布式系统的基石，它说的是**一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项**，而不能同时满足。

-   **C：一致性**，所有客户端看到都是同一份数据，即使在数据更新和删除之后
-   **A：可用性**，即使部分节点发生故障，所有客户端也能找到可用的数据备份
-   **P：分区容忍性**，即使发生网络分区故障，系统仍然能够按照预期正常工作

**CAP定理在分布式领域至关重要，在构建大型分布式系统的时候我们必须根据自己业务的独特性在三者之间进行权衡**。

由于网络的各种不确定因素，在构建分布式应用的时候我们往往不得不考虑分区容忍性，这个时候我们通常只能在一致性和可用性之间进行选择。


### Base理论
根据CAP定理，如果要完整的实现事务的ACID特性，只能放弃可用性选择一致性，即CP模型。然而如今大多数的互联网应用中，可用性也同样至关重要。于是eBay架构师根据CAP定理进行妥协提出一种ACID替代性方案，即BASE，从而来达到可用性和一致性之间的某种微妙的平衡，选择AP模型的同时最大限度的满足一致性。

BASE是下面三部分的英文缩写简称：

-   **BA**：**Basically Available** ，基本可用性
-   **S：Soft State**，软状态
-   **E：Eventually Consistency**，最终一致性

“**基本可用**”是相对CAP的“完全可用”而言的，即在部分节点出现故障的时候不要求整个系统完全可用，允许系统出现部分功能和性能上的损失：比如增加响应时间，引导用户到一个降级提示页面等等。

“**软状态**”则是相对CAP定理强一致性的“硬状态”而言，CAP定理的一致性要求数据变化要立即反映到所有的节点副本上去，是一种强一致性。“软状态”不要求数据变化立即反映到所有的服务器节点上，允许存在一个中间状态进行过渡，比如允许放大延时等。

“**最终一致性**”则是相对强一致性而言，它不要求系统数据始终保持一致的状态，只要求系统经过一段时间后最终会达到一致状态即可。

Base 理论是对 CAP 中一致性和可用性权衡的结果，其来源于对大型互联网分布式实践的总结，是基于 CAP 定理逐步演化而来的。其核心思想是：**强一致性（Strong consistency）无法得到保障时，我们可以根据业务自身的特点，采用适当的方式来达到最终一致性（Eventual consistency）**



## 强一致性方案
强一致性的方案便是前面提到的舍A保C的CP模型，即通过牺牲可用性来保证一致性，这种方案适用于对一致性要求很高的场景，比如金融交易等。

### 2PC-二阶段提交
二阶段提交(Two-phaseCommit)是指，在计算机网络以及数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常，二阶段提交也被称为是一种协议(Protocol))。

当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。

因此，二阶段提交的算法思路可以概括为： 参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。

所谓的两个阶段是指：

**_第一阶段：voting phase 投票阶段_**
事务协调者给每个参与者发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。

**_第二阶段：commit phase 提交阶段_**
如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)

以上这两个过程被称为“两段式提交”（2 Phase Commit，2PC）协议，而它能够成功保证一致性还需要一些其他前提条件。

-   必须假设**网络在提交阶段的短时间内是可靠的**，即提交阶段不会丢失消息。两段式提交中投票阶段失败了可以补救（回滚），而提交阶段失败了无法补救（不再改变提交或回滚的结果，只能等崩溃的节点重新恢复），因而此阶段耗时应尽可能短，这也是为了尽量控制网络风险的考虑。
-   必须假设因为网络分区、机器崩溃或者其他原因而导致失联的**节点最终能够恢复**，不会永久性地处于失联状态。由于在准备阶段已经写入了完整的重做日志，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但并未提交的事务数据，并向协调者查询该事务的状态，确定下一步应该进行提交还是回滚操作。

两段式提交的原理很简单，也不难实现，但有几个非常明显的缺点：

**1. 单点故障问题**

协调者在两段提交中具有举足轻重的作用，协调者等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理。一旦协调者宕机，所有参与者都会受到影响。如果协调者一直没有恢复，没有正常发送 Commit 或者 Rollback 的指令，那所有参与者都必须一直等待。

**2. 同步阻塞问题**

执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。也就是说从投票阶段到提交阶段完成这段时间，资源是被锁住的。

**3. 数据一致性问题**

前面已经提到，两段式提交的成立是有前提条件的，当**网络稳定性**和**宕机恢复能力**的假设不成立时，两阶段提交可能会出现一致性问题。

对于**宕机恢复能力**这一点无需多说。1985 年 Fischer、Lynch、Paterson 用定理（被称为FLP 不可能原理，在分布式中与 CAP 定理齐名）证明了如果宕机最后不能恢复，那就不存在任何一种分布式协议可以正确地达成一致性结果。

对于**网络稳定性**来说，尽管提交阶段时间很短，但仍是明确存在的危险期。如果协调者在发出准备指令后，根据各个参与者发回的信息确定事务状态是可以提交的，协调者就会先持久化事务状态，并提交自己的事务。如果这时候网络忽然断开了，无法再通过网络向所有参与者发出 Commit 指令的话，就会导致部**分数据（协调者的）已提交，但部分数据（参与者的）既未提交也没办法回滚，导致数据不一致。**


### 3PC-三阶段提交
为了解决两段式提交的单点故障问题、同步阻塞问题和数据一致性问题，**“三段式提交”（3 Phase Commit，3PC）** 协议出现了。

与两阶段提交不同的是，三阶段提交有两个改动点。

-   **引入超时机制**: 同时在协调者和参与者中都引入超时机制。
-   **把原本的2PC的准备阶段再细分为两个阶段**: 将准备阶段一分为二的理由是，这个阶段是重负载的操作，一旦协调者发出开始准备的消息，每个参与者都将马上开始写重做日志，这时候涉及的数据资源都会被锁住。如果此时某一个参与者无法完成提交，相当于所有的参与者都做了一轮无用功。所以，增加一轮询问阶段，如果都得到了正面的响应，那事务能够成功提交的把握就比较大了，也意味着因某个参与者提交时发生崩溃而导致全部回滚的风险相对变小了。

三个阶段分别为：

**_第一阶段：CanCommit阶段_**

3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。

**_第二阶段：PreCommit阶段_**

本阶段协调者会根据第一阶段的询盘结果采取相应操作，询盘结果主要有两种：

-   情况1-假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行：
-   情况2-假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。

**_第三阶段：doCommit阶段_**

该阶段进行真正的事务提交，也可以分为以下两种情况。

-   情况1-执行提交:针对第一种情况，协调者向各个参与者发起事务提交请求
-   情况2-中断事务:协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。

可以看出，**3PC可以解决单点故障问题，并减少阻塞**，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit，而不会一直持有事务资源并处于阻塞状态。

但是**3PC对于数据一致性问题并未有任何改进**，比如在进入PreCommit阶段后，如果协调者发送的是abort指令，而此时由于网络问题，有部分参与者在等待超时后仍未收到Abort指令的话，那这些参与者就会执行commit，这样就产生了不同参与者之间数据不一致的问题。

**由于3PC非常难实现，目前市面上主流的分布式事务解决方案都是2PC协议**。



### XA协议
2PC 的传统方案是在数据库层面实现的，如 Oracle、MySQL 都支持 2PC 协议，为了统一标准减少行业内不必要的对接成本，需要制定标准化的处理模型及接口标准，国际开放标准组织Open Group 在1994年定义了**分布式事务处理模型 DTP（Distributed Transaction Processing Reference Model）** 。

DTP 规范中主要包含了 AP、RM、TM 三个部分，如下图所示：

![[Pasted image 20220423121902.png]]

它定义了三大组件：

-   **AP(_Application Program_)**：应用程序，一般指事务的**发起者**（比如数据库客户端或者访问数据库的程序），定义事务对应的操作（比如更新操作 UPDATE table SET xxx WHERE xxx）
-   **RMs(_Resource Managers_)**：资源管理器，是分布式事务的**参与者**，管理共享资源，并提供访问接口，供外部程序来访问共享资源，比如数据库、打印服务等，另外 RM 还应该具有事务提交或回滚的能力。
-   **TM(_Transaction Manager_)**：事务管理器，是分布式事务的**协调者**，管理全局事务，与每个RM进行通信，协调事务的提交和回滚，并协助进行故障恢复。

其中XA约定了TM和RM之间双向通讯的接口规范，并实现了二阶段提交协议，从而在多个数据库资源下保证 ACID 四个特性。所以，DTP模型可以理解为：应用程序访问、使用RM的资源，并通过TM的事务接口（TX interface）定义需要执行的事务操作，然后TM和RM会基于 XA 规范，执行二阶段提交协议进行事务的提交/回滚：

-   **准备阶段**：TM 向所有与当前事务相关的 RM 发起准备请求，每个 RM 评估自身是否能正常进行提交，并在响应中告知 TM。这类似于一个 TM 发起投票，各个 RM 进行投票的过程。
-   **提交阶段**：在第一阶段中，如果所有 RM 能在一定时间内表示 OK，则第二阶段由 TM 向所有 RM 发起提交请求。有任何一个 RM 没有准备好，TM 则向所有 RM 发起回滚请求。

目前大多数实现XA的都是一些关系型数据库（包括PostgreSQL，MySQL，DB2，SQL Server和Oracle）和消息中间件（包括ActiveMQ，HornetQ，MSMQ和IBM MQ），所以**提起XA往往指基于资源层的底层分布式事务解决方案**。

> MySQL 从5.0.3开始支持XA分布式事务(只有InnoDB引擎才支持XA事务)，业务开发人员在编写代码时，不应该直接操作这些XA事务操作的接口。因为在DTP模型中，RM上的事务分支的开启、结束、准备、提交、回滚等操作，都应该是由事务管理器TM来统一管理。

XA是资源层面的分布式事务，强一致性，在两阶段提交的整个过程中，一直会持有资源的锁。基于两阶段提交的分布式事务在提交事务时需要在多个节点之间进行协调,最大限度延后了提交事务的时间点，客观上延长了事务的执行时间，这会导致事务在访问共享资源时发生冲突和死锁的概率增高。因此，**XA并发性能不理想**（使用 XA 协议的 MySQL 集群，操作延时是单机的 10 倍），**无法满足高并发场景，在互联网中使用较少**。



### 最终一致性方案
上面所述的强一致性方案在性能上都不理想，在CAP定理中属于CP范畴；在互联网应用中，为了提升性能和可用性，基于BASE理论使用最终一致性来替代强一致性，也就是通过牺牲部分一致性来换取性能和可用性的提升。

#### 本地事务状态表

本地事务状态表方案的大概处理流程是：

1.  在调用方请求外部系统前将待执行的事务流程及其状态信息存储到数据库中，依赖数据库本地事务的原子特性保证本地事务和调用外部系统事务的一致性，这个存储事务执行状态信息的表称为本地事务状态表。
2.  **在将事务状态信息存储到DB后，调用方才会开始继续后面流程**，同步调用外部系统，并且每次调用成功后会更新相应的子事务状态，某一步失败时则中止执行。
3.  同时在后台运行一个定时任务，定期扫描事务状态表中未完成的子事务，并重新发起调用，或者执行回滚，或者在失败重试指定次数后触发告警让人工介入进行修复。

如下图所示：
![[Pasted image 20220423122220.png]]

其中本地事务表的设计由业务方自己来定，可以是如上图中所示拆分为多个子事务来管理，简单点也可以只有一条记录，然后通过状态的流转来控制程序调用不同的外部系统。


#### 可靠消息队列

可靠消息队列方案是指当事务发起方执行完成本地事务后并发出一条消息，事务参与方（消息消费者）一定能够接收到消息并处理事务成功，此方案强调的是只要消息发给事务参与方，则最终事务要达到一致。

此方案是利用消息中间件完成，如下图：
![[Pasted image 20220423122546.png]]

事务发起方（消息生产方）将消息发给消息中间件，事务参与方从消息中间件接收消息，事务发起方和消息中间件之间，事务参与方（消息消费方）和消息中间件之间都是通过网络通信，由于网络通信的不确定性会导致分布式事务问题。

因此可靠消息最终一致性方案要解决以下几个问题：

1.  **本地事务与消息发送的原子性问题**：要求事务发起方在本地事务执行成功后消息必须发出去，否则就丢弃消息
2.  **事务参与方接收消息的可靠性**：要求事务参与方必须能够从消息队列接收到消息，如果接收消息失败可以重复接收消息
3.  **消息重复消费的问题**：要解决消息重复消费的问题就要实现事务参与方的方法幂等性。

目前主要的解决方案有2种，一种是本地消息表方案，一种是事务消息方案。

_**本地消息表**_

如果是使用 Kafka(< 0.11.0) 这类不支持事务消息的消息中间件，参与事务的系统需要在给消息中间件发送消息之前，把消息的信息和状态存储到本地的消息表中，如下图所示：

![[Pasted image 20220423123535.png]]

主要流程如下：

1.  参与分布式事务的系统A接收到请求后，在执行本地事务的同时把将待发送的消息记录到事务消息表中，**将业务表和消息表放在一个数据库事务里**，保证两者的原子性；
2.  执行完后系统A不直接给消息中间件发消息，而是通过后台定时任务扫描消息表将消息push到消息中间件，对于push失败的消息则会不断重试，直到消息中间件成功返回 ack 消息，并更细消息表中投递状态，从而保证消息的不丢失。
3.  消息中间件收到消息后，会将消息投递给订阅消息的外部系统1/2/3，外部系统1/2/3收到消息后执行本地事务，只有成功才应答 Ack 消息，消息中间件只有在收到Ack消息后才将该条消息丢弃，否则会不断的重复发送直到成功，所以事务的所有参与者需要自行保证事务执行的幂等性。

**_事务消息方案_**

如果是基于RocketMQ或Kafka（>=0.11.0）这类的支持事务操作的消息中间件，上述的方案则可以简化，此时上面的的定时任务的工作将交给消息中间件来提供，如下图所示：

![[Pasted image 20220423123559.png]]

流程比较简单不再赘述，需要说明的是，消息中间件如果收到Comfirm消息，则会将消息转为对消费者可见，并开始投递；如果收到Rollback消息，则会删除之前的事务消息；如果未收到确认消息，则会通过事务回查机制定时检查本地事务的状态，决定是否可以提交投递。

#### 最大努力通知

最大努力通知方案( Best-effort delivery)是最简单的一种柔性事务，**适用于一些最终一致性时间敏感度低的业务，且被动方处理结果不影响主动方的处理结果**。典型的使用场景：如银行通知、商户通知等。最大努力通知型的实现方案，一般符合以下特点：

-   **不可靠消息**：业务活动主动方，在完成业务处理之后，向业务活动的被动方发送消息，直到通知N次后不再通知，允许消息丢失(不可靠消息)。
-   **定期校对**：业务活动的被动方，根据定时策略，向业务活动主动方查询(主动方提供查询接口)，恢复丢失的业务消息。

比如充值的一个例子：
![[Pasted image 20220423123628.png]]

**与可靠消息队列方案区别：**

-   **解决方案思想不同**

可靠消息一致性，发起通知方需要保证将消息发出去，并且将消息发到接收通知方，消息的可靠性关键由发起通知方来保证。最大努力通知，发起通知方尽最大的努力将业务处理结果通知为接收通知方，但是可能消息接收不到，此时需要接 收通知方主动调用发起通知方的接口查询业务处理结果，通知的可靠性关键在接收通知方。

-   **两者的业务应用场景不同**

可靠消息一致性关注的是交易过程的事务一致，以异步的方式完成交易。最大努力通知关注的是交易后的通知事务，即将交易结果可靠的通知出去。

-   **技术解决方向不同**

可靠消息一致性要解决消息从发出到接收的一致性，即消息发出并且被接收到。最大努力通知无法保证消息从发出到接收的一致性，只提供消息接收的可靠性机制。可靠机制是，最大努力的将消息通知给接收方，当消息无法被接收方接收时，由接收方主动查询消息（业务处理结果）。