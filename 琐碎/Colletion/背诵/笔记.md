## 接口和抽象类

### 设计思想
```markdown
抽象类是对一类事物的抽象,通过提取共同的特征,将具有相同行为逻辑写在方法中,达到代码复用的效果;而对于行为相同但实现逻辑不同的情况,我们可以用抽象方法来做一个规范

接口是用于对一组行为的规范,对类的行为进行约束,但对其实现逻辑不限制


继承抽象类更用于说明:是什么. 而实现接口更用于:会什么

ArrayList和linkedList都直接或间接的继承了abstractList抽象类和实现了list接口。通过继承前者，说明二者属于“线性列表”类型，同时获得了一些和线性列表相关的可复用代码，而实现后者，规范了二者具有一些线性表的行为（如sort、set、get），但是并没有规定二者的具体实现，因此ArrayList可以基于数组实现以上行为，而linkedList可以基于链表实现以上行为。使用者可以通过List接口规范出来的方法，(而方法的实现)根据具体的实现类实现动态分派

讲到这个抽象类，上面已经说了，抽象类的抽象方法就是对一类事物行为相同但实现逻辑不同做一个规范，我们知道它的一个步骤流程，但不知道具体实现过程，所以采用抽象方法来规定，这就是模板方法
```

### 编程语言层面
抽象类与普通类的区别就是有 abstract修饰:
1. 无法被实例化,
2. 抽象方法可以有也可以没有


接口方法默认使用public abstract修饰,字段使用public static final修饰（注意，接口字段是静态常量，因此外部调用时不会引起接口初始化，因为编译后字段的值已经保存在接口字节码文件属性表的constantValue属性中了）

jdk8开始支持接口的默认方法和静态方法。其中默认方法是属于实例的，而静态方法是属于类的。


**接口重名问题**
1. 如果两个接口中定义了相同的方法（方法值相同），那么实现类只需要实现一次即可。  
2. 如果返回值不同，编译不通过。  
3. 如果两个接口定义了相同的默认方法，则实现类必须重写这个方法（也可以通过接口名.super.去引用接口对应的默认实现）
4. 如果存在重名的静态方法，只能通过接口名去调用  
5. 如果仅仅同名，但是参数列表不同，则可以看作两个方法。（相当于重载）


**多继承问题**
Java不允许类进行多重继承（extends），因为存在“菱形继承问题”：B和C都继承A，而D同时继承B和C，那么D相当于间接继承了两份A，而且方法解析是也十分复杂，例如当D菱形继承A后，到底表现B还是C的多态？java允许多实现（implements），因为接口中都是抽象方法，最终都需要交给实现类实现，“菱形继承”的接口在实现类中也只需实现一次即可，不会增加JVM解析的复杂度。（接口的继承也使用extends关键字）

**接口初始化**
当一个实现类初始化时，不会初始化它的接口。一个接口在初始化时，也不要求它的父类完成初始化。只有程序在首次访问接口的静态变量时，才会初始化——非string+8大基本类型的引用变量。（string+基本类型的值全部在编译期固化到使用方的字节码中了）



## String,StringBuilder,StringBuffer

```markdown
以JDK8的String为例,其关键属性就是char数组指向字符串类型的字面量

讲到String,最常见的就是其不可变性,那么该特性的体现方式是:
String类型的字面量一旦声明,便不可修改.(除非利用反射)

为什么不可更改?
1.value数字是private权限,这就导致我们无法通过对象.属性去修改字符串
2.String是final修饰的,无法被继承,这就导致其方法无法被修改
3.严谨的访问控制,设计string的程序员当碰到修改操作时总是返回一个新创建的对象，而不是返回一个指针。这从根本上保证了用户得到的一定是新对象，也保证了底层数组仅仅能被用于访问。一旦涉及到修改操作，那么它的生命基本也走到了尽头（当前使用价值没了，等待下一个用户重新从字符串常量池中获取）


**如果问你如何设计不可变类，那么string将是一个很好的参考：不可继承、底层数据结构私有化、严密的访问控制、涉及到对象本身的方法返回值总是一个（深）拷贝对象**

String不可变的意义:
1.保证了String的线程安全
	虽然多个线程可以持有同一个字面量,但若是其中某个线程想要修改,那么就会创建出新的对象并指向他,这一点类似COW
2.实现常量池
	常量池的内容和代码中出现的直接字面量有关（这里不考虑编译期优化的情景），而动态生成的字符串（new出来后 +出来的）的引用不会存在池中（除非你主动且抢 
    先intern）。
3.作为HashMap的key
	每个对象都有一个hashCode，这个值被记录在每个对象的对象头中。hashCode（）方法默认直接返回这个值。它是根据对象内部地址转换而来的整数值，可以看作对 
    内存地址的抽象。
    而java为每个对象提供hashCode的目的，主要是为了这个对象可以存放在hashMap中（源码注释中看的）。
	String的不可变性保证了一定能从HashMap中取出之前存放进去的value(可以举ArrayList作为Key当反例)


由String的不可变意义引发的对线程安全的思考:

什么是线程安全?
多线程环境下对共享资源的访问安全问题

在jvm的运行时数据区，堆内存是共享的，而栈内存是线程独有的
多线程环境下,线程关于对共享变量的操作其可见性和原子性都无法保证

那什么是线程不安全的?
举个例子,通常都会定义一个资源类，然后资源类包含一个成员以及操作它的方法。然后我们（在主方法）创建这个资源类的对象，以及一组线程去并发操作。以num++为例，num++不是一个原子操作
我们如果将这个操作看作一个事务，那么一个线程执行这个操作的期间**不管是否发生线程调度在逻辑上都应看作不能被打断**，如果可以被打断，我们称这个操作为线程不安全的。
线程不安全两种情况:
1.读写冲突
这里最直观的就是，一个线程正在执行这个“共两部操作的事务”，如果另一个线程能看到该线程执行到一半的num的值，那么就是读写冲突，用数据库的话语就是——**读到事务未提交的值**。
2.写写冲突
线程A执行到一半被打断，num被线程B修改，而线程A最终会覆盖这个值，而造成线程B修改的值丢失。即**更新丢失**

总结：  
线程安全发生的场景：**多线程环境**下，线程竞争**共享资源**。通常是多线程竞争访问资源类对象  
解决方法无非是：加锁、无锁（直接CAS操作资源）、隔离（threadLocal），这里不再展开。


String的优化:
JDK9 为了节省**string占用的内存空间**，已经将底层的数据结构改为字节数组了。而且根据字符串的内容自动选择编码方式（既然底层是字节，那么将字符存储为字节的过程必然涉及到编码）。一般出现汉字之类的，还是会采用utf-16编码，但是如果都是一些数字英文之类的，会采用Latin1编码。
可以理解为jdk9的字符串底层使用**字节数组**存储数据，同时**自适应编码**方式去将字符编码为字节

计算机的最小存储单元是字节，如果向存储一个字符串，那么免不了将字面量编码为字节去存储。而当用户需要访问字面量时，也会做一个解密操作。

**优化后的效果**：string（尤其是常量池指向的对象）占用的内存空间减少了，可用的内存资源增多了（不那么吃紧了)，GC频率也会有所调整,GC频率少一些，用户线程也不会因为GC而stop the world，用户线程工作有效时长也会跟着增加




其他的:
+: 如果涉及加号的表达式全部使用字面量，则在编译期间进行优化，消除加号，并且拼接为“aaa”,也就是说编译后的产物是“aaa”，而“a”和“aa”并没有放入池中（更不会触发对应的idc）。而如果表达式中涉及到了变量，那么就会执行另一个流程：创建一个stringBuilder空对象，然后每个+都是一次append操作。最终toString返回的是一个string对象，因此一定会创建一个新的string对象。但是有一个例外：如果变量是一个被final所修饰的常量，依然可以被编译优化。（只能是string或基本类型，引用类型（除了string）没有常量一说）

```


通过查看StringBuilder和String的源码我们会发现两者之间一个关键的区别: 对于String, 凡是涉及到返回参数类型为String类型的方法, 在返回的时候都会通过new关键字创建一个新的字符串对象; 而对于StringBuilder, 大多数方法都会返回StringBuilder对象自身

StringBuffer与StringBuilder的区别就是一个是线程安全,一个不安全.但线程不安全的效率高
StringBuffer每次都会对StringBuffer对象本身进行操作,不会生成新的对象并改变对象引用

## AQS

响应中断是在获取资源前抛出异常，被唤醒后检查到中断抛出异常



AQS:抽象同步队列AbstractQueuedSynchronizer

AQS是一个FIFO的双向队列，队列元素的类型为Node。AQS里面包括Node节点、state变量、ConditionObject内部类（条件变量）

一个锁对应一个AQS阻塞队列，对应多个条件变量，每个条件变量有自己的一个条件队列。

**①Node节点**

Node节点中的thread变量用来存放进入AQS队列里面的线程

shared变量用来标记该线程是获取共享资源时被阻塞挂起后放入AQS队列的

exclusive变量用来标记线程是获取独占资源时被挂起后放入AQS队列的

waitStatus变量记录当前线程的等待状态，waitStatus可以为cancelled(线程被取消了)、signal(线程需要被唤醒)、condition（线程在条件队列里面等待）、propagate（释放共享资源时需要通知其他节点）

**②ConditionObject类**

ConditionObject用来结合锁实现线程同步的。

ConditionObject是条件变量，每个条件变量对应一个条件队列（单向[链表](https://www.nowcoder.com/jump/super-jump/word?word=%E9%93%BE%E8%A1%A8)队列），其用来存放调用条件变量的await()方法后被阻塞的线程。

1.当一个获得锁的线程调用await()方法时（必须先调用锁的lock()方法获取锁），在内部会构造一个类型为Node.CONDITION的node节点，然后将该节点插入 条件队列末尾，之后当前线程会释放获取的锁（修改锁对应的state变量的值），并被阻塞挂起。

2.当另外一个线程调用ConditionObject条件变量的signal方法时（必须先调用锁的lock()方法获取锁），在内部会把条件队列里面队头的一个线程节点从条件队列里面移除并放入AQS的阻塞队列里面，然后激活这个线程。

[java中Condition接口原理详解_乘风如水的博客-CSDN博客](https://blog.csdn.net/weixin_39935887/article/details/80983187)
  
[【黑马程序员】Java并发之Condition的实现分析 - 百度文库 (baidu.com)](https://wenku.baidu.com/view/46b13a46db38376baf1ffc4ffe4733687f21fc0d.html)
**③state变量**

private volatile int state; //共享变量，使⽤volatile修饰保证线程可⻅性

线程同步的关键是对状态值state进行操作，根据state是否属于一个线程，操作state的方式分为独占方式和共享方式。

1.在独占方式下，获取锁与释放锁的流程如下

当一个线程调用acquire()方法获取独占资源时，会首先使用tryAcquire()方法尝试获取资源，具体是设置状态变量state的值，成功则直接返回，失败则将当前线       程封装为Node.EXCLUSIVE的Node节点后插入到AQS的阻塞队列的尾部，并调用LockSupport.park(this)方法挂起自己。

当一个线程调用release()方法时会尝试使用tryRelease()操作释放资源，这里是设置状态变量state的值，然后调用LockSupport.unpark(thread)方法激活AQS队       列里面被阻塞的一个线程(thread)。被激活的线程则使用tryAcquire()尝试，看当前状态变量state的值是否能满足自己的需要，满足则该线程被激活，然后继续       向下运行，否则还是会被放入AQS队列并挂起。

2.在共享方式下，获取与释放资源的流程如下

当一个线程调用acquireShared()方法获取共享资源时，会首先使用tryAcquireShared()方法尝试获取资源，具体是设置状态变量state的值，成功则直接返回，       失败则将当前线程封装为Node.SHARED的Node节点后插入到AQS的阻塞队列的尾部，并调用LockSupport.park(this)方法挂起自己。

当一个线程调用releaseShared()方法时会尝试使用tryReleaseShared()操作释放资源，这里是设置状态变量state的值，然后调用LockSupport.unpark(thread)方法激活AQS队列里面被阻塞的一个线程(thread)。被激活的线程则使用tryAcquireShared()尝试获取资源，具体是查看当前状态变量state的值是否能满足自己的       需要，满足则该线程被激活，然后继续向下运行，否则还是会被放入AQS队列并挂起。


②CAS

CAS：CompareAndSwap （比较并替换）

CAS[算法](https://www.nowcoder.com/jump/super-jump/word?word=%E7%AE%97%E6%B3%95)的过程是：它包含3个参数CAS(V,E,N)，其中V表示要更新的变量，E表示预期值，N表示新值。

仅当V值等于E值时，才会将V的值设置为N，如果V值和E值不同，说明已经有其他线程做了更新，则当前线程什么都不做。最后CAS返回当前V的真实值。

在多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败。失败的线程不会被挂起，仅是被告知失败，并允许再次尝试，当然也允许失败的线程放弃操作。

CAS怎么保证修改的值可见？volatile关键字

volatile 关键字的主要作⽤就是保证变量的可⻅性然后还有⼀个作⽤是防⽌指令重[排序](https://www.nowcoder.com/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F)。

当修改volatile变量时，JMM会把线程对应的工作内存中的共享变量值刷新到主内存中。

当读取volatile变量时，JMM会把该线程对应的工作内存置为无效，线程从主内存中读取共享变量值。

ABA问题：在CAS操作中有个经典的ABA问题？解决方式？(版本号、时间戳)

假如线程①使用CAS修改初始值为A的变量X，那么线程①会首先去获取当前变量X的值（为A），然后使用CAS操作尝试修改X的值为B，如果使用CAS操作成功了，程序运行也不一定是正确的。

在线程①获取变量X的值A后，在执行CAS前，线程②使用CAS修改了X的值为B，然后又使用CAS修改了变量X的值为A。

所以，线程①执行CAS时X的值是A，但是这个A已经不是线程①获取时的A了，这就是ABA问题。

ABA问题的产生是因为变量的状态值产生了环形转换。

避免ABA问题：使用版本号或时间戳。给每个变量的状态值配备一个时间戳或者版本号。




## 多态,重载和重写
**多态**
所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。
在Java中有两种形式可以实现多态：继承（多个子类对同一方法的重写）和接口（实现接口并覆盖接口中同一方法）。

**重载与重写**
重写：存在继承关系的基础上，子类对父类方法进行重新实现。【纵向选择】
重载：同一实例可以拥有多个同名方法，根据方法签名（参数列表：类型、顺序、长度，不包含返回值和修饰符）的不同，**编译期可以确定唯一载入的版本**。【横向选择】


**使用上区别**
重载：
	发生在同一个类中（或者父类和子类之间），**方法的签名必须不同**，也就是方法名必须相同，参数类型不同、个数不同、顺序不同，**方法返回值和访问修饰符可以不同。**

综上：重载就是同一个类中多个同名方法根据不同的传参来执行不同的逻辑处理。


重写：
	重写**发生在运行期**，是子类对父类的允许访问的方法的实现过程进行重新编写。
		1.  **返回值类型、方法名、参数列表必须相同**，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类。
		2. 如果父类方法访问修饰符为 `private/final/static` 则子类就不能重写该方法，但是被 static 修饰的方法能够被再次声明。
		3. 构造方法无法被重写


**方法的重写要遵循“两同两小一大”**

-   “两同”即方法名相同、形参列表相同；
    
-   “两小”指的是子类方法返回值类型应比父类方法返回值类型更小或相等，子类方法声明抛出的异常类应比父类方法声明抛出的异常类更小或相等；
    
-   “一大”指的是子类方法的访问权限应比父类方法的访问权限更大或相等。


⭐️ 关于 **重写的返回值类型** 这里需要额外多说明一下，上面的表述不太清晰准确：如果方法的返回类型是 void 和基本数据类型，则返回值重写时不可修改。但是如果方法的返回值是引用类型，重写时是可以**返回该引用类型的子类**的。


**扩展**
重载是静态的，而重写是动态。

编译器在编译期就可以确认某一个方法的重载版本，但是并不一定能确认它的调用入口。

哪些方法可以在运行前就可以确认方法的唯一调用版本——**当方法的符号引用，在类加载的解析阶段就可以转换为直接引用**：
>编译期指的是，源码被编译为字节码后，运行期指的是VM启动，加载类、创建实例等工作开始进行，主要指的是执行引擎开始工作、执行字节码指令…


【1】static方法(invokeStatic)
【2】super.XX() 即调用父类方法（invokeSpecial）
【3】final修饰的方法（invokeVirtual）
【4】private修饰的方法（invokeSpecial）
【5】构造器（invokeSpecial）

以上五个方法也被称为**非虚方法**，他们最大的特点就是**不能被重写**，因此可以在编译期确认唯一调用版本。与之相反的**虚方法**就是实例方法（invokeVirtual），虽然被final修饰的实例方法使用invokeVirtual调用，但是仍然属于非虚方法


```markdown
底层上区别:
当一个类被编译后，它的某一个方法的信息将被保存在方法表和常量池中，其中方法的各个参数的符号引用集合将作为特征签名将被保存在常量池中，而返回值不会作为特征签名的成员。因此无法仅仅依靠返回值确认重载版本。


重写是多态的体现，方法调用的本质就是将符号引用转换（解析）为直接引用，直接引用指向方法对应的字节码指令（的地址）。**对应非虚方法，这个过程在类加载的解析阶段完成，而对于虚方法，这个过程在运行时完成**（即执行引擎真正开始执行该方法调用代码时才进行解析）。
对重写方法调用的解析，就是将符号引用指向重写方法执行入口的过程，运行时执行动态分派的动作，取决于变量对应的真实类型（变量指向的对象类型，而不是变量类型），只有虚方法才会执行动态分派
```


```markdown
invokevirtual指令的运行时解析过程大致如下：
1，找到引用所指向的对象的实际类型。 //对于People p1=new Man();，其静态类型为People,实际类型为Man。
2，如果在实际类型中找到名称相符的方法，则返回该方法的直接引用，接着调用该方法。 //对于p1.say();，实际调用的是Man中定义的方法
3，如果没找到，按照继承关系从下往上在其各个父类中进行第2步

至此，终于明白，当我们使用父类引用调用方法时，会从引用指向的对象的实际类型中去找该方法。如果引用指向的是不同实际类型的对象，则调用的方法也会不同。多态也因此而实现。
需要注意的是，该多态是运行时多态，对于People p1=new Man();，其静态类型在编译器就已确定，实际类型在编译器无法确定，运行时才确定。
例如：People p3=(new Random()).nextBoolean() ? new Man() : new Woman();，p3的静态类型为People,编译器就可以确定，但其实际类型无法确定，只有程序执行到这行代码时才能确定。


**通过实例引用调用实例方法的时候，先从方法区中对象的实际类型信息找，找不到的话再去父类类型信息中找。**

如果继承的层次比较深，要调用的方法位于比较上层的父类，则调用的效率是比较低的，因为每次调用都要经过很多次查找。这时候大多系统会采用一种称为**虚方法表**的方法来优化调用的效率。

所谓虚方法表，就是在类加载的时候，为每个类创建一个表，这个表包括该类的对象所有动态绑定的方法及其地址，包括父类的方法，但一个方法只有一条记录，子类重写了父类方法后只会保留子类的。当通过对象动态绑定方法的时候，只需要查找这个表就可以了，而不需要挨个查找每个父类。

虚方法表会在类加载的链接阶段被创建并开始初始化，类的变量的初始值准备完成之后，JVM会把该类的方法表也初始化完毕

[(53条消息) JVM笔记-9Java虚拟机栈（动态链接，晚/早期绑定、非虚/虚方法、虚方法表）_秃头不用洗发水的博客-CSDN博客](https://blog.csdn.net/weixin_45910779/article/details/113910933)
```

## final关键字的作用和用法
>[this引用逃逸 - JJian - 博客园 (cnblogs.com)](https://www.cnblogs.com/jian0110/p/9369096.html)

[Java内存模型JMM之五final内存语义 - 莫待樱开春来踏雪觅芳踪 - 博客园 (cnblogs.com)](https://www.cnblogs.com/txmfz/p/14755661.html)
```markdown
1.修饰任何变量,都使得**为该变量开辟的内存空间仅能存放一次值，且不可以修改**.这个值可以是一个字面量，也可以是一个地址值。（如果更具体一点：基本类型变量的值不能变，引用类型指向的对象不能变,但其属性可变）

2.修饰方法：方法不能被重写。显然方法被修饰为**final具有意义的前提是继承**。
priate修饰方法使得该方法不能被子类对象使用，而final使得子类对象只能使用父类继承下来的方法而不可以重写。private final中final就没什么必要了，final具有意义的前提是存在继承关系！

3.修饰类：该类不能被继承。显然final和abstract是冲突的，二者如果同时出现是无法通过编译的。
如果把final变量定义在循环中，那么final语义起作用的范围仅仅是当前循环上下文，下一次循环时，此final就非彼final了。（如果把final变量定义在循环外，则仍然有效）

final的不可变语义是编译器保证的，如果对final变量进行二次赋值，则在编译期就可以检查出来。


final还可以保证内存可见性
编译器为final写（初始赋值）操作之后插入写屏障，在读操作之前插入读屏障。

final提供的内存语义  
**保证了一个线程在读取final变量之前必须首先获取包含这个变量的对象的引用（先拿到引用，再读final）。同时，还保证了对象引用被任何线程获取之前，final变量的初始值已经被正确的写入了。（先写final，再拿到引用）**

总结：final保证了对象引用对任意线程线程可见之前，对象的final域已经被初始化。线程在读到一个对象的final域之前，一定先读到该对象的引用。保证了线程不会读取到final域未初始化之前的默认值,**一旦构造器把“this”的引用传递出去，就无法保证了**

JMM禁止把Final域的写重排序到构造器的外部。
在一个线程中，初次读该对象和读该对象下的Final域，JMM禁止处理器重新排序这两个操作。

```

## Synchronized和Lock区别

Lock是JUC包下提供的接口，定义了一个锁类型应该具有的行为。  
Lock接口的意义就是把锁这个东西抽象为了一个对象拿到台面上来了，而不是像synchronized那样将锁这个东西透明化了。

Lock接口提供了与synchronized相似的行为，同时提供了一些额外的特性：  
1. 非阻塞获取锁tryLock  
2. 可响应中断的上锁方式lockInterruptibly  
3. 超时获取锁，在指定的时间内没有获取锁将返回一个布尔值。
4. 实现类可基于公平，非公平进行实现

另一方面，将Lock从底层抽象出来，也可以使得用户更好的监控锁的状态，如当前的owner是谁？锁是否被获取等。而且可以接着扩展用户子接口，来使得锁可以扩展出更多的行为，使得上锁操作更加灵活可控


Lock毕竟是一个接口，讨论还是需要具体到某一个实现类上的。以最常用的reentrantLock为例

synchronized实现线程通信时搭配wait以及monitor的waitSet,reentrantLock搭配condition对象和await方法。一个synchronized对应一个monitor，因此多个线程调用wait()后将会等待在同一个waitSet。而基于高层实现的reentrantLock可以创建多个condition对象，每个condition对应一个等待队列，因此不同的线程根据不同的等待条件，可以等待在不同的队列，可以使得线程唤醒更加精确。

synchronized实现线程通信时搭配wait以及monitor的waitSet,reentrantLock搭配condition对象和await方法。一个synchronized对应一个monitor，因此多个线程调用wait()后将会等待在同一个waitSet。而基于高层实现的reentrantLock可以创建多个condition对象，每个condition对应一个等待队列，因此不同的线程根据不同的等待条件，可以等待在不同的队列，可以使得线程唤醒更加精确。

实际上synchronized的优点也不少：
【1】synchronized使得用户不需要关心上锁、解锁的逻辑，甚至不需要关心锁对象的存在，而我如果想使用reentrantLock，那么我必须显示创建一个对象，并且显示的lock和unlock。而且必须写在try/finally中，因为synchronized隐式帮我们释放锁，即使出现了异常，而reentrantLock使用的过程中出现异常，并且没有处理锁对象的释放，那么可能出现死锁。
【2】以concurrentHashMap 1.8为例，万物皆为monitor，因此可以把数组元素本身看作一个锁，而不需要向concurrentHashMap 1.7那样显示创建锁对象，并且锁的粒度更小，并发度更大。

更深一层，synchronized和reentrantLock实现了相同的特性：可见性、原子性、有序性。
其中reentrantLock实现这些特性极大依赖于底层的AQS框架（AQS框架使得reentrantLock更加关注于如何实现可重入锁的逻辑而不是同步、阻塞等工作）
reentrantLock实现可见性和原子性，基于读写volatile变量和CAS指令，同时通过CAS修改锁变量保证原子性，volatile保证可见性
>实际上，抛开一些细节，reentrantLock可以看作对synchronized基于java代码的再次实现，一些实现逻辑十分相似，底层都离不开CAS加锁以及直接或间接地插入内存屏障。但是reentrantLock仅仅是Lock/AQS的冰山一角而已。synchronized中的可重入锁是透明的，它只是实现管程synchronized的一个组件，而reentrantLock则是被单独提取，提供给用户，出来以进行复用和扩展。


synchronized锁优化

**公平非公平**
而公平实现中，仅当队列中没有等待更久的节点时，才会尝试CAS占用（也就是说，只要队列中有其他节点正在排队，则当前线程就必须往后排队，不能插队）
公平锁对应的同步队列，节点获取同步状态是有严格的顺序要求的，获取公平锁的线程几乎总是需要创建节点和阻塞，导致线程切换频繁、吞吐量下降、并发度下降。


### countdownLatch
将一个程序分为n个互相独立的可解决任务，并创建值为n的CountDownLatch。**当每一个任务完成时，都会在这个锁存器上调用countDown**，被插队的任务调用这个锁存器的await，直至锁存器计数结束
创建countDownLatch时，构造函数传入的就是state的值，申请state时（调用await），**只有当state值为0时才能成功申请，否则阻塞**。而countDown就是将state减一。

总结：**创建countDownLatch时，它有若干个state，而调用await的线程将会阻塞直到state的值变成0，而另外一组线程则负责调用countDown将state减少**。

### cyclicBarrier

cyclicBarrier可以达到一种效果，N个线程调用cyclicBarrier.await()进入阻塞（相当于被堵在了一个栅栏处），当N个线程全部调用完毕，则“栅栏打开”，线程集中放行。

当第N个线程调用await方法，则N个线程集体放行，并且第N个方法将执行回调函数（其实就是执行传入的runnable接口对应的run方法）

cyclicBarrier依赖reentrantLock和condition对象实现，每个cyclicBarrier底层对应一个reentrantLock实例。可以循环使用，每一代绑定一个generation对象。当调用reset时，将会将当前屏障设置为已经破坏状态，并且唤醒所有阻塞的线程，并且创建新的generation对象

调用await底层对应count变量减一,当减少到0则唤醒所有的等待线程并重置。（parties保存总屏障数量，count对应剩余屏障数量）
## JMM
>[并发研究之Java内存模型（Java Memory Model) - 枫飘雪落 - 博客园 (cnblogs.com)](https://www.cnblogs.com/yanlong300/p/9009687.html)
>[第一节: JMM内存模型、CPU缓存一致性原则(MESI)、volatile、指令重排、内存屏障(Memory Barrier)、as-if-serial、happen-before原则 - qianbing12300 - 博客园 (cnblogs.com)](https://www.cnblogs.com/qianbing/p/12581736.html)

[[JMM]]

```markdown

线程之间是如何通信和同步的:
	两种方式:共享内存和消息传递
	java并发内存模型是采用共享内存来实现的,java线程之间的通信是隐式进行,若对通信机制不了解的话,易产生各种线程可见性问题(一个线程对共享变量值的修改，能够及时的被其他线程看到。). JMM的出现就是为了对线程间的通信进行控制,规定了不同线程如何以及何时可以看到其他线程写入共享变量的值以及如何在必要时同步对共享变量的访问,同时java程序员只需要面对JMM的规则来进行一系列并发操作,不用理会是在哪个平台上进行操作.


JMM规定了对变量的修改只能在线程自己的工作内存中,线程间的通信是通过主存

JMM解决了:可见性,原子性,有序性.通过volatile和synchronized来完成

讲下java层面可见性实现方式哪两种:
synchronized和volatile和final,通过内存屏障来保证可见性和有序性

为什么要保证有序性?
单线程 as-if-serial,保证结果不变,但执行顺序可变
多线程 happens-before 保证多线程之间对数据读写不冲突,但无法保证数据的写写不冲突,所以 volatile无法保证原子性,得加入互斥量才行
单例模式DCL若被重排序后,这里讲讲一个对象new的过程,顺序乱了拿到空指针未初始化的对象


```

线程安全出现的原因
CPU高速缓存的引入和MESI协议的优化
指令重排序问题


## 类
### 类的生命周期
#### 加载
分三步走：

1.  通过类的完全限定名获取定义该类的二进制字节流
    
2.  将该字节流表示的静态存储结构转换为方法区的运行时存储结构
    
3.  在方法区生成一个代表该类的java.lang.Class对象（JVM并没有规定在堆还是在方法区，HotSpot选择方法区），作为方法区中该类各种数据的访问入口


#### 链接
也分三步：

1.  验证
    
    确保Class文件的字节流包含的信息符合当前虚拟机的要求，并不会危害虚拟机自身安全，验证阶段会完成以下4个阶段的动作：
    
    文件格式验证（such 魔数） --> 元数据验证（该类是否继承了不能继承的类） --> 字节码验证（保证跳转指令不会跳到方法体以外的字节码指令上）--> 符号引用验证（通过类的全限定名能否找到对应的类）
    
2.  准备
    
    **jdk1.6 在方法区** 为类变量分配内存并设置初始值，jdk1.7及以后都是在堆分配内存
    
    如果类变量是常量，那么将初始化为表达式所定义的值（在编译时就被放到了class常量池）
    
3.  解析
    
    将常量池的符号引用替换为直接引用的过程
    
    该阶段可在初始化之后再开始，由于支持Java的动态绑定
    
    直接引用（对象引用）：指向目标的指针，相对偏移量或间接定位到目标的句柄


#### 初始化
执行类中定义的Java程序代码。初始化阶段是虚拟机执行类构造器\<clinit\>()方法（由编译器按语句在源文件出现顺序自动收集类变量的赋值动作和静态代码块中的语句合并产生的）的过程

接口中不可以使用静态代码块，但可由类变量初始化的赋值操作，所以接口和类都有\<clinit\>()方法，但执行接口的\<clinit\>()方法不需要执行父接口的\<clinit\>，只有当父接口中定义的变量使用时，父接口才会初始化。接口的实现类在初始化也不会执行接口的\<clinit\>方法

jvm会保证一个类的\<clinit\>方法在多线程环境下被正确的加锁和同步，多个线程执行\<clinit\>只会有一个能执行，其他阻塞，直到方法执行完毕





## 对象与对齐填充
[JVM中的对象探秘（三）- 对象的实例数据与对齐填充_q13145241q的博客-CSDN博客_java对象对齐填充](https://blog.csdn.net/q13145241q/article/details/108169128?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-108169128.pc_agg_new_rank&utm_term=%E4%B8%BA%E4%BB%80%E4%B9%88java%E8%A6%81%E8%BF%9B%E8%A1%8C%E5%AF%B9%E8%B1%A1%E5%A1%AB%E5%85%85&spm=1000.2123.3001.4430)


[Java JVM 字节码-为什么 new 指令后执行 dup 指令? - 代码先锋网 (codeleading.com)](https://www.codeleading.com/article/86952776754/)
### 对象内存
 对象一般存放在堆内存，一个对象可以划分为三个部分：
 1】对象头：对象元信息
【2】实例数据：对象存储的有效信息
【3】对齐填充：保证对象是8的整数倍，因此最小的对象也会占用8字节
对象头主要包含两类信息：对象本身的运行时数据（mark word）和类型指针
通过类型指针，可以指定这个对象的真实类型是什么（属于哪个的实例）。如果是数组还会保存一个用于标记长度的数据。

>java的数组类型是jvm运行时基于newarray指令动态创建的，长度字段直接维护在底层的对象结构中

mark word包含了各种运行时数据，包含hashCode值、锁标记、对象分代年龄、GC标记等

### 对象的创建过程
>[Java中new一个对象是一个怎样的过程？JVM中发生了什么？ - 额是无名小卒儿 - 博客园 (cnblogs.com)](https://www.cnblogs.com/gjmhome/p/11401397.html)
>

1. 查找类在运行时常量池中的引用，如果不是直接引用则说明类还未必加载，则会对类进行加载、连接和初始化。
2. 为对象分配内存空间，**并且置零值**，此时一个空对象创建完毕。
	>如果内存规整，则使用指针碰撞的方式分配内存：把空闲与非空闲内存使用一个指针隔开，分配内存移动指针实现  
	 如果内存不规整，则使用空闲列表管理内存  
	 更新基于CAS保证原子性，如内存分配
	 
分配空间方式有两种：

-   指针碰撞
    
    JVM将堆区抽象为两块区域，一块是已经被其他对象占用的区域，另一块是空白区域，中间通过一个指针进行标注，只需要将指针向空白区域移动相应大小空间，就完成内存的分配。 **这种划分方式要求虚拟机的内存是地址连续的，且虚拟机带有内存压缩机制，可以在内存分配完成时压缩内存，形成连续地址空间**，但存在的问题就是多线程创建对象，可能出现指针划分不一致的问题，对于这个问题虚拟机采用循环CAS操作来保证内存的正确划分
    
-   空闲列表
    
    虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录
    
-   TLAB（不算分配方式）
    
    为了提高多线程创建对象的效率，，虚拟机为每个线程分配不同的空间，这样每个线程在分配内存时只是在自己的空间中操作，避免了同步的开销
    
    > JVM设置了最大浪费空间: ① 当剩余的空间小于最大浪费空间，那该TLAB属于的线程在重新向Eden区申请一个TLAB空间，进行对象创建，如果还是空间不够，那你这个对象就是太大了，需要去Eden区直接创建； ② 当剩余的空间大于最大浪费空间，那这个大对象请你直接去Eden区创建，我TLAB放不下没有使用完的空间；
    > 
    > 链接：[https://www.jianshu.com/p/3684869af4cc](https://www.jianshu.com/p/3684869af4cc)

```markdown
对象虽然创建完了，但是在创建对象的过程中，可能会发生一些小意外。比如：在划分可用空间时，如果是在并发情况下，那么划分就不一定是线程安全的。因为有可能出现正在给A对象分配内存，指针还没有来得及修改，对象B又同时使用了原来的指针分配内存的情况，那么，解决这个问题有两种方案：

    1. 分配内存空间的动作进行**同步处理** ：实际上虚拟机采用CAS配上失败重试的方式保证了更新操作的原子性。

    2.内存分配的动作按照线程划分在不同的空间中进行： 为每个线程在Java堆中**预先分配**一小块内存 ，称为本地线程分配缓冲（Thread Local Allocation Buffer, TLAB）。

```


3. 设置对象头，完成对象的构造(虚拟机对将要创建出来的对象进行信息标记，包括存储在新/老生代，对象的哈希码，元数据信息)
4. 执行\<init\>()进行初始化（实例属性和构造块按照顺序收敛，最后是构造函数）
5. 将堆中对象的首地址赋值给引用变量，入栈

### 对象的创建方式
1. new：通过构造函数创建
2. 反射，动态创建：借助java.lang.Class类的newInstance（）方法（调用无参构造器）
3. 使用java.lang.reflectConstructor类的newInstance（）方法（反射调用某个构造器）
4. 使用对象克隆方法clone（）
5. 先进行序列化，然后在调用反序列化（objectInputStream）的readObject方法。（深拷贝）
>静态创建：创建哪个对象编译后JVM就知道了，类已经被载入常量池了。  
>动态创建：JVM仅知道需要加载反射相关的类，但是要创建什么对象只有运行到反射方法才知道，类可能也是运行时载入内存的。（编译后类的符号引用可能没有被放入常量池）


### new关键字做了什么
通过反编译，可以指定new对应四个指令  
1. new  
在堆中开辟内存空间，并将一个引用类型(this)入栈。
>OS管理内存，jvm向OS申请内存，并且为堆划分出一部分内存，类加载更多的是向jvm方法区申请内存，而创建任意对象则是向jvm的堆区申请内存

2. dup
把栈顶的this拷贝一份，因为之后需要调用（构造器）方法也需要这个引用
>**那么new 指令后,为什么一定要dup操作呢?**
>**虚拟机指令new在堆上分配了内存并在栈顶压入了指向这段内存的地址供任何下面的操作来调用**, 但是在这个操作数被程序员能访问的操作之前,虚拟机自己肯定要调用对象的方法
>第一次调用invokespecial 时会弹出一个,下面一个留给对该对象访问的操作

```markdown
new 指令后，会执行构造函数，使用了第一个引用。

1.程序做赋值操作。第二个引用会保存到局部变量表槽位中。比如：Object o = new Object()
    
2.程序不做赋值操作，直接操作对象的成员。则直接使用第二个引用。比如：new Object().toString()
    
3.程序不对这个对象操作，第二个引用被 `pop` 指令弹出

```

3. invokeSpecial
执行构造器方法，参数是一个类的常量池引用，这会触发类的加载。而子类的加载又会触发父类的加载，而且编译器为\<init\>方法首行自动调用父类的\<init\>方法，最终的效果：
执行父\<clinit\>()——> 子\<clinit\>()——>父 \<init\>()——>子\<init\>()
> 我的理解，代码块和变量赋值的动作优先级高于\<init\>()，编译器会默认在构造函数第一句执行空的父构造器，也可以指定。如果没有写构造器则编译器生成默认的空构造器，否则不生成默认空构造器，因此父 \<init\>()中执行的是子\<init\>()指定调用的构造器或者默认构造器。

4. 引用出栈，存入局部变量表（astore）

#### this的本质
因此，this本质上就是一个引用，它指向的就是当前实例对象，我们使用this和使用其他的引用无本质区别。
另一方面，new指令的本质就是触发构造器的调用。构造器的写法上是不加返回值的，但是它其实是有返回值的，返回的就是this这个引用。而this引用指向的就是创建完成的对象。

而**实例方法中可以直接使用this，是因为实例方法的局部变量表中总是在第一个位置存放this引用（slot_0）,static则没有this这个隐式参数。**


#### super的本质
super代表当前实例从父类继承而来**信息域**的引用（地址）  
也就是说super并不是一个完整的对象，他只是一个内存范围，因此使用super可以访问有限的信息，但是却不能把super当做一个引用
`        Program cur = this;`
`        Object o = super;  报错`
子类字节码中有父类索引，因此可以直接找到父类的各种信息（元信息、方法指令），父类定义的内存全部在子类的内存范围，new开辟的内存空间中，不仅含有子类的数据，也包含父类拿到的数据，子类是父类的延伸，因此子类对象往往比父类对象更占用内存空间。


**能否访问**
子类能否访问父类的字段和方法由标准ACC_FLAG决定，而且这在编译阶段和类检验阶段已经可以保证这条语义的正确性了。用户看似“没有继承”或者“看不见”，其实是“继承”下来的，同样占用内存空间，这也就解释为什么通过反射暴力破解能够访问到相应的值了——不是拿不到，而是私有字段或方法对应的内存地址禁止访问，这在编译期是可以检查出来的。

总结：
this和super本质上都是指向一段内存（new出来的内存空间）的指针，但是super只能访问该空间的部分数据（专门存储父类信息的内存数据），调用父类构造函数是为这段空间的成员初始化/填充数据。通过super调用方法对应invokeSpecial指令，调用版本编译期确认，就是父类的方法，解析阶段将常量池中的引用解析为直接引用。而this调用的方法对应invokeVirtual，运行时分派，无法确认方法是否被子类重写。

#### 变量
变量分类（按数据类型区分）：1) 基本数据类型   2) 引用数据类型
在类中声明位置区分：
    1) 成员变量：在使用前，都经历过默认初始化赋值，
       类变量：在链接(Linking)的准备(Prepare)阶段，给类变量默认赋值，初始化(initialization)阶段给类变量显式赋值，即静态代码块赋值。
    2) 局部变量：在使用前，必须进行显式赋值，否则编译不通过。

局部变量表与垃圾回收的关系：
**在方法执行时，虚拟机使用局部变量表完成方法的传递。**
  局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收。

## JVM
### 垃圾回收
```markdown
判断对象存活有两种: 1引用计数法 2.可达性分析算法
- 首先是进行一个根节点枚举(如何确保一致性快照,如何快速完成根节点枚举)
使用可达性分析算法时,这个操作必须要在一个能保证一致性的快照中进行,否则无法保证结果的准确性,因此需要**stop the world**，停止所有的用户线程工作，使得GC线程可以在一个一致性快照中进行垃圾回收工作

由于程序执行过程中并不是在任意位置都能够停下来,得到达"安全点"才行
主流JVM采用主动式中断,垃圾收集器需要中断线程时,在安全点以及所有创建对象和其他需要在堆上分配内存的地方设置了中断标志,各个线程在运行过程中不停地主动轮询这个标志,若为真则在最近的安全点主动挂起

但是对于处于阻塞或等待状态的线程，就无法执行中断操作，因为它们此时无法进入运行状态，这时需要引入安全区域。（如果一个线程长期sleep，那么GC将暂时无法回收该线程在堆中产生的垃圾）
安全区域可以看作安全点的拉伸，线程要么冻结在安全点的位置，要么冻结在安全区域的范围。


用户线程到达安全点后,更新自己的oopMap

- oopMap
**oop (ordinary object pointer) 普通对象指针，oopmap就是存放这些指针的map,OopMap 用于枚举 GC Roots，记录栈中引用数据类型的位置**,类加载动作完成后HotSpot就会把对象内什么偏移量上是什么类型的数据计算出来收集器扫描时可以

一个线程为一个栈，一个栈由多个栈桢组成，一个栈桢对应一个方法，一个方法有多个安全点。GC发生时，程序首先运行到最近的一个安全点停下来，然后更新自己的OopMap，记录栈上哪些位置代表着引用。枚举根节点时，递归遍历每个栈桢的OopMap ，通过栈中记录的被引用的对象内存地址，即可找到这些对象（GC Roots）




从这些节点开始往下遍历其引用关系,这里就涉及到三色标记法(黑,白,灰),遍历完成后,就只剩下两类对象,分别是白和黑

- 由于并发标记阶段用户线程并未停止，仍然在改变对象的引用关系,所以就可能导致:
1.黑色对象通过灰色对象引用了白色对象,但该灰色对象在这之后取消了对白色对象的引用
2.黑色对象不再被引用

第一种情况若发生,将会导致空指针,使得虚拟机崩溃,若以下两个条件同时发生将会导致该情况出现:
1.黑色对象直接引用了白色对象
2.灰色对象删除了对白色对象的引用

为了破坏这两个条件,引入了:
1.强三色不变式:保证永远不会存在黑色对象到白色对象的引用
2.弱三色不变式:所有被黑色对象引用的白色对象都处于灰色保护状态，即直接或间接从灰色对象可达

CMS收集器采用增量更新（incremental update）写屏障实现强三色不变式

解决方案  
【1】**增量更新——记录新增加引用**，这也是CMS的解决方案  
黑色对象一旦插入新的指向白色对象的引用时，就记录这个引用，之后再以这些引用中的黑色对象为根再次扫描一次——**黑色对象一旦插入了指向白色对象的引用之后，就变成了灰色对象**  
【2】**原始快照——记录被删除的引用**，这是G1的解决方案  
灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再将这些**记录过的引用关系中的灰色对象为根，重新扫描一次**——无论引用关系删除与否，都会**按照刚刚开始扫描那一刻的对象图快照进行扫描**

第二种是浮动垃圾,等待下一次GC即可



标记修正


并发清除
```


### 跨代引用问题

**老年代对象指向新生代对象的引用**,标记的时候就得扫描全部的老年代对象,效率低,所以在新生代建立一个全局的数据结构——**记忆集**
记忆集相当于一个映射结构，它将老年代内存块划分为若刚个小块，每一个单位与一个小块产生映射，相当于bitMap。  

[[JVM#卡表]]

### 类加载流程

[[JVM#类加载过程]]


### 栈 和 堆
>[(53条消息) JVM之栈详解_可小辉的博客-CSDN博客_jvm栈](https://blog.csdn.net/weixin_44364444/article/details/110248863)
>[深入理解JVM-java虚拟机栈 - 李东平|一线码农 - 博客园 (cnblogs.com)](https://www.cnblogs.com/newAndHui/p/11168791.html)
>[(53条消息) JVM栈帧内部结构-局部变量表_chenxi_blog的博客-CSDN博客_局部变量表结构](https://blog.csdn.net/qq_20394285/article/details/104673874)

**JVM 栈描述的是每个线程 Java 方法执行的内存模型**：每个方法被执行的时候，JVM 会同步创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息
是一个只能在表尾进行插入和删除操作的线性表，其生命周期和线程同步，线程结束，栈内存就释放，不存在垃圾回收的问题

**栈与堆的区别**

栈是运行时的单位，而堆是存储的单位，即栈解决的是运行问题，即程序如何执行，或者如何处理数据，功能类似于计算机硬件 PC寄存器。堆解决的是数据存储的问题，即数据怎么放、放哪儿。

特点
-   访问速度快，仅次于程序计数器
-   线程私有
-   存在 OOM，不存在 GC

**存放的类型**：8种数据类型、对象的引用、实例的方法

>栈中的数据都是以栈帧（Stack Frame）的格式存在，栈帧是一个内存区块，是一个数据集，是一个有关方法 (Method) 和运行期数据的数据集，当一个方法A被调用时就产生了一个栈帧 F1，并被压入到栈中


栈帧的定义，栈帧结构（局部变量表），操作数栈，动态链接，返回地址
栈帧（Stack Frame）是用于支持虚拟机进行方法调用和方法执行的数据结构

局部变量表（Local Variable Table）是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量
局部变量表存放了编译期可知的各种基本数据类型(boolean、byte、char、short、int、float、long、double)「String是引用类型」，对象引用(reference类型) 和 returnAddress类型（它指向了一条字节码指令的地址）

局部变量表的容量以变量槽为最小单位，每个变量槽都可以存储32位长度的内存空间

方法执行的过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是出栈和入栈操作（与 Java 栈中栈帧操作类似）。操作栈调用其它有返回结果的方法时，会把结果 push 到栈上（通过操作数栈来进行参数传递）。

**每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，
持有这个引用是为了支持方法调用过程中的动态连接（Dynamic Linking）。
在类加载阶段中的解析阶段会将符号引用转为直接引用，这种转化也称为静态解析。
另外的一部分将在每一次运行时期转化为直接引用。这部分称为动态连接。**


### 双亲委派机制
>[如何打破双亲委派机制？ - looyee - 博客园 (cnblogs.com)](https://www.cnblogs.com/looyee/articles/13954722.html)
>
![[Pasted image 20220224165739.png]]

![[Pasted image 20220224165817.png]]



![[Pasted image 20220224165856.png]]
![[Pasted image 20220224165949.png]]

![[Pasted image 20220224170039.png]]
## 进程和线程

#### 进程和线程的来历
历史：
最开始，没有进程和线程的概念，一个程序就是一个任务，CPU按照顺序执行用户输入的任务。
出现的问题就是：程序是顺序执行的，一个任务正在执行的过程中，另一个任务必须等待。
这就导致了两个问题：
	1. 如果存在某些紧急任务需要执行，就必须等待前面的任务执行，
    2. 当前执行的任务可能在某些环节，CPU并不参与计算（如等待IO设备就绪），但是CPU仍被该任务占用。

为了解决这两类问题，引入了进程，引入进程后的改变：
	原来的程序是静态的，而且一次只能执行一个程序，而且不能被中断，也不能被抢占。一个任务只有两种状态：没执行，执行完了。
	而现在引入进程的主要作用是什么——**引入了一个新的状态“正在执行的程序”**。有了这个状态，我们可以指明哪个程序在执行的过程中遇到了中断，哪些程序执行到一半CPU被抢占了。说白了，引入进程本质上是为了保存程序运行途中的上下文。
	“上下文”是一个比较抽象的概念，它指的是一组软件或硬件的状态，比如当前某个寄存器保存的值、当前程序计数器指向了那个指令等，例如游戏打到一半存个档，当前的血槽、当前的金币数目都是上下文的一部分。上下文可以直接看作一组寄存器的状态和一组变量的值。（或者理解为硬件软件状态在某一刻的快照）
	能够保存存档，我就能玩玩其他存档了，于是你可以“并发”玩多个存档
	狭义上的并发就是这样产生的，**并发的基础就是上下文能够被保存与恢复。** 我们可以将进程想象为一长串**顺序**的指令流，当指令流执行完毕后，进程就退出来了，那么我们可以将这一串指令流来切开，即将这一长串指令流切为一片一片的指令片，只要CPU按照顺序执行这些指令片，也能得到和一直执行进程一样的结果。

引入进程后，由于进程切换代价大，我们由引入了线程，为什么：
	进程切换知识点
	引入线程之后，本质上是为了实现多线程，减少进程的切换。如果默认创建一个进程，那么它仅有一个执行流，我们可以称之为主线程。之前谈论的都可以看作单线程进程，进程之间的切换其实本质上是两个线程的跨进程切换。
	如果一个程序内部想要实现并发，那么程序内部能够包含多个执行流，这个执行流就是线程。如果将多个单线程进程的程序改造成多线程单进程的程序，那么执行流之间的切换，时间成本将大大降低，CPU就可以更多的执行程序本身的代码，而不是执行流切换的内核代码。

总结：线程是对程序执行流的抽象，引入线程是为了实现程序内执行流之间的并发，进而减少执行流切换的代价，同时进一步提升CPU利用率。进程侧重程序之间的并发，而线程侧重于程序内部的并发


之前说过，不管进程切换还是线程切换，本质上切换的是任务执行流。进程至少包含一个执行流，同时它管理了各种资源如内存地址空间、文件描述符等程序所拥有的资源。这个执行流就是一个线程，而线程的实现主要分为系统线程和用户线程。
系统线程之间由操作系统管理(os能够“看见”它，因为os转为为它定义了特定的结构体)。而os“看不见”用户线程。
系统线程的切换、销毁、创建等全部由os负责，但是如果系统线程过多，对操作系统来说也是不小的压力，因为系统线程的保存占用系统内存，**系统线程的调度也是需要经过“陷入内核”的 ，这个“陷入内核”将导致上下文切换，使得一部分时间不得不用来执行内核的代码。**
为了解决上下文切换这个问题，引入了协程：
协程的引用，其实就是通过线程的**分时复用**实现基于一对多或多对多的线程模型。
其中一个系统线程可以与多个用户线程产生映射，用户线程的切换在用户态进行，不需要上下文切换，CPU利用率进一步提高。
>再次使用上面的例子，CPU使用的会议软件有多个对话框， 每个框是一个系统线程，CPU可以看见每一个框。引入协程，一个框不再是一个用户了，而是若干个用户，每个用户都是一个用户线程。（这下子，CPU切换框的几秒钟摸鱼时间都没了，CPU快被榨干了！）
这也存在一个问题，当其中一个用户线程（协程）发起系统调用或其他阻塞操作，系统线程对应的一组用户线程（协程）都将被阻塞。因此协程一般不进行阻塞调用，一般将协程和异步IO结合使用。（框里面一个用户办点事，然后CPU开始框中服务另一个用户，前一个用户办完事后主动通知CPU我办完了，咱们继续吧）
黑皮书里提了一个解决方案：如果某个协程进行阻塞调用，就拿到一个新的系统线程，然后将其他任务迁移过去，调用返回后读取结果

总之：常规的线程通常指的是操作系统可以直接控制的系统线程，而协程是一种用户线程，一个线程与多个协程可以通过分时复用进行映射，协程的引入通过减少线程切换的次数来进一步提升CPU利用率。
但是，协程毕竟是用户级层面的，而系统线程委托给操作系统管理，操作系统直接管理CPU硬件，它将把线程映射到多核CPU的每一个核心上，实现线程（执行流）的并行执行。而协程则无法利用这一点，因为操作系统只能看见与协程关联的系统进程而已


### 进程和线程的区别
1. 进程是对**运行中程序**的抽象，而线程是对**程序执行流**的抽象
2. 广义上的进程是资源调度的基本单位,而线程是描述任务执行的基本单位
3. 进程切换的开销远大于线程
```markdown
进程的切换，实质上就是被中断运行进程与待运行进程的上下文切换。从主观上来理解。只分为两步：  
**1.切换新的页表(把虚拟地址空间对应的部分，映射到物理地址上**)，然后使用新的虚拟地址空间  
2.切换内核栈，加入新的内容(PCB控制块，资源相关)，硬件上下文切换(CPU 寄存器和程序计数器的内容)

因为线程共享进程的虚拟地址空间，所以切换的时候没有第一步的过程((TCB))
进程调用系统调用，陷入内核，在内核中执行代码也需要调用函数，这时函数调用所用到的栈就是内核栈

进程上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址和TLB一瞬间都作废了。

进程调度，切换进程上下文，包括分配的内存，数据段，堆栈段等  
线程调度，切换线程上下文，主要切换堆栈，以及各寄存器（同个进程里的线程 堆栈不同）

协程，（轻量级线程） 每个协程都自带一个栈，协程就是一个函数和这个函数运行时数据的栈

```
4. 线程崩溃可能导致其所在的进程崩溃,而进程崩溃不会影响到其他进程
>线程崩溃的本质就是内存出错。而内存出错有时不会引起其他线程出错的，因为崩溃的线程，也就是出错的内存有时侯没有被其他线程访问，也就不会产生问题，但有时候会打乱其他线程的内存。



我们聊一聊进程与线程的区别，进程是对**运行中程序**的抽象，而线程是对**程序执行流**的抽象。进程的引入是为了保存运行到一半的程序的状态，转而可以执行别的程序，以此来实现程序之间的并发。而线程的引入同理，也是为了保存运行到一半的某条执行流，转而可以执行另外的一条执行流，以此来实现执行流之间的并行。
其实线程可以粗略地看作进程的一个子集，广义上的进程可以看作内存空间、CPU、文件描述符等资源的分配的基本单位。而狭义上的进程可以看作一个仅有一个主线程的工作单元，因此线程也称为轻量级线程。引入线程概念之前，进程即使资源分配的单位，又是程序调度和执行的基本单位。而引入线程后，“执行流”这个抽象的东西就被概念化为了“线程”，因此线程称为了描述任务执行的基本单位。
>一个程序如果能够被执行下去，那么地址空间必不可少，程序中可能涉及打开文件、申请变量等操作，而且程序想要执行也必须占用CPU这个资源。如何理解资源分配的基本单位？内存条这个硬件被操作系统管理，操作系统将内存地址分配出去是以进程为单位分配的，但是一般分配的都是逻辑地址（虚拟地址），当对应空间需要被访问时才会映射为物理地址。而CPU也是一次分配给一个进程的，CPU的作用可以粗略理解为：一行行扫描代码，然后转换为CPU指令集中的汇编指令，产生结果…执行一个范围内的代码就是一个执行流，因此线程是程序执行的基本单位。


### 进程和线程切换
因为线程共享进程的一切资源，最主要是内存地址空间。使得线程切换时不会发生页表的切换，仅仅需要保存与加载线程上下文即可。

> CPU是执行代码用的，CPU在任意时刻在某一进程——这里的意思是：读取一个进程上下文的数据后，就开始在为该进程分配的内存空间中执行计算，如果需要创建对象，就在进程的堆内存中创建，如果需要执行方法就在进程的栈内存中创建栈帧，进程基本上只是为CPU提供了初始数据、代码、和存放中间数据的内存空间等资源。CPU执行某段代码所产生的上下文可以使用线程上下文来描述——因此进程、线程上下文本质上都是CPU上下文，或者说进程和线程这两个结构就是**用于存储/描述不同粒度的CPU上下文的**。  
> 执行代码产生的临时数据都可以看作CPU上下文，而**CPU执行中断后会把此时的上下文数据保存到进程的内核栈，当程序恢复后会从内核栈去读取线程上下文**。因此当程序正在用户栈执行时，内核栈都是空的。而一个没有持有CPU的**就绪进程/线程**，它的**上下文数据保存在内核栈**。

#### 具体的过程

CPU执行A线程中的代码时（其实就是执行一个个方法，用户态），如果A线程发生线程切换，CPU将陷入内核（CPU的程序状态字寄存器修改状态，进入内核态），然后CPU将堆栈指针从用户栈指向内核栈，并将线程上下文保存的内核栈后，开始在内核栈中执行线程切换的内核代码（主要是读取线程B的上下文，当线程切换相关的代码/方法全部执行完毕，相应的栈帧全部出栈，此时内核栈就剩下一个上下文数据了），切换程序执行文本后，此时CPU上下文已经被载入新的上下文数据（读取线程B上下文，栈帧出栈，然后堆栈指针指向线程B的用户栈，同时将PSW拨回用户态），因此CPU开始执行另一些代码了。

#### 线程切换代价对比

进程切换和线程切换都需要涉及一次CPU上下文（中断上下文）的切换，CPU的堆栈指针会指向内核栈，然后将包括程序计数器、通用寄存器、程序状态字等硬件上下文保存在内核栈中。 

**进程切换**还需要额外做的就是切换虚拟地址空间，通过切换页表指针来实现，这个过程需要访问内存，重新读取页表的地址。  
同时，页表切换意味着CPU的高速缓存要刷新，主要是页表条目的高速缓存TLB会被刷新（清空），CPU进行地址转换时必须通过访问内存。

> CPU在一个时钟周期能够执行多条指令，而访问一次内存耗费的时间占用多个时钟周期，这使得CPU利用率下降。而现代内存地址映射一般采用多级页表，从内存中加载页表项的代价相对会更大。



### 多进程和多线程

>[是不是说cpu有几个核心，系统就最多能有几个进程处于执行状态?-CSDN社区](https://bbs.csdn.net/topics/390950384?list=lz)
>[主流WEB服务器的多线程和多进程模型的选用 - 简书 (jianshu.com)](https://www.jianshu.com/p/a253d21e4b16)
>[(52条消息) 线程和进程有什么区别（简单介绍）_邦杠的博客-CSDN博客](https://blog.csdn.net/weixin_42981419/article/details/86162071)




分为多进程单线程 和 单进程多线程来探讨

**稳定性**
当需要运行的个体互不影响时,相互保持独立性,就需要使用多进程,但通信麻烦

**性能提升**
多进程模式 下想要提升性能,通过增加CPU数量

多线程 提升性能也可以,但收到当前进程的限制,因为它的内存地址空间总是不能高于进程申请的总地址空间

**密集访问情况**
若是需要创建的实例大于核心数,那么多进程性能弱于多线程
>较轻的上下文切换开销 - 不用切换地址空间，不用更改寄存器，不用刷新TLB。

**总结**
线程程序天生共享内存，通信方便。创建、切换、销毁代价更小。但是性能提升有瓶颈。（是否稳定需要具体分析，和具体的线程模型、线程的实现等有关）。  
多进程粒度大、切换代价大之外，但是性能扩展比较容易实现，而且具有稳定性（健壮性）

面对大量短任务,多线程优势在于其较轻的上下文切换开销;
面对稳定性较高的任务,需要多进程(redis集群)


### 通信

线程同步机制
[线程通信机制：共享内存 VS 消息传递 - youxin - 博客园 (cnblogs.com)](https://www.cnblogs.com/youxin/p/3589881.html)

![[Pasted image 20220220223446.png]]

>[进程间通信 （IPC） 方法总结 (一) - 12oz - 博客园 (cnblogs.com)](https://www.cnblogs.com/joker-wz/p/11000489.html)
>[(52条消息) 【Linux】详细理解进程间通信机制（管道、消息队列、共享内存、信号量）_C/C++菜鸟养成记-CSDN博客](https://blog.csdn.net/weixin_43753894/article/details/100164351)


进程间通信方式
-   管道：
    -   无名管道（内存文件）：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程之间使用。进程的亲缘关系通常是指父子进程关系。
        
    -   有名管道（FIFO文件，借助文件系统）：有名管道也是半双工的通信方式，但是允许在没有亲缘关系的进程之间使用，管道是先进先出的通信方式。
        
-   共享内存：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与信号量，配合使用来实现进程间的同步和通信。
    
-   消息队列：消息队列是有消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
    
-   套接字：适用于不同机器间进程通信，在本地也可作为两个进程通信的方式。
    
-   信号：用于通知接收进程某个事件已经发生，比如按下ctrl + C就是信号。
    
-   信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，实现进程、线程的对临界区的同步及互斥访问。



进程通信和线程通信**本质上都是程序之间的两个执行流的通信**。  
通信无处不在，通过cmd窗口执行命令、连接数据库、使用浏览器都是通信。

进程通信核心关注点，是将两个内存地址独立的进程可以互相发送消息。  
大致的思路：使用一个中间的载体，一个进程放入一个进程取，或者进程能够通过端口+ip地址定位到另一个进程，约定某一种格式的信息，像写信一样交流、还有一种思路是内存映射。

由于同一进程下线程是共享内存空间的，也就是说“线程没有自己的内存空间”或者“线程可以访问进程的地址空间”，亦或者“线程可以轻易地访问对方的地址空间”。  
因此线程通信非常简单，它们天生共享内存。因此线程通信的关注点在于如何“安全地”访问内存——线程安全问题。

进程如果想要达成线程的效果，需要使用共享内存映射或者共享内存文件映射。  
因此，**线程关注点在于“安全访问”，而进程关注点在于“信息传递”。**


> 这里简单说一下通信方式。进程之间可以
> 【1】采用管道通信，属于内核中的缓存（是否阻塞取决于具体实现和策略），但是通信效率低下（访问需要涉及系统调用，而且一般是阻塞调用），不适合频繁交换数据  ，但是简单，一般执行简单的指令可以使用  
> 【2】消息队列，进程以格式化的消息（类似报文）为单位，将数据封装到消息中，并且通过OS的原语进行消息传递。  
> 通信不及时、而且消息体的大小有限制，通信的过程中需要把消息在内核缓存和用户缓存中进行数据拷贝。因此也不适合大数据传输以及频繁的通信  
> 【3】内存映射  
> 进程可以通过内存映射实现共享内存，达到和线程类似的效果（指内存），之后应用程序（CPU）可以像访问普通内存一样访问共享内存（不用切换PSW）  
> 【4】线程和基于共享内存通信的进程都具有“访问安全问题”。因此需要使用锁或者信号量进行解决不安全问题。  
> 操作系统层面可以使用P/V原语实现进程的同步或互斥。一些编程语言提供了锁和信号量的API可以直接使用。（这里同步与互斥的对象都是执行流，没必要区分太开）  
> 【5】信号是一种异步的通信机制，如Ctrl+C和kill命令。  
> 【6】同主机或跨主机进程还可以使用socket通信。  
> 【7】锁。锁本质上是一个标志，是否已经上锁？owner是谁？锁也可以分为共享锁、互斥锁、自旋锁、无锁等。上锁（标志被置位）一般是基于CAS指令实现的（关中断、testAndSet也可以实现）。  
> **有锁**：资源访问前先CAS修改锁变量。  
> **无锁**：CAS直接修改资源，如果修改失败则认为竞争失败，如何重试取决具体逻辑  
> 线程层面，锁一般是**进程内存地址中的一个变量**，而进程层面（跨进程线程），锁一般是两个进程**共同指向的一个打开的文件**  
> 【8】文件映射。是共享内存的实现方式之一。先将磁盘物理块部分或者全部映射到内存物理块上，然后将这个内存物理块映射到若干个进程的内存地址空间（虚拟内存页）上。（内存映射后，内存物理块保存的二进制内存最终会保存到磁盘的物理块上）  
> 【9】文件。如果说线程共享是进程内存地址下某个共享变量，那么进程就可以共享共同指向的某个文件。


### 线程模型
>[(52条消息) Java线程和操作系统线程的关系_CringKong的博客-CSDN博客_java线程和操作系统线程](https://blog.csdn.net/CringKong/article/details/79994511)

操作系统线程的状态：
【1】创建（new）
【2】销毁（terminated）
【3】运行（running）：获得CPU
【4】就绪（ready）：获得除了CPU之外的所有必要资源
【5】等待（waiting）：等待某个事件发生而无法继续执行（IO设备就绪、系统调用执行完毕、请求到达等），进程主动申请阻塞，CPU被调度给别的就绪进程


Java的线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一条线程，都需要操作系统来帮忙完成，这就需要从用户态转换到核心态中，因此状态转换需要耗费很多的处理器时间。所以synchronized是Java语言中的一个重量级操作。在JDK1.6中，虚拟机进行了一些优化，譬如在通知操作系统阻塞线程之前加入一段自旋等待过程，避免频繁地切入到核心态中

而java线程的状态：
【1】runnable：调用start（）方法后
【2】blocked：阻塞，阻塞进同步队列。（进入同步块且没有成功抢占锁将进入该状态）
【3】waiting：无限期等待，如果等待的事件不发生就一直等待
【4】time_waiting：有限期等待，到底一定时间后自动返回
【5】new：创建线程对象，但是没有调用start（）方法
【6】terminated：线程任务执行完毕

**为什么java只有Runnable**
操作系统层面，处于running状态的线程如果放弃CPU则进入runnable状态，而java为我们屏蔽了线程切换（CPU调度）的细节，我们只需要知道创建一个线程，然后调用start()方法该线程进入runnable状态即可。如果将runnable拆分为两个状态，那么就相当于打破了操作系统和虚拟机之间的隔离性，违背了jvm设计的初衷，本末倒置了。
java线程执行的过程中，总是不断的发生CPU调度，但是对于用户是透明的，因为java屏蔽了这一切的细节，对于用户来说，一旦一个线程被start()调用，那么它便是runnable的。



#### Java线程使用方式
[[JUC#4 java线程]]




## IO

>[NIO/IO多路复用 - 云+社区 - 腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1637752)
>[NIO核心组件 - 云+社区 - 腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1638898)
>[Reactor NIO（IO多路复用） - 云+社区 - 腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1640178)
>[select、poll、epoll之间的区别(搜狗面试) - aspirant - 博客园 (cnblogs.com)](https://www.cnblogs.com/aspirant/p/9166944.html)

**IO 模型对比**

**IO 操作其实就分为两个步骤，等待和操作。等待的意思其实就是等待连接建立，等待数据可读，等待数据可写，而操作则指的是读数据写数据。**
**同步**：线程自己去获取结果（一个线程）
**异步**：线程自己不去获取结果，而是由其它线程返回结果（至少两个线程）
>线程1调用方法后理解返回，**不会被阻塞也不需要立即获取结果**
>当方法的运行结果出来以后，由线程2将结果返回给线程1

**多路复用与阻塞IO的区别**
-   阻塞IO模式下，**若线程因accept事件被阻塞，发生read事件后，仍需等待accept事件执行完成后**，才能去处理read事件
-   多路复用模式下，一个事件发生后，若另一个事件处于阻塞状态，不会影响该事件的执行


###  堆外内存
[堆内内存与堆外内存 - wellDoneGaben - 博客园 (cnblogs.com)](https://www.cnblogs.com/ronnieyuan/p/11718536.html)
-   使用堆外内存的优点
    -   减少了垃圾回收机制(GC 会暂停其他的工作)
    -   加快了复制的速度
        -   堆内在flush到远程时, 会先复制到直接内存(非堆内存), 然后再发送。
        -   而堆外内存(本身就是物理机内存)几乎省略了该步骤
-   使用堆外内存的缺点
    -   内存难以控制
        -   使用了堆外内存就间接失去了JVM管理内存的可行性，改由自己来管理，当发生内存溢出时排查起来非常困难。

直接内存并非Java运行时数据区域，该区域不受Java堆大小限制，但是受到本机总内存限制。在直接或间接使用DirectByteBuffer（间接使用如NIO）也可能出现OOM。

写的挺好的
[堆外内存的回收机制分析 - 简书 (jianshu.com)](https://www.jianshu.com/p/35cf0f348275)


### 零拷贝

这个也不错
>[(62条消息) socket怎么知道数据来源那个网卡_你知道吗？ 8 张图，搞定「零拷贝」_weixin_39689297的博客-CSDN博客](https://blog.csdn.net/weixin_39689297/article/details/111014627)

**零拷贝指的是数据无需拷贝到 JVM 内存中**，同时具有以下三个优点

-   更少的用户态与内核态的切换
-   不利用 cpu 计算，减少 cpu 缓存伪共享
-   零拷贝适合小文件传输


#### 传统IO问题
![[Pasted image 20220313113211.png]]
-   Java 本身并不具备 IO 读写能力，因此 read 方法调用后，要从 Java 程序的**用户态切换至内核态**，去调用操作系统（Kernel）的读能力，将数据读入**内核缓冲区**。这期间用户线程阻塞，操作系统使用 DMA（Direct Memory Access）来实现文件读，其间也不会使用 CPU
    
    `DMA 也可以理解为硬件单元，用来解放 cpu 完成文件 IO`
    
-   CPU将数据从**内核缓冲区**拷贝到**用户缓冲区**（即 byte[] buf），无法利用 DMA,拷贝完成后read函数放回,从**内核态**切换回**用户态**，
    
-   调用 write 方法，用户态切换为内核态，这时将数据从**用户缓冲区**（byte[] buf）写入 **socket 缓冲区，CPU 会参与拷贝**
    
-   接下来要向网卡写数据，使用 DMA 将 **socket 缓冲区**的数据写入网卡，不会使用 CPU
- wtire函数返回，切换了一次
    

可以看到中间环节较多，java 的 IO 实际不是物理设备级别的读写，而是缓存的复制，底层的真正读写是操作系统来完成的

-   用户态与内核态的切换发生了 3 次，这个操作比较重量级
-   数据拷贝了共 4 次


#### NIO
[linux dma拷贝数据到用户态,图解：零拷贝Zero-Copy技术大揭秘_学习中的小包的博客-CSDN博客](https://blog.csdn.net/weixin_32452127/article/details/116683728)


通过 **DirectByteBuf**

-   ByteBuffer.allocate(10)
    -   底层对应 HeapByteBuffer，使用的还是 Java 内存
-   ByteBuffer.**allocateDirect**(10)
    -   底层对应DirectByteBuffer，**使用的是操作系统内存**

[![](https://nyimapicture.oss-cn-beijing.aliyuncs.com/img/20210418162410.png)](https://nyimapicture.oss-cn-beijing.aliyuncs.com/img/20210418162410.png)

大部分步骤与优化前相同，唯有一点：**Java 可以使用 DirectByteBuffer 将堆外内存映射到 JVM 内存中来直接访问使用**

-   这块内存不受 JVM 垃圾回收的影响，因此内存地址固定，有助于 IO 读写
-   Java 中的 DirectByteBuf 对象仅维护了此内存的虚引用，内存回收分成两步
    -   DirectByteBuffer 对象被垃圾回收，将虚引用加入引用队列
        -   当引用的对象ByteBuffer被垃圾回收以后，虚引用对象Cleaner就会被放入引用队列中，然后调用Cleaner的clean方法来释放直接内存
        -   DirectByteBuffer 的释放底层调用的是 Unsafe 的 freeMemory 方法
    -   通过专门线程访问引用队列，根据虚引用释放堆外内存
-   **减少了一次数据拷贝，用户态与内核态的切换次数没有减少**


#### 进一步优化1

**以下两种方式都是零拷贝**，即无需将数据拷贝到用户缓冲区中（JVM内存中）

底层采用了 **linux 2.1** 后提供的 **sendFile** 方法，Java 中对应着两个 channel 调用 **transferTo/transferFrom** 方法拷贝数据

[![](https://nyimapicture.oss-cn-beijing.aliyuncs.com/img/20210418162750.png)](https://nyimapicture.oss-cn-beijing.aliyuncs.com/img/20210418162750.png)

-   Java 调用 transferTo 方法后，要从 Java 程序的**用户态**切换至**内核态**，使用 DMA将数据读入**内核缓冲区**，不会使用 CPU
    
-   数据从**内核缓冲区**传输到 **socket 缓冲区**，CPU 会参与拷贝
    
-   最后使用 DMA 将 **socket 缓冲区**的数据写入网卡，不会使用 CPU
    

这种方法下

-   只发生了2次用户态与内核态的切换
-   数据拷贝了 3 次

#### 进一步优化2

**linux 2.4** 对上述方法再次进行了优化

[![](https://nyimapicture.oss-cn-beijing.aliyuncs.com/img/20210418163033.png)](https://nyimapicture.oss-cn-beijing.aliyuncs.com/img/20210418163033.png)

-   Java 调用 transferTo 方法后，要从 Java 程序的**用户态**切换至**内核态**，使用 DMA将数据读入**内核缓冲区**，不会使用 CPU
    
-   只会将一些 offset 和 length 信息拷入 **socket 缓冲区**，几乎无消耗
    
-   使用 DMA 将 **内核缓冲区**的数据写入网卡，不会使用 CPU
    

**整个过程仅只发生了2次用户态与内核态的切换，数据拷贝了 2 次**


### AIO

AIO 用来解决数据复制阶段的阻塞问题

-   同步意味着，在进行读写操作时，线程需要等待结果，还是相当于闲置
-   异步意味着，在进行读写操作时，线程不必等待结果，而是将来由操作系统来通过回调方式由另外的线程来获得结果

> 异步模型需要底层操作系统（Kernel）提供支持
> 
> Windows 系统通过 IOCP **实现了真正的异步 IO**
>  Linux 系统异步 IO 在 2.6 版本引入，但其**底层实现还是用多路复用模拟了异步 IO，性能没有优势**



### 五种IO模型
-   传统 IO(阻塞 I/O)会阻塞所有的操作
-   非阻塞 I/O(NIO)在等待阶段不会进行阻塞，但是在操作阶段依然阻塞。非阻塞 IO 会不停的检查数据是否就绪，如果就绪则进行操作，但是这样会有一个缺点就是这个检查的时机你怎么控制，因为这些等待就绪的时间点我们是无法确定的，如果有多个 IO 那么我们需要一一进行检查会发生线程上下文的切换
-   IO 多路复用其实就是基于 NIO 的基础上加入了事件机制，程序会注册一组 socket 文件描述符给操作系统，然后监视这些 fd 是否有 IO 事件发生，如果有，程序会被通知，IO 多路复用的方式主要有 select、poll、epoll，这三个函数都会进行阻塞，所以可以放在 while(true)循环里使用，不会造成 CPU 的空转
- 信号驱动式 I/O 是指进程预先告知内核，使得当某个描述符上发生某个事件时，内核使用信号通知相关进程
-   异步 IO 不但等待就绪时非阻塞的，数据从网卡到内存的过程(操作)也是异步的



BIO是一种阻塞性的 IO。之所以称他为阻塞性 IO 是因为**接收连接，读取数据、写回数据都会阻塞我们的线程**。上述代码我们开启了一个线程池用来处理 Server 与客户端连接建立后的操作，这样可以避免我们的主线程一直阻塞只能处理单个连接。上述模型的主要缺点就是：

-   过于依赖线程
-   线程的创建和销毁成本很高，在 Linux 这种系统中线程本质上就是一个进程。创建和销毁都是重量级的函数
-   线程本身就很占内存，如果系统中的线程数过多，将会占用大量的 JVM 内存
-   线程切换成本很高，操作系统在进行线程切换时需要保留线程的上下文，然后执行系统调用。如果线程数过高，线程切换的时间可能会大于线程执行的时间，往往会造成 cpu load 过高。
-   系统负载过高，如果客户端网络环境不稳定，回传速度变慢，那么将会造成大量线程阻塞，从而活动线程数明显增高，增大系统负载压力
```java

public class BioServer {

    private final ExecutorService executorService;

    private final int port;

    public BioServer(int port) {
        executorService = Executors.newFixedThreadPool(100);
        this.port = port;
    }

    public void startServer() throws IOException {
        ServerSocket serverSocket = new ServerSocket();
        serverSocket.bind(new InetSocketAddress(port));
        while (!Thread.currentThread().isInterrupted()) {
            Socket socket = serverSocket.accept();
            executorService.submit(new IoHandler(socket));
        }
    }


    private static class IoHandler implements Runnable {

        private Socket socket;

        public IoHandler(Socket socket) {
            this.socket = socket;
        }

        @Override
        public void run() {
            try {
                while (!Thread.currentThread().isInterrupted() && !socket.isClosed()) {
                    // 读取数据
                    String data = readData(socket.getInputStream());
                    // 处理数据
                    String response = handlerData(data);
                    // 写入数据
                    writeResponse(socket.getOutputStream(), response);
                }
            } catch (Exception e) {
                System.out.println("io handler occur error. " + e.getMessage());
            }
        }

        private void writeResponse(OutputStream out, String data) throws IOException {
            out.write(data.getBytes());
        }

        private String handlerData(String data) {
            System.out.println(data);
            return data;
        }

        private String readData(InputStream input) throws IOException {
            BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(input));
            StringBuilder builder = new StringBuilder();
            String line;
            while ((line = bufferedReader.readLine()) != null) {
                builder.append(line);
            }
            return builder.toString();
        }
    }
}
```


**select**
select 只有一个函数，调用 select 时，需要将监听句柄和最大等待时间作为参数传递进去，select 会发生阻塞，直到一个事件发生了，或者等到最大 1 秒钟(tv 定义了这个时间长度）就返回。select 主要有以下缺点：

-   select 返回后要挨个遍历 fd，找到被“SET”的那些进行处理
-   select 是无状态的，即每次调用 select，内核都要重新检查所有被注册的 fd 的状态。select 返回后，这些状态就被返回了，内核不会记住它们；到了下一次调用，内核依然要重新检查一遍。于是查询的效率很低
-   select 能够支持的最大的 fd 数组的长度是 1024



**poll**
poll 优化了 select 的一些问题，参数变得简单一些，没有了 1024 的限制。缺点：

-   依然是无状态的，性能的问题与 select 差不多一样
-   应用程序仍然无法很方便的拿到那些有事件发生的 fd，还是需要遍历所有注册的 fd


**epoll**
使用 epoll 时，需要先使用函数 epoll_create()在内核层创建了一个数据表，接口参数是一个表达要监听事件列表的长度的数值（会动态改变的）。这样一来，不用每次监听都要传一遍 fd（传递 fd 会导致 fd 数据从用户态复制到内核态）。创建完数据表，就可以使用另外一个函数 epoll_ctl()来管理数据表，对监听的 fd 执行增删改操作。最后再调用 epoll_wait()方法等待事件的发生。这样做的优点是：

-   select 和 poll 每次都需要把完成的 fd 列表传入到内核，迫使内核每次必须从头扫描到尾。而 epoll 完全是反过来的。epoll 在内核的数据被建立好了之后，每次某个被监听的 fd 一旦有事件发生，内核就直接标记之。epoll_wait 调用时，会尝试直接读取到当时已经标记好的 fd 列表，如果没有就会进入等待状态。
-   epoll_wait 直接只返回了被触发的 fd 列表，这样上层应用写起来也轻松愉快，再也不用从大量注册的 fd 中筛选出有事件的 fd 了。



>[聊聊Linux 五种IO模型 - 简书 (jianshu.com)](https://www.jianshu.com/p/486b0965c296)
>[select、poll、epoll之间的区别总结[整理] - Rabbit_Dale - 博客园 (cnblogs.com)](https://www.cnblogs.com/anker/p/3265058.html)
>[select、poll、epoll之间的区别(搜狗面试) - aspirant - 博客园 (cnblogs.com)](https://www.cnblogs.com/aspirant/p/9166944.html)

IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合：
-   当客户处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用。
    
-   当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。
    
-   如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。
    
-   如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。
    
-   如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。
    
与多进程和多线程技术相比，`I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程`，也不必维护这些进程/线程，从而大大减小了系统的开销。

目前支持I/O多路复用的系统调用有 `select，pselect，poll，epoll`，I/O多路复用就是`通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作`。`但select，pselect，poll，epoll本质上都是同步I/O`，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。


>[(54条消息) Netty - Java网络编程基础（Linux网络IO模型，select、poll、epoll的区别，水平，边缘触发）日薪灬越亿的博客-CSDN博客_netty用的是select还是epoll](https://blog.csdn.net/a1173537204/article/details/102609087)
>[聊聊IO多路复用之select、poll、epoll详解 - 简书 (jianshu.com)](https://www.jianshu.com/p/dfd940e7fca2)


Level_triggered(水平触发)：

当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它还会通知你在上没读写完的文件描述符上继续读写，当然如果你一直不去读写，它会一直通知你！！！如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率！！！

Edge_triggered(边缘触发)：

当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你！！！这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符！！

 select(),poll()模型都是水平触发模式，信号驱动IO是边缘触发模式，epoll()模型即支持水平触发，也支持边缘触发，默认是水平触发。



#### Reactor NIO（IO多路复用）
### Reactor是什么

反应器设计模式(Reactor pattern)是一种为处理并发服务请求，并将请求提交到一个或
者多个服务处理程序的事件设计模式。当客户端请求抵达后，服务处理程序使用多路分配策略，由一个非阻塞的线程来接收所有的请求，然后派发这些请求至相关的工作线程进行处理。

[Reactor NIO（IO多路复用） - 云+社区 - 腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1640178)




[Netty学习之NIO基础 - Nyima's Blog (gitee.io)](https://nyimac.gitee.io/2021/04/18/Netty%E5%AD%A6%E4%B9%A0%E4%B9%8BNIO%E5%9F%BA%E7%A1%80/#3%E3%80%81%E9%9B%B6%E6%8B%B7%E8%B4%9D)








### 完整版堆内内存(on-heap memory)

-   堆内内存是java程序员在日常工作中解除比较多的, 可以在jvm参数中使用-Xms, -Xmx 等参数来设置堆的大小和最大值
    
-   堆内内存 = 年轻代 + 老年代 + 持久代
    
-   年轻代 (Young Generation)
    
    -   存放的是新生成的对象
        
    -   年轻代的目标是尽可能快速的收集掉那些生命周期短的对象
        
    -   Eden
        
        -   大部分对象在Eden区中生成
            
        -   当Eden区满时, 依然存活的对象将被复制到Survivor区, 当一个Survivor 区满时, 此区的存活对象将被复制到另外一个Survivor区
            
    -   Survivor（通常2个)
        
        -   当两个 Survivor 区 都满时, 从第一个Survivor 区 被复制过来 且 依旧存活的 对象会被复制到 老年区(Tenured)
            
        -   Survivor 的两个区是对称的, 没有先后关系, 所有同一个区中可能同时存在从Eden复制过来的对象 和 从前一个 Survivor 复制过来的对象。
            
        -   Survivor 区可以根据需要配置多个, 从而增加对象在年轻代的存在时间, 减少被放到老年代的可能。
            
-   老年代 (Old Generation)
    
    -   存放了在年轻代中经历了N次垃圾回收后仍存活的对象, 是一些生命周期较长的对象
-   持久代 (Permanent Generation)
    
    -   存放静态文件, 如静态类和方法等。持久代对垃圾回收没有显著影响, 但是有些应用可能动态生成或者调用一些class, 比如Hibernate, Mybatis 等, 此时需要设置一个较大的持久代空间来存放这些运行过程中新增的类。
        
    -   设置持久代大小参数: -XX:MaxPermSize= Perm => Permanent
        
-   垃圾回收(GC)
    
    -   Scavenge GC
        -   一般当新对象生成并且在Eden申请空间失败时就会触发Scavenger GC, 对Eden区域进行GC, 清除非存活对象, 并且把尚存或的对象移动到Survivor区, 然后整理两个Survivor区。
        -   该方式的GC是对年轻代的Eden区进行，不会影响到年老代。
        -   由于大部分对象是从Eden区开始的, 同时Eden区分配的内存不会很大, 所以Eden区的GC会很频繁。
    -   Full GC
        -   对整个堆进行整理, 包括Young, Tenured 和Permanent。
        -   所消耗的时间较长, 所以要尽量减少 Full GC 的次数
        -   d导致 Full GC 的可能原因:
            -   老年代(Tenured) 被写满
            -   持久代(Permanent) 被写满
            -   System.gc() 被显示调用
            -   上一次GC之后Heap 的各域分配策略动态变化
    -   常用垃圾回收算法
        -   Reference Counting (引用计数算法)
        -   Mark-Sweep (标记清除法)
        -   Coping (复制法)
        -   Mark-Compact (标记压缩法)
        -   Generational Collecting (分代收集法)
        -   Region (分区法)
        -   GC Roots Tracing (可达性算法)

堆外内存(off-heap memory)

-   定义
    
    -   堆外内存就是把内存对象分配在Java虚拟机的堆以外的内存
-   java.nio.DirectByteBuffer
    
    -   Java 开发者经常用 java.nio.DirectByteBuffer 对象进行堆外内存的管理和使用, 该类会在创建对象时就分配堆外内存。
        
        ![1571709464016](https://images.cnblogs.com/cnblogs_com/ronnieyuan/1573372/o_1571709464016.png)
        
    -   JDK1.8 取消了永久代, 由MetaSpace(元空间)代替。-XX:MaxPermSize由 -XX:MetaspaceSize, -XX:MaxMetaspaceSize 等代替
        
    -   对堆外内存的申请主要是通过成员变量unsafe来操作


## 启动一个Java main程序
在java中，启动一个简单的main程序，并非只是单单建立了一个main线程而已，JVM会自动建立一些辅助用的线程，主要有如下几个：java

　　Attach Listener：Attach Listener线程是负责接收到外部的命令，而对该命令进行执行的而且吧结果返回给发送者。一般咱们会用一些命令去要求jvm给咱们一些反 馈信 息，如：java -version、jmap、jstack等等。若是该线程在jvm启动的时候没有初始化，那么，则会在用户第一次执行jvm命令时，获得启动。linux

　　Signal Dispatcher：前面咱们提到第一个Attach Listener线程的职责是接收外部jvm命令，当命令接收成功后，会交给signal dispather线程去进行分发到各个不一样的模块处理命令，而且返回处理结果。signal dispather线程也是在第一次接收外部jvm命令时，进行初始化工做。windows

　　Finalizer：这个线程也是在main线程以后建立的，其优先级为10，主要用于在垃圾收集前，调用对象的finalize()方法；多线程

　　Reference Handler：VM在建立main线程后就建立Reference Handler线程，其优先级最高，为10，它主要用于处理引用对象自己（软引用、弱引用、虚引用）的垃圾回收问题。
　　
　　**Monitor Ctrl-Break后台监控线程(IDEA开发环境创建的一个线程)，后台线程可通过setDaemon(true)来设定，如网络连接(主线程)和心跳包发送(守护线程，主线程断开连接，那么不需要再发送心跳包)。**
　　这5个线程，加上，main，因此总共会有6个线程被建立，能够经过这几行代码来查看jvm

```java
class MainTest {  
  
    public static void main(String[] args) {  
        // 计算方法1  
 ThreadGroup threadGroup = Thread.currentThread().getThreadGroup();  
        while (threadGroup.getParent() != null) {  
            threadGroup = threadGroup.getParent();  
        }  
        int totalThread = threadGroup.activeCount();  
        System.out.println("当前程序线程总数： " + totalThread);  
        Thread[] lstThreads = new Thread[totalThread];  
        threadGroup.enumerate(lstThreads);  
        for (int i = 0; i < totalThread; i++) {  
            System.out.println("线程号：" + lstThreads[i].getId() + " = " + lstThreads[i].getName());  
        }  
    }  
}


当前程序线程总数： 6
线程号：2 = Reference Handler
线程号：3 = Finalizer
线程号：4 = Signal Dispatcher
线程号：5 = Attach Listener
线程号：1 = main
线程号：6 = Monitor Ctrl-Break
```
