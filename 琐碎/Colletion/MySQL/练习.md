### 177. 第N高的薪水
[177. 第N高的薪水](https://leetcode-cn.com/problems/nth-highest-salary/)



# 提问

### 事务的四大特性及实现原理
```markdown

先来一发什么是事务:事务保证了数据库将从一种一致性状态转移到另一种一致性状态，事务一般对于一组操作，这组操作的执行是原子的，要么全部完成要么全部失败，而且一旦提交必然能够保证对数据库永久性的改变，即使数据库发生故障也可以恢复数据。而且事务之间应该是独立。  
事务具体体现在ACID四个特性。

A: 一个是事务中的操作要么全部成功,要么全部失败,不存在第三种情况
C:一致性,对数据库的操作总是使得数据库从一个一致性状态变为另一个一致性状态,转钱的例子
I:隔离性,针对不同事务之间相互影响的程度,通常使用锁机制保证两个写事务之间的隔离性,而采用MVCC机制保证读写事务之间的隔离性
D:持久性,事务一旦提交,那么对数据库中数据的修改就是永久性的,不管之后是否发生宕机


原子性:通过undo log和锁实现(若是其他事务发现当前记录被上锁就不能对其上锁,特制互斥锁),如果执行事务的过程中回滚或者mysql实例崩溃,可通过undo log回滚到事务开始前的一致性状态

undo log:分为两种格式:1.insert undo log记录插入操作产生的undo log，只有在事务回滚时需要，事务提交后被丢弃。  
					 2.update undo log记录update和delete操作产生的undo log，**不能在提交事务后进行删除，因为可能被快照读需要（MVCC），提交后加入undo log链表，等待purge线程进行删除**。只有当快照读或者事务回滚不涉及该事务时，对应的日志才会被purge线程同一清除

隔离性:锁机制保证两个写事务之间的隔离性,而采用MVCC机制保证读写事务之间的隔离性

一致性:编不出来,

持久性:由两阶段提交协议保障,而两阶段提交协议就是 redo log 和 bin log,只要bin log 到磁盘上,redo log就随便了

下面来一发日志介绍:

**bin log**:Server层日志,是对mysql操作记录的归档日志,记录的格式有两种:1.statement格式(基于SQL语句记录) 2.row格式(对表数据,结构,索引等的变更操作)

具体设置:当以启动选项 --binlog-format=STATEMENT 启动MySQL服务器时，生成的binlog称作`基于语句的日志`
		当以启动选项 --binlog-format=ROW 启动MySQL服务器时，生成的binlog称作`基于行的日志`。此时会将该语句所改动的记录的全部信息都记录上。

注意:在有主从复制的场景中，使用`基于语句的日志`可能会造成主服务器和从服务器维护的数据不一致的情况。

执行事务的时候，会将binlog写入bin log cache（写入cache比较快，事务通常涉及多个操作，避免每个操作都直接写磁盘造成性能下降），事务最终提交的时候才会将缓存内容同步到磁盘（事务提交的默认行为，syn_binlog参数决定）  
当开始一个事务时，mysql会自动分配一个大小为 binlog cache size的缓存，如果日志内容超过缓存大小，则会把缓存中的日志写入一个临时文件。

同步时机:
1.Syn_binlog=0 ,提交事务时不会马上将binlog cache同步到磁盘，而是写到操作系统的page cache（内核缓存），操作系统崩溃有丢失日志的风险（默认 0）
默认值。事务提交后，将二进制日志从缓冲写入磁盘，但是不进行刷新操作（fsync()），此时只是写入了操作系统缓冲，若操作系统宕机则会丢失部分二进制日志。

2.Syn_binlog=1 每次提交事务都会执行fsync调用，将文件刷新到磁盘
事务提交后，将二进制文件写入磁盘并立即执行刷新操作，相当于是同步写入磁盘，不经过操作系统的缓存

3.Syn_binlog>1 每次提交都写入到page cache，N表示**写缓存的次数**，写缓存次数积累到N次之后才会fsync写入磁盘，mysql崩溃有丢失N个日志的风险


**重做日志redo log**:重做日志用来保证事务的持久性，由重做日志缓存与重做日志文件组成。
WAL技术即**write ahead log**。在一个事务中，数据库实例执行的修改操作将同时对内存中的redo log 与page（内存没有就先读到内存）进行修改。当事务提交时，将**内存中的redo log**持久化（fsync()）到硬盘中即可返回，内存中的脏页将按照一定频率刷入硬盘中。

Redo log **顺序写**，节省了随机写磁盘的IO消耗，循环写。写指针指向当前记录的位置，**检查点指针**指向当前要擦除的位置。当写指针追上检查点指针的时候，就需要暂停所有的更新操作，并将一部分记录进行擦除（redo log内存满了后执行覆盖写，刷新对应脏页）。
对比change buffer:节省随机读的开销


**redo log 的写入磁盘时机**是可以配置的。除了主线程会每秒的写入外 
1.**innodb_flush_log_at_trx_commit=1是默认情况**，事务提交时，强制fsync（阻塞操作）将文件系统缓冲区的数据刷新入磁盘。【值为1的基本都是同步操作】
`写入重做日志文件的操作不是直接写，而是先写入重做日志缓存，再按照一定顺序写入日志文件。默认情况下，属于强制同步写入（没写完就等着），而其他两个选项相当于把同步操作中的若干步骤采用异步操作替换，使得提交可以更快返回。`

2.若为0,提交事务的时候，不立即把 redo log buffer 里的数据刷入磁盘文件的，而是依靠 InnoDB 的主线程每秒执行一次刷新到磁盘。此时可能你提交事务了，结果 mysql 宕机了，然后此时内存里的数据全部丢失

3.若为2,则提交时，将redo cache中的数据全部刷入**文件系统的缓冲区 page cache**，而不是直接进入磁盘文件

刷盘的其他情况:
1.定时处理：后台线程master thread每隔一秒进行同步操作
2.redo log buffer大小占用到 innoDB log buffer size的一半时，进行同步操作

总结下三种:上面两种加上默认策略

重做日志文件的大小对innoDB存储引擎的性能有很多影响，如果设置过大，则恢复需要很长时间，设置太小又可能使得写指针与检查点指针重合，导致频繁异步刷新

从操作日志缓存往磁盘写入时，按照512字节写入（一个扇区的大小、写入的最小单位）。


讲得有点多,开下一页总结,O(∩_∩)O哈哈~
```

```markdown
对比redo log 和 bin log:

Redo日志是物理日志，记录的是对某个数据页做了什么修改，binlog（二进制日志）记录的是语句的逻辑(分两种格式)
Redo是循环写，空间用完会覆盖写。Binlog是追加写，不会覆盖，空间不够用会切换到下一个日志  
二进制日志仅在**事务提交时写入**，只写磁盘一次（默认行为是仅提交时仅写入操作系统缓冲区）。而重做日志可以在**事务进行的过程中被后台线程异步写入磁盘**
Redo log用于崩溃恢复。而binlog用于基于时间点的恢复，还可以用于主从复制

redo log 为什么具有crash-safe能力:
`Mysql将某一页的数据进行同步磁盘操作的时候，将数据刷新到底层磁盘的多个扇区，这个过程无法保证原子性，逻辑日志binlog无法保证崩溃恢复能力，因为它记录的太“抽象”，没有redo log具体。`

本质原因就是 binlog是写前日志,无法判断追加写后在BufferPool 中的 page有没有刷到磁盘
而redo log中存储的是没有刷入磁盘的数据,只要刷入磁盘,数据就会从redo中被删除

crash后,如何恢复未刷盘的数据到内存中:
根据 redo log 和 binlog 的两阶段提交，未持久化的数据分为几种情况：

change buffer 写入，redo log 虽然做了 fsync 但未 commit，binlog 未 fsync 到磁盘，这部分数据丢失。
change buffer 写入，redo log fsync 未 commit，binlog 已经 fsync 到磁盘，先从 binlog 恢复 redo log，再从 redo log 恢复 change buffer。
change buffer 写入，redo log 和 binlog 都已经 fsync，直接从 redo log 里恢复。


每当系统重启时，都会先进入恢复过程。

此时首先按照已经刷新到磁盘的redo日志修改页面，把系统恢复到崩溃前的状态。

然后在表空间中找一下各个`Undo页面链表`的首个页面的页号，然后就可以读取该页面的各种信息。通过这个页面，我们可以知道该`Undo页面链表`对应的事务状态是什么：
1.如果是`TRX_UNDO_ACTIVE`状态，也就是活跃状态，直接按照undo日志里记载的内容将其回滚就好了。
2.如果是`TRX_UNDO_PREPARE`状态，那么是提交还是回滚就取决于binlog的状态了，我们稍后再说。
3.如果是其他状态，就将该事务提交即可。
对于处于PREPARE状态的事务，存储引擎既可以提交，也可以回滚，这取决于目前该事务对应的binlog是否已经写入硬盘。这时就会读取最后一个binlog日志文件，从日志文件中找一下有没有该PREPARE事务对应的xid记录，如果有的话，就将该事务提交，否则就回滚好了。
```


### 数据库的三大范式
```markdown
第一范式:数据项不可以再分,每个字段都应该是原子的,不可分割的.eg: 学号+姓名合在一起当一个字段
第二范式:第一范式基础上,其他数据项完全依赖主键,eg:(学分,学号)当主键
第三范式:第二范式基础上,非主键字段不传递依赖于主键,也不部分依赖于主键,每一列数据和主键直接相关,不能间接相关(也就是不能出现冗余数据,如电影表中增加一列票房统计字段,而这个字段通过观众表与电影表间接相关)

```


### 事务隔离级别及实现原理
```markdown
脏读,读已提交,可重复读,串行化

脏读:一个事务还没提交,他做的变更能被其他事务看见
读已提交:一个事务提交之后,他做的变更才能被其他事务看见
可重复读:一个事务执行过程中看到的数据,总是跟这个事务启动时看到的一样
串行化:通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超 时现象和锁竞争。


**读已提交如何解决脏读问题? || 可重复读如何解决幻读?**

快照读全依赖MVCC,而MVCC机制是由版本链和读视图来实现的.区别就是读视图什么时候形成
这样来看MVCC就是避免读写冲突

而当前读的话,区别就是 间隙锁加不加的问题



**版本链作用就是记录着数据的历史版本,而读视图就是判断版本链中哪个版本对当前事务是可见的**

首先讲下**版本链**:InnoDB存储引擎的表,其聚簇索引记录中都包含两个必要的列,一个是trx_id,代表对该条数据进行修改的事务id;另一个是roll_pointer,每次对某条聚簇索引记录进行改动时,都会把旧的版本写入undo日志中,然后这个隐藏列就相当于一个指针,通过他来找到该记录前改签的信息.这些旧的版本通过roll_pointer属性连接起来,就串成一个链表,这就是版本链

**读视图**:记录着当前系统中还有哪些活跃的读写事务,将它们的事务id放到一个列表中,这样在访问某条记录时,按照规则就可以判断记录的那个版本对当前事务可见,另外还会存储两个值,一个代表生成读视图时列表中的最小值,另一个代表生成读视图时系统应该分配给下一个事物的id值:
1.若是记录的trx_id 列小于 min_trx_id,可见
2.若是记录的...大于 max_trx_id,不可见
3.>= min_trx_id && <= max_trx_id,就需要判断下trx_id在不在m_ids中,在就不可见,不在可见

如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本，如果最后一个版本也不可见的话，那么就意味着该条记录对该事务不可见，查询结果就不包含该记录。




```



### 索引

#### 索引的意义
索引就是书签，有了索引可以对内容进行快速定位，实现**加速读**。  
如果把一张表看作一个内容线性表，没有索引的表可能就是一个普通的链表结构，我们只能从头读到尾，而具备索引结构，它就可以看作一个跳表结构，可以支持部分随机读取的行为。  
具体的谈论索引，我们必须具体到某一种实现。


#### 索引优缺点
索引具有以下优点：  
1. 提高查询速度、表连接速度  
2. 避免额外的内存或临时文件排序，减少排序和分组的时间  
3. 唯一索引保证每一行数据的唯一性

维护索引的数据结构，也需要付出以下代价：  
1. 维护、创建、**页合并**、**页分裂**等操作耗时  
2. 创建索引时，需要**对表进行加锁**，可能会其他事务的影响正常操作（锁其实就是基于索引实现的）  
3. 索引缓存和各种索引文件需要额外占用内存和磁盘资源（需要有额外的文件和内存去存放索引）  
4. 修改数据时会触发索引的维护，降低性能


#### 索引的建立

##### 索引设计原则
1. 主键自动建立唯一索引  
2. **频繁作为查询条件的字段**应该建立索引  
3. **被驱动表关联的字段**，**外键关系建立索引**  
4. 频繁更新的字段不适合建立索引（因为每次更新不仅仅更新数据还要更新索引）  
5. Where条件中用不到的字段不创建索引  
6. 高并发下倾向创建联合索引  
7. 查询中**排序的字段**，若通过索引去访问排序字段将大大提高排序速度  
8. 查询中统计或者**分组字段**  
9. **写多读少**的字段，如果要键索引则应该建立**普通非唯一索引**


不适合建立索引的情况：  
1. 表记录太少（少于一千）  
2. 经常增删改的表  
3. **区分度不高**的字段不适合建立索引，如性别等(数据重复且分布平均的表字段（例如性别，如果一个表中男女各半，则每次根据性别查询都需要回表查出50%的数据，性能远不如全表扫描）)
4. **参与列计算**的列不适合建索引


维护索引不但需要在磁盘上维护索引文件，还需要在内存中维护存放索引页的内存区。另一方面，B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。不免涉及到数据的移动和数据页的增加和删减。  
一个数据页满了，按照B+Tree算法需要新增加一个数据页进行数据分散，需要进行**页分裂**，会导致性能下降。空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做数据**页合并**，合并的过程是分裂过程的逆过程


##### InnoDB的索引
mysql具有许多需要遍历元素的场景：范围查询、全表查询、关联子查询等，因此B+树是更合适的，而B树更适合于单条记录的查询。innoDB使用B+树索引模型，所以数据都是存储在B+树中的，每一个索引在innoDB中对应一颗B+树。索引文件和数据文件存放在表空间中，而且mysql为每一个索引分配两个段去存放叶子节点和非叶子节点。


**索引创建**
索引可以分为三类：  
1. 单值索引：一个索引只包含单个列，一个表可以有多个单列索引  
2. 唯一索引：索引列的值必须唯一，但允许有空值  
3. 复合索引:即一个索引包含多个列

创建方式：
1. 创建表的时候创建索引：
```sql
create table testTable(  
    id int not null,   
    username varchar(16) not null,  
    index [indexName] (username(length))  -- 为字符类型创建索引可以指定前缀
); 
```


2. 创建表之后创建索引：（index前面可以加上unique前缀表示唯一索引，否则默认普通索引）
```sql
CREATE INDEX idx_ceo_deptnam ON dept(ceo,deptname)
CREATE INDEX idx_deptnam ON dept(deptname)
CREATE INDEX idx_deptid ON emp(deptid)
```

**CREATE INDEX** 索引名称 **ON** 表名（字段名）  
（mysql会默认对主键创建一个索引——主键索引）

展示索引：**SHOW INDEX FROM** 表名  
删除索引：**DROP INDEX** 索引名 **ON** 表名


#### 索引的数据结构
索引本质上就是一种数据结构，它支持快速查找

【1】有序数组  
查询效率很高，因为**有序数组结构适合通过二分查找算法**，但是插入删除可能会造成整体拷贝，因此更加适合**静态存储引擎**或者**只读的数据类型存储**。例如：历史记录，用户可以通过日期快速从有序数组中找到历史记录。  
【2】哈希表  
哈希表的效率一定程度上依赖哈希函数（桶映射函数）和解决哈希冲突的方案。  
输入待查找的值作为key，通过对key进行哈希计算得到一个桶的索引，一般通过链表法解决哈希冲突，因此**查询效率高，增删效率也高**。  
但是由于元素在桶内的分布是无序的，因此做区间查询的时候很慢，仅适合做**等值查询**的场景，如nosql的redis数据库。  
**哈希表实现索引的限制**：  
a.只能包含哈希值和行指针，无法存储字段值或数据行，因此**无法避免回表**  
b.不支持部分索引匹配查找，因为hash索引始终使用索引列的全部内容计算hash值的，**不能更好的利用联合索引**

> 如果索引使用哈希表实现，则一个索引对应一颗哈希表。默认会对主键建立一个索引（哈希表）。假如对name字段建立索引，则磁盘上至少存在两个索引文件。Where name = ‘123’，首先查询name索引文件，通过hash(‘123’)得到键值对的存放位置，得到‘123’-主键id，然后再查询一次主键索引哈希表得到最终的记录。

c.hash索引不是按照索引值顺序存储的，**天生无序**。  
d.仅支持等值查询  
e.存在哈希冲突问题

innoDB会在系统自动生成**自适应索引**，由于哈希表是离散存储的，因此无法排序，也不支持最左前缀索引，而且存储哈希冲突的问题，不支持范围查询。

【3】平衡二叉树/红黑树

> 搜索二叉树、平衡二叉树和红黑树都是二叉树，其中平衡二叉树解决了搜索二叉树“在一定情况下会退化成单向链表”的问题，而平衡二叉树的约束过多且实现复杂，红黑树可以看作平衡二叉树的一种“弱平衡性”的一种实现方案。

平衡二叉树的查询速度是log2(N)，每次查找都是一次二分，但是每一层分叉过少的代价就是树的高度过高，每一层查找都是一次磁盘I/O，**平衡二叉树的查询成本随着树高升高而增加**，因此平衡二叉树不适合作为数据库的索引结构。

> 每次查找都会将索引页面读入内存，然后确定下一个需要读入的索引页面，因为页面本身也是有序的，因此在内存中的查找是很快的（可以基于二分查找算法），而这时的瓶颈就在于它是二叉还是二十叉了，而是在于I/O导致的时间开销，因为每读入一次节点都至少需要一次I/O，而一层中不管几个节点都是对应一次I/O，**树高过高导致I/O次数上升才是正在的瓶颈**，因此**二叉树更多用于内存结果对象的查找，比如在内存中维护一个treeMap作为作为内存索引结构**。

【4】B树/B+树（多叉平衡树）  
B树是专门为磁盘设备设计的平衡查找树，它相对于二叉平衡树有了更适合磁盘I/O的特点，如：**树的节点可以存放多个元素**，这样树的高度就得到了压缩，查询某个节点可以进行更少的I/O次数。B树的节点单位通常与磁盘的存储单位是对应的，**数据库设计者通常利用磁盘预读原理，将一个节点的大小设计等于一个页的大小，这样每个节点只需要一次I/O便可以完全载入**，因此每次读入内存的其实是一个数据块或索引块。  
另一方面，B数节点中的元素数据行都是有序的，这就**降低了排序成本，将随机I/O转换为了顺序I/O**，避免为排序分配临时内存或临时中间文件。



##### B树和B+树

感觉还是key值,指针和数据行较好

一颗M叉的B树是一颗平衡的M路搜索树，**所有叶子节点都在同一层，每个节点中即存放key值又存放指针**。  
而B+树是B树的变种，**B+树的叶子节点用于保存key值的信息，而所有的非叶子节点都可以看作是搜索目标叶子节点的索引部分**。  
B+树的所有叶子节点都新增了**链表指针**，这使得所有数据在B+数叶子节点中按照key排序。

**B树通过压缩高度虽然解决了“磁盘IO次数较多的问题”，但是未能解决遍历查找效率低下的问题**

B+树索引每次加载出的都是一个页，页中包含多个数据行。根据索引字段可以定位数据行所在的数据页，将数据页加载进入内存。在内存值通过对索引的key值进行二分查找可以取出对应数据行。  
B+树非叶子节点可以看作索引节点，不存储数据行，所有数据行存在于叶子节点。这使得**B+树搜索可以更加稳定**（因此连接查询时总是将小表做主表），**每个叶子节点可以存储的元素更多**，查询所需的IO次数也会更少，一个数据页可以包含更多的数据行。

**B+树更适合进行范围查找**，因为遍历一个范围的元素，只需要遍历叶子节点。而B树的不同页面之间不连续，如果要进行范围扫描，B+树以链表的形式扫描聚簇索引叶子节点进行优化，而**B树需要同时在多个节点之间切换**，因为B树节点内部的数据行虽然是有序的，但是从节点之间看，则是不连续的。

而**B树更加适合等值查找**，因为B树的key不像B+树全部存储在叶子节点，因此如果对B树查询某个key，很可能在某个距离根很近的位置就能找到，而最坏的情况才是在叶子结点找到。另一方，B树不适合大范围的搜索，如果仅仅是小范围的搜索并不影响性能，如果需要大范围遍历，顺序I/O将退化为随机I/O（不断回旋查找），从而导致I/O次数上升，性能下降。**B+树含有数据行的节点都是叶子结点，有序且相连，直接对叶子节点遍历即可，查找较稳定，遍历元素效率高**

B+树的非叶子节点会冗余一份在叶子节点中（所有的非叶子节点key都保存一份key/value到叶子节点），并且叶子节点之间使用指针相连。B树一个叶子节点可以存储多个元素，相当于完全平衡二叉树整体的树高降低了，磁盘IO效率提升了。而**B+树只是通过叶子节点冗余非叶子节点，提升了范围查找的效率，B+树同时也具有B树的一切优点**。

> 树的路数也不是无限延伸的， 如果树的路数无限延伸则会**退化成一个有序数组**，如果数据量过大**无法一次性载入内存，会进行多次IO**，效率会下降。**因为树高下降，索引的粒度（叉数）就会变大，节点装入的内容变多，会多于一页**，这样读入一个页面可能需要至少两次I/O

总结：  
B+数的单一节点存放更多数据，IO效率高。由于每次都是从叶子节点载入页面，查找更稳定。天然有序，便于范围查询和排序。  
B树比较适合单值查询，因为如果所在页靠近根结点，那么可以很快锁定目标页。



#### (非)聚簇索引和辅助索引

**主键索引**的叶子节点存的是**key所在的数据行**。在InnoDB里，主键索引也被称为**聚簇索引**  
**非主键索引**的叶子节点内容是**主键的值**。在InnoDB里，非主键索引也被称为**辅助索引**  
而搜索辅助索引的B+树，最终拿到的也只是一个主键的ID值罢了，必须再一次通过这个主键id搜索聚簇索引对应的B+树，拿到最终的页面载入内存，因此其实搜索了两次B+树，这种行为就叫做**回表**。


MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址
MyISAM引擎使用B+Tree作为索引结构，叶节点的**data域存放的是数据记录的地址**
非聚簇索引：主键索引和辅助索引存储都是存储一个指向真正表数据的地址，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。


#### 索引查找规则

```markdown
1.索引覆盖:查询的列被所建的索引覆盖.select的数据列可以从辅助索引的叶子节点中就可以取得,不必通过回表再次读取数据行,如果索引不能覆盖查询的所有列,则不得不每扫描记录就进行一次回表,这属于随机IO,这种情况下,按照索引顺序读取数据可能比全表扫描慢,这时优化器可能放弃走索引而选择全表扫描
2.最左前缀:列的排列顺序决定了可命中的索引列数,最左前缀原则帮助用户更好的设计联合索引，通过复用联合索引减少创建单独索引的开销
创建一个联合索引的时候如（name,age,sex），逻辑上其实创建了三个索引（name）、（name,age）和（name,age,sex）。联合索引的最左N个字段，也可以是字符串索引的最左N个字符。因为B+树对数据行的存储依照（name,age,sex）三个关键字进行排序（先按照name排序，name相同按照age，age相同按照sex）。

3.索引下推(下沉):索引下推可以在索引遍历过程中对**索引中包含的字段**先进行判断，过滤到不满足的条件，**减少回表的次数**
注意：参与索引下沉的过滤项，一定要是**索引中的字段**。

```

#####  最左前缀 

基于B+树结构的组合索引的基础上,查询条件字段能按从左到右的顺序,连续的命中组合索引的列数,决定了能使用组合索引的前多少个字段实现加速读的效果,查询条件得是 等值, 若是范围查询,就会停止匹配,组合索引后面的字段无法参与加速读

本质就是mysql按从左到右的顺序进行查找

对`(a,b,c)`建立索引，查询条件使用 a/ab/abc 会走索引，使用 bc 不会走索引。

对`(a,b,c,d)`建立索引，查询条件为`a = 1 and b = 2 and c > 3 and d = 4`，那么a、b和c三个字段能用到索引，而d无法使用索引。因为遇到了范围查询。

如下图，对(a, b) 建立索引，a 在索引树中是全局有序的，而 b 是全局无序，局部有序（当a相等时，会根据b进行）。直接执行`b = 2`这种查询条件无法使用索引。

![最左前缀](https://uploadfiles.nowcoder.com/files/20211030/8683776_1635580314321/%E6%9C%80%E5%B7%A6%E5%89%8D%E7%BC%80.png)

当a的值确定的时候，b是有序的。例如`a = 1`时，b值为1，2是有序的状态。当`a = 2`时候，b的值为1，4也是有序状态。 当执行`a = 1 and b = 2`时a和b字段能用到索引。而执行`a > 1 and b = 2`时，a字段能用到索引，b字段用不到索引。因为a的值此时是一个范围，不是固定的，在这个范围内b值不是有序的，因此b字段无法使用索引。



#### 关联查询优化

LEFT JOIN 条件用于确定如何从右表搜索行,左边一定都有,所以**右边是关键点,一定需要建立索引**，相当于是一个双循环，外循环遍历所有行，而对于外循环的每一行，如果不进行任何优化则是O（n）复杂度，而如果建立索引则可以优化到O（logm(n)）。

1. 能够直接多表关联的，**尽量直接关联，不使用子查询**  
2. 尽量减少join语句中的循环总次数，不用join过多或嵌套，永远使用小结果集驱动大结果集【内循环使用B+索引查询，很稳定，因此决定于外循环，外循环结果集越小越好】

**当B表的数据集必须小于A表数据集时，in 优于exists**  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F6eab2f77691743a4854c73e431e49c47.png)被驱动表 in (驱动表)  
**当A表的数据集必须小于B表数据集时，exists优于in**  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F120006eb05bd4c648953e8c878b34822.png)驱动表 exists （被驱动表）

> Exists——将主查询的数据，放入子查询中做条件验证，根据返回值（true或false）来决定主查询的数据结果是否得以保留

**被驱动表需要在相应字段建立索引**

```SQL
SELECT * from student
where student.SId in 
(SELECT sc.sid from sc)

    
```

效果上等价于

```SQL
SELECT * from student
where EXISTS (SELECT 1 from sc WHERE sc.sid=student.sid)

    
```

内连接时，mysql优化器会自动帮你把小结果集选为驱动表，因为驱动表无论如何都会被全表扫描，所以扫描次数越少越好。  
子查询生成的子表尽量作为驱动表，因为如果作为被驱动表可能不能被选择索引

#### 分组与排序优化
Order by满足两种情况时，会基于索引方式排序：  
1. order by语句使用索引的最左前列  
2. **使用where子句与order by子句条件列组合满足索引最左前列**  
尽可能在索引列上完成排序操作，遵循索引键的最佳左前缀

使用索引的排序，不需要开辟额外排序内存或者临时文件，通过索引依次按照顺序扫描一组主键id，然后通过回表取出数据行并拼装结果集（如果select的内容直接可以从叶子节点拿到，那直接走覆盖索引，可以避免回表）。

注意：order by时，select * 是一个大忌

**Group by 使用索引的原则几乎和order by一致，唯一区别是group by即使没有过滤条件使用索引，也可以直接使用索引**

> 当范围条件和group by或者order by的字段出现二选一的时候，优先观察条件字段的过滤数量，如果过滤数量足够多，而需要排序的数据并不多的时候，优先把索引放在范围字段上。

**Group by实质是先排序后分组**，按照索引建的最佳左前缀。Where优先于having，能写在where限定的条件就不要去having限定了


#### limit优化
Limit语法由偏移量offset和取值数量size组成，其中偏移量默认从0开始，其中limit 10000，10代表从第10001条数据开始取，取size个。注意这里是扫描到10001条数据后，开始往后拿数据，而前面这些数据都被抛弃了，因此offset特别大的时候，效率非常低

```sql
Select * from Student limit 1000,10

    
```

可以被改造为：

```sql
Select * from Student 
Join (Select id  from Student limit 1000,10 ) as stu
On student.id = stu.id

    
```

子查询id是主键，本身就是一个索引结构，因此外部进行关联时能够很快取出对应的数据行。内部查询是id，其效率高于*，相当于内部查询到10个id，然后外部通过id拿到对应数据行。


### 索引失效分析和解决方案


#### 范围过大

【1】使用不等号!=或<>、not in 、is not null 的时候优化器使用全表扫描  
【2】like 以通配符开头如(’%a’)，可以使用**覆盖索引**解决。  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F6184dabe3ad148088c480869c97ce0e1.png)使用覆盖索引的情况：  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fb3e551a28455480d9183340d2ea7979c.png)【3】使用or进行连接

#### 隐式转型

【1】在索引列一则执行计算等操作，如计算、函数、类型转换。例如 where a+1=3  
【2】字符串不加单引号导致索引失效（例如：name=张三 会导致失效）  
【3】隐式编码格式转换也会导致失效，应该使两个表的字符集相同

> 如果对索引字段做函数操作，可能破坏索引值的有序性，这种情况下，优化器放弃走索引树的搜索，而是全索引表扫描（只是放弃了通过非叶子节点定位，而是直接遍历叶子节点）。同理where id + 1 =99不可以 where id =99-1可以

#### 其他

【1】搜索引擎不能使用索引中**范围条件右边的列**。  
【2】错误使用最左前缀法则。  
【3】**如果对主键进行删除或者重建，会导致整个表的重建**

> 例如index(a,b,c),where b=3 不可以。where a=3 and c=5 使用了a，但是c不可以（找到aXX节点对应的id叶子节点）（因为抛开a，单独看b或者c，它们并不是全局有序的，不能作为扫描使用的标志，仅能用作一些过滤和优化）  
> where a=3 and b>2 and c=5 使用了a b,但是c不能用在范围之后。（找到abX节点对应的所有id叶子节点）

注意，如果where的内容是四个const。建立的索引如index（a,b,c,d）,查询顺序为d,c,b,a或者a,b,d,c。Mysql的查询优化器会最终调整为a,b,c,d的形式后再进行查询

### 索引的选择

#### change buffer
>[(59条消息) 写缓冲(change buffer)，这次彻底懂了！！！_58沈剑的博客-CSDN博客](https://blog.csdn.net/shenjian58/article/details/93691224)

参数：innodb_change_buffer_max_size

介绍：配置写缓冲的大小，占整个缓冲池的比例，默认值是25%，最大值是50%。

画外音：写多读少的业务，才需要调大这个值，读多写少的业务，25%其实也多了。

参数：innodb_change_buffering

介绍：配置哪些写操作启用写缓冲，可以设置成all/none/inserts/deletes等。





change buffer指的是对“写操作”的缓存，推迟更新的行为。  
需要同时满足两个添加：辅助索引 和 非唯一索引

如果**非唯一普通索引页**不在缓冲池（内存）中，则对页进行写操作时，不会先去加载磁盘，而是**直接将修改操作记录在changeBuffer上**，等到未来数据页被读取时，再将数据合并恢复到缓冲池中。  
后台线程也会时不时地进行合并操作，正常退出mysql时也会合并，其他如重写日志不可用、内存中的changeBuffer超过缓冲池1/2  
**事务提交的时候，changeBuffer的操作已经记录到redo log中了，因此崩溃恢复时可以找回**

changeBuffer适合于==“写多读少”==的场景，如果读操作很频繁，那么写缓存就没有意义了，反而是记录与合并的操作显得很多余。

changeBuffer和数据页一样，是物理页的一个组成部分，**底层是一颗B+树**，负责**对索引表的辅助索引的更新操作进行缓存**，存放于共享表空间。changeBuffer在内存中有缓存，同时也可以持久化到磁盘中。  
changeBuffer在内存的部分占用了缓冲池的内存，默认最大可用占用缓冲池的1/2.

changeBuffer的目的是**降低对磁盘的随机读次数**（更新时不用将页面读入内存，而是更新处于内存中的change buffer结构），磁盘IO是数据库操作中成本最高的一部分，同时数据页不用调入缓冲池，节省了内存空间。而**数据页缓存则是减少了随机写磁盘的IO次数**（每次写内存中的页面，而不是直接写磁盘中的页面，直到redo log失效、后台线程同步等时间发生才会将脏页面更新磁盘）。

如果要修改的字段是唯一索引或者主键，还需要加载数据页，**判断是否违反唯一性约束**，从而导致changeBuffer没有了意义。

总结：  
**读多写少**的场景适合定义**唯一索引**，如果使用普通索引进行等值搜索，搜索到第一个记录后不会停止，因为可能有值重复的记录，会继续搜索直到碰到不相等的记录才会退出。而唯一索引字段在遇到第一个满足条件的记录后，就会自动停止检索。  
由于引擎一次读出一页，因此对于普通索引，引擎需要多做一次指针寻址和判断，如果第一个记录在数据页的最后一条记录，还必须读取下一个数据页。

**写多读少**适合定义**普通（非唯一）索引**，因为普通非唯一索引字段的修改会在写缓存中进行（如果页面不再内存的前提下），不需要频繁的加载页面

普通索引和唯一索引在查询方面区别不大，但是**更新唯一索引字段更加消耗性能**，因此建议使用普通索引。

Redo log主要节省的是随机写磁盘的IO消耗（将随机写入脏页的行为，记录在redo log日志文件中，某一时间点将redo log同步到磁盘，只要redo log成功同步，就不担心脏页更新丢失），而changebuffer主要节省的是随机读磁盘的IO消耗。

#### 索引与约束

约束是一种逻辑上的概念，用于保证数据的完整性，它更像是一种检查机制。而索引是一个数据结构，在数据库中通常有对应的物理存储，而且它具体的功能如加速读取。

#### 自增

> MYLSAM 引擎的自增长值保存在数据文件中  
> innoDB 5.7之前,自增长值保存在内存中，mysql 8将自增长值的变更保存在redo log中，重启时依靠redo log恢复重启之前的值。

插入新数据而进行平衡调整可能会引起**页分裂**（数据页满了，申请新的数据页，移动部分数据），这个过程不但影响性能，还会降低页的利用率。删除操作可能会引发**页合并**。  
**自增主键的插入模式符合递增插入的场景**，不涉及平衡的调整，不会触发叶子节点分裂。同时，**主键长度越小**，**普通索引的叶子节点越小**，普通索引所**占用的空间也就越小**。

> 修改时机：前提是字段被声明为**auto_increment**  
> 【1】插入数据时id没有指定或者被指定为0或者null  
> 【2】使用了具体值X，就使用指定的值。如果要插入的值小于自增值，则表的自增值不变，否则自增计时器的值被更新为X+1。  
> 新的自增值生成算法：从auto_increment_offset开始，以auto_increment_increment为步长，持续叠加，直到找到第一个大于插入值X的值，作为新的自增值。

**唯一键冲突（插入失败）**和**事务回滚**都会导致**自增主键id不连续**，另一个不连续的原因是由于**mysql对批量插入语句分配自增id策略**导致的。

> 如果自增主键用完了，再尝试插入新的数据就会导致主键冲突报错（根据自增主键类型不同，范围也不同）



### InnoDB和MyISAM的数据分布对比

MyISAM的数据分布：按照**数据插入顺序**存储在磁盘上（数据和索引分开存储，通常内存缓存索引数据，而数据由操作系统/文件系统（磁盘）缓存，因此访问数据需要一次系统调用），**叶子节点存储的是“行号”**，这种分布方式很容易创建索引，**且二级索引和主键索引的存储方式相同**

InnoDB的数据分布：聚簇索引的每一个叶子节点都包含了**主键值**，**事务ID**，用于事务和MVCC的**回滚指针**以及所有剩余**数据列**，二级索引和聚簇索引很不同，叶子节点存储的是主键值，这种策略**减少了当出现行移动或者数据页分裂时二级索引的维护工作**。





### 存储结构
innoDB存储引擎中，表都是根据**主键顺序**进行存放的，这种存储方式的表称为索引组织表。  
如果创建一张表的时候没有显示指定主键，则使用**非空的唯一索引**作为主键（如果有多个，则寻找定义索引顺序的第一个非空唯一索引），若不存在则innoDB存储引擎自动创建一个指针结构作为隐式主键。

所有数据都存放在表空间中，表空间由各个段组成，其中数据段存储B+树的叶子节点，索引段存储B+树的非叶子节点。段由若干个区组成，区由连续的页组成，区的对象固定为1MB，默认情况下，innoDB存储引擎页的大小为16KB（一个区中一共有64个连续的页面）。而页面则是innoDB磁盘管理的最小单位，页中的数据按行存放。  
数据库每次读取的就是页中存放的行记录。


### 锁的类型
从对**数据结构的操作类型**分类  
**读锁(共享锁)** 针对同一份数据，多个读操作可以同时进行而不会互相影响。  
**写锁(排它锁)** 当前写操作没有完成前，它会阻断其他写锁和读锁。

从**粒度**分类：表锁和行锁  
MySQL常用的两种引擎MyISAM和InnoDB，MyISAM默认使用表锁，InnoDB默认使用行锁。  
注意：使用InnoDB引擎，如果筛选条件里面没有索引字段，就会锁住整张表，否则的话，锁住相应的行

> Mysql行锁由引擎层实现，mylsam不支持行锁。  
> Mysql也支持lock tables和unlock tables语句，这时服务器层实现的，和存储引擎无关  
> 意向锁是innoDB自己加的，如果要对某个元组加锁，那么需要对上层节点加意向锁。

innoDB采用的是**两阶段锁定协议**。在事务执行的过程中，**随时都可以执行锁定，锁只有在执行commit或者rollback的时候才会释放**，并且所有的锁都是在同一时刻被释放的。**innoDB会根据隔离级别在需要的时候为被事务访问的数据自动加上隐式锁**。

意向锁  
innoDB支持**多粒度锁定**，运行事务在行级和表级的锁同时存在。意向锁将锁定的对象分为多个层次，意向锁表明事务希望在更细粒度上进行上锁。  
假设事务A对某一行加入写锁，事务B希望对该表加入加锁。事务表加锁之前必须对表中的每一行进行遍历，这样效率很低。而**有了意向锁，A加行锁之前，先申请意向锁，申请成功后再申请一行的行锁。而如果事务B希望加表锁，它发现该表存在意向锁，那么申请锁的行为就会被阻塞。**  
**申请意向锁的行为由数据库完成，当事务申请某一行的行锁的时候，数据库会自动该表的意向锁。**


## 两阶段提交协议之残缺版

[[MySQL#两阶段提交]]完整版

执行一条UPDATE语句过程中都发生了什么事情。当优化器分析出成本最小的执行计划后，就开始对执行计划中的各个扫描扫描区间中的记录进行更新。具体更新一条记录的流程如下：

1. 先在B+树中定位到该记录（这个过程也被称作加锁读），如果该记录所在的页面不在buffer pool里，先将其加载到buffer pool里再读取。
2. 读取到记录后判断记录更新前后是否一样，一样的话就跳过该记录，否则进行后续步骤。
3. 首先更新聚簇索引记录。更新聚簇索引记录时：①先向Undo页面写undo日志。不过由于这是在更改页面，所以修改Undo页面前需要先记录一下相应的redo日志。②真正的更新记录。不过在真正更新记录前也需要记录相应的redo日志。
4. 更新其他的二级索引记录。

至此，一条记录就更新完了。

然后开始记录该语句对应的binlog日志，此时记录的binlog并没有刷新到硬盘上的binlog日志文件，在事务提交时才会统一将该事务运行过程中的所有binlog日志刷新到硬盘。


下面就是两阶段提交

**内部XA**

对于一台服务器来说，即使客户端使用`BEGIN/START TRANSACTION`语句开启的普通事务，该事务所包含的语句也有可能涉及多个存储引擎。此时MySQL内部采用XA规范来保证所有支持事务的存储引擎要么全部提交，要么全部回滚，这也被称作MySQL的`内部XA`。

另外有一点值得注意的是，`内部XA`除了解决这种设计多个存储引擎的事务之外，还解决保证binlog和存储引擎所做的修改是一致的问题。我们稍后重点展开一下这个问题。

在MySQL内部执行一个事务时，存储引擎会修改相应的数据，server层会记录语句对应的binlog。这是两个要么都完成，要么都不完成的事情。否则的话：

•如果存储引擎修改了相应数据并且提交了事务，而server层却未写入binlog。在有主从复制的场景中，意味着这个事务不会在从库中得以执行，从而造成主从之间的数据不一致。

•如果server层写入了binlog，但存储引擎却回滚了事务。在有主从复制的场景中，意味着这个事务会在从库中得以执行，从而造成主从之间的数据不一致。

那我们需要保证：**如果存储引擎提交了事务，server层的binlog日志必须也被写入到硬盘上；如果存储引擎回滚了事务，server层的binlog日志必须不能被写入到硬盘上**。

MySQL采用`内部XA`来实现上述内容，下边以Innodb存储引擎为例，具体讨论一下Innodb事务的提交和binlog日志写入的过程。

当客户端执行`COMMIT`语句或者在自动提交的情况下，MySQL内部开启一个XA事务，分两阶段来完成XA事务的提交：

- Prepare阶段：存储引擎将该事务执行过程中产生的redo日志刷盘，并且将本事务的状态设置为`PREPARE`。binlog啥也不干。
- Commit阶段：先将事务执行过程中产生的binlog刷新到硬盘，再执行存储引擎的提交工作。


两阶段提交是为了**保证redo log和bin log的数据一致性**。

commit阶段之前的崩溃，都是通过undo log进行回滚的。而如果是commit阶段崩溃，需要考虑binlog的状态：  
【1】如果binlog的记录是完整的，那么使用redo log对页面数据进行重新更新  
【2】如果binlog的记录是不完整的，那么使用undo log进行数据回滚。





**另一版本**：
更新语句update、insert等都是默认开启自动提交事务的，因此当一条记录被更新后，缓冲池中的页面必然会变脏。但是一般不会同步刷新页面，而是通过后台线程异步刷新页面。当事务提交时，默认情况下会将redo log的内容同步到磁盘，当完成这个操作的时候（redo log更新成功（这里仅考虑redo log）），整个更新操作就算完成了。因为redo log是实现原子性和持久性的关键元素，如果日志被成功更新，那么即使脏页发生丢失，也可以通过redo log进行恢复操作  
核心就是WAL（write ahead log）——**先同步日志，再将数据写入磁盘**

innoDB的redo log是固定大小，如果满了就会覆盖开头，循环写入。

两个重要参数（其实就是双指针）：**write pos（当前记录的位置）**和**checkpoint（当前要擦除的位置）**  
一边写一边后移，擦除记录前需要将记录更新到数据文件中，【w,c】之间都是可以使用的空间，如果w追上c则表示redo log满了，暂时不能执行新的更新。  
有了redolog，innoDB可以保证**即使数据库发送异常重启，之前提交的记录都不会丢失**，被称为crash-safe崩溃安全。

Redo log是innoDB独有的日志。Server的日志叫binlog（归档日志/二进制日志），所有引擎都可以使用。Redo log是物理日志，记录“某个页面上做了什么修改”，而binlog是逻辑日志，记录的是语句级别的（statement）或者行的逻辑修改级别的（row）。而且Binlog是追加写入的，达到一定大小后会切换下一个文件，不会覆盖以前的日志。

> Redolog不是记录数据页更新之后的状态，而是记录某个页面、某个偏移量做了什么改动，是物理数据层面的。  
> Binlog有两种模式，statement模式记录SQL语句，row模式记录行的内容（两条，更新前和更新后）

binLog记录了数据库执行更改的所有逻辑操作（如SQL语句），用于做数据规定、数据恢复和数据复制。**不具备崩溃恢复功能**。  
**两阶段提交**  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fdf2b9af4ef4945919ea8cfa51214c16a.png)【1】执行器先调用引擎接口取得ID=2的这行记录，如果数据页存在于内存直接返回给执行器，否则先从磁盘读入内存，然后再返回。（简单概况：**从磁盘或缓冲池中读取（拷贝）目标数据行，放入目标内存区域**）  
【2】记录undo log（事务开启前的数据版本）  
【3】执行器得到记录，将c字段值加一，得到新的记录，再调用引擎接口写入新数据  
【4】**引擎将新数据更新到内存**中（缓冲池中的页面变脏）  
【5】同时**将redo log写入内存**（执行整个事务的过程中，redo log就不断被保存进内存），此时redo log处于**prepare准备状态**。（写入redo log缓冲区，表示预提交）  
【6】执行器生成该操作的binlog，并将binlog写入磁盘（这里的写是广义概念，是否同步到磁盘看具体参数，**默认是不同步磁盘，仅仅从应用程序的binlog cache写入操作系统缓存**）  
【7】执行器调用引擎的提交事务接口，（默认情况下）将redo log写入磁盘，此时redo log处于提交阶段。




## select语句的执行顺序

select的机读流程：  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fa0bd66262d434719b9c296f7bd20af1f.png%3Fx-oss-process%3Dimage%2Fwatermark%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NzkzOTkz%2Csize_16%2Ccolor_FFFFFF%2Ct_70)每一个步骤都会生成一个虚表，并且下一步生成的虚表都是在某一个虚表的基础上生成的，这些中间生成的表对用户不可用，只有最后一步生成的表才会返回给调用者。  
【1】from：对两个表执行笛卡尔积（类比双循环），生成虚表A  
【2】对虚表A进行ON筛选，只有满足条件的行才会被连接并插入虚表B  
【3】外连接（外部行连接）：**保留主表，找到未匹配的、主表一侧的行**添加到B，生成C，如果from子句中多于两个表则重复以上步骤，直到生成唯一的虚拟表。其中从表中与主表没有对应的字段（主表有值，从表没有值）将被赋值为NULL  
【4】对C进行where筛选，符合条件的行插入虚表D  
【5】按照group by字段对D进行分组（先通过临时表排序再分组），生成虚表E  
【6】having子句对E进行筛选，将符合条件的语句插入F  
【7】select从F中选取目标列，生成G  
【8】distinct语句去除重复的行，生成H

> 如果指定了distinct子句，则会创建一张内存临时表（内部不够，使用文件排序），这张临时表的表结构和G表一样，但是**distinct列被增加了唯一索引**

【9】将H中的数据行按照order by字段进行排序，并生成一个游标。注意，**此时select执行完毕，因此可以使用select指定的别名**。

> 这一步返回的是游标。由于SQL是基于**集合**的，因此**不存在预先排序**，对表进行排序的查询可以返回一个对象，包含按特定物理顺序组织的行，这种对象就是游标。

【10】从游标的开始处选择指定数量或者比例的行(例如进行limit操作)，生成结果集返回调用者。

> Limit n,m 从第n条记录（0开始）选择m条记录，但是数据量很大的时候非常低效，因为limit每次从头开始扫描（移动游标对象扫描记录，不走索引，因为走到这个位置时索引的作用已经发挥完毕了，这里返回的游标就是一个迭代器的指针）。

使用了Order by子句的查询不能用作表 表达式（视图、子查询、派生表）  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F0ba979a42a164a17a9bc5908f45dfae5.png)上面这种写法会保存，因为from子句的内容中不是一张表（**带有排序作用的order by子句的查询**），而是一个**对象**，其中的行按特定的顺序组织在一起，这种对象就是游标。

## update语句的执行流程

更新语句update、insert等都是默认开启自动提交事务的，因此当一条记录被更新后，缓冲池中的页面必然会变脏。但是一般不会同步刷新页面，而是通过后台线程异步刷新页面。当事务提交时，默认情况下会将redo log的内容同步到磁盘，当完成这个操作的时候（redo log更新成功（这里仅考虑redo log）），整个更新操作就算完成了。因为redo log是实现原子性和持久性的关键元素，如果日志被成功更新，那么即使脏页发生丢失，也可以通过redo log进行恢复操作  
核心就是WAL（write ahead log）——**先同步日志，再将数据写入磁盘**

innoDB的redo log是固定大小，如果满了就会覆盖开头，循环写入。

两个重要参数（其实就是双指针）：**write pos（当前记录的位置）**和**checkpoint（当前要擦除的位置）**  
一边写一边后移，擦除记录前需要将记录更新到数据文件中，【w,c】之间都是可以使用的空间，如果w追上c则表示redo log满了，暂时不能执行新的更新。  
有了redolog，innoDB可以保证**即使数据库发送异常重启，之前提交的记录都不会丢失**，被称为crash-safe崩溃安全。

Redo log是innoDB独有的日志。Server的日志叫binlog（归档日志/二进制日志），所有引擎都可以使用。Redo log是物理日志，记录“某个页面上做了什么修改”，而binlog是逻辑日志，记录的是语句级别的（statement）或者行的逻辑修改级别的（row）。而且Binlog是追加写入的，达到一定大小后会切换下一个文件，不会覆盖以前的日志。

> Redolog不是记录数据页更新之后的状态，而是记录某个页面、某个偏移量做了什么改动，是物理数据层面的。  
> Binlog有两种模式，statement模式记录SQL语句，row模式记录行的内容（两条，更新前和更新后）

binLog记录了数据库执行更改的所有逻辑操作（如SQL语句），用于做数据规定、数据恢复和数据复制。**不具备崩溃恢复功能**。  
**两阶段提交**  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fdf2b9af4ef4945919ea8cfa51214c16a.png)【1】执行器先调用引擎接口取得ID=2的这行记录，如果数据页存在于内存直接返回给执行器，否则先从磁盘读入内存，然后再返回。（简单概况：**从磁盘或缓冲池中读取（拷贝）目标数据行，放入目标内存区域**）  
【2】记录undo log（事务开启前的数据版本）  
【3】执行器得到记录，将c字段值加一，得到新的记录，再调用引擎接口写入新数据  
【4】**引擎将新数据更新到内存**中（缓冲池中的页面变脏）  
【5】同时**将redo log写入内存**（执行整个事务的过程中，redo log就不断被保存进内存），此时redo log处于**prepare准备状态**。（写入redo log缓冲区，表示预提交）  
【6】执行器生成该操作的binlog，并将binlog写入磁盘（这里的写是广义概念，是否同步到磁盘看具体参数，**默认是不同步磁盘，仅仅从应用程序的binlog cache写入操作系统缓存**）  
【7】执行器调用引擎的提交事务接口，（默认情况下）将redo log写入磁盘，此时redo log处于提交阶段。

两阶段提交是为了**保证redo log和bin log的数据一致性**。

commit阶段之前的崩溃，都是通过undo log进行回滚的。而如果是commit阶段崩溃，需要考虑binlog的状态：  
【1】如果binlog的记录是完整的，那么使用redo log对页面数据进行重新更新  
【2】如果binlog的记录是不完整的，那么使用undo log进行数据回滚。
