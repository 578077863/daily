## SQL语句执行流程

连接器

分析器

1. 词法分析
分析器会先做词法分析，输入的是由多个字符串和空格组成的一条SQL语句，mysql需要识别出里面的字符串分别是什么，代表什么。
mysql从你输入的“select”这个关键字识别出来，这是一个查询语句。它也要把字符串"T" 识别成“表名T”，把字符串“ID”识别成“列ID”。
2. 语法分析
根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足mysql语法。如果语句不对就会收到“You have an error in your SQL syntax”的错误提醒；例如这个语句select少了开头字母“s”:
3. 语义分析
之后还会对合法的查询语句进行语义检查。根据数据字典中有关的模式定义检查语句中的数据库对象如关系名、属性名是否存在。如果是视图则通过视图消解方法将对视图的操作转换为对基本表的操作。还会根据数据字典中的用户权限和完整性约束定义对用户的存取权限进行检查。
检查通过后便将SQL查询语句转换为等价的关系代数表达式。
这个过程把数据库对象的外部名称转换为内部表示（查询树或语法分析树）


优化器





>change buffer降低了随机读的消耗，redolog 降低了随机写的消耗，将随机写转为顺序写（通过批量写来接近的）
>change buffer的目的应该是降低读操作的磁盘IO的消耗，而不写磁盘IO的消耗



## MySQL架构
Mysql服务器可以分为**server层**和**存储引擎层**，其中server层包含**连接器**、**查询缓存**、**分析器**、**优化器**、**执行器**。而存储引擎最大的特点就是**基于表**的和**插件式**的，可以根据不同的应用建立不同的存储引擎表，mysql默认使用innoDB。

一个连接进程和Mysql数据库实例通信**本质上就是两个进程在通信**，数据库只能算作一组文件的集合，而正在与底层数据库打交道的是数据库实例这个程序。

其中**连接层**负责将数据库实例与客户端程序建立TCP连接，并且完成一些认证、校验工作，这一层在大多基于C/S的服务都有类似架构。  
而**服务层**完成了大多数核心服务，包括sql的解析、分析、优化、缓存以及所有的内置函数。所有跨存储引擎的功能也都在这一层实现：存储过程、触发器、视图等。  
而**存储引擎**才是正在负责mysql中**数据的存储和提取**，存储引擎是基于表的，而且是以插件的形式存在，可以根据不同的表更换不同的存储引擎。（**存储引擎就是如何管理操作数据的一种方法，数据最终需要存储在磁盘（文件系统）上**）  
存储层主要是将数据存储在运行于裸设备的文件系统之上，并完成与存储引擎的交互，这才是数据真正落地的地方，需要操作系统（如文件系统）和硬件（如磁盘）的支持

> 每个客户端连接（服务器为之维护客户端套接字）都会在服务器进程中拥有一个线程，每个查询都会在单独的线程中执行，对应一个CPU核心中执行。服务器会负责线程的分配和撤销（线程池），因此不需要为每一个新建的连接创建或者销毁线程


## mysql执行流程
mysql客户端（例如命令行打开的mysql client）与mysql服务器建立连接后，服务器需要对客户端进行认证，一旦认证成功，服务器还会继续验证该客户端是否具有执行某个特定查询的权限。

Mysql会解析查询（sql语句），并创建内部数据结构（语法解析树），然后对其进行各种优化（如选择合适的索引、重写查询等）。用户可以通过特殊的关键字提示（hint）优化器，影响他的决策过程。也可以请求优化器解释（explain）优化过程的各个因素，使用户可以得知服务器是如何进行优化决策的，提供一个参考基准，便于用户重构sql和schema、修改相关配置

一个查询请求在mysql的基本处理步骤：  
【1】MySQL客户端通过**连接器**与MySQL服务器建立TCP连接，然后服务器对客户端进行一些权限认证操作  
【2】对于select语句，在解析sql之前，服务器会先检查**查询缓存（query cache）**，如果能够在其中找到对应的sql，服务器就会直接返回查询缓存中的结果集。（该部分已经在MySQL8被移除，因为查询缓存失效十分频繁，一旦进行了任何一个更新操作，整个缓存都会被清空）  
【3】**分析器**对查询语句进行扫描、**词法分析**及**语法分析**。如果sql语法有误，就会收到**you hava an error in your SQL syntax**的错误提示。

> 之后还会对合法的查询语句进行**语义检查**。根据数据字典中有关的模式定义检查语句中的数据库对象如关系名、属性名是否存在。如果是视图则通过**视图消解**方法将对视图的操作转换为对基本表的操作。还会根据数据字典中的用户权限和完整性约束定义对用户的存取权限进行检查。  
> 检查通过后便将SQL查询语句转换为等价的**关系代数表达式**。  
> 这个过程把数据库对象的外部名称转换为内部表示（查询树或语法分析树）

【4】**优化器**会生成执行计划，并且选择合适的索引，为字段选择合适的查询位置，为多表确定正确的连接顺序等。  
【5】根据优化器生成的执行计划，由**代码生成器**生成执行这个查询计划的代码加以执行并回送查询结果。**执行器**根据表的引擎定义，去调用相应引擎提供的读取接口，最终得到接口返回的结果。


## innoDB体系架构

存储引擎和文件系统打交道，负责将用户对数据库实例的访问，同步到数据库系统（作为应用层一部分的数据库系统接收操作系统的文件系统或磁盘系统的服务）。数据库实例是由后台线程以及一个共享内存区组成，数据库实例才是真正用于操作数据库文件的。而数据库系统是物理操作系统文件或其他形式文件类型的集合


### 内存池

**缓冲池技术避免每次都访问磁盘，而是查询内存上的缓存数据，以加速对数据的访问。缓冲池以页（16K）为单位**  
Mysql缓冲池用于**弥补CPU处理速度和磁盘IO速度的瓶颈**（不能老让CPU等着I/O行为的完成）  
缓冲池可以起到加速读和加速写的作用。数据库实例的读操作，会将磁盘的页存放到缓冲池中，下次读取相同的页时，首先从池中读，未命中才读取磁盘。数据库实例的写操作，首先修改缓冲池中的页，脏页被后台线程以一定频率刷新到磁盘上。（索引修改操作也可以经过change buffer进行优化）

#### buffer pool

innoDB有一块内存区用来充当应用层面的磁盘缓存（page cache），可以缓存磁盘中加载出来的数据、磁盘页面，称为buffer pool。  
**缓冲池技术避免每次都访问磁盘，而是查询内存上的缓存数据，以加速对数据的访问。缓冲池以页（16K）为单位**

innoDB存储引擎是基于磁盘存储的，并将其中的数据按照记录页的方式进行管理，对数据页的修改是基于缓冲池中的页的，并**按照一定频率异步刷新到磁盘上**。


##### 内存链表
缓冲池是通过LRU算法进行管理内存页面的。频繁使用的页面放在头部，当缓冲池没有空闲内存时，则释放尾部的页面，如果是脏页就进行同步，否则直接释放（将该页面的内存地址挂载到空闲页面链表中）。

MySQL的预读机制，这个所谓预读机制，说的就是当你从磁盘上加载一个数据页的时候，他可 能会连带着把这个数据页相邻的其他数据页，也加载到缓存里去！

传统LRU的两个问题及innoDB的优化策略：  
【1】页面“内存泄露”——**预读失效**：我的理解是：当加载一个数据页的时候，通过预读机制会将其周围的数据页加载到内存中，而这些数据页其实并没有人访问
优化：对LRU列表进行了分代优化，默认以5:3分为了新生代和老年代，**预读页存放至老年区，真正被访问的数据页存入新生区**。

【2】**缓冲池污染**：进行大范围扫描时，进入缓冲池的页可能将列表中原始的页面全部排挤出去，导致大量热数据被换出。  
优化：通过**老年代停留**策略，短时间内被大量载入的页存入老年代，且如果一段时间后这些页仍然存留在老年代则插入新生代（即这个时间内没有被后来的新页挤出去）【这里的老年代和新生代和GC的不能相提并论，这里老年代指的是old页面，优先被淘汰的一组页面】

>>[(53条消息) mysql lru_聊聊缓存淘汰算法-LRU 实现原理_weixin_39992831的博客-CSDN博客](https://blog.csdn.net/weixin_39992831/article/details/113431550)


> 重要的三个参数：  
> 【1】innoDB_buffer_pool_size。为缓冲池申请连续的内存空间（逻辑上连续）  
> 【2】innoDB_old_blocks_pct。老年代比例，如果100则退化为普通的LRU列表  
> 【3】innoDB_old_blocks_time。老年代停留时间窗口。默认1秒钟（即页面被放入老年代后，多久才会被加入年轻代，如果时间窗口结束页面已经被移除列表，就不需要做任何操作）。**必须同时满足“被访问”和“老年代停留超过1秒”才会移入新生代头部**


缓冲池上通过多个链表管理脏页、空闲页和正常页。并且基于LRU算法进行管理  
缓冲池对LRU列表进行了分代优化，默认以5:3分为了新生代和老年代，**预读页（加载一个页的时候，把其相邻的数据页也加载到缓存里去）优先放入老年代**，**当页1s（可以设置）后被访问时才进入新生代**，以**防止热页被预读入的新页淘汰**。同时在老年代设置了**存留阈值**，只有在老年代停留时间超过该阈值才存入新生代，以**防止缓冲池污染问题**

本质就是冷热分离思想

**LRU链表的热数据区域是如何进行优化的？**
在热数据区域中，如果你访问了一个缓存页， 是不是应该要把他立马移动到热数据区域的链表头部去？
热数据区域里的缓存页可能是经常被访问的，所以这么频繁的进行移动是不是性能也并不是太好？也没这个必要。 所以说，LRU链表的热数据区域的访问规则被优化了一下，即你只有在热数据区域的后3/4部分的缓存页被访问了，才 会给你移动到链表头部去。 
如果你是热数据区域的前面1/4的缓存页被访问，他是不会移动到链表头部去的。 
举个例子，假设热数据区域的链表里有100个缓存页，那么排在前面的25个缓存页，他即使被访问了，也不会移动到 链表头部去的。但是对于排在后面的75个缓存页，他只要被访问，就会移动到链表头部去。 

这样的话，他就可以尽可能的减少链表中的节点移动了。


### 刷页

为了避免刷新脏页入磁盘时发生宕机导致数据丢失，目前的事务数据库普遍采用了：当事务提交时，先写重做日志，再修改页（如果事务不提交，那么刷新脏页没有意义）  
一旦数据提交，redo buffer中的数据就会写入磁盘、主线程也会每秒将redo buffer的数据写入磁盘（**innoDB基于异步I/O，因此可以一次提交多个I/O请求然后交给后台I/O线程响应回调函数**），目的是**加速事务提交的速度**。当重做日志缓冲池空间不足时也会将一部分写入磁盘（循环写）  
只要有日志，就可以保证事务的一致性。

脏页通过**检查点机制**同步磁盘，脏页由缓冲池中的flush链表管理，检查点技术可以异步地将部分脏页刷回磁盘，减少数据库恢复的时间。当缓冲池不够用（需要从LRU列表释放部分页面）时，将脏页刷回磁盘，当redo 日志不可用时（循环写入时，将被覆盖的部分），刷新脏页。

>>[SQL Server事务日志-检查点、redo和undo(1) - 简书 (jianshu.com)](https://www.jianshu.com/p/e9d10bbc0ec5?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation)

> innoDB通过**LSN（日志序列号）** 来标识版本  
> 数据库宕机时，不需要重做所有页，只需要**对检查点之后的重做日志进行恢复**，大大减少了恢复时间

mysql当多个线程在提交完prepare，relog写入到redolog buffer中，此时存在多个redo logbuffer中有多个线程的日志内容，并同步更新了日志逻辑序列号。第一个写完的线程带着lsn去刷写磁盘，写完后，别的线程发现自己的redolog日志已经写完了便直接返回了



**刷页时机：**  
【1】mysql正常关闭时  
【2】后台线程（page cleaner thread）空闲时  
【3】缓冲池换出脏页时  
【4】redo日志满了，需要覆盖写，则缓冲池对应脏页应被刷新（如果redo满了，则用户对内存redo log将被暂停，检查点将向前推进，直到具有足够的空间）

**当用户执行修改操作后（开启事务前记录undo log），首先会写内存中的数据页，其次写内存中的redo log，当用户提交事务时，默认情况下，redo log刷入磁盘，此时内存中的数据页则一般不会刷入磁盘，但是只要要保证redo log刷入磁盘，就可以保证持久性了**。  
此设计保证了：  
【1】用户如果能够从内存中读取到页面，那么页面一定是最新值  
【2】如果用户无法从内存中读取页面，那么从磁盘读取的也一定是最新值



当数据库实例发出写请求，首先查询缓冲池，如果存在：  
【1】直接修改缓冲池中的页（一次内存操作）  
【2】写redo buffer（一次内存操作）（这里的写是广义上的写，具体行为看参数设置）  
否则会先执行一次IO操作，将数据页读入缓冲池然后执行上述操作。

脏页刷盘时机：  
【1】mysql正常关闭时  
【2】后台线程（主线程或脏页刷新线程page cleaner thread）空闲时  
【3】缓冲池换出脏页时（空闲链表没有页面可用，需要进行页面换出操作）  
【4】重做日志满了，需要覆盖写，则缓冲池对应脏页应被刷新（如果redo满了，则用户对内存redo log将被暂停，检查点将向前推进，直到具有足够的空间）


#### redo logo buffer

上面提到的缓存池主要是对数据页、索引页、change buffer等数据的缓存，innoDB的内存区还有重做日志缓冲，innoDB首先将重做日志信息放入该缓冲区，然后按照一定频率将其刷新到日志文件中（磁盘还是文件系统的内核缓冲区，需要看具体设置的参数）  
重做日志缓存的大小由配置参数**innoDB_log_buffer_size**控制

Redo log记录着磁盘数据的变更日志，以物理存储的最小单位“页”进行记录，如对某个页面的某个偏移量做了某个更新操作，**记录的是物理信息，是磁盘数据级别的**。

重做日志的刷新时机  
【1】主线程每秒负责将一部分重做日志缓存的内容刷新到日志文件  
【2】（默认）每个事务提交时，会进行一次重做日志缓存的fsync调用  
【3】当重做日志缓冲池剩余空间大小小于1/2时，进行刷新操作

> 其中主线程每秒刷新，主要是为了优化事务提交的速度。


其实除此以外还有一部分额外的内存池——对数据结构本身进行内存分配（缓冲池帧、重做日志缓存帧。各种变量等系统内存的维护）



### 后台线程

innoDB是多线程的模型，后台具有多个不同的后台线程。  
【1】主线程  
主线程负责将缓冲池中的**数据异步刷新到磁盘（通过fsyn调用将内存中的数据同步到磁盘）**（这里的数据包括刷新redo log、数据页、索引页等，包括主动和被动行为），保证数据的一致性，同时还负责脏页的刷新，对change buffer（延迟写操作）进行合并、undo页回收等。

> 后台线程中的purge线程负责回收不被需要的undo页面，page cleaner用于刷新脏页。他们都一定程度上分担了主线程的工作量。

【2】IO线程  
innoDB使用了大量异步请求来处理写I/O请求，而当I/O完成都会触发回调函数，I/O线程就是负责处理I/O请求的回调逻辑的  
【3】undo页回收线程  
【4】脏页刷新线程


## innoDB重要特性
【1】change buffer，对**非唯一普通索引**进行修改后，如果页面不再内存中，则不需要立即读出索引页并进行修改，而是延迟这个动作的执行，等到之后页面被读出，再执行合并操作并恢复到内存中的缓冲池。后台线程也会时不时地执行合并操作（内存不够用、mysql正常退出等情况也会执行合并操作）。  
change Buffer的目的就是**降低对磁盘的随机读次数**（不需要专门地从磁盘中读出到内存），同时不用专门将页面调入缓冲池，节省了内存空间。

> changeBuffer和数据页一样，是物理页的一个组成部分，底层是一颗B+树，负责对索引表的辅助索引进行changeBuffer，存放于共享表空间。changeBuffer在内存中有缓存，同时也可以持久化到磁盘中。

如果要修改的字段是唯一索引或者主键，还需要加载数据页（从磁盘读出来），**判断是否违反唯一性约束**，从而导致changeBuffer没有了意义。

【2】double write  
主要是**防止页本身损坏导致的重做失效**，使用重做日志进行恢复之前，用户需要一个页面的副本，当发送写失效时，先通过页的副本对损坏页进行恢复，之后再进行重做。

对缓冲池的脏页进行刷新时，不是直接写磁盘，而是会通过memcpy()函数**将脏页先复制到内存中的doublewrite buffer**，之后通过doublewrite buffer写入物理磁盘，之后doublewrite buffer中的各个页面会写入各个表空间文件中。  
如果操作系统将页面写入磁盘的过程中发生了崩溃，恢复过程中，innoDB存储引擎可以从**共享表空间中的doublewrite 中找到一个该页的副本**，并复制到表空间文件中重新执行日志重做。

> doublewrite由内存中的doublewrite buffer和共享表空间中的两个连续的区（2M）组成。doublewrite buffer缓存buffer pool的脏页（备份），防止写磁盘过程中崩溃导致页损坏而使得无法恢复，可以通过innoDB缓存找到页面的备份去重新执行崩溃恢复操作


为什么不能利用redo log 恢复呢，它不是物理日志吗？
>[MySQL doublewrite与redo - 章怀柔 - 博客园 (cnblogs.com)](https://www.cnblogs.com/lovezhr/p/15399255.html)

扇区(IO sector)，扇区是磁盘物理操作的基本单位，而IO 块是磁盘操作的逻辑单位，一个IO块对应一个或多个扇区，扇区大小一般为512个字节

由于任何DB page的写入，最终都会转为sector的写入，如果在写磁盘的过程中，出现异常重启，就可能会发生一个DB页只写了部分sector到磁盘，进而出现页断裂的情况。

页断裂与数据库一致性

前面我们分析了异常重启一定会导致页断裂，而页断裂就意味着数据库页面不完整，那么数据库页面不完整是否就意味着数据库不一致呢？？？我们知道，数据库异常重启时，自身有异常恢复机制，我这里不打算展开讲异常恢复机制，因为不同数据库的异常恢复流程不同。主流数据库基本原理类似：第一阶段重做redo日志，恢复数据页和undo页到异常crash时的状态；第二阶段，根据undo页的内容，回滚没有提交事务的修改。通过两个阶段保证了数据库的一致性。对于mysql而言，在第一阶段，若出现页断裂问题，则无法通过重做redo日志恢复，进而导致恢复中断，数据库不一致。这里大家可能会有疑问，数据库的redo不是记录了所有的变更，并且是物理的吗？理论上来说，无论页面是否断裂，从上一个检查点对应的redo位置开始，一直重做redo，页面自然能恢复到正常状态。对吗？讲清楚这个问题，先讲讲重做日志(redo)格式。

数据库系统实现日志主要有三种格式，逻辑日志(logical logging)，物理日志(physical logging)，物理逻辑日志(physiological logging)，而对于redo日志，则主要采用物理日志和物理逻辑日志两类。逻辑日志，记录一个个逻辑操作，不涉及物理存储位置信息，比如mysql的binlog；物理日志，则是记录一个个具体物理位置的操作，比如在2号表空间，1号文件，48页的233这个offset地方写入了8个字节的数据，通过(group_id,file_id,page_no,offset)4元组，就能唯一确定数据存储在磁盘的物理位置；物理逻辑日志是物理日志和逻辑日志的混合，如果一个数据库操作(DDL，DML，DCL)产生的日志跨越了多个页面，那么会产生多个物理页面的日志，但对于每个物理页面日志，里面记录则是逻辑信息。这里我举一个简单的INSERT操作来说明几种日志形式。

[mysql的逻辑日志、物理日志与物理逻辑日志 - 简书 (jianshu.com)](https://www.jianshu.com/p/646961b93c7e)

比如innodb表T(c1,c2, key key_c1(c1)),插入记录row1(1,’abc’)

逻辑日志：
-   与物理日志相同，更新操作相对于 page 进行，每一条日志仅仅涉及一个 page 的修改；
-   与逻辑日志相同：日志内容为更新语句（update query）本身，而不是状态机某些字段更新前后的状态。
对应页是物理的，页内部操作是逻辑的。即根据物理页进行日志记录，根据不同的逻辑操作进行日志写入。

<insert OP, T, 1,’abc’>

逻辑物理日志：

因为表T含有索引key_c1, 一次插入操作至少涉及两次B树操作，二次B树必然涉及至少两个物理页面,因此至少有两条日志

<insert OP, page_no_1, log_body>

<insert OP, page_no_2, log_body>

物理日志:

由于一次INSERT操作，物理上来说要修改页头信息(如,页内的记录数要加1)，要修改相邻记录里的链表指针，要修改Slot属性等，因此对应逻辑物理日志的每一条日志，都会有N条物理日志产生。

< group_id,file_id,page_no,offset1, value1>

< group_id,file_id,page_no,offset2, value2>

……

< group_id,file_id,page_no,offsetN, valueN>

因此对于上述一个INSERT操作，会产生一条逻辑日志，二条逻辑物理日志，2\*N条物理日志。从上面简单的分析可以看出，逻辑日志的日志量最小，而物理日志的日志量最大；物理日志是纯物理的；而逻辑物理日志则页间物理，页内逻辑，所谓physical-to-a-page, logical-within-a-page。

redo格式与数据一致性

回到“发生页断裂后，是否会影响数据库一致性”的问题，发生页断裂后，对于利用纯物理日志实现redo的数据库不受影响，因为每一条redo日志完全不依赖物理页的状态，并且是幂等的(执行一次与N次，结果是一样的)。另外要说明一点，redo日志的页大小一般设计为512个字节，因此redo日志页本身不会发生页断裂。而逻辑物理日志则不行，比如修改页头信息，页内记录数加1，slot信息修改等都依赖于页面处于一个一致状态，否则就无法正确重做redo。而mysql正是采用这种日志类型，所以发生页面断裂时，异常恢复就会出现问题，需要借助于double write技术来辅助处理。

double write处理页断裂

doublewrite是Innodb表空间内部分配的一片缓冲区，一般double write包含128个页，对于pagesize为16k的页，总共2MB，doublewrite页与数据页一样有物理存储空间，存在于共享表空间中。Innodb在写出缓冲区中的数据页时采用的是一次写多个页的方式，这样多个页就可以先顺序写入到doublewrite缓冲区，并调用fsync()保证这些数据被写出到磁盘，然后数据页才被写出到它们实际的存储位置并再次调用fsync()。故障恢复时Innodb检查doublewrite缓冲区与数据页原存储位置的内容，若doublewrite页处于页断裂状态，则简单的丢弃；若数据页不一致，则会从doublewrite页还原。由于doublewrite页落盘与数据页落盘在不同的时间点，不会出现doublewrite页和数据页同时发生断裂的情况，因此doublewrite技术可以解决页断裂问题，进而保证了重做日志能顺利进行，数据库能恢复到一致的状态。




【3】自适应哈希索引  
自适应哈希索引是根据**缓冲池（内存）**中的B+树页面进行构造的，建立速度很快，不需要对整张表构建索引。**innoDB引擎会自动根据访问的频率与模式自动的为某些热点页面建立哈希索引**。（占用一部分buffer pool的内存空间）  
建立条件比较严苛：访问模式一样（查询条件一样）。如果以where a = 1 被查询了100次。而且哈希索引只能用于等值查询。

【4】刷新临界页  
当刷新一个脏页的时候，innoDB存储引擎会检查**该页所在区的所有页**，如果存在脏页则一起刷新。基于该特点，多个异步I/O可以合并为一个同步I/O操作。对于传统机械硬盘建议开启该特性，而对于固态硬盘则没有必要。（可以通过设置innoDB flush neighbors = 0 关闭该特性）

【5】异步I/O  
用户可以在发出一个I/O请求后立即再次发送另一个I/O请求，这些I/O请求将会调用相应的回调函数，innoDB的后台I/O线程会处理这些异步请求的回调。

> AIO的一个优势是可以将多个I/O合并为一个I/O操作。


## innoDB与myisam对比
innoDB的存储引擎是mysql的默认存储引擎。InnoDB存储引擎提供了具有提交、回滚、**崩溃恢复能力**的**事务安全**。相对于MyISAM的存储引擎，InnoDB写的处理效率差一些，并且会**占用更多的磁盘空间**以保留数据和索引，因此当需要频繁的更新、删除操作，同时还对事务的完整性要求较高，需要实现并发控制，建议选择。  
innoDB的设计目标主要面向在线事务处理（OLTP）的应用（偏I/O密集型）。它的特点就是行锁设计。支持外键，支持类似于oracle的**非锁定读（默认读取不会加锁）**，通过MVCC来获得高并发性。  
对于表中数据的存储，innoDB存储引擎采用**聚集**的方式，因此每张表的存储都是按主键的顺序进行存放。

**支持外键的存储引擎只有InnoDB**.在创建外键时，要求父表必须有对应索引，子表在创建外键的时候，也会自动的创建对应的索引。

MyISAM不支持事务和外键和行级锁,，支持全文索引，主要面向在线分析处理（OLAP）的应用（偏CPU密集型），优势是**访问的速度快**。对事务的完整性没有要求或者以SELECT/INSERT为主的应用基本上都可以这个引擎来创建表。有一个缺陷——**崩溃后无法安全恢复**。  
事务是在引擎层实现的，myisam不支持事务是被innoDB取代的重要原因之一。

**Myisam索引文件和数据文件是分开存放的**。主键索引是**非聚簇索引**。MyISAM的存储引擎表由MYD和MYI组成，MYD用于存储数据文件，MYI用于存储索引文件。  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F45ddc6ccb504407e89c4e36e01a83603.png%3Fx-oss-process%3Dimage%2Fwatermark%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NzkzOTkz%2Csize_16%2Ccolor_FFFFFF%2Ct_70)

两个存储引擎的对比  
Myslam的每张表中，数据、索引、元信息分开存储，而innoDB所有的表默认存储在一个表空间，或者若干个表空间文件。其中数据和索引存放在一个文件中。（**Myslam的缓冲池仅缓存索引文件，数据文件交给操作系统的内核缓存来维护**，因此访问数据部分时需要涉及一次系统调用）  
Myslam索引表的叶子节点存储的是“行号”，这种分布方式很容易创建索引，且辅助索引和主键索引的存储方式相同。（而innoDB的辅助索引和主键索引采用了不同的存储方式，这种策略**减少了当出现行移动或者数据页分裂时，辅助索引的维护工作**）  
Mylsam的记录按照**插入顺序**保存，而innoDB的记录按照**主键顺序**存储。  
innoDB支持行锁、外键和事务。Mylsam仅仅支持表锁。  
Mylsam是堆表，innoDB是索引组织表。

Mylsam比innoDB查询快，因为**innoDB查询时维护的东西多**：  
【1】innoDB需要缓存数据块（页）和索引块，而mylsam只需要缓存索引块  
【2】innoDB寻址要映射到块，再到行。而mylsam记录直接是文件的偏移量。  
【3】innoDB要维护MVCC相关的数据结构


## 日志文件
>https://cloud.tencent.com/developer/article/1679325


### 回滚日志

Undo日志是**逻辑日志**，只是将数据库逻辑地恢复到原来的样子，存放于数据库共享表空间中的undo段。  

**记录的是主键和与当前相反的操作，可看作修改前将当前数据记录下来，便于回退**

Undo log保存的是数据的历史版本，通过**历史版本指针**可以让数据在任何时候都可以回滚到某个事务开始之前的版本。  
通常事务开始之前，都会生成一个回滚版本（修改之前的历史数据），数据行里面也会记录**操作该数据的事务ID**，然后可以通过事务ID对数据进行回滚。（表示某个事务所属版本，而不是回滚到别的事务的历史版本）

innoDB存储引擎中的MVCC也是通过undo log进行实现的，当用户读到一行记录的时候，若该记录已经被其他事务占用，当前事务则可以通过undo log读取之前的数据版本（行），以实现非锁定读。

undo分为两种格式：  
【1】insert undo log记录插入操作产生的undo log，只有在事务回滚时需要，事务提交后被丢弃。  
【2】update undo log记录update和delete操作产生的undo log，**不能在提交事务后进行删除，因为可能被快照读需要（MVCC），提交后加入undo log链表，等待purge线程进行删除**。只有当快照读或者事务回滚不涉及该事务时，对应的日志才会被purge线程同一清除

> 事务提交后，innoDB执行两个操作：【1】将undo log放入列表，以供undo log释放线程执行purge操作（回收undo log页面）【2】判断undo log页是否可以重用，可以则分配给下一个事务使用。（事务通过undo log和行隐藏的版本字段可以计算出之前的版本，达到事务隔离的效果）

### 二进制日志

Binlog是server层面的日志，而redo log和undo log都是存储引擎层面的日志。

Binlog是对mysql操作记录的归档日志，主要记录的是**SQL语句（statement格式：基于SQL语句记录**）以及对**表数据、结构、索引等的变更操作（row格式：基于数据行记录或mixed格式）或是mixed格式**。Binlog相当于银行卡的流水。

- 当以启动选项`--binlog-format=STATEMENT`启动MySQL服务器时，生成的binlog称作`基于语句的日志`。此时只会将一条SQL语句将会被完整的记录到binlog中，而不管该语句影响了多少记录。
每一条被修改数据的sql都会记录到master的bin-log中，slave在复制的时候sql进程会解析成和原来master端执行过的相同的sql再次执行

- 当以启动选项`--binlog-format=ROW`启动MySQL服务器时，生成的binlog称作`基于行的日志`。此时会将该语句所改动的记录的全部信息都记录上。
**日志中会记录每一行数据被修改的情况，然后在slave端对相同的数据进行修改。 优点：能清楚的记录每一行数据修改的细节 缺点：数据量太大**

Row 格式不记录 SQL 语句上下文相关信息，仅仅只需要记录某一条记录被修改成什么样子了。
Row 格式的日志内容会非常清楚地记录下每一行数据修改的细节，这样就不会出现 Statement 中存在的那种数据无法被正常复制的情况。


在有主从复制的场景中，使用`基于语句的日志`可能会造成主服务器和从服务器维护的数据不一致的情况。

如果主库和从库的服务器执行`SELECT c FROM other_table`返回记录的顺序不同的话（不同服务器版本、不同的系统变量配置都可能导致同一条语句返回结果的顺序不同），那么针对表t相同id值的记录来说，列c就可能具有不同的值，这就会造成主从之间数据的不一致。

而如果将binlog的格式改为`基于行的日志`的话，由于主库在执行完语句后将该语句插入的每条完整的记录都写入binlog日志，就不会造成主从之间不一致了。



执行事务的时候，会将binlog写入bin log cache（写入cache比较快，事务通常涉及多个操作，避免每个操作都直接写磁盘造成性能下降），事务最终提交的时候才会将缓存内容同步到磁盘（事务提交的默认行为，syn_binlog参数决定）  
当开始一个事务时，mysql会自动分配一个大小为 binlog cache size的缓存，如果日志内容超过缓存大小，则会把缓存中的日志写入一个临时文件。

> 参数max binlog size 指定了单个二进制日志文件的最大值，如果超过该值就会创建新的binlog文件。

同步时机：  
【1】Syn_binlog=0 ,提交事务时不会马上将binlog cache同步到磁盘，而是写到操作系统的page cache（内核缓存），操作系统崩溃有丢失日志的风险（默认 0）  
默认值。事务提交后，将二进制日志从缓冲写入磁盘，但是不进行刷新操作（fsync()），此时只是写入了操作系统缓冲，若操作系统宕机则会丢失部分二进制日志。
【2】Syn_binlog=1 每次提交事务都会执行fsync调用，将文件刷新到磁盘  
事务提交后，将二进制文件写入磁盘并立即执行刷新操作，相当于是同步写入磁盘，不经过操作系统的缓存
【3】Syn_binlog>1 每次提交都写入到page cache，N表示**写缓存的次数**，写缓存次数积累到N次之后才会fsync写入磁盘，mysql崩溃有丢失N个日志的风险

binlog另一个更重要的应用是主从复制，这里不再展开。



把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，我来给你举一个可以直接看出来的好处：恢复数据。接下来，我们就分别从 delete、insert 和 update 这三种 SQL 语句的角度，来看看数据恢复的问题。通过图 6 你可以看出来，即使我执行的是 delete 语句，row 格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条 delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了。如果你是执行错了 insert 语句呢？那就更直接了。row 格式下，insert 语句的 binlog 里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行。这时，你直接把 insert 语句转成 delete 语句，删除掉这被误插入的一行数据就可以了。如果执行的是 update 语句的话，binlog 里面会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了 update 语句的话，只需要把这个 event 前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了。其实，由 delete、insert 或者 update 语句导致的数据操作错误，需要恢复到操作之前状态的情况，也时有发生。MariaDB 的Flashback工具就是基于上面介绍的原理来回滚数据的。


### 重做日志

重做日志用来保证事务的持久性，由重做日志缓存与重做日志文件组成。  
WAL技术即**write ahead log**。在一个事务中，数据库实例执行的修改操作将同时对内存中的redo log 与page（内存没有就先读到内存）进行修改。当事务提交时，将**内存中的redo log**持久化（fsync()）到硬盘中即可返回，内存中的脏页将按照一定频率刷入硬盘中。

Redo log的设计目的是为了支持innoDB的事务特性，其中**原子性和持久性都离不开redo log和undo log的配合**。

Redo log **顺序写**，节省了随机写磁盘的IO消耗，循环写。写指针指向当前记录的位置，**检查点指针**指向当前要擦除的位置。当写指针追上检查点指针的时候，就需要暂停所有的更新操作，并将一部分记录进行擦除（redo log内存满了后执行覆盖写，刷新对应脏页）。

> 也就是说提交时，我们不一定非要将脏页同步以随机写的方式到磁盘，而是以顺序写的方式写入重做日志文件（或缓存），顺序写代替随机写，效率大大提高。（脏页也不是说不写，而是等到后面“不忙”的时候再写）

当数据库宕机时，数据库只需要**重做检查点之后的记录**即可，缩短了恢复时间。当缓冲池内存不足时，根据LRU算法淘汰部分页面，此时需要强制移动检查点，将脏页刷入磁盘。

**redo log 的写入磁盘时机**是可以配置的。除了主线程会每秒的写入外  
【1】**innodb_flush_log_at_trx_commit=1是默认情况**，事务提交时，强制fsync（阻塞操作）将文件系统缓冲区的数据刷新入磁盘。【值为1的基本都是同步操作】

> 写入重做日志文件的操作不是直接写，而是先写入重做日志缓存，再按照一定顺序写入日志文件。默认情况下，属于强制同步写入（没写完就等着），而其他两个选项相当于把同步操作中的若干步骤采用异步操作替换，使得提交可以更快返回。

【2】提交事务的时候，不立即把 redo log buffer 里的数据刷入磁盘文件的，而是依靠 InnoDB 的主线程每秒执行一次刷新到磁盘。此时可能你提交事务了，结果 mysql 宕机了，然后此时内存里的数据全部丢失。
【3】2则提交时，将redo cache中的数据全部刷入**文件系统的缓冲区 page cache**，而不是直接进入磁盘文件

> Redo log buffer刷新磁盘的其他操作：  
> 【1】定时处理：后台线程master thread每隔一秒进行同步操作  
> 【2】redo log buffer大小占用到 innoDB log buffer size的一半时，进行同步操作

重做日志文件的大小对innoDB存储引擎的性能有很多影响，如果设置过大，则恢复需要很长时间，设置太小又可能使得一个事务的日志需要多次切换重做日志文件，或由于写指针与检查点指针重合，导致频繁异步刷新。

从操作日志缓存往磁盘写入时，按照512字节写入（一个扇区的大小、写入的最小单位）。

重做日志的刷新时机  
【1】主线程每秒负责将一部分重做日志缓存的内容刷新到日志文件  
【2】（默认）每个事务提交时，会进行一次重做日志缓存的fsync调用  
【3】当重做日志缓冲池剩余空间大小小于1/2时，进行刷新操作



WAL 机制主要得益于两个方面：redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；组提交机制，可以大幅度降低磁盘的 IOPS 消耗。

#### 组提交
这里，我需要先和你介绍日志逻辑序列号（log sequence number，LSN）的概念。LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log

1. trx1 是第一个到达的，会被选为这组的 leader；
2. 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；
3. trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；
4. 这时候 trx2 和 trx3 就可以直接返回了。
   
所以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。


#### MySQL IO瓶颈方案
如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？

针对这个问题，可以考虑以下三种方法：
1. 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。
   ```markdown
   为什么没有丢失数据的风险？ 是设置了 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数后，要等到触发条件调用fsync之后才给客户端应答吗？也就是才算这个事务提交了？ 找了官方文档： Controls how many microseconds the binary log commit waits before synchronizing the binary log file to disk。 **我理解事务提交后先在server层写binlog，等待group commit ，提交后就相当于commit可以给客户端应答处理成功，然后告诉引擎commit，写redo log commit**。
   
   ```


2. 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。
   sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。
   
3. 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。
   设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ; 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘； 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。


binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。

这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。所以，当 binlog_group_commit_sync_delay 设置为 0 的时候，binlog_group_commit_sync_no_delay_count 也无效了。

我不建议你把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。


### 对比redo log 和 binlog

Redo日志是物理日志，记录的是对某个数据页做了什么修改，binlog（二进制日志）记录的是语句的逻辑，如“对id=2这一行的a字段加一”  
Redo是循环写，空间用完会覆盖写。Binlog是追加写，不会覆盖，空间不够用会切换到下一个日志  
二进制日志仅在**事务提交时写入**，只写磁盘一次（默认行为是仅提交时仅写入操作系统缓冲区）。而重做日志可以在**事务进行的过程中被后台线程异步写入磁盘**

Redo log记录的**数据变更粒度**和binlog不同，这也是binlog没有崩坏恢复事务数据的原因之一。Redo log记录着**磁盘数据的变更日志**，以**物理存储的最小单位“页”**进行记录。例如：  
_把表空间10、页号5、偏移量为10处的值更新为18_。

> Mysql将某一页的数据进行同步磁盘操作的时候，将数据刷新到底层磁盘的多个扇区，这个过程无法保证原子性，逻辑日志binlog无法保证崩溃恢复能力，因为它记录的太“抽象”，没有redo log具体。

总结：  
**binlog日志记录的是“上层记录”，是逻辑的，是SQL语句基本或数据行操作级别的。而redo log日志记录的是“底层记录”，是物理的，是磁盘数据级别的。因此可以用于实现磁盘数据更新的原子性。**






## 关键字实现细节

### limit

Limit语法由偏移量offset和取值数量size组成，其中偏移量默认从0开始，其中limit 10000，10代表从第10001条数据开始取，取10条记录，当offset特别大的时候，效率非常低。

> 以下是实验数据：  
> select * from user limit 0,100 ---------耗时0.03s  
> select * from user limit 10000,100 ---------耗时0.05s  
> select * from user limit 100000,100 ---------耗时0.13s  
> select * from user limit 500000,100 ---------耗时0.23s

查询id只是一种优化方式，相当于覆盖索引，但是仍然需要扫描m+n的数据（只不过生成的结果集占用内存小一些，快一些而已）

一种比较常见的limit优化方式：先拿到目标主键，外表关联数据时会走主键索引。而且内部查询主键性能比查询全字段好一些

```
Select * from Student 
Join (Select id  from Student limit 1000,10 ) as stu
On student.id = stu.id

    
    
```

> 经过实验发现：explain select id from emp limit 10000,10走了覆盖索引，而且是直接扫描叶子节点（type值为index），而explain select * from emp limit 100,10执行的是全表扫描（type类型为all）

### order by

如果order by没有走索引，那么使用explain得到的优化器解释一定会在extra选项中出现using filesort一项。  
一般mysql会为每个线程分配一块内存用于排序——**排序缓冲区sort buffer**。  
如果内存够用，mysql会优先使用**全字段排序**——将**select中的字段和排序字段**全部载入排序缓冲区，这样的好处是可以直接在内存区中构建结果集，**避免了回表**。  
如果mysql认为无法为排序分配足够多的内存区域，则只会取**核心字段（主键和排序字段）**，在排序内存区使用排序字段进行排序后，需要根据主键进行回表取数据行，回表操作增加了随机I/O的次数，是时间换空间的操作。

> 如果sort buffer不够用，那么每次只能取sort_buffer容量大小的数据进行不完整排序，从而进行了多次I/O和排序。通常可以修改相关参数：【1】增大sort_buffer_size参数【2】增大max_length_for_sort_data参数  
> 也可以考虑减少不必要的select字段。

如果内存不够使用，会基于**临时文件排序**，排序效率低下。

> 临时文件排序基于**归并算法**，将需要排序的数据拆分到多个临时文件中，进行并行排序，然后最终返回一个合并后的结果集，因为是磁盘文件中进行，因此性能下降很多

使用了索引的排序  
index(a,b) :where a=1 order by b  
先从索引中定位第一个满足添加a=1的元素数据页，回表查出select字段，拼装结果集。然后去辅助索引表查询下一个。（**如果一个页已经被在载入内存缓冲池，就不用IO了**）  
注意，此处没有进行单独的排序，因为是**按顺序从索引树中叶子节点中取的页面**，而叶子节点是默认升序的。**此过程既不需要临时表，也不需要额外排序操作**

如果select的内容是id就不用回表了（即索引上的信息足够满足查询条件，可以进行覆盖索引优化，就不需要再到主键索引表上取数据了）

### group by

语句执行的过程中会**创建内存临时表**，其中存放了group by字段和select字段，扫描指定表，向临时表插入记录。最终**按照group by字段排序**。如果不需要排序则使用order by null.  
如果过程中发现内存临时表放不下数据，则会转换为磁盘临时表/临时文件。

临时表的作用是用于**存储中间结果集，以便于排序**。如果**对group by 字段建立索引**，那么就不用额外排序了，从左到右顺序扫描并且依次累加即可

### union

A union B .这个过程会**创建用于存放临时数据的临时表**。执行第一个查询后存入该表，然后第二个查询尝试插入临时表。最后从临时表中按行取出数据，填入结果集，并且删除临时表。  
**Union具有去重的语义**，这是通过**临时表主键id唯一性约束**实现的。

如果使用union All则失去去重语义，执行的时候会附带执行一次子查询，并将得到的结果作为结果集的一部分发给客户端，同时也不会使用临时表。

### count

Count(主键id)，innoDB会遍历整张表，将每个数据行id取出，并返回给server层，server层将其累加。  
Count（字段），如果字段被定义为非空，按行累加。如果允许为null，还需要额外读取数据行中的值，判断不是null才累加  
Count(*)不会取出字段，而是直接按行累加。  
Count(1)不取值，每遍历一行就对结果集填入一个1，server按行累加

**效率对比:count(非空字段)最低，其次是count(主键id)，因为它们都涉及取值操作。而按行累加的count(*)最佳，count(1)次之**

### join

不经过任何优化的Join其实就是一个双循环语句、对两张表进行笛卡尔积。那么总共需要匹配的次数就等于：**外层表行数 * 内层表行数**，如果我们对“内循环中的表”或者说“被驱动表”建立索引，那么就可以将次数优化为：**外层表的行数 * 内层表索引的高度**  
因此一个常用的优化就是，选择小表作为驱动表，被驱动表连接字段建立索引。

mysql还会为连接分配**缓存块join buffer**，一次性将多条驱动表的字段去和被驱动表进行匹配。  
通过**一次性缓存外层表多条记录，来减少内层表的扫表次数**。如果无法使用索引嵌套循环，数据库默认使用该算法

## select语句的执行顺序

select的机读流程：  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fa0bd66262d434719b9c296f7bd20af1f.png%3Fx-oss-process%3Dimage%2Fwatermark%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NzkzOTkz%2Csize_16%2Ccolor_FFFFFF%2Ct_70)每一个步骤都会生成一个虚表，并且下一步生成的虚表都是在某一个虚表的基础上生成的，这些中间生成的表对用户不可用，只有最后一步生成的表才会返回给调用者。  
【1】from：对两个表执行笛卡尔积（类比双循环），生成虚表A  
【2】对虚表A进行ON筛选，只有满足条件的行才会被连接并插入虚表B  
【3】外连接（外部行连接）：**保留主表，找到未匹配的、主表一侧的行**添加到B，生成C，如果from子句中多于两个表则重复以上步骤，直到生成唯一的虚拟表。其中从表中与主表没有对应的字段（主表有值，从表没有值）将被赋值为NULL  
【4】对C进行where筛选，符合条件的行插入虚表D  
【5】按照group by字段对D进行分组（先通过临时表排序再分组），生成虚表E  
【6】having子句对E进行筛选，将符合条件的语句插入F  
【7】select从F中选取目标列，生成G  
【8】distinct语句去除重复的行，生成H

> 如果指定了distinct子句，则会创建一张内存临时表（内部不够，使用文件排序），这张临时表的表结构和G表一样，但是**distinct列被增加了唯一索引**

【9】将H中的数据行按照order by字段进行排序，并生成一个游标。注意，**此时select执行完毕，因此可以使用select指定的别名**。

> 这一步返回的是游标。由于SQL是基于**集合**的，因此**不存在预先排序**，对表进行排序的查询可以返回一个对象，包含按特定物理顺序组织的行，这种对象就是游标。

【10】从游标的开始处选择指定数量或者比例的行(例如进行limit操作)，生成结果集返回调用者。

> Limit n,m 从第n条记录（0开始）选择m条记录，但是数据量很大的时候非常低效，因为limit每次从头开始扫描（移动游标对象扫描记录，不走索引，因为走到这个位置时索引的作用已经发挥完毕了，这里返回的游标就是一个迭代器的指针）。

使用了Order by子句的查询不能用作表 表达式（视图、子查询、派生表）  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F0ba979a42a164a17a9bc5908f45dfae5.png)上面这种写法会保存，因为from子句的内容中不是一张表（**带有排序作用的order by子句的查询**），而是一个**对象**，其中的行按特定的顺序组织在一起，这种对象就是游标。

## update语句的执行流程（两阶段主要背这个版本就行）

更新语句update、insert等都是默认开启自动提交事务的，因此当一条记录被更新后，缓冲池中的页面必然会变脏。但是一般不会同步刷新页面，而是通过后台线程异步刷新页面。当事务提交时，默认情况下会将redo log的内容同步到磁盘，当完成这个操作的时候（redo log更新成功（这里仅考虑redo log）），整个更新操作就算完成了。因为redo log是实现原子性和持久性的关键元素，如果日志被成功更新，那么即使脏页发生丢失，也可以通过redo log进行恢复操作  
核心就是WAL（write ahead log）——**先同步日志，再将数据写入磁盘**

innoDB的redo log是固定大小，如果满了就会覆盖开头，循环写入。

两个重要参数（其实就是双指针）：**write pos（当前记录的位置）**和**checkpoint（当前要擦除的位置）**  
一边写一边后移，擦除记录前需要将记录更新到数据文件中，【w,c】之间都是可以使用的空间，如果w追上c则表示redo log满了，暂时不能执行新的更新。  
有了redolog，innoDB可以保证**即使数据库发送异常重启，之前提交的记录都不会丢失**，被称为crash-safe崩溃安全。

Redo log是innoDB独有的日志。Server的日志叫binlog（归档日志/二进制日志），所有引擎都可以使用。Redo log是物理日志，记录“某个页面上做了什么修改”，而binlog是逻辑日志，记录的是语句级别的（statement）或者行的逻辑修改级别的（row）。而且Binlog是追加写入的，达到一定大小后会切换下一个文件，不会覆盖以前的日志。

> Redolog不是记录数据页更新之后的状态，而是记录某个页面、某个偏移量做了什么改动，是物理数据层面的。  
> Binlog有两种模式，statement模式记录SQL语句，row模式记录行的内容（两条，更新前和更新后）

binLog记录了数据库执行更改的所有逻辑操作（如SQL语句），用于做数据规定、数据恢复和数据复制。**不具备崩溃恢复功能**。  
**两阶段提交**  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fdf2b9af4ef4945919ea8cfa51214c16a.png)【1】执行器先调用引擎接口取得ID=2的这行记录，如果数据页存在于内存直接返回给执行器，否则先从磁盘读入内存，然后再返回。（简单概况：**从磁盘或缓冲池中读取（拷贝）目标数据行，放入目标内存区域**）  
【2】记录undo log（事务开启前的数据版本）  
【3】执行器得到记录，将c字段值加一，得到新的记录，再调用引擎接口写入新数据  
【4】**引擎将新数据更新到内存**中（缓冲池中的页面变脏）  
【5】同时**将redo log写入内存**（执行整个事务的过程中，redo log就不断被保存进内存），此时redo log处于**prepare准备状态**。（写入redo log缓冲区，表示预提交）  
【6】执行器生成该操作的binlog，并将binlog写入磁盘（这里的写是广义概念，是否同步到磁盘看具体参数，**默认是不同步磁盘，仅仅从应用程序的binlog cache写入操作系统缓存**）  
【7】执行器调用引擎的提交事务接口，（默认情况下）将redo log写入磁盘，此时redo log处于提交阶段。

两阶段提交是为了**保证redo log和bin log的数据一致性**。

commit阶段之前的崩溃，都是通过undo log进行回滚的。而如果是commit阶段崩溃，需要考虑binlog的状态：  
【1】如果binlog的记录是完整的，那么使用redo log对页面数据进行重新更新  
【2】如果binlog的记录是不完整的，那么使用undo log进行数据回滚。












## 为什么 redo log 具有 crash-safe 的能力，是 binlog 无法替代的？
本质原因就是 binlog是写前日志,无法判断追加写后在BufferPool 中的 page有没有刷到磁盘
而redo log中存储的是没有刷入磁盘的数据,只要刷入磁盘,数据就会从redo中被删除



#### 当数据库 crash 后，如何恢复未刷盘的数据到内存中？
根据 redo log 和 binlog 的两阶段提交，未持久化的数据分为几种情况：

change buffer 写入，redo log 虽然做了 fsync 但未 commit，binlog 未 fsync 到磁盘，这部分数据丢失。
change buffer 写入，redo log fsync 未 commit，binlog 已经 fsync 到磁盘，先从 binlog 恢复 redo log，再从 redo log 恢复 change buffer。
change buffer 写入，redo log 和 binlog 都已经 fsync，直接从 redo log 里恢复。





### char 和 varchar

【1】CHAR 和 VARCHAR 类型在存储和检索方面有所不同。  
【2】CHAR 列长度固定为创建表时声明的长度，长度值范围是 1 到 255（一个字节）。  
【3】当 CHAR 值被存储时，它们被**用空格填充到特定长度**，检索 CHAR 值时需删除尾随  
空格  
Char和varchar都是字符串类型，而且**声明的时候后面都需要跟随一个数字n**。

Char(n)表示该字段**最大可用容纳的字符数量**，如果少于n则会使用**空格（0x20）填充**，而超过的部分则会**截断**。  
Varchar(n)也表示**最大可用容纳n个字符数量**，但是未达到n的部分不会使用空白填充，同时varchar底层**使用一字节存储实际的字符数量size**。

（对于**多字节字符编码**的Char数据类型，innoDB存储时也会视为变长字符类型，例如UTF-8下的char(1)可以存在字节的范围是1到3）


```markdown
引入变长字段的长度列表，解决一行数据的读取问题
“hello”的长度是5，十六进制就是0x05，所以此时会在“hello a a”前面补充一些额外信息，首先就是变 长字段的长度列表，你会看到这行数据在磁盘文件里存储的时候，其实是类似如下的格式：0x05 null值列表 数据头 hello a a。

引入变长字段长度列表后，如何解决变长字段的读取问题
所以假设此时你要读取“hello a a”这行数据，你首先会知道这个表里的三个字段的类型是VARCHAR(10) CHAR(1) CHAR(1)，那么此时你先要读取第一个字段的值，那么第一个字段是变长的，到底他的实际长度是多少呢？ 此时你会发现第一行数据的开头有一个变长字段的长度列表，里面会读取到一个0x05这个十六进制的数字，发现第一 个变长字段的长度是5，于是按照长度为5，读取出来第一个字段的值，就是“hello” 接着你知道后续两个字段都是CHAR(1)，长度都是固定的1个字符，于是此时就依次按照长度为1读取出来后续两个字 段的值，分别是“a”“a”，于是最终你会读取出来“hello a a”这一行数据！

如果有多个变长字段，如何存放他们的长度？
比如一行数据有VARCHAR(10) VARCHAR(5) VARCHAR(20) CHAR(1) CHAR(1)，一共5个字段，其中三个是变长字 段，此时假设一行数据是这样的：hello hi hao a a

此时在磁盘中存储的，必须在他开头的变长字段长度列表中存储几个变长字段的长度，一定要注意一点，他这里是逆 序存储的！
也就是说先存放VARCHAR(20)这个字段的长度，然后存放VARCHAR(5)这个字段的长度，最后存放VARCHAR(10)这 个字段的长度。
现在hello hi hao三个字段的长度分别是0x05 0x02 0x03，但是实际存放在变长字段长度列表的时候，是逆序放的， 所以一行数据实际存储可能是下面这样的： 0x03 0x02 0x05 null值列表 头字段 hello hi hao a a

NULL值是以二进制bit位来存储的
接着来看NULL值列表，这个NULL值列表是这样存放的，你所有允许值为NULL的字段，注意，是允许值为NULL，不 是说一定值就是NULL了，只要是允许你为NULL的字段，在这里每个字段都有一个二进制bit位的值，如果bit值是1说 明不是NULL，如果bit值是0说明是NULL。
比如上面4个字段都允许为NULL，每个人都会有一个bit位，这一行数据的值是“jack NULL m NULL xx_school”， 然后其中2个字段是null，2个字段不是null，所以4个bit位应该是：1010
但是实际放在NULL值列表的时候，他是按逆序放的，所以在NULL值列表里，放的是：0101，整体这一行数据看着是 下面这样的 0x09 0x04 0101 头信息 column1=value1 column2=value2 ... columnN=valueN

另外就是他实际NULL值列表存放的时候，不会说仅仅是4个bit位，他一般起码是8个bit位的倍数，如果不足8个bit位 就高位补0，所以实际存放看起来是如下的： 0x09 0x04 00000101 头信息 column1=value1 column2=value2 ... columnN=valueN
```



### 整数类型

整型类型tinyint、smallint、mediumint、int和bigint共五种，声明列的时候可以跟上n（一般不跟，因为几乎没有应用场景，仅表示显示位宽）  
这五种int的占用大小与n无关，**tiny。Small、medium、int、big的占用字节数依次：1-2-3-4-8**  
**一旦插入的值超过范围，mysql不会报错而是自动取临近的边界值**，例如往tinyInt插入256会被自动修改为255。  
Decimal类型的定义方式为**decimal(最大位数，小数点右侧的位数)**，它是以**字符串**的形式存储的。

> oracle数据库并没有专用的类型，只有number(m,n)，m表示数字的有效位数，默认38。n表示小数点之后的有效位数，默认0.如果m小于n的话，表示没有整数部分的小数（整数部分是无效数字0）。int的范围是-2147483648-2147483647，可以使用number(10,0)替代







## 慢查询日志

慢查询日志用于记录mysql中响应时间超过慢查询阈值的语句，阈值通过**long_qurey_time**进行设置，默认是10。一旦sql超过这个阈值，那么会被记录到慢查询日志中。  
如果设置了**log_queries_not_using_indexes**参数，那么没有走索引的SQL语句也会被记录到慢查询日志中。  
该日志用于调优参考，需要手动开启.

```
set global slow_query_log=1

    
```

查看开启状态：

```
show VARIABLES like '%slow_query_log%';

    
```

查看阈值

```
show VARIABLES like '%long_query_time%';

    
```

**查询当前系统内的慢查询记录。**

```
set global long_query_time=5;
设置完后重连数据库就可以看到了
    
```

可以借用**日志分析工具mysql dump slow**进行分析慢查询（去mysql的bin目录下使用命令行运行）

> 常用参数 -s以某种方式排序如c 访问次数 、 t 查询时间 、l 锁定时间、ar 平均返回行记录。-t 返回前面多少条的数据。-g 跟正则表达式。  
> 得到返回集最多的5个SQL：mysqldumpslow -s r -t 5 /mySlow.log

## show profile

show profile 是mysql提供的，可以用来分析当前会话中语句执行的**资源消耗情况**，可以用于SQL的调优的测量。

开启

```
set profiling=1;

    
```

查看开启状态：

```
show VARIABLES like '%profiling%'

    
```

查看结果

```
show profiles

    
```

默认保存最近15次的查询

诊断查询id为3的语句

```
show profile cpu,block io for query 3;	

    
```

> 常用参数：  
> 【1】ALL显示所有开销 【2】block IO 显示IO的开销 【3】context switches 上下文切换开销  
> 【4】 CPU 【4】IPC 进程通信，发送与接收的开销 【5】memory 【6】page faults 缺页中断的开销【7】 swaps 等  
> 需要在于的部分：  
> 【1】converting HEAP to MyISAM 查询结果太大，内存都不够用了，需要将一部分结果置换到磁盘  
> 【2】creating tmp table 创建临时表——拷贝数据到临时表，用完再删除  
> 【3】copying to tmp table on disk 把内存中临时表复制到磁盘上，因为临时表在内存放不下了。（耗费时间很长，需要优化，一般通过调整tmp_table_size和max_heap_size来控制内存表的大小上限。如果超过上限则会数据写入磁盘则会发生磁盘读写，因此需要提高内存分配大小）  
> 【4】locked上锁。

**当数据库服务器过慢的常见处理流程**：  
【1】观察，跑一天数据库，看看生产的慢SQL情况  
【2】开启**慢查询日志**，设置阀值，比如超过5秒就是慢查询，并抓取出来  
【3】Explain+慢SQL分析  
【4】**Show profile** 查询SQL在mysql服务器里面的执行细节和生命周期情况  
【5】运维 or DBA 进行SQL数据库服务器的参数调优

如果SQL执行偶尔比较慢，可能是数据库在某一时刻刷新脏页（后台线程占用了CPU资源，导致用户线程需要短暂等待）、或是出现了因为未能获取锁的短期阻塞。  
如果长期很慢有以下几个可能：字段索引失效（或是优化器选错索引）或者压根没有索引，总是走全表扫描。


# 宕机恢复

下面讲讲当意外宕机后重启mysql数据恢复的全过程：  
重启后通过redo log和数据文件当中的LSN对比发现，redo log日志中记录的数据变化版本要高于数据文件记录的数据版本，因此存储引擎会将redo log加载到redo log buffer中，再将数据文件中的旧数据加载到buffer pool当中，然后内存当中的buffer pool会根据redo log buffer记录的新版本数据变化进行数据更新，最后再将最新版本的数据写入到mysql的磁盘数据文件当中，完成数据的更新，极大地保证的数据的安全性。



### 主从
节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。
但是，双 M 结构还有一个问题需要解决。
业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（我建议你把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。
那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？
从上面的图 6 中可以看到，MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：
1. 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；
2. 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；
3. 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。
   
   
按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：
1. 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；
2. 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；
3. 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。



备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：
1. 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
2. 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。
3. 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
4. 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
5. sql_thread 读取中转日志，解析出日志里的命令，并执行。


# 版本2
## MVCC

### 版本链
对于使用`InnoDB`存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列（`row_id`并不是必要的，我们创建的表中有主键或者非NULL唯一键时都不会包含`row_id`列）：

-   `trx_id`：每次对某条聚簇索引记录进行改动时，都会把对应的事务id赋值给`trx_id`隐藏列。
-   `roll_pointer`：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到`undo日志`中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。

每次对记录进行改动，都会记录一条`undo日志`，每条`undo日志`也都有一个`roll_pointer`属性（`INSERT`操作对应的`undo日志`没有该属性，因为该记录并没有更早的版本），可以将这些`undo日志`都连起来，串成一个链表，所以现在的情况就像下图一样：

![[Pasted image 20220306171043.png]]


对该记录每次更新后，都会将旧值放到一条`undo日志`中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被`roll_pointer`属性连接成一个链表，我们把这个链表称之为`版本链`，版本链的头节点就是当前记录最新的值。另外，每个版本中还包含生成该版本时对应的事务id，这个信息很重要，我们稍后就会用到。


### ReadView

对于使用`READ UNCOMMITTED`隔离级别的事务来说，直接读取记录的最新版本就好了，对于使用`SERIALIZABLE`隔离级别的事务来说，使用加锁的方式来访问记录。对于使用`READ COMMITTED`和`REPEATABLE READ`隔离级别的事务来说，就需要用到我们上边所说的`版本链`了，核心问题就是：需要判断一下版本链中的哪个版本是当前事务可见的。所以设计`InnoDB`的大叔提出了一个`ReadView`的概念，这个`ReadView`中主要包含当前系统中还有哪些活跃的读写事务，把它们的事务id放到一个列表中，我们把这个列表命名为为`m_ids`。这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见：

在事务生成`readview`时，会把当前系统中正在执行的读写事务写入到`m_ids`列表中，另外还会存储两个值：

-   `min_trx_id`：该值代表生成`readview`时`m_ids`中的最小值。

-   `max_trx_id`：该值代表生成`readview`时系统中应该分配给下一个事务的id值。
    
    > 小贴士： 注意max_trx_id并不是m_ids中的最大值，事务id是递增分配的。比方说现在有id为1，2，3这三个事务，之后id为3的记录提交了。那么一个新的读事务在生成readview时，m_ids就包括1和2，min_trx_id的值就是1，max_trx_id的值就是4。
    

所以判断可见性的步骤就是：

-   如果记录的`trx_id`列小于`min_trx_id`，说明肯定可见。

-   如果记录的`trx_id`列大于`max_trx_id`，说明肯定不可见。

-   如果记录的`trx_id`列在`min_trx_id`和`max_trx_id`之间(<=  <=)，就要看一下该`trx_id`在不在`m_ids`列表中，如果在，说明不可见，否则可见。
    
如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本，如果最后一个版本也不可见的话，那么就意味着该条记录对该事务不可见，查询结果就不包含该记录。

在`MySQL`中，`READ COMMITTED`和`REPEATABLE READ`隔离级别的的一个非常大的区别就是它们生成`ReadView`的时机不同，我们来看一下。

>事务执行过程中，只有在第一次真正修改记录时（比如使用INSERT、DELETE、UPDATE语句），才会被分配一个单独的事务id，这个事务id是递增的。


**MVCC总结**
从上边的描述中我们可以看出来，所谓的MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用`READ COMMITTD`、`REPEATABLE READ`这两种隔离级别的事务在执行普通的`SEELCT`操作时访问记录的版本链的过程，这样子可以使不同事务的`读-写`、`写-读`操作并发执行，从而提升系统性能。`READ COMMITTD`、`REPEATABLE READ`这两个隔离级别的一个很大不同就是生成`ReadView`的时机不同，`READ COMMITTD`在每一次进行普通`SELECT`操作前都会生成一个`ReadView`，而`REPEATABLE READ`只在第一次进行普通`SELECT`操作前生成一个`ReadView`，之后的查询操作都重复这个`ReadView`就好了。


## 两阶段提交

### 双一配置
通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog


每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。




更新记录前，首先要记录相应的undo日志
MySQL的undo日志是要写到一种专门存储undo日志的页面中的。如果一个事务写入的undo日志非常多，需要占用多个Undo页面，那这些页面会被串联成一个链表，称作`Undo页面链表`。

`trx_undo_page_report_modify`函数用于真正的向Undo页面中写入undo日志。另外，由于我们这里是在修改页面，一个事务执行过程中凡是修改页面的地方，都需要记录相应的redo日志，所以在这个函数的末尾，有一个记录修改这个Undo页面的redo日志的函数

有同学在这里肯定会疑惑：是先将undo日志写入Undo页面，然后再记录修改该页面对应的redo日志吗？

先说答案：是的。

不过这里修改后的页面并没有加入buffer pool的flush链表，记录的redo日志也没有加入到redo log buffer。当这个函数执行完后，才会：

- 先将这个过程产生的redo日志写入到redo log buffer。
- 再将这个过程修改的页面加入到buffer pool的flush链表中。

>设计MySQL的大叔把对底层页面的一次原子修改称作一个Mini Trasaction，即MTR。一个MTR中包含若干条redo日志，在崩溃恢复时，要么全部恢复该MTR对应的redo日志，要么全部不恢复。

也就是说实际上虽然先修改Undo页面，后写redo日志，但是此时InnoDB并不认为Undo页面是脏页，就不会将其刷新到硬盘，redo日志也没有写入到redo log buffer，这些redo日志也不会被刷新到redo日志文件。只有当MTR提交时，才先将redo日志复制到redo log buffer，再将修改的Undo页面加入到flush链表。

所以我们可以粗略的认为**修改Undo页面的redo日志是先写的，而修改页面的过程是后发生的**。
>有后台线程不断的将redo log buffer中的redo日志刷新到硬盘的redo日志文件，也有后台线程不断的将buffer pool里的脏页（只有加入到flush链表后的页面才能算作是脏页）刷新到硬盘中的表空间中。设计InnoDB的大叔规定，在刷新一个脏页到硬盘时，该脏页对应的redo日志应该被先刷新到redo日志文件。而redo日志是顺序刷新的，也就是说，在刷新redo log buffer的某条redo日志时，在它之前的redo日志也都应该被刷新到redo日志文件。


修改页面内容
首先更新系统字段trx_id以及roll_pointer，然后真正的修改记录内容，然后记录更新的redo日志，像Undo页面写入undo日志一样，InnoDB规定更新一个页面中的一条记录也属于一个MTR。在该MTR提交时，也是先将MTR中的redo日志复制到redo log buffer，然后再将修改的页面加入到flush链表。

所以我们也可以认为在这个过程中，**先记录修改页面的redo日志，然后再真正的修改页面**。

至此，一条聚簇索引记录就更新完毕了。


更新二级索引记录
更新二级索引记录时不会再记录undo日志，但由于是在修改页面内容，会先记录相应的redo日志。


记录binlog

在一条更新语句执行完成后（也就是将所有待更新记录都更新完了），就需要该语句对应的binlog日志了：
不过值得注意的是，此时记录的binlog日志并不会被写到binlog日志文件中，而是被暂时保存到内存的某个地方，等之后事务提交的时候才会真正将该事物执行过程中产生的所有binlog统一写入binlog日志文件。


提交事务的时候

内部XA

**总结**

本篇文章唠叨了执行一条UPDATE语句过程中都发生了什么事情。当优化器分析出成本最小的执行计划后，就开始对执行计划中的各个扫描扫描区间中的记录进行更新。具体更新一条记录的流程如下：

1. 先在B+树中定位到该记录（这个过程也被称作加锁读），如果该记录所在的页面不在buffer pool里，先将其加载到buffer pool里再读取。
2. 读取到记录后判断记录更新前后是否一样，一样的话就跳过该记录，否则进行后续步骤。
3. 首先更新聚簇索引记录。更新聚簇索引记录时：①先向Undo页面写undo日志。不过由于这是在更改页面，所以修改Undo页面前需要先记录一下相应的redo日志。②真正的更新记录。不过在真正更新记录前也需要记录相应的redo日志。
4. 更新其他的二级索引记录。

至此，一条记录就更新完了。

然后开始记录该语句对应的binlog日志，此时记录的binlog并没有刷新到硬盘上的binlog日志文件，在事务提交时才会统一将该事务运行过程中的所有binlog日志刷新到硬盘。

剩下的就是所谓的`两阶段提交`的事情了，我们下节再会～


**内部XA**

对于一台服务器来说，即使客户端使用`BEGIN/START TRANSACTION`语句开启的普通事务，该事务所包含的语句也有可能涉及多个存储引擎。此时MySQL内部采用XA规范来保证所有支持事务的存储引擎要么全部提交，要么全部回滚，这也被称作MySQL的`内部XA`。

另外有一点值得注意的是，`内部XA`除了解决这种设计多个存储引擎的事务之外，还解决保证binlog和存储引擎所做的修改是一致的问题。我们稍后重点展开一下这个问题。

在MySQL内部执行一个事务时，存储引擎会修改相应的数据，server层会记录语句对应的binlog。这是两个要么都完成，要么都不完成的事情。否则的话：

•如果存储引擎修改了相应数据并且提交了事务，而server层却未写入binlog。在有主从复制的场景中，意味着这个事务不会在从库中得以执行，从而造成主从之间的数据不一致。

•如果server层写入了binlog，但存储引擎却回滚了事务。在有主从复制的场景中，意味着这个事务会在从库中得以执行，从而造成主从之间的数据不一致。

那我们需要保证：**如果存储引擎提交了事务，server层的binlog日志必须也被写入到硬盘上；如果存储引擎回滚了事务，server层的binlog日志必须不能被写入到硬盘上**。

MySQL采用`内部XA`来实现上述内容，下边以Innodb存储引擎为例，具体讨论一下Innodb事务的提交和binlog日志写入的过程。

当客户端执行`COMMIT`语句或者在自动提交的情况下，MySQL内部开启一个XA事务，分两阶段来完成XA事务的提交：

•**Prepare阶段：存储引擎将该事务执行过程中产生的redo日志刷盘，并且将本事务的状态设置为`PREPARE`。binlog啥也不干。**

这个函数做了很多事情，我们得好好唠叨一下。

首先我们知道事务执行过程中需要写undo日志，这些undo日志被写到若干个页面中，这些页面也被称作`Undo页面`，这些页面会串成一个链表，称作`Undo页面`链表。在一个事务对应的Undo页面链表的首个页面中，记录了一些关于这个事务的一些属性，我们贴个图看一下：

![[Pasted image 20220306161816.png]]


其中的`TRX_UNDO_STATE`字段就表明该事务目前处于什么状态。当处于Prepare阶段时，调用`innobase_xa_prepare`函数会将`TRX_UNDO_STATE`字段的值设置为`TRX_UNDO_PREPARED`（整数5），表明当前事务处在Prepare阶段。

我们再看一下`Undo Log Header`部分：
![[Pasted image 20220306161829.png]]


这个部分体现着这个`Undo页面链表`所属的事务的各种信息，包括事务id。其中两个属性和我们今天主题特别搭：
![[Pasted image 20220306161750.png]]
- `TRX_UNDO_XID_EXISTS`：表示有没有xid信息。
- `XID信息`：表示具体的xid是什么。

当处于Prepare阶段时，调用`innobase_xa_prepare`函数会将`TRX_UNDO_XID_EXISTS`设置为TRUE，并将本次内部XA事务的`xid`（这个xid是MySQL自己生成的）写入`XID信息`处。


> 再一次强调，修改Undo页面也是在修改页面，事务凡是修改页面就需要先记录相应的redo日志。

记录了关于该事务的各种属性之后，接下来该将到现在为止所产生的所有redo日志进行刷盘

在将redo日志刷盘之后，即使之后系统崩溃，在重启恢复的时候也可以将处于Prepare状态的事务完全恢复。

- **Commit阶段：先将事务执行过程中产生的binlog刷新到硬盘，再执行存储引擎的提交工作。**

`innobase_commit`函数做了很多事情，我们挑一些重要的来说。

首先是更新`Undo页面链表`的状态，将我们上边说的`Undo Log Segment Header`部分的STATE字段更新一下。更新规则如下：

也就是说如果当前事务产生的undo日志比较少，那么就继续让别的事务复用该`Undo页面链表`，将STATE设置为`TRX_UNDO_CACHED`；如果`Undo页面链表`用于存储INSERT操作产生的undo日志，那么就将STATE设置为`TRX_UNDO_TO_FREE`，稍后会释放`Undo页面链表`占用的页面；如果`Undo页面链表`用于存储其他操作产生的undo日志，那么就将STATE设置为`TRX_UNDO_TO_PURGE`，等待purge线程后台回收该`Undo页面链表`。

>UPDATE、DELETE操作产生的undo日志可能会用于其他事务的MVCC操作，所以不能立即删除。


对于存储UPDATE、DELETE操作产生的undo日志的`Undo页面链表`，还要将其加入所谓的History链表，关于这个History链表是啥，我们这里就不展开了。

每个`Undo页面链表`的首个页面的页号会被存储在表空间的某个地方，以便崩溃恢复的时候可以根据该页来进行恢复。如果此时在事务提交时，`Undo页面链表`的状态被设置为`TRX_UNDO_CACHED`，那存储`Undo页面链表`的首个页面的页号的地方也就不需要做改动；如果此时在事务提交时，`Undo页面链表`的状态被设置为`TRX_UNDO_CACHED`，那存储`Undo页面链表`的首个页面的页号的地方就得被设置为空，这样这个地方就可以被其他事务使用了。

至此，这个事务就算是提交完了。


**崩溃恢复**
每当系统重启时，都会先进入恢复过程。

此时首先按照已经刷新到磁盘的redo日志修改页面，把系统恢复到崩溃前的状态。

然后在表空间中找一下各个`Undo页面链表`的首个页面的页号，然后就可以读取该页面的各种信息。我们再把这个页面的内容给大家看一下：
![[Pasted image 20220306162134.png]]

通过这个页面，我们可以知道该`Undo页面链表`对应的事务状态是什么：

- 如果是`TRX_UNDO_ACTIVE`状态，也就是活跃状态，直接按照undo日志里记载的内容将其回滚就好了。
- 如果是`TRX_UNDO_PREPARE`状态，那么是提交还是回滚就取决于binlog的状态了，我们稍后再说。
- 如果是其他状态，就将该事务提交即可。

对于处于PREPARE状态的事务，存储引擎既可以提交，也可以回滚，这取决于目前该事务对应的binlog是否已经写入硬盘。这时就会读取最后一个binlog日志文件，从日志文件中找一下有没有该PREPARE事务对应的xid记录，如果有的话，就将该事务提交，否则就回滚好了。


![[Pasted image 20220329002655.png]]

MySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后
这么一来，binlog 也可以组提交了。在执行图 5 中第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。


## 索引

索引就是书签，有了索引可以对内容进行快速定位，实现**加速读**。  
如果把一张表看作一个内容线性表，没有索引的表可能就是一个普通的链表结构，我们只能从头读到尾，而具备索引结构，它就可以看作一个跳表结构，可以支持部分随机读取的行为。  
具体的谈论索引，我们必须具体到某一种实现。

索引具有以下优点：  
【1】提高查询速度、表连接速度  
【2】避免额外的内存或临时文件排序，减少排序和分组的时间  
【3】唯一索引保证每一行数据的唯一性

维护索引的数据结构，也需要付出以下代价：  
【1】维护、创建、**页合并**、**页分裂**等操作耗时  
【2】创建索引时，需要**对表进行加锁**，可能会其他事务的影响正常操作（锁其实就是基于索引实现的）  
【3】索引缓存和各种索引文件需要额外占用内存和磁盘资源（需要有额外的文件和内存去存放索引）  
【4】修改数据时会触发索引的维护，降低性能


### 索引的几种实现

索引本质上就是一种数据结构，它支持快速查找

【1】有序数组  
查询效率很高，因为**有序数组结构适合通过二分查找算法**，但是插入删除可能会造成整体拷贝，因此更加适合**静态存储引擎**或者**只读的数据类型存储**。例如：历史记录，用户可以通过日期快速从有序数组中找到历史记录。  
【2】哈希表  
哈希表的效率一定程度上依赖哈希函数（桶映射函数）和解决哈希冲突的方案。  
输入待查找的值作为key，通过对key进行哈希计算得到一个桶的索引，一般通过链表法解决哈希冲突，因此**查询效率高，增删效率也高**。  
但是由于元素在桶内的分布是无序的，因此做区间查询的时候很慢，仅适合做**等值查询**的场景，如nosql的redis数据库。  
**哈希表实现索引的限制**：  
a.只能包含哈希值和行指针，无法存储字段值或数据行，因此**无法避免回表**  
b.不支持部分索引匹配查找，因为hash索引始终使用索引列的全部内容计算hash值的，**不能更好的利用联合索引**

> 如果索引使用哈希表实现，则一个索引对应一颗哈希表。默认会对主键建立一个索引（哈希表）。假如对name字段建立索引，则磁盘上至少存在两个索引文件。Where name = ‘123’，首先查询name索引文件，通过hash(‘123’)得到键值对的存放位置，得到‘123’-主键id，然后再查询一次主键索引哈希表得到最终的记录。

c.hash索引不是按照索引值顺序存储的，**天生无序**。  
d.仅支持等值查询  
e.存在哈希冲突问题

innoDB会在系统自动生成**自适应索引**，由于哈希表是离散存储的，因此无法排序，也不支持最左前缀索引，而且存储哈希冲突的问题，不支持范围查询。

【3】平衡二叉树/红黑树

> 搜索二叉树、平衡二叉树和红黑树都是二叉树，其中平衡二叉树解决了搜索二叉树“在一定情况下会退化成单向链表”的问题，而平衡二叉树的约束过多且实现复杂，红黑树可以看作平衡二叉树的一种“弱平衡性”的一种实现方案。

平衡二叉树的查询速度是log2(N)，每次查找都是一次二分，但是每一层分叉过少的代价就是树的高度过高，每一层查找都是一次磁盘I/O，**平衡二叉树的查询成本随着树高升高而增加**，因此平衡二叉树不适合作为数据库的索引结构。

> 每次查找都会将索引页面读入内存，然后确定下一个需要读入的索引页面，因为页面本身也是有序的，因此在内存中的查找是很快的（可以基于二分查找算法），而这时的瓶颈就在于它是二叉还是二十叉了，而是在于I/O导致的时间开销，因为每读入一次节点都至少需要一次I/O，而一层中不管几个节点都是对应一次I/O，**树高过高导致I/O次数上升才是正在的瓶颈**，因此**二叉树更多用于内存结果对象的查找，比如在内存中维护一个treeMap作为作为内存索引结构**。

【4】B树/B+树（多叉平衡树）  
B树是专门为磁盘设备设计的平衡查找树，它相对于二叉平衡树有了更适合磁盘I/O的特点，如：**树的节点可以存放多个元素**，这样树的高度就得到了压缩，查询某个节点可以进行更少的I/O次数。B树的节点单位通常与磁盘的存储单位是对应的，**数据库设计者通常利用磁盘预读原理，将一个节点的大小设计等于一个页的大小，这样每个节点只需要一次I/O便可以完全载入**，因此每次读入内存的其实是一个数据块或索引块。  
另一方面，B数节点中的元素数据行都是有序的，这就**降低了排序成本，将随机I/O转换为了顺序I/O**，避免为排序分配临时内存或临时中间文件。



### B树和B+树

一颗M叉的B树是一颗平衡的M路搜索树，**所有叶子节点都在同一层，每个节点中即存放key值又存放指针**。  
而B+树是B树的变种，**B+树的叶子节点用于保存key值的信息，而所有的非叶子节点都可以看作是搜索目标叶子节点的索引部分**。  
B+树的所有叶子节点都新增了**链表指针**，这使得所有数据在B+数叶子节点中按照key排序。

**B树通过压缩高度虽然解决了“磁盘IO次数较多的问题”，但是未能解决遍历查找效率低下的问题**

B+树索引每次加载出的都是一个页，页中包含多个数据行。根据索引字段可以定位数据行所在的数据页，将数据页加载进入内存。在内存值通过对索引的key值进行二分查找可以取出对应数据行。  
B+树非叶子节点可以看作索引节点，不存储数据行，所有数据行存在于叶子节点。这使得**B+树搜索可以更加稳定**（因此连接查询时总是将小表做主表），**每个叶子节点可以存储的元素更多**，查询所需的IO次数也会更少，一个数据页可以包含更多的数据行。

**B+树更适合进行范围查找**，因为遍历一个范围的元素，只需要遍历叶子节点。而B树的不同页面之间不连续，如果要进行范围扫描，B+树以链表的形式扫描[聚簇索引](https://so.csdn.net/so/search?q=%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95&spm=1001.2101.3001.7020)叶子节点进行优化，而**B树需要同时在多个节点之间切换**，因为B树节点内部的数据行虽然是有序的，但是从节点之间看，则是不连续的。

而**B树更加适合等值查找**，因为B树的key不像B+树全部存储在叶子节点，因此如果对B树查询某个key，很可能在某个距离根很近的位置就能找到，而最坏的情况才是在根结点找到。另一方，B树不适合大范围的搜索，如果仅仅是小范围的搜索并不影响性能，如果需要大范围遍历，顺序I/O将退化为随机I/O（不断回旋查找），从而导致I/O次数上升，性能下降。**B+树含有数据行的节点都是根结点，有序且相连，直接对叶子节点遍历即可，查找较稳定，遍历元素效率高**

B+树的非叶子节点会冗余一份在叶子节点中（所有的非叶子节点key都保存一份key/value到叶子节点），并且叶子节点之间使用指针相连。B树一个叶子节点可以存储多个元素，相当于完全平衡二叉树整体的树高降低了，磁盘IO效率提升了。而**B+树只是通过叶子节点冗余非叶子节点，提升了范围查找的效率，B+树同时也具有B树的一切优点**。

> 树的路数也不是无限延伸的， 如果树的路数无限延伸则会**退化成一个有序数组**，如果数据量过大**无法一次性载入内存，会进行多次IO**，效率会下降。**因为树高下降，索引的粒度（叉数）就会变大，节点装入的内容变多，会多于一页**，这样读入一个页面可能需要至少两次I/O

总结：  
B+数的单一节点存放更多数据，IO效率高。由于每次都是从叶子节点载入页面，查找更稳定。天然有序，便于范围查询和排序。  
B树比较适合单值查询，因为如果所在页靠近根结点，那么可以很快锁定目标页。


### mysql innoDB的索引

mysql具有许多需要遍历元素的场景：范围查询、全表查询、关联子查询等，因此B+树是更合适的，而B树更适合于单条记录的查询。innoDB使用B+树索引模型，所以数据都是存储在B+树中的，每一个索引在innoDB中对应一颗B+树。索引文件和数据文件存放在表空间中，而且mysql为每一个索引分配两个段去存放叶子节点和非叶子节点。



### 索引创建

索引可以分为三类：  
【1】单值索引：一个索引只包含单个列，一个表可以有多个单列索引  
【2】唯一索引：索引列的值必须唯一，但允许有空值  
【3】复合索引:即一个索引包含多个列

创建表的时候创建索引：

```
create table testTable(  
    id int not null,   
    username varchar(16) not null,  
    index [indexName] (username(length))  -- 为字符类型创建索引可以指定前缀
); 

    
```

创建表之后创建索引：（index前面可以加上unique前缀表示唯一索引，否则默认普通索引）

```
CREATE INDEX idx_ceo_deptnam ON dept(ceo,deptname)
CREATE INDEX idx_deptnam ON dept(deptname)
CREATE INDEX idx_deptid ON emp(deptid)

    
```

**CREATE INDEX** 索引名称 **ON** 表名（字段名）  
（mysql会默认对主键创建一个索引——主键索引）

展示索引：**SHOW INDEX FROM** 表名  
删除索引：**DROP INDEX** 索引名 **ON** 表名

### 存储结构

innoDB存储引擎中，表都是根据**主键顺序**进行存放的，这种存储方式的表称为索引组织表。  
如果创建一张表的时候没有显示指定主键，则使用**非空的唯一索引**作为主键（如果有多个，则寻找定义索引顺序的第一个非空唯一索引），若不存在则innoDB存储引擎自动创建一个指针结构作为隐式主键。

所有数据都存放在表空间中，表空间由各个段组成，其中数据段存储B+树的叶子节点，索引段存储B+树的非叶子节点。段由若干个区组成，区由连续的页组成，区的对象固定为1MB，默认情况下，innoDB存储引擎页的大小为16KB（一个区中一共有64个连续的页面）。而页面则是innoDB磁盘管理的最小单位，页中的数据按行存放。  
数据库每次读取的就是页中存放的行记录。

### （ 非）聚簇索引和辅助索引

**主键索引**的叶子节点存的是**key所在的数据行**。在InnoDB里，主键索引也被称为**聚簇索引**  
**非主键索引**的叶子节点内容是**主键的值**。在InnoDB里，非主键索引也被称为**辅助索引**  
而搜索辅助索引的B+树，最终拿到的也只是一个主键的ID值罢了，必须再一次通过这个主键id搜索聚簇索引对应的B+树，拿到最终的页面载入内存，因此其实搜索了两次B+树，这种行为就叫做**回表**。


MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址
MyISAM引擎使用B+Tree作为索引结构，叶节点的**data域存放的是数据记录的地址**
非聚簇索引：主键索引和辅助索引存储都是存储一个指向真正表数据的地址，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。


### InnoDB和MyISAM的数据分布对比

MyISAM的数据分布：按照**数据插入顺序**存储在磁盘上（数据和索引分开存储，通常内存缓存索引数据，而数据由操作系统/文件系统（磁盘）缓存，因此访问数据需要一次系统调用），**叶子节点存储的是“行号”**，这种分布方式很容易创建索引，**且二级索引和主键索引的存储方式相同**

InnoDB的数据分布：聚簇索引的每一个叶子节点都包含了**主键值**，**事务ID**，用于事务和MVCC的**回滚指针**以及所有剩余**数据列**，二级索引和聚簇索引很不同，叶子节点存储的是主键值，这种策略**减少了当出现行移动或者数据页分裂时二级索引的维护工作**。

### 索引优化

#### explain

使用**explain关键字**可以模拟优化器执行SQL查询语句，从而知道mysql如何处理你的sql语句。分析你的查询语句或者表结构的性能瓶颈  
这里只重点强调两个字段：type 和 extra

##### type

访问类型，显示了当前查询使用了何种类型——mysql决定如何查找表中的行。  
以下性能依次下降：  
【1】System：**表只有一行记录**（等于系统表），这是const类型的特例，平时不出现，可以忽略不计  
【2】Const：表示**通过索引一次就找到了**。Const用于搜索主键或者唯一索引。因为只匹配一行数据，所以很快。（将主键置于where列表中，mysql就可以将该查询转换为一个常量）  
【3】Eq_ref：唯一性索引扫描，对于每个索引值，**表中只有一条记录与之匹配**。常见于主键或唯一索引扫描。  
【4】ref：非唯一性索引扫描**，返回匹配某个单独值的所有行**。本质上也是一种索引访问，它返回所有匹配某个单独值的行。但是它可能会找到多个符合条件的行，所有应该属于查找和扫描的混合体。（使用非唯一索引，或者唯一索引的非唯一性前缀）

> **唯一索引**打印的type值是const。表示通过索引一次就可以找到。即找到值就结束扫描返回查询结果。  
> **普通索引**打印的type值是ref。表示非唯一性索引扫描。**找到值还要继续扫描**，直到将索引文件扫描完为止。

【5】range：**只检索给定范围的行**，使用一个索引来选择行。Key列显示使用了哪个索引，一般就是在你的where语句中出现了between、<、>、in等的查询。这种范围扫描比全表扫描好。因为它只需要**开始于索引的某一点，结束于另外一点，返回匹配这个值域的行**，不用扫描全部索引  
【6】index：full index scan 、index与all区别为**index类型只遍历索引树**。这通常比all快，因为索引文件通常比数据文件小。（虽然all和index都是读全表，但是index是从索引中读取，而all是从硬盘中读）

> 实验：Index(a,b,c)，并且where c = 1（不符合最左前缀），如果查询a/b/c/id某一个或多个最终为index，如果查询的是d（没有索引）或者*则为all （因为顺序查询，能够通过优化确定什么时候可以结束）

【7】all：遍历整个表，全表扫描，mysql从头到尾，扫描所有的行，寻找目标行

> index中，mysql扫描表时按照索引次序而不是行。主要优点是避免了排序，最大的缺点是要承担按索引次序读取整个表的开销，如果按随机访问顺序访问行（随机访问回表），开销将会非常大，优化器会斟酌损失去选择index还是all

##### key

**实际使用的索引**。如果为null，则没有使用索引。查询中如果使用了覆盖索引，则该索引和查询的select字段重叠。通过该值可以判断是否存在索引用错或失效的情况。  
可以使用关键字**force index**强制优化器选择某个索引

```
SELECT * 
FROM my_table force index(orderid)
WHERE orderid > 100 AND orderid < 200

    
```

另一种非强制的提示性的关键字是 use index

##### extra

extra包含不适合在其他列显示，但十分重要的额外信息  
【1】using filesort：说明mysql会对数据使用一个额外的排序，而不是按照表内的顺序进行读取。Mysql中无法利用索引完成的排序操作称之为文件排序。有可能是一个基于内存的排序，也可能是一个基于临时文件的排序。  
【2】using temporary：**使用了临时表保存中间结果**，mysql在对查询结果排序时使用了临时表。常见于order by和group by （**分组之前必排序**）  
【3】using index，表明相应的select操作使用了**覆盖索引**，避免访问了回表操作。  
如果同时出现using where，表示使用了覆盖索引，但是where中存在类似a=1 and c=1的情况，因此对结果又进行了一次筛选。**如果没有using index说明存在回表**  
【4】using join [buffer](https://so.csdn.net/so/search?q=buffer&spm=1001.2101.3001.7020)：使用了连接缓存  
【5】using where：数据集被过滤过（mysql服务器将在存储引擎检索行后再进行过滤，并不是所有待where子句的查询都会显示。往往是一种暗示：查询可受益于不同的索引）  
【6】impossible where：where子句的值总是false，不能用来获取任何元组

### 索引覆盖

Select的数据列只用从**辅助索引的叶子节点**中就可以取得**，不必通过回表再次读取数据行**，mysql可以利用索引返回select列表中的字段，而不用再次读取数据文件——**查询的列要被所建的索引覆盖**  
使用非主键索引可以查出主键的值，那么如果将主键作为查询内容，就不用回表了，因为待查询的数据在辅助索引的叶子节点就能拿到，没必要再进行回表操作。

扫描索引本身虽然很快，但是如果索引如果不能覆盖查询的所有列，则不得不每扫描一条记录就进行一次回表，这些都属于随机IO，这种情况下，按照索引顺序读取数据可能比全表扫描要慢，这时优化器可能放弃走索引而选择全表扫描。

*_总之尽量使用覆盖索引（只访问索引的查询——索引列和查询列一致），减少select _的查询__

### 最左前缀

创建一个联合索引的时候如（name,age,sex），逻辑上其实创建了三个索引（name）、（name,age）和（name,age,sex）。联合索引的最左N个字段，也可以是字符串索引的最左N个字符。因为B+树对数据行的存储依照（name,age,sex）三个关键字进行排序（先按照name排序，name相同按照age，age相同按照sex）。

> b+树按照**从左到右的顺序建立B树**，当遇见（小明，18，F）的时候，树将优先比较name，然后确定下一步的搜索方向。如果遇见（小明，F），则b+树只能根据name搜索，下一个字段age丢失（这个时候相当于先走name找出了一部分按照name有序的数据行对应主键id，然后回表查出id对应的数据行，然后再进行sex的过滤）

**列的排列顺序，决定了可命中的索引列数**  
最左前缀原则**帮助用户更好的设计联合索引**，通过**复用联合索引减少创建单独索引的开销**

### 索引下沉

索引下推可以在索引遍历过程中对**索引中包含的字段**先进行判断，过滤到不满足的条件，**减少回表的次数**

> 以上面（小明，F）为例，上面没有使用索引下推优化，则先通过小明找到一堆id，然后回表。而使用了索引下沉，会先对这些id过滤掉sex不为F的部分id，然后将剩下的id进行回表，回表的id数量减少了。

注意：参与索引下沉的过滤项，一定要是**索引中的字段**。

### 关联查询优化

LEFT JOIN 条件用于确定如何从右表搜索行,左边一定都有,所以**右边是关键点,一定需要建立索引**，相当于是一个双循环，外循环遍历所有行，而对于外循环的每一行，如果不进行任何优化则是O（n）复杂度，而如果建立索引则可以优化到O（logm(n)）。

【1】能够直接多表关联的，**尽量直接关联，不使用子查询**  
【2】尽量减少join语句中的循环总次数，不用join过多或嵌套，永远使用小结果集驱动大结果集【内循环使用B+索引查询，很稳定，因此决定于外循环，外循环结果集越小越好】

**当B表的数据集必须小于A表数据集时，in 优于exists**  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F6eab2f77691743a4854c73e431e49c47.png)被驱动表 in (驱动表)  
**当A表的数据集必须小于B表数据集时，exists优于in**  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F120006eb05bd4c648953e8c878b34822.png)驱动表 exists （被驱动表）

> Exists——将主查询的数据，放入子查询中做条件验证，根据返回值（true或false）来决定主查询的数据结果是否得以保留

**被驱动表需要在相应字段建立索引**

```
SELECT * from student
where student.SId in 
(SELECT sc.sid from sc)

    
```

效果上等价于

```
SELECT * from student
where EXISTS (SELECT 1 from sc WHERE sc.sid=student.sid)

    
```

内连接时，mysql优化器会自动帮你把小结果集选为驱动表，因为驱动表无论如何都会被全表扫描，所以扫描次数越少越好。  
子查询生成的子表尽量作为驱动表，因为如果作为被驱动表可能不能被选择索引

### 分组与排序优化

Order by满足两种情况时，会基于索引方式排序：  
【1】order by语句使用索引的最左前列  
【2】**使用where子句与order by子句条件列组合满足索引最左前列**  
尽可能在索引列上完成排序操作，遵循索引键的最佳左前缀

使用索引的排序，不需要开辟额外排序内存或者临时文件，通过索引依次按照顺序扫描一组主键id，然后通过回表取出数据行并拼装结果集（如果select的内容直接可以从叶子节点拿到，那直接走覆盖索引，可以避免回表）。

注意：order by时，select * 是一个大忌

**Group by 使用索引的原则几乎和order by一致，唯一区别是group by即使没有过滤条件使用索引，也可以直接使用索引**

> 当范围条件和group by或者order by的字段出现二选一的时候，优先观察条件字段的过滤数量，如果过滤数量足够多，而需要排序的数据并不多的时候，优先把索引放在范围字段上。

**Group by实质是先排序后分组**，按照索引建的最佳左前缀。Where优先于having，能写在where限定的条件就不要去having限定了

### limit优化

Limit语法由偏移量offset和取值数量size组成，其中偏移量默认从0开始，其中limit 10000，10代表从第10001条数据开始取，取size个。注意这里是扫描到10001条数据后，开始往后拿数据，而前面这些数据都被抛弃了，因此offset特别大的时候，效率非常低

```
Select * from Student limit 1000,10

    
```

可以被改造为：

```
Select * from Student 
Join (Select id  from Student limit 1000,10 ) as stu
On student.id = stu.id

    
```

子查询id是主键，本身就是一个索引结构，因此外部进行关联时能够很快取出对应的数据行。内部查询是id，其效率高于*，相当于内部查询到10个id，然后外部通过id拿到对应数据行。

### 索引失效分析和解决方案

#### 范围过大

【1】使用不等号!=或<>、not in 、is not null 的时候优化器使用全表扫描  
【2】like 以通配符开头如(’%a’)，可以使用**覆盖索引**解决。  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F6184dabe3ad148088c480869c97ce0e1.png)使用覆盖索引的情况：  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fb3e551a28455480d9183340d2ea7979c.png)【3】使用or进行连接

#### 隐式转型

【1】在索引列一则执行计算等操作，如计算、函数、类型转换。例如 where a+1=3  
【2】字符串不加单引号导致索引失效（例如：name=张三 会导致失效）  
【3】隐式编码格式转换也会导致失效，应该使两个表的字符集相同

> 如果对索引字段做函数操作，可能破坏索引值的有序性，这种情况下，优化器放弃走索引树的搜索，而是全索引表扫描（只是放弃了通过非叶子节点定位，而是直接遍历叶子节点）。同理where id + 1 =99不可以 where id =99-1可以

### 其他

【1】搜索引擎不能使用索引中**范围条件右边的列**。  
【2】错误使用最左前缀法则。  
【3】**如果对主键进行删除或者重建，会导致整个表的重建**

> 例如index(a,b,c),where b=3 不可以。where a=3 and c=5 使用了a，但是c不可以（找到aXX节点对应的id叶子节点）（因为抛开a，单独看b或者c，它们并不是全局有序的，不能作为扫描使用的标志，仅能用作一些过滤和优化）  
> where a=3 and b>2 and c=5 使用了a b,但是c不能用在范围之后。（找到abX节点对应的所有id叶子节点）

注意，如果where的内容是四个const。建立的索引如index（a,b,c,d）,查询顺序为d,c,b,a或者a,b,d,c。Mysql的查询优化器会最终调整为a,b,c,d的形式后再进行查询

### 索引的选择

#### change buffer
>[(59条消息) 写缓冲(change buffer)，这次彻底懂了！！！_58沈剑的博客-CSDN博客](https://blog.csdn.net/shenjian58/article/details/93691224)

参数：innodb_change_buffer_max_size

介绍：配置写缓冲的大小，占整个缓冲池的比例，默认值是25%，最大值是50%。

画外音：写多读少的业务，才需要调大这个值，读多写少的业务，25%其实也多了。

参数：innodb_change_buffering

介绍：配置哪些写操作启用写缓冲，可以设置成all/none/inserts/deletes等。





change buffer指的是对“写操作”的缓存，推迟更新的行为。  
需要同时满足两个添加：辅助索引 和 非唯一索引

如果**非唯一普通索引页**不在缓冲池（内存）中，则对页进行写操作时，不会先去加载磁盘，而是**直接将修改操作记录在changeBuffer上**，等到未来数据页被读取时，再将数据合并恢复到缓冲池中。  
后台线程也会时不时地进行合并操作，正常退出mysql时也会合并，其他如重写日志不可用、内存中的changeBuffer超过缓冲池1/2  
**事务提交的时候，changeBuffer的操作已经记录到redo log中了，因此崩溃恢复时可以找回**

changeBuffer适合于==“写多读少”==的场景，如果读操作很频繁，那么写缓存就没有意义了，反而是记录与合并的操作显得很多余。

changeBuffer和数据页一样，是物理页的一个组成部分，**底层是一颗B+树**，负责**对索引表的辅助索引的更新操作进行缓存**，存放于共享表空间。changeBuffer在内存中有缓存，同时也可以持久化到磁盘中。  
changeBuffer在内存的部分占用了缓冲池的内存，默认最大可用占用缓冲池的1/2.

changeBuffer的目的是**降低对磁盘的随机读次数**（更新时不用将页面读入内存，而是更新处于内存中的change buffer结构），磁盘IO是数据库操作中成本最高的一部分，同时数据页不用调入缓冲池，节省了内存空间。而**数据页缓存则是减少了随机写磁盘的IO次数**（每次写内存中的页面，而不是直接写磁盘中的页面，直到redo log失效、后台线程同步等时间发生才会将脏页面更新磁盘）。

如果要修改的字段是唯一索引或者主键，还需要加载数据页，**判断是否违反唯一性约束**，从而导致changeBuffer没有了意义。

总结：  
**读多写少**的场景适合定义**唯一索引**，如果使用普通索引进行等值搜索，搜索到第一个记录后不会停止，因为可能有值重复的记录，会继续搜索直到碰到不相等的记录才会退出。而唯一索引字段在遇到第一个满足条件的记录后，就会自动停止检索。  
由于引擎一次读出一页，因此对于普通索引，引擎需要多做一次指针寻址和判断，如果第一个记录在数据页的最后一条记录，还必须读取下一个数据页。

**写多读少**适合定义**普通（非唯一）索引**，因为普通非唯一索引字段的修改会在写缓存中进行（如果页面不再内存的前提下），不需要频繁的加载页面

普通索引和唯一索引在查询方面区别不大，但是**更新唯一索引字段更加消耗性能**，因此建议使用普通索引。

Redo log主要节省的是随机写磁盘的IO消耗（将随机写入脏页的行为，记录在redo log日志文件中，某一时间点将redo log同步到磁盘，只要redo log成功同步，就不担心脏页更新丢失），而changebuffer主要节省的是随机读磁盘的IO消耗。

#### 索引与约束

约束是一种逻辑上的概念，用于保证数据的完整性，它更像是一种检查机制。而索引是一个数据结构，在数据库中通常有对应的物理存储，而且它具体的功能如加速读取。

#### 自增

> MYLSAM 引擎的自增长值保存在数据文件中  
> innoDB 5.7之前,自增长值保存在内存中，mysql 8将自增长值的变更保存在redo log中，重启时依靠redo log恢复重启之前的值。

插入新数据而进行平衡调整可能会引起**页分裂**（数据页满了，申请新的数据页，移动部分数据），这个过程不但影响性能，还会降低页的利用率。删除操作可能会引发**页合并**。  
**自增主键的插入模式符合递增插入的场景**，不涉及平衡的调整，不会触发叶子节点分裂。同时，**主键长度越小**，**普通索引的叶子节点越小**，普通索引所**占用的空间也就越小**。

> 修改时机：前提是字段被声明为**auto_increment**  
> 【1】插入数据时id没有指定或者被指定为0或者null  
> 【2】使用了具体值X，就使用指定的值。如果要插入的值小于自增值，则表的自增值不变，否则自增计时器的值被更新为X+1。  
> 新的自增值生成算法：从auto_increment_offset开始，以auto_increment_increment为步长，持续叠加，直到找到第一个大于插入值X的值，作为新的自增值。

**唯一键冲突（插入失败）**和**事务回滚**都会导致**自增主键id不连续**，另一个不连续的原因是由于**mysql对批量插入语句分配自增id策略**导致的。

> 如果自增主键用完了，再尝试插入新的数据就会导致主键冲突报错（根据自增主键类型不同，范围也不同）

### 索引设计原则

【1】主键自动建立唯一索引  
【2】**频繁作为查询条件的字段**应该建立索引  
【3】**被驱动表关联的字段**，**外键关系建立索引**  
【4】频繁更新的字段不适合建立索引（因为每次更新不仅仅更新数据还要更新索引）  
【5】Where条件中用不到的字段不创建索引  
【6】高并发下倾向创建联合索引  
【7】查询中**排序的字段**，若通过索引去访问排序字段将大大提高排序速度  
【8】查询中统计或者**分组字段**  
【9】**写多读少**的字段，如果要键索引则应该建立**普通非唯一索引**

不适合建立索引的情况：  
【1】表记录太少（少于一千）  
【2】经常增删改的表  
【3】数据重复且分布平均的表字段（例如性别，如果一个表中男女各半，则每次根据性别查询都需要回表查出50%的数据，性能远不如全表扫描）

维护索引不但需要在磁盘上维护索引文件，还需要在内存中维护存放索引页的内存区。另一方面，B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。不免涉及到数据的移动和数据页的增加和删减。  
一个数据页满了，按照B+Tree算法需要新增加一个数据页进行数据分散，需要进行**页分裂**，会导致性能下降。空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做数据**页合并**，合并的过程是分裂过程的逆过程

### 补充：数据库设计三大范式

【1】数据项不可再分，**每个字段都应该是原子的、不可分割的**。  
【2】满足第一范式，其他数据项完全依赖主键，也就是说**一张表内只做一件事**，演员表中所有的信息应该指向演员，电影表中所有信息就应该指向电影，（**如将电影信息表拆分为电影表和分类表**）。  
【3】满足第二范式，非主键字段不传递依赖于主键，也不部分依赖于主键，**每一列的数据和主键直接相关，不可以间接相关**（相当于不允许出现冗余数据，例如电影表中增加一列票房统计字段，而这个字段通过观众表与电影表间接相关，但是有时候确实需要这样的字段）

> 阿里开发手册要求关联查询的表不可以超过三张表（基于成本和用户体验的考量），**规范越多，性能越低**  
> **有时会故意增加冗余字段和计算列来提升性能**


## 事务与锁

### 理解事务

事务保证了数据库将从一种一致性状态转移到另一种一致性状态，事务一般对于一组操作，这组操作的执行是原子的，要么全部完成要么全部失败，而且一旦提交必然能够保证对数据库永久性的改变，即使数据库发生故障也可以恢复数据。而且事务之间应该是独立。  
事务具体体现在ACID四个特性。

### 四个特性及innoDB的实现

【1】atomic原子性：一个事务中的所有操作都是一个不可分割的工作单元，要么全部成功，要么全部失败。这个工作单元中的任何一个操作失败，所有已经执行的操作都应该被撤销。  
【2】consistency一致性：事务开始前和结束后，数据库的完整性不被破坏。事务将数据库从一个一致性转变为下一种一致性状态，因**此事务是一致性的单位**。  
【3】isolation隔离性：事务提交前对其他事务不可见，一个事务的执行不受到其他事务的影响。  
【4】durability持久性：事务一旦提交，就是永久性的改变，即使系统故障也可以恢复，持久性保证事务系统的高可靠性。

#### 原子性

原子性是基于 **undo log** 和 **锁** 实现的。锁本质上就是数据行上的一个变量，如果其他事务发现当前此记录被上锁便不能继续对其上锁（这里指互斥锁），同时如果执行事务的过程中出现所谓，便可以通过undo log回滚到事务开始之前的**一致性状态**。

#### 持久性

持久性记录redo log实现。一旦事务提交，便会刷新重做日志，重做日志记录的就是对页面的具体操作，即使脏页还没有刷新到表空间而发生宕机，恢复时可以直接读取redo log进行恢复，默认情况下，事务提交时会调用fsync()将redo log buffer中的内容同步到磁盘。  
redo log写入时脏页并没有同步到磁盘，但是redo log记录了对哪些页执行什么操作，因此即使内存中的脏页数据丢失就可以恢复（除非页本身收到损坏）

> Redo log用于崩溃恢复。而binlog用于基于时间点的恢复，还可以用于主从复制

#### 隔离性

隔离性侧重研究不同事务之间的互相影响（干扰的程度）。通常使用**锁**机制保证两个**写事务**之间的隔离性，通过**MVCC**机制保证**读写**事务之间的隔离性。

#### 一致性

一致性指的是事务执行结束后，**数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态**。  
一致性是事务追求的最终目标，前面的三个性质都是为了保证数据库状态的一致性、同时还需要应用层的保证。

事务本质上是**为了服务应用层**而产生的。AID是手段，而C是目的。一致性就是应用系统借助AID从一个正确的状态到达另一个正确的状态。AID是数据库的特征，而C依赖于应用层、开发者。而正确的状态就是**满足预定的约束的状态**。

### 事务的开启与提交

mysql命令行的默认设置下，事务都是自动提交的（执行完SQL语句之后就会执行commit）。

【1】禁用当前会话的自动提交（1代表自动提交，0代表手动提交）

```
SET @@autocommit = 0;

    
```

【2】通过**start transaction** 或 **begin** 开始一个事务  
还可以通过savepoint设置一个保存点，当发起回滚的时候仅仅回滚到保存点，而保存点之前的工作不受影响。

```
SET autocommit=0;
START TRANSACTION;
DELETE FROM account WHERE id=25;
SAVEPOINT a; -- 设置保存点
DELETE FROM account WHERE id=28;
ROLLBACK TO a;  -- 回滚到保存点

    
```

> 在自动提交模式下，如果没有start transaction显示地开启一个事务，那么没有sql语句会被当做一个事务执行提交操作。而auto commit是针对连接的，修改某个连接不会影响其他连接。

权限管理语句、mysql架构修改语句、DDL语句（alter、drop、create、truncate等）会执行一个隐式的commit操作。格外注意：truncate table和delete虽然可以达到同样的效果，但是前者是不可以被回滚的。

innoDB存储引擎中可以查询关于事务的统计信息（只有显示提交的事务才会被统计）

```
show global status like 'com_commit'
show global status like 'com_rollback'

    
```

每秒事务请求数question per second (QPS) = com_commit + com_rollback  
每秒事务处理能力transaction per second（TPS）= QPS / time

### 锁

数据库的锁都是基于**索引**实现的，如果SQL命中索引，锁住的是命中条件内的索引节点（行锁），否则锁定的是整个索引树（表锁）

> innoDB行锁是通过给索引上的索引项加锁实现的，因此只有当通过索引条件检索数据时innoDB才使用行级锁，否则使用表锁。

### 锁的类型

从对**数据结构的操作类型**分类  
**读锁(共享锁)** 针对同一份数据，多个读操作可以同时进行而不会互相影响。  
**写锁(排它锁)** 当前写操作没有完成前，它会阻断其他写锁和读锁。

从**粒度**分类：表锁和行锁  
MySQL常用的两种引擎MyISAM和InnoDB，MyISAM默认使用表锁，InnoDB默认使用行锁。  
注意：使用InnoDB引擎，如果筛选条件里面没有索引字段，就会锁住整张表，否则的话，锁住相应的行

> Mysql行锁由引擎层实现，mylsam不支持行锁。  
> Mysql也支持lock tables和unlock tables语句，这时服务器层实现的，和存储引擎无关  
> 意向锁是innoDB自己加的，如果要对某个元组加锁，那么需要对上层节点加意向锁。

innoDB采用的是**两阶段锁定协议**。在事务执行的过程中，**随时都可以执行锁定，锁只有在执行commit或者rollback的时候才会释放**，并且所有的锁都是在同一时刻被释放的。**innoDB会根据隔离级别在需要的时候为被事务访问的数据自动加上隐式锁**。

意向锁  
innoDB支持**多粒度锁定**，运行事务在行级和表级的锁同时存在。意向锁将锁定的对象分为多个层次，意向锁表明事务希望在更细粒度上进行上锁。  
假设事务A对某一行加入写锁，事务B希望对该表加入加锁。事务表加锁之前必须对表中的每一行进行遍历，这样效率很低。而**有了意向锁，A加行锁之前，先申请意向锁，申请成功后再申请一行的行锁。而如果事务B希望加表锁，它发现该表存在意向锁，那么申请锁的行为就会被阻塞。**  
**申请意向锁的行为由数据库完成，当事务申请某一行的行锁的时候，数据库会自动该表的意向锁。**

### 隔离级别

【1】读未提交：一个事务还没提交，它做的变更能被别的事务看见  
【2】读已提交：一个事务提交之后，它做的变更才可以被看见  
【3】可重复读：一个事务执行过程中看到的数据，总是跟这个事务启动时看到的数据一致。  
【4】串行化：访问一个记录会加读写锁，出现冲突时，后访问的事务必须等前一个事务执行完成才能继续执行


注意：**隔离性是事务之间的特性，同一个事务update后跟select，select查到的更新到的数据，因为二者是同一事务，不存在隔离性，而其他事务的select可能差不到**

mysql的默认隔离级别是可重复读RR，而oracle的默认隔离级别是读已提交RC。其中隔离级别越高越符合数据库隔离性的规范，但是并发性能会下降。（隔离级别越低，事务请求的锁锁越少、保持锁的时间越短）。

标准的SQL下，会存在脏读、不可重复读、幻读三种问题。其中串行化可以完全避免这些问题，可重复读具有幻读问题，读已提交具有不可重复读、幻读问题，读未提交则有以上所以问题。  
但是mysql通过next-key lock避免的幻读问题（指全程当前读）。

### 为什么mysql使用可重复读作为默认隔离级别？
[MySQL为什么选择可重复读作为默认的隔离级别？ | 打工这件小事 (lilu.org.cn)](https://lilu.org.cn/2020/07/12/database/mysql/why-does-mysql-choose-repeatable-read-as-the-default-isolation-level/)
这是具有历史原因的，mysql 的binlog在statement格式下，会出现**主从不一致**的情况。如果修改为row格式才会解决这个问题（但是mysql5.1才引入row格式）  
binlog记录的顺序可能与实际的顺序不一样，导致主从数据库数据不一致。  
第一个事务先执行，未结束时执行第二条事务，第二条事务先结束执行，第一个事务后结束执行。执行顺序是1-2，但是记录顺序是2-1。（如果从服务器重放这个命令，那么相当于第二条事务先开启事务并执行，然后才是第一个事务再执行）

### 隔离级别选择和死锁

除非在特殊的业务场景，要求一定的一致性，否则推荐**读已提交**。  
因为RR通过间隙锁进行实现隔离级别，使得出现死锁几率更大（共享锁粒度过大，两个事务，拿到共享锁插入时导致死锁）。RR下如果条件列未命中索引会锁住整张表，而RC下只锁住待修改的目标行。而且RC一致性弱于RR，并发量更高

做一个实验：  
开启两个事务，首先二者全部是拿着共享锁去读，然后让其中两个事务升级为互斥锁去读。这个时候**两个事务分别等待对方释放共享锁，并且尝试获取互斥锁，因此发生死锁**。  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F8648196027ac4474939e7adbf5e9f1d4.png%3Fx-oss-process%3Dimage%2Fwatermark%2Ctype_ZHJvaWRzYW5zZmFsbGJhY2s%2Cshadow_50%2Ctext_Q1NETiBA4p2A56We6Iqx4p2A%2Csize_20%2Ccolor_FFFFFF%2Ct_70%2Cg_se%2Cx_16)**其中一个事务，因为死锁会回滚，另一个事务则因为被回滚的事务放弃竞争锁而成功返回**

Mysql有两种处理死锁：**【1】等待，直到超时【2】发起死锁检测（锁等待图）。**主动回滚一条事务（需要开启innoDB_deadlock_detect=on）

**死锁检测原理**：  
构建一个**以事务为顶点、锁为边的有向图**，判断这个图**是否存在环**。  
检测到死锁之后，选择其中**插入更新或者删除行数最少（回滚开销更小）的事务**进行回滚。通过命令show engine innodb status 查看死锁原因

### innoDB死锁的避免

【1】将事务中需要申请的锁，一次性申请完毕。可以使用select … for update一次性为增删改操作的需要使用的锁一次性申请完毕。  
【2】避免使用长事务，将大事务拆分为小事务，每个事务都应该是“短小精悍”的。  
【3】尽量使用（在视图一致性要求不严格，看重性能）RC级别。因为可重复读的next-key lock的粒度更大，容易造成死锁。  
【4】**设置锁的超时时间——innoDB_lock_wait_timeout。**  
【5】尽量使用主键更新，锁定程度可以退化为行锁，粒度更小。而且避免回表，提升性能。  
【6】多个程序尽量约定以相同的顺序访问表，例如事务统一先修改字段A再修改字段B，如果事务1先修改A或修改B，而事务2先修改B再修改A就可能造成死锁。

## 锁问题

### 脏读

脏读就是读到了其他事务没有提交的数据，读未提交的隔离级别下具有该问题。

### 不可重复读

不可重复读：由于其他事务的更新操作导致，某一个事务对一个字段执行了两次读，但是读出的值不一样，是由于读的中间该字段被某一个事务修改了——读到了另外一个事务更新的数据。特指一个事务读到另外事务中提交的update数据（对已存在数据操作导致）

### 幻读

幻读：由于其他事务插入新记录而当前事务不可感知导致，当前事务第一读发现表只有一条记录，于是预插入一条id为2的记录，但是插入时却发现id冲突，第一次读好像出现了幻觉。（由于是可重复读的问题之一，出错最好通过更新操作体现）特指一个事务读到另外事务中提交的insert数据（对不存在数据进行操作导致）

解决不可重复读的思路，就是将每次满足添加的语句加锁，这样别的事务就不能操作where = target。而幻读不能使用该思路，因为**幻读不存在“当前行”**，next-key lock的思路就是**限制对范围的访问**（别的事务向往范围插入或更新都会被阻塞），这样就不能插入到某一个范围了。  
行锁只能锁住行，但是无法锁住范围，next-key lock只有在可重复读隔离级别下才会生效。

## 快照读（一致性非锁定读）

innoDB存储引擎通过多版本并发控制MVCC的方式读取当前执行时间数据库中行的数据。快照读避免了读写事务之间的冲突。

某一个读事务请求读取数据库中的行数据，如果读取的行正在执行修改操作（被别的事务上了互斥锁），则读事务不会被阻塞。而是读取行的快照数据。快照数据就是当前行数据的历史版本，每行记录可能有多个历史版本，对于多版本的并发控制就是**MVCC多版本并发控制**。

> MVCC是并发控制的一种理念，维持一个数据行的多个版本，主要用于更好的解决读写冲突（通过维护多个版本，每个版本都可以被不同的事务读，通过事务id标识，每修改一个版本就生成一个新版本），可以提高数据库并发性能。是一种**解决读写冲突（非阻塞并发读）的无锁机制**

快照读是默认的读取方式，不会占用和等待表上的锁，不同隔离级别下，读取的方式是不一样的。快照就是当前行的历史版本记录，每行的记录可能有多个版本。

在读已提交下，非锁定一致读总是读取被锁定行的最新快照数据。因为每**次快照读都会生成一份最新的读视图**。  
而可重复读下，总是读取事务开始时的行快照数据。**同一个事务中的第一个快照读才会创建读视图**，之后的快照读获取的都是同一个读视图。

> begin或者start transaction。他们不是一个事务的起点，执行到他们之后的第一个操作innoDB的语句，事务才真正启动，一致性视图是在执行第一个快照读语句时创建的start transaction with consistent snapshot命令：**马上启动一个事务，一致性视图是在执行这条命令时创建的**。

其中读已提交，当前事务可以看见**其他事务提交的最新数据**。而可重复读保证了**事务启动执行期间看到的数据必须是前后一致的**。而串行化使得事务完全同步执行了（串行化不存在快照读，总是在读之前对数据行加共享锁）。

Mysql中，每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚日志可以得到前一个状态的值。

有了并发读写控制，可以实现读的时候不阻塞写，写的时候不阻塞读。MVCC可以提升数据库并发读写性能，同时可以解决脏读、幻读、不可重复读问题。但是不可以解决写写造成的更新丢失问题（属于写写冲突问题，必须加锁）——**MVCC可以用于读写冲突，加锁可以解决写写冲突**

## 当前读（一致性锁定读）

加锁读、insert、update、delete（增删改本身具有查询的语义）都属于当前读，读取的是记录的最新版本，同时还要保证其他并发事务不可以修改当前记录，**会对读取的记录进行加锁（悲观锁的体现）**  
默认下的select采用快照读，前提是隔离级别不是串行化的。快照读的实现基于MVCC，属于**非阻塞读，体现了乐观锁**

innoDB支持两种一致性锁定读（当前读）：  
【1】select…for update  
对行记录加一个**排他锁**，其他事务不能对已锁定行加任何锁  
【2】select…lock in share mode  
对行记录加一个**共享锁**，其他事务只能对被锁定行加共享锁

补充：  
innoDB通过两种方式**避免死锁**：  
【1】超时时间设置。一旦事件超过阈值（innoDB_lock_wait_timeout）则会进行回滚。  
【2】等待图wait-for-graph主动检查死锁。一旦发现等待图发生回路，则回滚undo量最小的事务。

## 乐观锁

为数据增加一个**版本标识字段version**可以实现乐观锁。  
**读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一**。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，**如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据**。

```
update goods set store=store-1,version=version+1 
where id=xx and version=orginal_version

    
```

乐观锁机制避免了长事务中的数据库加锁开销（两个用户操作过程中，都没有对数据  
库数据加锁），大大提升了大并发量下的系统整体性能表现。

> mybatis-plus提供了乐观锁支持，可以自动为实体生成乐观锁版本，并且自动进行对比

悲观锁则是使用数据库提供的锁机制，交给数据库实现。

## 锁的算法

innoDB有三种行锁的算法：  
【1】record lock 记录锁，锁住某条记录  
【2】gap lock 间隙锁，锁住某个范围，但是不包含记录本身。可以看作开区间( )  
【3】next-key lock ，它的效果等同于间隙锁加上记录锁。锁住一个范围，包含行本身，可以看作左闭右开的区间[ )

> 例如存在一个索引，她在数据行中有三个值 1 3 5 ,那么可以分为三个范围(无穷,1]、(1,3]，(3,5]、(5，无穷]，某一事务执行where a = 5 lock in share mode ，此时就为表加入间隙锁，其他事务不能向间隙插入数据，这防止了写事务-写事务、或当前读事务-写事务的幻读问题发生。  
> （上面的数据行基于非唯一索引，因为唯一索引上的锁将退化为行锁。如果一个SQL加锁涉及多个列，那么需要组合讨论）

（默认情况下，可重复读隔离级别）  
【1】当where的条件**不是索引字段**的话（索引未命中），innoDB会为整张表上锁，然后放到server层，在server过滤掉不符合条件的数据后，在进行解锁。  
【2】当where的条件是**普通索引字段**的时候会使用gap lock或者next-key lock。

> 一般是next-key lock，不够在某些情况会退化为gap lock。例如现在有个字段age建立的普通索引，数据 10 17 20 ，现在我要查询where age = 18 ，由于向右搜索不到记录，因此退化为间隙锁，锁住(17,20)。（相当于通过优化，降低了锁的粒度，仅保存两次where age = 18 不会存在幻读问题即可）

【3】当where的条件是**主键索引字段**时，锁策略降级为行锁。（因为主键索引必须是唯一的，因此不会有一个相同值的主键字段被插入，不存在幻读问题）

加锁原则：**访问到的对象才会被加锁**  
优化：如果是索引上的等值连接，给唯一索引加锁的时候，退化为行锁。向右遍历时且最后一个不满足等值条件的时候，退化为间隙锁。（如果使用范围查询，不论是什么索引类型，都会加next-key lock）

总结：  
可重复读下，当前读采用next-key lock实现语义，而快照读采用MVCC（同一快照视图）实现语义。读已提交中，当前读则采用记录锁 record lock 实现语义，快照读采用MVCC（多个快照视图）实现语义。

> 简单总结一下**什么时候加next-key lock**：首先innoDB在可重复读的隔离级别下，非唯一索引的等值查询（且where的条件需要命中记录，否则退化为间隙锁），或者是范围查询，一直加到不满足条件的第一条记录为止。

**优化建议**：  
　　【1】尽可能让所有数据检索都通过**索引**来完成，**避免无索引行锁升级为表锁**。  
　　【2】尽可能**减少检索条件**，避免间隙锁  
　　【3】尽量控制事务大小，减少锁定资源量和时间长度  
　　【4】锁住某行后，尽量不要去调别的行或表，赶紧处理被锁住的行然后释放掉锁。  
　　【5】涉及相同表的事务，对于调用表的顺序尽量保持一致。  
　　【6】在业务环境允许的情况下,尽可能低级别事务隔离

## 多版本并发控制MVCC

MVCC是一种解决读写冲突的无锁并发控制机制

每一个启动的事务都会被分配一个**递增的事务ID**，每个记录行都有一些隐含字段：创建了该行的事务ID、最近修改了该行的事务的ID、回滚指针、删除标志。

每当某个事务需要更新某个字段时，需要先对该行加排他锁，然后将旧版本记录拷贝到undo log中，修改记录的同时，将行的隐藏字段更新为当前事务的ID，并更新回滚指针（链表结构）。事务提交后释放锁。不同事务或者相同事务对同一记录的修改，会使得该记录形成一条**关于版本的链表，链头指向最新记录，链尾指向最近的版本**。  
（注意，可重复读下，如果并发量很大，事务为了搜寻某个版本的数据可能要遍历链表很长时间）

当一个事务进行快照读的时候，innoDB为该事务提供一个**事务ID数组（版本号数组）**，其中对应的事务都是数组创建时，**开启事务但是没有提交事务的事务ID（活跃事务ID）**，这个数组就是一个逻辑上的**读视图**。  
这个数组中的最大的事务ID和最小的事务ID可以可以划分为三个区间，**(负无穷,min)对应已提交事务**、**[min,max]对应未提交事务**,**(max,正无穷)对应未开始事务** 。每当事务拿到一个行记录首先判断它的事务ID，然后和事务ID数组（读视图）进行比较，如果落在低水位区间、等于当前事务的ID以及在中间数组范围内但不存在，那么说明该行记录对当前事务是可见的，否则说明不可见，此时事务顺着回滚指针向前遍历，继续执行以上的判断，直到找到一个可见的版本为止。

> 低于低水位数组，一定是提交过了，如果是事务自己的版本也是一定可见的，还有一种情况，数据行上的事务id属于[min,max]的范围，但是数组中找不到这个ID，这种情况也是可见的，因为**如果能在数组中找到对应的ID一定是不可见的**，而如果范围在[min,max]但是没有对应ID，说明这个**事务创建晚于min**，但是在**当前事务生成视图之前已经完成了提交**，因此可见。

每行数据都有多个版本，每当被某一个事务更新，就会生成一个新的版本，并使用事务id进行标记。**通过回滚日志和当前版本可以计算出任何一个旧版本**。  
为了防止更新丢失，**更新操作必须基于最新版本**，而读操作可以读取旧版本（可重复读可以读旧版本，但是读已提交读的是提交的新版本，读到的一定是已经提交过的数据，否则就成脏读了）

> 更新数据的时候不能在旧版本上进行，否则会造成写写冲突，从而引发其他写事务的更新丢弃。而且更新涉及两阶段锁协议，如果其他事务没有释放排他锁，那么当前写事务阻塞。

**可重复读在事务开始后，第一次执行select前创建readView，直到事务提交之前都不再创建。而读已提交每次select之前都会重新产生一个readView。**

> MVCC只在repeatable read和read committed两个隔离级别下工作。其他两个隔离级别和MVCC不兼容。因为READ UNCOMMITTED 总是读取最新的数据行，而不是符合当前事务版本的数据行。而SERIALIZABLE 则会对所有读取的行都加（共享）锁

MVCC的缺点就是要求每行记录包含更多的用于支持MVCC的字段，一些undo log为了支持MVCC也不能立即被回收，总体上增加了维护的开销。

## 可重复读下，能够避免幻读吗？

对应这个问题，应该分类讨论：  
【1】其中一个事务全程快照读，两次读的中间另一个事务视图插入一行记录  
【2】其中一个事务全程当前读，两次读的中间另一个事务视图插入一行记录  
【3】其中一个事务先快照读再当前读，两次读的中间另一个事务视图插入一行记录

（先当前读再快照读同两次当前读，因为当前读的时候已经获取到锁了，第二次读旧不会发生冲突了）

现在假设一个场景，有两个事务A和B，一张表，里面有一个普通索引子弹num，num此时有1,2,3,4 共五条数据。A先执行一个读操作（where num<=2），然后B事务尝试插入一条num=0的记录（提交事务），这时A再次读取（where num<=2），会发生什么？

## 全程当前读

如果A是当前读，那么会为表加上间隙锁，B执行事务时会阻塞。当A两次读完毕后提交事务，B才会返回，最终插入成功。而且A的两次读都是一致的内容。  
因此：全程当前读，基于next-key lock保证可重复读的隔离级别。

## 全程快照读

如果A的两次都是快照读，都会在同一个一致性视图进行读数据，和B的插入操作互不干涉（B的插入操作最终会创建一个新的版本，而对旧版本不干涉）。  
因此：全程快照读，基于MVCC机制保证可重复读的隔离级别。

## 先快照读，再当前读

A事务

```
start TRANSACTION

select num
from nums where num<2

select num
from nums where num<2
for UPDATE

COMMIT

    
```

B事务

```
insert into nums VALUE(-2);

    
```

A第一次读到的数据和第二次读到的数据并不相同，因此**先快照再当前读并不能避免幻读发生**。因为快照读中，读的是旧版本而再次当前读则相当于退化为了读已提交状态。

### 间隙锁不能解决幻读问题，不要再误导人了

看了不少的博客，前后矛盾，我先单独谈一谈这个问题

间隙锁锁住的是间隙，如果我有一个字段age建立的普通索引10 15 17 20 ，那么我进行一个当前读加上的都是一些列开区间锁，其中幻读问题强调的是插入。这时10 15 17 20等行都是没有加锁的，如果我插入10 、15等，我再进行一次当前读将会读出一些新的记录。  
而next-key lock 是间隙锁和行锁的组合，是左开右必的区间如(25,17] 、(17,20] ，是能够在当前读的时候锁住区间以及值的，可以避免幻读（这里仅指两次当前读）。

个人理解：mysql的读已提交在当前读这块是使用行锁保证的，可以避免脏读，但是存在不可重复读和幻读问题。mysql的可重复读采用next-key lock保证（在行锁继承上锁住间隙），可以避免脏读、不可重复读以及幻读（全程当前读层面）

间隙锁应该不是单独作为一个锁去使用的，如果单独作为一个锁去实现，一个事务对一个数据行进行修改时没有行锁加持，那岂不是脏读都不能避免？

### next-key lock锁定范围个人总结

next-key lock只在可重复读隔离级别下使用。为主键字段（具有唯一属性的索引字段）加锁时，如果命中则退化为行锁，否则会在主键值所在间隙加gap lock（例如数据库中只有1和3，但是申请对2的锁，那么使用(1,3)的范围锁，防止2的插入）。范围查询的时候会加多个next-key lock。（如果是普通索引加锁，首先仍会对主键进行加锁）

next-key lock说白了，就是范围锁+行锁。（next-key指的就是范围的右区间是一个闭区间，对应一个行锁）。行锁可以用来阻塞对“数据行”的锁请求，范围锁用于“阻止多个事务将记录插入到同一范围”  
**当向右遍历到最后一个不满足等值条件（强调：等值）的时候，next-key lock会退化为间隙锁**。  
![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fc5e8cdefb8784fb5aa8614dfd74e5645.png%3Fx-oss-process%3Dimage%2Fwatermark%2Ctype_ZHJvaWRzYW5zZmFsbGJhY2s%2Cshadow_50%2Ctext_Q1NETiBA4p2A56We6Iqx4p2A%2Csize_20%2Ccolor_FFFFFF%2Ct_70%2Cg_se%2Cx_16)上图中，（数据库中是5 10 15 20）其中c>=10 是等值条件而c<11不算等值条件，因此最终加锁(5,10]和(10,15]

如果一个SQL涉及多个字段，例如a是主键，b是辅助索引等，我们需要依次讨论每个字段需要如何申请锁。（锁是基于索引实现的，一个字段可能属于多个索引，因此一个SQL的阻塞可能有多种锁定的原因）

![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fimg-blog.csdnimg.cn%2F49574b122784416380b9610b939b7430.png)其中a是主键索引，b是普通索引。我们只关注索引b的情况。  
现在A事务执行SQL SELECT * from z where b = 3 for UPDATE;它的加锁范围是什么？  
经过实验，加锁范围: 1 2 3 4 5 。其中0 6 7 8 … 的插入都是不被阻塞的。这里的实验结果还是有些出入的，目前博主也没有想到最优的解释。暂时的个人理解：行锁可以防止update，而insert具有“先查询再插入”的语义，因此需要对“前一个间隙”加间隙锁，而后一个加间隙进行加锁可能是由于实现的问题（bug？）。（至于为什么前一个间隙的左边界也被上锁，这个有待讨论）



## 生产经验

#### MySQL数据库机器配置
通常来说，根据我们的经验值而言，Java应用系统部署的时候常选用的机器配置大致是2核4G和4核8G的较多一些，数据库部 署的时候常选用的机器配置最低在8核16G以上，正常在16核32G 
那么以我们大量的高并发线上系统的生产经验观察下来而言，一般Java应用系统部署在4核8G的机器上，每秒钟抗下500左右 的并发访问量，差不多是比较合适的，当然这个也不一定。因为你得考虑一下，假设你每个请求花费1s可以处理完，那么你一 台机器每秒也许只可以处理100个请求，但是如果你每个请求只要花费100ms就可以处理完，那么你一台机器每秒也许就可以 处理几百个请求。 
所以一台机器能抗下每秒多少请求，往往是跟你每个请求处理耗费多长时间是关联的，但是大体上来说，根据我们大量的经验 观察而言，4核8G的机器部署普通的Java应用系统，每秒大致就是抗下几百的并发访问，从每秒一两百请求到每秒七八百请 求，都是有可能的，关键是看你每个请求处理需要耗费多长时间

高并发场景下，数据库应该用什么样的机器？ 对于数据库而言，我们刚才也说过了，通常推荐的数据库至少是选用8核16G以的机器，甚至是16核32G的机器更加合适一 些。
因为大家要考虑一个问题，对于我们的Java应用系统，主要耗费时间的是Java系统和数据库之间的网络通信。对Java系统自己 而言，如果你仅仅只是系统内部运行一些普通的业务逻辑，纯粹在自己内存中完成一些业务逻辑，这个性能是极高极高的。 
对于你Java系统接收到的每个请求，耗时最多的还是发送网络请求到数据库上去，等待数据库执行一些SQL语句，返回结果给 你。 
所以其实我们常说你有一个Java系统压力很大，负载很高，但是其实你要明白一点，你这个Java系统其实主要的压力和复杂都 是集中在你依赖的那个MySQL数据库上的！ 
因为你执行大量的增删改查的SQL语句的时候，MySQL数据库需要对内存和磁盘文件进行大量的IO操作，所以数据库往往是 负载最高的

#### 性能测试
当你手头有一个可以使用的数据库之后，你觉得就可以直接基于他开发Java系统了吗？
并不是这样的！这么做在一个互联网公司里往往会显得比较的业余，因为你首先得先对这个数据库进行一个较为基本的基准压 测。 
也就是说，你得基于一些工具模拟一个系统每秒发出1000个请求到数据库上去，观察一下他的CPU负载、磁盘IO负载、网络 IO负载、内存复杂，然后数据库能否每秒处理掉这1000个请求，还是每秒只能处理500个请求？这个过程，就是压测。 
你不光用工具每秒发送1000个请求，还可以模拟每秒发送2000个请求，甚至3000个请求，逐步的测试出来，这个数据库在目 前的机器配置之下，他大致的一个负载压力如何，性能表现如何，每秒最多可以抗多少请求。 
可能有的人会提出疑问了，他会说：老师，为什么刚开始就要对数据库搞一个基准压测？你完全可以等Java系统都开发完毕 了，然后直接让Java系统连接上MySQL数据库，然后直接对Java系统进行压测啊！
如果有人提出这个问题，那就有所不知了，数据库的压测和他上面的Java系统的压测，其实是两回事儿，首先你得知道你的数 据库最大能抗多大压力，然后你再去看你的Java系统能抗多大压力。 
**因为有一种可能是，你的数据库每秒可以抗下2000个请求，但是你的Java系统每秒只能抗下500个请求，这也是有可能的**。所 以你不能光是针对Java系统去进行压测，在那之前也得先对数据库进行压测，心里得有个数。


傻傻分不清楚：**QPS和TPS到底有什么区别？** 
既然要压测了，那么肯定得先明白一点，我们压测数据库，最终是想看看这个数据库在现有的机器配置之下，每秒可以抗下多 少个请求呢？这个每秒抗下多少个请求，其实是有专业术语的，分别是QPS和TPS。 就**QPS而言，他的英文全称是：Query Per Second。 其实就是英文字面意思已经很明确了，QPS就是说，你的这个数据库每秒可以处理多少个请求，你大致可以理解为，一次请求 就是一条SQL语句，也就是说这个数据库每秒可以处理多少个SQL语句。 对于QPS而言，其实你的一些Java系统或者中间件系统在进行压测的时候，也可以使用这个指标，也就是说，你的Java系统每 秒可以处理多少个请求**。 然后另外一个术语是**TPS，他的英文全称是：Transaction Per Second。其实就是每秒可处理的事务量，这个TPS往往是用在 数据库中较多一些，其实从字面意思就能看的出来，他就是说数据库每秒会处理多少次事务提交或者回滚**。 因为大家应该都对数据库有一个基本的了解，就是他的事务到底是什么？


IO相关的压测性能指标 接着再给大家讲几个压测的时候要关注的IO相关的性能指标，大家也要对他做一个了解： 
（1）IOPS：这个指的是机器的随机IO并发处理的能力，比如机器可以达到200 IOPS，意思就是说每秒可以执行200个随机 IO读写请求。 这个指标是很关键的，因为之前我们在数据库架构原理中讲解过，你在内存中更新的脏数据库，最后都会由后台IO线程在不确 定的时间，刷回到磁盘里去，这就是随机IO的过程。如果说IOPS指标太低了，那么会导致你内存里的脏数据刷回磁盘的效率 就会不高。 
（2）吞吐量：这个指的是机器的磁盘存储每秒可以读写多少字节的数据量 这个指标也是很关键的，因为大家通过之前的学习都知道，我们平时在执行各种SQL语句的时候，提交事务的时候，其实都是 大量的会写redo log之类的日志的，这些日志都会直接写磁盘文件。 所以一台机器他的存储每秒可以读写多少字节的数据量，就决定了他每秒可以把多少redo log之类的日志写入到磁盘里去。一 般来说我们写redo log之类的日志，都是对磁盘文件进行顺序写入的，也就是一行接着一行的写，不会说进行随机的读写，那 么一般普通磁盘的顺序写入的吞吐量每秒都可以达到200MB左右。 所以通常而言，机器的磁盘吞吐量都是足够承载高并发请求的。 
（3）latency：这个指标说的是往磁盘里写入一条数据的延迟。

这个指标同样很重要，因为我们执行SQL语句和提交事务的时候，都需要顺序写redo log磁盘文件，所以此时你写一条日志到 磁盘文件里去，到底是延迟1ms，还是延迟100us，这就对你的数据库的SQL语句执行性能是有影响的。 一般来说，当然是你的磁盘读写延迟越低，那么你的数据库性能就越高，你执行每个SQL语句和事务的时候速度就会越快。

压测的时候要关注的其他性能指标 ：
除了上面说的QPS、TPS、IOPS、吞吐量、latency这些指标之外，在压测的时候还需要关注机器的其他一些性能指标。 
（1）CPU负载：CPU负载是一个很重要的性能指标，因为假设你数据库压测到了每秒处理3000请求了，可能其他的性能指标 都还正常，但是此时CPU负载特别高，那么也说明你的数据库不能继续往下压测更高的QPS了，否则CPU是吃不消的。
（2）网络负载：这个主要是要看看你的机器带宽情况下，在压测到一定的QPS和TPS的时候，每秒钟机器的网卡会输入多少 MB数据，会输出多少MB数据，因为有可能你的网络带宽最多每秒传输100MB的数据，那么可能你的QPS到1000的时候，网 卡就打满了，已经每秒传输100MB的数据了，此时即使其他指标都还算正常，但是你也不能继续压测下去了 
（3）内存负载：这个就是看看在压测到一定情况下的时候，你的机器内存耗费了多少，如果说机器内存耗费过高了，说明也 不能继续压测下去了


##### 压测
先给大家介绍一个非常好用的数据库压测工具，就是sysbench，这个工具可以自动帮你在数据库里构造出来大量的数据，你 想要多少数据，他就自动给你构造出来多少条数据。 然后这个工具接着可以模拟几千个线程并发的访问你的数据库，模拟使用各种各样的SQL语句来访问你的数据库，包括模拟出 来各种事务提交到你的数据库里去，甚至可以模拟出几十万的TPS去压测你的数据库。

在linux上安装sysbench工具 首先你需要有一台linux机器，如果你只有一个windows笔记本电脑，可以在里面装一个linux的虚拟机，然后你可以用如下的 命令设置一下yum repo仓库，接着基于yum来安装sysbench就可以了，安装完成以后验证一下是否成功。
curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash 
sudo yum -y install sysbench 
sysbench --version
如果上面可以看到sysbench的版本号，就说明安装成功了。

**数据库压测的测试用例**
接着我们需要在自己的数据库里创建好一个测试库，我们可以取个名字叫做test_db，同时创建好对应的测试账号，可以叫做 test_user，密码也是test_user，让这个用户有权限可以访问test_db。 
然后我们将要基于sysbench构建20个测试表，每个表里有100万条数据，接着使用10个并发线程去对这个数据库发起访问， 连续访问5分钟，也就是300秒，然后对其进行压力测试。

**基于sysbench构造测试表和测试数据**
sbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=127.0.0.1 --mysqlport=3306 --mysql-user=test_user --mysql-password=test_user --mysql-db=test_db --tables=20 -- table_size=1000000 oltp_read_write --db-ps-mode=disable prepare

上面我们构造了一个sysbench命令，给他加入了很多的参数，现在我们来 解释一下这些参数，相信很多参数大家自己看到也 就大致明白什么意思了： 

--db-driver=mysql：这个很简单，就是说他基于mysql的驱动去连接mysql数据库，你要是oracle，或者sqlserver，那 自然就是其他的数据库的驱动了 

--time=300：这个就是说连续访问300秒

--threads=10：这个就是说用10个线程模拟并发访问 
--report-interval=1：这个就是说每隔1秒输出一下压测情况 
--mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=test_user --mysql-password=test_user：这一大串，就 是说连接到哪台机器的哪个端口上的MySQL库，他的用户名和密码是什么 
--mysql-db=test_db --tables=20 --table_size=1000000：这一串的意思，就是说在test_db这个库里，构造20个测试 表，每个测试表里构造100万条测试数据，测试表的名字会是类似于sbtest1，sbtest2这个样子的 
oltp_read_write：这个就是说，执行oltp数据库的读写测试 
--db-ps-mode=disable：这个就是禁止ps模式

最后有一个prepare，意思是参照这个命令的设置去构造出来我们需要的数据库里的数据，他会自动创建20个测试表，每个表 里创建100万条测试数据，所以这个工具是非常的方便的。


### Buffer Pool大小
buffer pool设置你的机器内存的50%~60%左右

buffer pool总大小=(chunk大小 * buffer pool数量)的2倍数

接着确定了buffer pool的总大小之后，就得考虑一下设置多少个buffer pool，以及chunk的大小了 此时要记住，有一个很关键的公式就是：buffer pool总大小=(chunk大小 * buffer pool数量)的倍数 比如默认的chunk大小是128MB，那么此时如果你的机器的内存是32GB，你打算给buffer pool总大小在20GB左右， 那么你得算一下，此时你的buffer pool的数量应该是多少个呢？ 假设你的buffer pool的数量是16个，这是没问题的，那么此时chunk大小 * buffer pool的数量 = 16 * 128MB = 2048MB，然后buffer pool总大小如果是20GB，此时buffer pool总大小就是2048MB的10倍，这就符合规则了。 当然，此时你可以设置多一些buffer pool数量，比如设置32个buffer pool，那么此时buffer pool总大小（20GB）就 是（chunk大小128MB * 32个buffer pool）的5倍，也是可以的。 那么此时你的buffer pool大小就是20GB，然后buffer pool数量是32个，每个buffer pool的大小是640MB，然后每 个buffer pool包含5个128MB的chunk，算下来就是这么一个结果了。

SHOW ENGINE INNODB STATUS 当你的数据库启动之后，你随时可以通过上述命令，去查看当前innodb里的一些具体情况，执行SHOW ENGINE INNODB STATUS就可以了。此时你可能会看到如下一系列的东西： Total memory allocated xxxx; Dictionary memory allocated xxx Buffer pool size xxxx Free buffers xxx Database pages xxx Old database pages xxxx Modified db pages xx Pending reads 0 Pending writes: LRU 0, flush list 0, single page 0 Pages made young xxxx, not young xxx xx youngs/s, xx non-youngs/s Pages read xxxx, created xxx, written xxx xx reads/s, xx creates/s, 1xx writes/s Buffer pool hit rate xxx / 1000, young-making rate xxx / 1000 not xx / 1000 Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s LRU len: xxxx, unzip_LRU len: xxx I/O sum[xxx]:cur[xx], unzip sum[16xx:cur[0] 

下面我们给大家解释一下这里的东西，主要讲解这里跟buffer pool相关的一些东西。 （1）Total memory allocated，这就是说buffer pool最终的总大小是多少 （2）Buffer pool size，这就是说buffer pool一共能容纳多少个缓存页 （3）Free buffers，这就是说free链表中一共有多少个空闲的缓存页是可用的 （4）Database pages和Old database pages，就是说lru链表中一共有多少个缓存页，以及冷数据区域里的缓存页 数量 （5）Modified db pages，这就是flush链表中的缓存页数量 （6）Pending reads和Pending writes，等待从磁盘上加载进缓存页的数量，还有就是即将从lru链表中刷入磁盘的数 量、即将从flush链表中刷入磁盘的数量 （7）Pages made young和not young，这就是说已经lru冷数据区域里访问之后转移到热数据区域的缓存页的数 量，以及在lru冷数据区域里1s内被访问了没进入热数据区域的缓存页的数量 （8）youngs/s和not youngs/s，这就是说每秒从冷数据区域进入热数据区域的缓存页的数量，以及每秒在冷数据区 域里被访问了但是不能进入热数据区域的缓存页的数量 （9）Pages read xxxx, created xxx, written xxx，xx reads/s, xx creates/s, 1xx writes/s，这里就是说已经读取、 创建和写入了多少个缓存页，以及每秒钟读取、创建和写入的缓存页数量 （10）Buffer pool hit rate xxx / 1000，这就是说每1000次访问，有多少次是直接命中了buffer pool里的缓存的 （11）young-making rate xxx / 1000 not xx / 1000，每1000次访问，有多少次访问让缓存页从冷数据区域移动到 了热数据区域，以及没移动的缓存页数量 （12）LRU len：这就是lru链表里的缓存页的数量 （13）I/O sum：最近50s读取磁盘页的总数 （14）I/O cur：现在正在读取磁盘页的数量


造多个缓冲池，因为对共享资源如数据页链表的操作等都是必须保证线程安全。

多线程并发访问BufferPool必然是要加锁

### 调度算法
IO请求转换为Block IO请求之后，会把这个Block IO请求交给IO调度层，在这一层里默认是用CFQ公平调度算法 的 
也就是说，可能假设此时你数据库发起了多个SQL语句同时在执行IO操作。 

有一个SQL语句可能非常简单，比如update xxx set xx1=xx2 where id=1，他其实可能就只要更新磁盘上的一个 block里的数据就可以了 但是有的SQL语句，比如说select * from xx where xx1 like "%xx%"可能需要IO读取磁盘上的大量数据。 
那么此时如果基于公平调度算法，就会导致他先执行第二个SQL语句的读取大量数据的IO操作，耗时很久，然后第一 个仅仅更新少量数据的SQL语句的IO操作，就一直在等待他，得不到执行的机会。 
所以在这里，其实一般建议MySQL的生产环境，需要调整为deadline IO调度算法，他的核心思想就是，任何一个IO 操作都不能一直不停的等待，在指定时间范围内，都必须让他去执行。 
所以基于deadline算法，上面第一个SQL语句的更新少量数据的IO操作可能在等待一会儿之后，就会得到执行的机 会，这也是一个生产环境的IO调度优化经验。

### 文件句柄被限制导致连接数上不去
这个时候如果MySQL报异常说Too many Connections，就说明目前MySQL甚至都无法建立400个网络连接？这 也太少了吧！毕竟是高配置的数据库机器！
于是我们检查了一下MySQL的配置文件，my.cnf，里面有一个关键的参数是max_connections，就是MySQL能建立 的最大连接数，设置的是800

那奇怪了，明明设置了MySQL最多可以建立800个连接，为什么居然两台机器要建立400个连接都不行呢？

这个时候我们可以用命令行或者一些管理工具登录到MySQL去，可以执行下面的命令看一下：

show variables like 'max_connections'

此时你可以看到，当前MySQL仅仅只是建立了214个连接而已！

所以我们此时就可以想到，是不是MySQL根本不管我们设置的那个mac_connections，就是直接强行把最大连接数设 置为214了？于是我们可以去检查一下MySQL的启动日志，可以看到如下的字样

Could not increase number of max_open_files to more than mysqld (request: 65535) 
Changed limits: max_connections: 214 (requested 2000) 
Changed limits: table_open_cache: 400 (requested 4096)

所以说，看看日志就很清楚了，MySQL发现自己无法设置max_connections为我们期望的800，只能强行限制为214 了！

这是为什么呢？简单来说，就是因为底层的linux操作系统把进程可以打开的文件句柄数限制为了1024了，导致 MySQL最大连接数是214！

可能有的人会疑惑说，为什么linux的文件句柄数量被限制了，MySQL最大连接数就被限制了呢？

今天我们继续讲解昨天的那个案例背景，其实就是经典的Too many connections故障，他的核心就是linux的文件句 柄限制，导致了MySQL的最大连接数被限制，那么今天来讲讲怎么解决这个问题。

其实核心就是一行命令： ulimit -HSn 65535 
然后就可以用如下命令检查最大文件句柄数是否被修改了 

cat /etc/security/limits.conf
cat /etc/rc.local

如果都修改好之后，可以在MySQL的my.cnf里确保mac_connections参数也调整好了，然后可以重启服务器，然后重 启MySQL，这样的话，linux的最大文件句柄就会生效了，MySQL的最大连接数也会生效了。 

然后此时你再尝试业务系统去连接数据库，就没问题了！

另外再给大家解释一个问题，有人还是疑惑说，为什么linux的最大文件句柄限制为1024的时候，MySQL的最大连接 数是214呢？ 
这个其实是MySQL源码内部写死的，他在源码中就是有一个计算公式，算下来就是如此罢了！

然后再给大家说一下，这个linux的ulimit命令是干嘛用的，其实说白了，linux的话是默认会限制你每个进程对机器资 源的使用的，包括可以打开的文件句柄的限制，可以打开的子进程数的限制，网络缓存的限制，最大可以锁定的内存 大小。 
因为linux操作系统设计的初衷，就是要尽量避免你某个进程一下子耗尽机器上的所有资源，所以他默认都是会做限制 的。 
那么对于我们来说，常见的一个问题，其实就是文件句柄的限制。 
因为如果linux限制你一个进程的文件句柄太少的话，那么就会导致我们没办法创建大量的网络连接，此时我们的系统 进程就没法正常工作了

我们平时可以用ulimit命令来设置每个进程被限制使用的资源量，用ulimit -a就可以看到进程被限制使用的各种资 源的量

比如 core file size 代表的进程崩溃时候的转储文件的大小限制，max locked memory就是最大锁定内存大小，open files就是最大可以打开的文件句柄数量，max user processes就是最多可以拥有的子进程数量。 
设置之后，我们要确保变更落地到/etc/security/limits.conf文件里，永久性的设置进程的资源限制 
所以执行ulimit -HSn 65535命令后，要用如下命令检查一下是否落地到配置文件里去了。
cat /etc/security/limits.conf 
cat /etc/rc.local



### 脏写和脏读
事务B去修改了事务A修改过的值，但是此时事务A还没提交，所以事务A随时会回滚， 导致事务B修改的值也没了，这就是脏写的定义。

事务B去查询了事务A修改过的数据，但是此时事务A还没提 交，所以事务A随时会回滚导致事务B再次查询就读不到刚才事务A修改的数据了！这就是脏读。


### Spring的事务隔离
在@Transactional注解里是有一个isolation参数的，里面是可以设置事务隔离级别的，具体的设置方式 如下：
@Transactional(isolation=Isolation.DEFAULT)，然后默认的就是DEFAULT值，这个就是MySQL默认支 持什么隔离级别就是什么隔离级别。