## Java 语言的特点
面向对象（封装，继承，多态）；
平台无关性（ Java 虚拟机实现平台无关性）；
支持多线程（而 Java 语言却提供了多线程支持）；；
支持网络编程并且很方便（ Java 语言诞生本身就是为简化网络编程设计的，因此 Java 语言不仅支持网络编程而且很方便）；
编译与解释并存；



### 为什么说 Java 语言“解释与编译并存”

高级编程语言按照程序的执行方式分为编译型和解释型两种。简单来说，编译型语言是指编译器针对特定的操作系统将源代码一次性翻译成可被该平台执行的机器码；解释型语言是指解释器对源程序逐行解释成特定平台的机器码并立即执行。比如，你想阅读一本英文名著，你可以找一个英文翻译人员帮助你阅读， 有两种选择方式，你可以先等翻译人员将全本的英文名著（也就是源码）都翻译成汉语，再去阅读，也可以让翻译人员翻译一段，你在旁边阅读一段，慢慢把书读完。

Java 语言既具有编译型语言的特征，也具有解释型语言的特征，因为 Java 程序要经过先编译，后解释两个步骤，由 Java 编写的程序需要先经过编译步骤，生成字节码（\*.class 文件），这种字节码必须由 Java 解释器来解释执行。因此，我们可以认为 Java 语言编译与解释并存。

## 比较 JVM 和 JDK 以及 JRE

### JVM

Java 虚拟机（JVM）是运行 Java 字节码的虚拟机。
JVM 有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。


#### 什么是字节码?采用字节码的好处是什么?

在 Java 中，JVM 可以理解的代码就叫做**字节码**（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效，而且，由于字节码并不针对一种特定的机器，因此，Java 程序无须重新编译便可在多种不同操作系统的计算机上运行。
![[Pasted image 20220206184110.png]]


我们需要格外注意的是 .class->机器码 这一步。在这一步 JVM 类加载器首先加载字节码文件，然后通过解释器逐行解释执行，这种方式的执行速度会相对比较慢。而且，有些方法和代码块是经常需要被调用的(也就是所谓的热点代码)，所以后面引进了 JIT 编译器，而 JIT 属于运行时编译。当 JIT 编译器完成第一次编译后，其会将字节码对应的机器码保存下来，下次可以直接使用。而我们知道，机器码的运行效率肯定是高于 Java 解释器的。这也解释了我们为什么经常会说 Java 是编译与解释共存的语言。 HotSpot 采用了惰性评估(Lazy Evaluation)的做法，根据二八定律，消耗大部分系统资源的只有那一小部分的代码（热点代码），而这也就是 JIT 所需要编译的部分。JVM 会根据代码每次被执行的情况收集信息并相应地做出一些优化，因此执行的次数越多，它的速度就越快。JDK 9 引入了一种新的编译模式 AOT(Ahead of Time Compilation)，它是直接将字节码编译成机器码，这样就避免了 JIT 预热等各方面的开销。JDK 支持分层编译和 AOT 协作使用。但是 ，AOT 编译器的编译质量是肯定比不上 JIT 编译器的。

### JDK和JRE

JDK 是 Java Development Kit 缩写，它是功能齐全的 Java SDK。它拥有 JRE 所拥有的一切，还有编译器（javac）和工具（如 javadoc 和 jdb）。它能够创建和编译程序。 JRE 是 Java 运行时环境。它是运行已编译 Java 程序所需的所有内容的集合，包括 Java 虚拟机（JVM），Java 类库，java 命令和其他的一些基础构件。但是，它不能用于创建新程序。 如果你只是为了运行一下 Java 程序的话，那么你只需要安装 JRE 就可以了。如果你需要进行一些 Java 编程方面的工作，那么你就需要安装 JDK 了。但是，这不是绝对的。有时，即使您不打算在计算机上进行任何 Java 开发，仍然需要安装 JDK。例如，如果要使用 JSP 部署 Web 应用程序，那么从技术上讲，您只是在应用程序服务器中运行 Java 程序。那你为什么需要 JDK 呢？因为应用程序服务器会将 JSP 转换为 Java servlet，并且需要使用 JDK 来编译 servlet。


## Java为什么泛型不能放int
泛型只能只能代表引用类型，不能是原始类型，原始类型有byte/short/int/long [浮点型](https://so.csdn.net/so/search?q=%E6%B5%AE%E7%82%B9%E5%9E%8B&spm=1001.2101.3001.7020)：float.double 字符型char 布尔型：boolean,引用类型与原始类型的区别在于虽然二者保存在栈中，但原始类型保存的是实际值，而引用类型保存的是一个对象的内存地址

## Java 基本类型有哪几种，各占多少位？

Java 中有 8 种基本数据类型，分别为：

1. 6 种数字类型 ：`byte`、`short`、`int`、`long`、`float`、`double`
2. 1 种字符类型：`char`
3. 1 种布尔型：`boolean`。
![[Pasted image 20220206190701.png]]

另外，对于 `boolean`，官方文档未明确定义，它依赖于 JVM 厂商的具体实现。逻辑上理解是占用 1 位，但是实际中会考虑计算机高效存储因素。

**注意：**

1.  Java 里使用 `long` 类型的数据一定要在数值后面加上 **L**，否则将作为整型解析。
    
2.  `char a = 'h'`char :单引号，`String a = "hello"` :双引号。
    

这八种基本类型都有对应的包装类分别为：`Byte`、`Short`、`Integer`、`Long`、`Float`、`Double`、`Character`、`Boolean` 。

包装类型不赋值就是 `Null` ，而基本类型有默认值且不是 `Null`。

另外，这个问题建议还可以先从 JVM 层面来分析。

基本数据类型直接存放在 Java 虚拟机栈中的局部变量表中，而包装类型属于对象类型，我们知道对象实例都存在于堆中。相比于对象类型， 基本数据类型占用的空间非常小。

> 《深入理解 Java 虚拟机》 ：局部变量表主要存放了编译期可知的基本数据类型 **（boolean、byte、char、short、int、float、long、double）**、**对象引用**（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。


## Java 泛型，类型擦除
Java 泛型（generics）是 JDK 5 中引入的一个新特性, 泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型。泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。

Java 的泛型是伪泛型，这是因为 Java 在运行期间，所有的泛型信息都会被擦掉，这也就是通常所说类型擦除 。
```java
List<Integer> list = new ArrayList<>();

list.add(12);
//这里直接添加会报错
list.add("a");
Class<? extends List> clazz = list.getClass();
Method add = clazz.getDeclaredMethod("add", Object.class);
//但是通过反射添加，是可以的
add.invoke(list, "kl");

System.out.println(list);

```

泛型一般有三种使用方式:泛型类、泛型接口、泛型方法。

**1.泛型类**：
```java
//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型
//在实例化泛型类时，必须指定T的具体类型
public class Generic<T> {

    private T key;

    public Generic(T key) {
        this.key = key;
    }

    public T getKey() {
        return key;
    }
}


//如何实例化泛型类：
Generic<Integer> genericInteger = new Generic<Integer>(123456);

```

**2.泛型接口** ：
```java
public interface Generator<T> {
    public T method();
}


//实现泛型接口，不指定类型：
class GeneratorImpl<T> implements Generator<T>{
    @Override
    public T method() {
        return null;
    }
}

//实现泛型接口，指定类型：
class GeneratorImpl implements Generator<String>{
    @Override
    public String method() {
        return "hello";
    }
}

```

**3.泛型方法** ：
```java
public static <E> void printArray(E[] inputArray) {
    for (E element : inputArray) {
        System.out.printf("%s ", element);
    }
    System.out.println();
}

//使用：
// 创建不同类型数组： Integer, Double 和 Character
Integer[] intArray = { 1, 2, 3 };
String[] stringArray = { "Hello", "World" };
printArray(intArray);
printArray(stringArray);

```

**常用的通配符为： T，E，K，V，？**

-   ？ 表示不确定的 java 类型
    
-   T (type) 表示具体的一个 java 类型
    
-   K V (key value) 分别代表 java 键值中的 Key Value
    
-   E (element) 代表 Element



## == 和 equals() 的区别

对于基本数据类型来说，==比较的是值。对于引用数据类型来说，==比较的是对象的内存地址。

> 因为 Java 只有值传递，所以，对于 == 来说，不管是比较基本数据类型，还是引用数据类型的变量，其本质比较的都是值，只是引用类型变量存的值是对象的地址。

**`equals()`** 作用不能用于判断基本数据类型的变量，只能用来判断两个对象是否相等。`equals()`方法存在于`Object`类中，而`Object`类是所有类的直接或间接父类。

`Object` 类 `equals()` 方法：
```java
public boolean equals(Object obj) {
     return (this == obj);
}

```

`equals()` 方法存在两种使用情况：

-   **类没有覆盖 `equals()`方法** ：通过`equals()`比较该类的两个对象时，等价于通过“==”比较这两个对象，使用的默认是 `Object`类`equals()`方法。
    
-   **类覆盖了 `equals()`方法** ：一般我们都覆盖 `equals()`方法来比较两个对象中的属性是否相等；若它们的属性相等，则返回 true(即，认为这两个对象相等)。

```java
public class test1 {
    public static void main(String[] args) {
        String a = new String("ab"); // a 为一个引用
        String b = new String("ab"); // b为另一个引用,对象的内容一样
        String aa = "ab"; // 放在常量池中
        String bb = "ab"; // 从常量池中查找
        if (aa == bb) // true
            System.out.println("aa==bb");
        if (a == b) // false，非同一对象
            System.out.println("a==b");
        if (a.equals(b)) // true
            System.out.println("aEQb");
        if (42 == 42.0) { // true
            System.out.println("true");
        }
    }
}

```

-   `String` 中的 `equals` 方法是被重写过的，因为 `Object` 的 `equals` 方法是比较的对象的内存地址，而 `String` 的 `equals` 方法比较的是对象的值。
    
-   当创建 `String` 类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个 `String` 对象。


## hashCode() 和 equals()

面试官可能会问你：“你重写过 `hashcode` 和 `equals`么，为什么重写 `equals` 时必须重写 `hashCode` 方法？”

**1)hashCode()介绍:**

`hashCode()` 的作用是获取哈希码，也称为散列码；它实际上是返回一个 int 整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。`hashCode()`定义在 JDK 的 `Object` 类中，这就意味着 Java 中的任何类都包含有 `hashCode()` 函数。另外需要注意的是： `Object` 的 hashcode 方法是本地方法，也就是用 c 语言或 c++ 实现的，该方法通常用来将对象的 内存地址 转换为整数之后返回。

散列表存储的是键值对(key-value)，它的特点是：能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象）

**2)为什么要有 hashCode？**

我们以“`HashSet` 如何检查重复”为例子来说明为什么要有 hashCode？

当你把对象加入 `HashSet` 时，`HashSet` 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，`HashSet` 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 `equals()` 方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，`HashSet` 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的 Java 启蒙书《Head First Java》第二版）。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。

**3)为什么重写 `equals` 时必须重写 `hashCode` 方法？**

我们以“**类的用途**”来将“hashCode() 和 equals()的关系”分2种情况来说明。

**1. 第一种 不会创建“类对应的散列表”**

这里所说的“不会创建类对应的散列表”是说：我们不会在HashSet, Hashtable, HashMap等等这些本质是散列表的数据结构中，用到该类。例如，不会创建该类的HashSet集合。

在这种情况下，该类的“hashCode() 和 equals() ”没有半毛钱关系的！ ​ 这种情况下，equals() 用来比较该类的两个对象是否相等。而hashCode() 则根本没有任何作用，所以，不用理会hashCode()。

**2. 第二种 会创建“类对应的散列表”**

这里所说的“会创建类对应的散列表”是说：我们会在HashSet, Hashtable, HashMap等等这些本质是散列表的数据结构中，用到该类。例如，会创建该类的HashSet集合。

在这种情况下，该类的“hashCode() 和 equals() ”是有关系的： ​ 1)、如果两个对象相等，那么它们的hashCode()值一定相同。 ​ **这里的相等是指，通过equals()比较两个对象时返回true。** ​ 2)、如果两个对象hashCode()相等，它们并不一定相等。 ​ 因为在散列表中，hashCode()相等，即两个键值对的哈希值相等。然而哈希值相等，并不一定能得出键值对相等。补充说一句：“两个不同的键值对，哈希值相等”，这就是哈希冲突。

此外，在这种情况下。若要判断两个对象是否相等，除了要覆盖equals()之外，也要覆盖hashCode()函数。否则，equals()无效。 例如，创建Person类的HashSet集合，必须同时覆盖Person类的equals() 和 hashCode()方法。 ​ 如果单单只是覆盖equals()方法。我们会发现，equals()方法没有达到我们想要的效果。
```markdown
重写hashcode后，equals()生效了，HashSet中没有重复元素。
比较p1和p2，我们发现：它们的hashCode()相等，通过equals()比较它们也返回true。所以，p1和p2被视为相等。
比较p1和p4，我们发现：虽然它们的hashCode()相等；但是，通过equals()比较它们返回false。所以，p1和p4被视为不相等。
```


## 重载和重写的区别
重载就是同样的一个方法能够根据输入数据的不同，做出不同的处理

重写就是当子类继承自父类的相同方法，输入数据一样，但要做出有别于父类的响应时，你就要覆盖父类方法

### 重载
发生在同一个类中（或者父类和子类之间），方法名必须相同，参数类型不同、个数不同、顺序不同，**方法返回值和访问修饰符可以不同。**
![[Pasted image 20220206191102.png]]
综上：重载就是同一个类中多个同名方法根据不同的传参来执行不同的逻辑处理。


### 重写
重写**发生在运行期**，是子类对父类的允许访问的方法的实现过程进行重新编写。

1.  **返回值类型、方法名、参数列表必须相同**，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类。
    
2.  如果父类方法访问修饰符为 `private/final/static` 则子类就不能重写该方法，但是被 static 修饰的方法能够被再次声明。
    
3.  构造方法无法被重写
    

综上：重写就是子类对父类方法的重新改造，外部样子不能改变，内部逻辑可以改变
![[Pasted image 20220206191133.png]]
**方法的重写要遵循“两同两小一大”**

-   “两同”即方法名相同、形参列表相同；
    
-   “两小”指的是子类方法返回值类型应比父类方法返回值类型更小或相等，子类方法声明抛出的异常类应比父类方法声明抛出的异常类更小或相等；
    
-   “一大”指的是子类方法的访问权限应比父类方法的访问权限更大或相等。
    

⭐️ 关于 **重写的返回值类型** 这里需要额外多说明一下，上面的表述不太清晰准确：如果方法的返回类型是 void 和基本数据类型，则返回值重写时不可修改。但是如果方法的返回值是引用类型，重写时是可以**返回该引用类型的子类**的。




## 深拷贝和浅拷贝

## 面向对象和面向过程的区别

## 成员变量与局部变量的区别

## 面向对象三大特性是什么。并解释这三大特性

## **`String`、`StringBuffer` 和 `StringBuilder` 的区别**


![[Pasted image 20220217230039.png]]


String的底层是基于数组实现的,这就使得存放字符串内容必须是向操作系统申请一块连续的空间

jdk 8 :String char\[\] 和 hash
jdk 9 : byte\[\] , coder, hash
一个 char 字符占16位，2个字节。这个情况下，存储单字节编码内的字符（占一个字节的字符）就显得非常浪费。JDK1.9 的 String 类为了节约内存空间，于是使用了占8位，1个字节的 byte 数组来存放字符串。

而新属性 coder 的作用是，在计算字符串长度或者使用 indexOf() 函数时，我们需要根据这个字段，判断如何计算字符串长度。coder 属性默认有 0 和 1 两个值，0 代表 Latin-1（单字节编码），1 代表 UTF-16。如果 String 判断字符串只包含了 latin-1，而 coder 属性值为 0， 反之则为 1。

final private char\[\],final主要作用还是告诉用户char\[\]指向字符串的地址关系不能变,真正起作用的我认为还是private,阻止了用户通过char\[\]来修改字符串的值


String对象的不可变性体现在:
String类型的字面量一旦声明,便不可再修改

为什么不可更改?
1. value数字是private权限,这就导致我们无法通过对象.属性去修改字符串
2. String是final修饰的,无法被继承,这就导致其方法无法被修改
3. 严谨的访问控制,设计string的程序员当碰到修改操作时总是返回一个新创建的对象，而不是返回一个指针。这从根本上保证了用户得到的一定是新对象，也保证了底层数组仅仅能被用于访问。一旦涉及到修改操作，那么它的生命基本也走到了尽头（当前使用价值没了，等待下一个用户重新从字符串常量池中获取）_…


如果问你如何设计不可变类，那么string将是一个很好的参考：不可继承、底层数据结构私有化、严密的访问控制、涉及到对象本身的方法返回值总是一个（深）拷贝对象


由于一旦发生修改操作,或者返回值是一个String对象,总是需要返回一个新创建的String对象,String本质上就变成只读对象
创建一个对象是需要内存空间、初始化等一系列操作的，而销毁一个对象也不是说销毁就销毁的，GC是不可预知的，如果不停的丢弃对象（不再指向）而这些对象又没有被GC及时回收，那么这些对象就会造成内存泄露。

java提出了一种优化思路：
string作为一个经常被使用的、不可变的对象。我能不能在用户正式使用前（如String类加载阶段）先创建出一些对象，然后将这些对象的指针保存在一个哈希表中，当用户需要用，我就把这个指针给它。它用完（这个string对象）之后把指针给了别人（别的string指针/引用），那么这个对象由于被哈希表强引用着，它并不会被GC回收掉，一旦有其他方法想要接着使用这个对象，那么再把这个指针给他。
上面说的对象就是存放在堆中的字符串对象，而指针指的就是双引号代表的字面量。


[字符串常量池和String.intern()方法在jdk1.6、1.7、1.8中的变化 | 常量 (lmlphp.com)](https://www.lmlphp.com/user/59808/article/item/804073/)

String.intern()在JDK1.6中，会先判断常量池中是否存在当前字符串，不存在就会将当前字符串复制到常量池，并返回常量池中字符串的引用。

而JDK1.7以后，会先判断常量池中是否存在当前字符串，不存在时不会将当前字符串复制到常量池，只是当前字符串的引用。**如果存在，也不会改变存在的引用，以及只会保存首次存储的字符串的引用**。如上代码所示，常量池保存的是str1的引用，即使str2调用intern()方法，返回的也是str1的引用。

**优化**

```java
        String a ="aa"+"a";
        String b1 ="bb";String b2 ="bbb";
        String b ="b"+b1+b2+"bbbbb";
```
如果涉及加号的表达式全部使用字面量，则在编译期间进行优化，消除加号，并且拼接为“aaa”,也就是说编译后的产物是“aaa”，而“a”和“aa”并没有放入池中（更不会触发对应的idc）。  
而如果表达式中涉及到了变量，那么就会执行另一个流程：创建一个stringBuilder空对象，然后每个+都是一次append操作。最终返回的是一个string对象，因此一定会创建一个新的string对象。但是有一个例外：如果变量是一个被final所修饰的常量，依然可以被编译优化。（只能是string或基本类型，引用类型（除了string）没有常量一说）

>1.5及其以前+默认采用stringBuffer，是[线程安全](https://so.csdn.net/so/search?q=%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8&spm=1001.2101.3001.7020)的，但效率低。1.6之后采用效率高但是线程不安全的stringBuilder。  
线程安全下面会介绍。这里简单理解：如果有一个语句 s = “”+a。（线程安全问题出现的前提是操作共享资源，因此s肯定不能是一个局部变量）如果三个线程同时执行该语句，就会存在s可能最终的值为a。而我们的预期是，每个线程执行一次该操作，s应该为aaa。正是因为每个线程执行该语句的行为不是一个原子的（事务的），因此存在写写冲突——数据被覆盖、更新丢失。


## Java 异常
不会问的特别细。经常的问法是异常可以分为哪几种，然后你答了可检查异常和不可检查异常以后，会让你举例可检查异常有哪些，不可检查有哪些。然后，异常的代码要会写，有一场字节的面试，直接让我写一个把异常捕获了然后抛出去的代码。


## 反射
面试官可能会问你什么是反射，它的优缺点是什么，有哪些应用场景。

JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法，对于任意一个对象，都能够调用它的任意一个方法和属性，这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。

反射，就是在运行时，拿到一个类型的元信息。从哪里拿到这些元信息？JVM的元信息统一保存在方法区，类加载阶段，class文件被载入内存，并且转换为了保存在方法区的数据结构中。同时向堆中放入一个class实例，用作元信息访问的入口。我们可以通过class.forName(）、实例.getClass()、或者类型.class这三种方法拿到这个class实例。（8大基本类型和void关键字都具有class实例）

拿到class实例，可以直接使用newInstance方法通过空参构造器创建对象，或者也可以使用getConstructor（）根据参数数量、类型拿到具体的构造器实例，当找到需要调用的方法时，都会复制一份而不是使用原来的实例，保证数据隔离。反射是线程安全的。

一旦我们拿到这个class实例，就找到了访问类型元数据的入口，我们可以通过这个class实例拿到构造器实例、方法实例、字段实例、注解实例等，进而我们还可以拿到字段类型、方法参数类型等。反射技术通常用于实现各种框架包括注解的解析、依赖注入、占位符替换、动态代理等。

反射的特点可以用于实现类型之间的解耦，提供系统灵活性，例如输入全限定类名，反射创建一个实例（动态加载），避免大量if/else条件（静态加载）。包括spring的依赖注入、切面编程以及解析配置文件都离不开反射特性的支持。
但是反射的性能比较低（一般配合缓存使用）、JVM无法对某些动态加载的类型进行优化，而且一定程度上破坏了Java的封装语义。另一方面，反射技术可能减低代码可读性，使得代码难以维护。

## List、Set、 Map 的区别


## `ArrayList` 和 `LinkedList` 的区别
答清楚每个分别采用什么数据结构，对比相应的优点和缺点。


## 比较 `HashSet`、`LinkedHashSet` 和 `TreeSet` 三者的异同


## HashMap 多线程操作导致死循环问题
jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使用 `HashMap`,因为多线程下使用 `HashMap` 还是会存在其他问题比如数据丢失。并发环境下推荐使用 `ConcurrentHashMap` 。

## HashMap 的长度为什么是 2 的幂次方


## **`HashMap`、`HashTable`、以及 `ConcurrentHashMap` 的区别。**【⭐⭐⭐⭐⭐】：现在面试的超高频考点。当面试官问到这个问题的时候，展现你背面试八股文能力的机会来了。你可以展开去讲在 Java7 和 Java8 中 `HashMap` 分别采用什么数据结构，为什么 Java8 把之前的`头插法`改成了`尾插法`，怎样实现`扩容`，为什么`负载因子`是 `0.75`，为什么要用`红黑树`等等一系列的东西。只要面试官不打断我，我在这个知识点上能背到面试官下班





# [java final可以修饰String吗？](https://www.cnblogs.com/brainstorm/p/7612034.html)

我们知道String对象是不可变的，是指String内部的东西是不变的

String a = "xxx";

这里a还是可以重新引用别的：a = "yyy";

但是加上final修饰：

final String a = "xxxx";

这时就不可以：a = "yyy";

总结一下：final是让被修饰的变量，不能再引用别的变量

final修饰的变量就是常量，是放在特定存储区域的，类常量一般要加static

比如：final修饰的hashmap，内部可以修改，可以添加元素，但是这个变量不能被赋值，也就是引用不能变了




## i++和 ++i的区别
```markdown
int j = 0;  
int k = j++ + 2;

 0 iconst_0
 1 istore_1
 2 iload_1
 3 iinc 1 by 1
 6 iconst_2
 7 iadd
 8 istore_2


iconst_0  //把数值0 push到操作数栈
istore_1 // 把操作数栈写回到本地变量第2个位置
iload_1 // 把本地变量第2个位置的值push到操作数栈
iinc 1,1  // 把本地变量表第2个位置加1 
istore_1 // 把操作数据栈写回本地变量第2个位置

```
i++本质就是将i从局部变量表中的值放到操作数栈中,然后本地变量表上的i自增1
而++i就是将局部变量表上的i自增,然后才放到操作数栈中


## new一个对象流程
[(51条消息) JMM相关基础知识点汇总（笔记）_wanghaobillgill的博客-CSDN博客](https://blog.csdn.net/weixin_40970862/article/details/118679035)
new一个对象的过程是如下的
instance = new DoubleCheckLockSingleton()；的汇编层面的实现
17行 new指令，开辟一块内存空间
21行 invokespecial指令，执行初始化方法，给内存中的变量赋值
24行 putstaitic指令，将初始化好的内存地址赋给变量，让变量指向该内存地址
当CPU进行指令重排的话，会发生下列的问题
17行 new指令，开辟一块内存空间
24行 putstaitic指令，将开辟好的内存地址赋给变量，让变量指向该内存
21行 invokespecial指令，执行初始化方法，给内存中的变量赋值
以上条件发送的CPU指令重排的情况，当线程A执行到24行的时候，对象还是初始化状态，线程B去读取对象是否为空（变量是否已经指向堆中的对象）的时候，发现变量以及有指针指向对象，故读到的值为对象初始化的值，并不是真正想要的值，这个情况，称为对象的半初始化状态

![[Pasted image 20220217172519.png]]



## final

语义就是最终的,其体现的就是不变性

```markdown
1.修饰任何变量,都使得**为该变量开辟的内存空间仅能存放一次值，且不可以修改**.这个值可以是一个字面量，也可以是一个地址值。（如果更具体一点：基本类型变量的值不能变，引用类型指向的对象不能变,但其属性可变）

2.修饰方法：方法不能被重写。显然方法被修饰为**final具有意义的前提是继承**。
priate修饰方法使得该方法不能被子类对象使用，而final使得子类对象只能使用父类继承下来的方法而不可以重写。private final中final就没什么必要了，final具有意义的前提是存在继承关系！

3.修饰类：该类不能被继承。显然final和abstract是冲突的，二者如果同时出现是无法通过编译的。
如果把final变量定义在循环中，那么final语义起作用的范围仅仅是当前循环上下文，下一次循环时，此final就非彼final了。（如果把final变量定义在循环外，则仍然有效）

final的不可变语义是编译器保证的，如果对final变量进行二次赋值，则在编译期就可以检查出来。
```


### final 的内存语义
[并发编程笔记（三）：Java 内存模型（二） - 简书 (jianshu.com)](https://www.jianshu.com/p/eb831f229628)
```markdown
final可以保证内存可见性。  
编译器为final写（初始赋值）操作之后插入写屏障，在读操作之前插入读屏障。

final提供的内存语义  
**保证了一个线程在读取final变量之前必须首先获取包含这个变量的对象的引用（先拿到引用，再读final）。同时，还保证了对象引用被任何线程获取之前，final变量的初始值已经被正确的写入了。（先写final，再拿到引用）**

如果final域是一个引用类型：在构造函数内对一个final引用的对象的成员域的写入，与随后这个被构造对象引用被保存给一个引用值，这两个操作不能重排序。（对象被获取之前，final域一定已经初始化完毕，而且return语句之前的成员写入操作也执行完毕，不会被重排序到获取操作之后）

总结：final保证了对象引用对任意线程线程可见之前，对象的final域已经被初始化。线程在读到一个对象的final域之前，一定先读到该对象的引用。
```


final可以保证内存可见性。  
编译器为final写（初始赋值）操作之后插入写屏障，在读操作之前插入读屏障。这个由编译器插入的内存屏障，要求处理机在“某些位置”禁用cpu指令的重排序这项优化。

> 因为不同的CPU提供对内存屏障的支持指令不同，JMM屏蔽了平台的差异，提供了统一的内存屏障指令这个解决方案——开发人员可以通过synchronized、volatile、final可以告诉编译器哪些地方不应该进行重排序优化，编译器在编译层面不会进行重排序，同时插入内存屏障来告诉处理器哪些地方禁止重排序。  
> 处理器层面，JMM通过在某些适当的位置插入特定类型的**内存屏障指令**来禁止特定类型的处理器重排序（CPU指令）。而编译器层面的重排序，JMM的**编译器重排序规则**会禁止特定类型的编译器重排序（JVM指令）【jvm指令最终是会映射到cpu指令上的】。

> 以final写为例：【1】编译器层面，JMM禁止编译器将final写重排序到构造函数之外。【2】处理器层面，编译器在final写之后，构造函数return之前，插入一个storestore屏障。该屏障禁止处理器把final写操作排序到构造函数之外

final提供的内存语义  
**保证了一个线程在读取final变量之前必须首先获取包含这个变量的对象的引用（先拿到引用，再读final）。同时，还保证了对象引用被任何线程获取之前，final变量的初始值已经被正确的写入了。（先写final，再拿到引用）**

如果final域是一个引用类型：在构造函数内对一个final引用的对象的成员域的写入，与随后这个被构造对象引用被保存给一个引用值，这两个操作不能重排序。（对象被获取之前，final域一定已经初始化完毕，而且return语句之前的成员写入操作也执行完毕，不会被重排序到获取操作之后）

> 内存屏障下面的代码不能重排序到屏障上方。有内存屏障的地方，线程修改完共享数据后，需要立即写回主内存，并且通过总线发送信号，嗅探总线的其他线程收到后会使相应的缓存行数据过期。（更多细节可以搜一搜**缓存一致性协议MESI**）

> 单线程下，程序执行结果正确的前提下（as-if-serial），cpu或编译器会做出指令级别（cpu指令或jvm指令）的重排序，但对于多线程环境，这会导致结果出错。

jdk5之前，final语义还未被增强，缺陷：**线程有可能看到final域的值是可变的**——线程两次读取同一个final域，第一次读到的是未初始化之前的默认值，第二次读到的是初始化之后的值。  
final语义在jdk5时得到了加强，通过为final域增加**读写的重排序规则**，为程序员做出初始化安全的保障：  
只有对象被正确的构造，则不需要使用同步就可以保证在任意线程都可以看到这个final域在构造函数被初始化之后的值。

总结：final保证了对象引用对任意线程线程可见之前，对象的final域已经被初始化。线程在读到一个对象的final域之前，一定先读到该对象的引用。


## 内部类

### 静态内部类

**静态内部类的本质就是一个普通的、独立的类**。它无非就是写在了类的内部（因此只能通过 _**外部类名.**_ 的方式创建对象或访问）。  
编译后它和外部类**没有任何关系**（不存在谁依赖谁），这也就解释了它为什么不能访问外部类的成员字段。  
如果你想定义一个链表，那么节点元素完全可以定义为一个静态内部类。

### 成员内部类

经过反编译可以知道，成员内部类内部会生成一个**外部类类型的字段**，并且创建成员内部类对象的同时，还会**将外部类对象（this）的引用作为构造函数参数传入**。  
内部类对象可以通过这个外部类字段访问外部类的所有成员属性，因此成员内部类的实例依赖外部类，没有外部类对象，就没有成员内部类。（创建对象需要先创建外部类对象，然后才能再创建内部类对象——人与心脏的关系）

> 内部类中如果想获取外部类的引用，应该使用**外部类名.this**

成员内部类不允许定义静态方法或字段，因为成员内部类依赖实例对象，每个实例对象都可以对应一个成员内部类，而且**每个成员内部类的实例指向一个公共的外部类实例**，使用static是冲突的。  
如果一个内部类对象不被释放（不满足GC），那么外部类实例就总被指向，也不会被释放，此时就有可能造成内存泄露。

### 局部内部类

局部内部类可以看作一个局部变量，不需要使用任何修饰符，而成员内部类和成员变量地位一致（运行使用四种访问修饰符）。（外部类只有public和默认两种）  
局部内部类还可以被abstract修饰。

局部内部类和成员内部类很相似，都是通过构造函数传入外部的引用或值。  
**如果局部内部类使用到了外部的值（不论是方法中还是成员字段或类字段），都会在编译后生成一个构造函数和若干字段，将字面值或地址值传入字段。**

但是局部内部类只能读外部传入的值，而不能修改。即**局部内部类只能访问局部final变量**。

### 局部内部类与final

这是因为局部变量修改外部变量，实现上本质是在修改自己的成员。但是这在逻辑上造成了**数据不一致**的情况。因此编译器限定往内部类构造器传递的参数必须是final修饰的。

> jdk8之后，局部内部类中调用方法中的局部变量可以不需要显示修饰为final，但是仍然不能修改变量（只读）。  
> 如果需要修改，那么完全可以将值类型定义为一个**值数组**的类型。

```java
    Object method(){
        final int[] num = {1};
        class Inner{
            void displayLocvar(){
                num[0]++;
            }
        }
        Object in = new Inner();
        return in;
    }

    
```

### 匿名内部类

匿名内部类其实就是**特殊的局部内部类**。只能继承一个类或实现一个接口。且匿名类没有名字所以不可以定义构造函数，且不可以是抽象的。





## 容器类库
java 中的容器（这里不区分集合、容器）通常指的是能够存放对象的类型，底层通常都是数组对象，并且提供了一组操作底层这个数组的API。容器对象其实也就是一个普通的对象，它的成员是一个数组，可以存放外部传递的值或对象引用，但是由于封装的特性，我们不需要关注底层的数组，只需要关心容器对象本身即可。  
jdk为了规范容器的行为提供了collection接口，list、set、queue都是collection的子接口，看作对“容器”行为的进一步细化与扩展。而Map是JDK提供的映射接口,map的实现类大多保存entry或node节点，因此也可以看作容器。  
值得注意的是，map接口本身是不提供返回迭代器的方法的，而collection实现了iterator接口，规定容器对象必须具有返回迭代器对象的方法，map实现类对象如果想要迭代一般是通过返回keySet实例间接实现迭代的。

容器是一种框架，是对底层数据结构访问的封装，因此**如果能够直接使用数组解决的功能我们应该尽量使用数组**，数组占用内存肯定是比封装了数组的容器对象要小的。使用容器，主要就是容器的开发者为我们封装了操作底层数据结构的接口如排序、遍历、插入、删除。容器各种操作的复杂度和底层的数据结构息息相关，应该根据**具体的场景**选择合适的容器（分析它的**底层数据结构**）。  
我们应该尽量**避免使用“无界”的容器**，应该指定合适的初始容量和扩容阈值（如果可以的话）。  
如果使用的基于哈希函数实现的容器，那么我们应该保证待存入的对象重写了hashCode()方法和equals()方法。


###  泛型
java的泛型是伪泛型，这是因为Java在编译期间，所有的泛型信息都会被擦掉，正确理解泛型概念的首要前提是理解类型擦除。Java的泛型基本上都是在编译器这个层次上实现的，在生成的字节码中是不包含泛型中的类型信息的，使用泛型的时候加上类型参数，在编译器编译的时候会去掉，这个过程成为**类型擦除**。

**Java泛型设计原则：只要在编译时期没有出现警告，那么运行时期就不会出现ClassCastException异常**.
**早期Java是使用Object来代表任意类型的，但是向下转型有强转的问题，这样程序就不太安全**

聊容器就离不开泛型了。泛型就是一种工具，没有它也不影响我们使用，因为它也不过是JDK5才引入的。  
泛型的本质是参数化类型，被操作的**数据类型**可以被指定为方法签名的一个**参数**  
【1】泛型可以**将类型安全检查从运行期提前到编译期**。  
【2】我们将一个从一个指定了泛型的容器取出元素时，不需要手动强制类型装换了，这个工作在编译期将自动完成  
【3】增加了代码的复用性，框架普遍使用了泛型。  
由于泛型不支持基本类型（因为无法将一个基本类型和Object类型之间进行强制类型装换），所以使用泛型容器时总是存在大量的拆箱和装箱。  
**java源码经过编译后，所有类型参数都会被替换为实际类型（泛型擦除），在生成的字节码中是不包含泛型中的类型信息的**，编译器在元素访问的代码出进行解语法糖，插入强制类型转换的代码。


泛型参数不考虑继承关系，通配符？可以让泛型可以接收任意类型参数，？可以引用各种参数化类型，可以调用与参数化无关的方法（例如size()），对于返回值就是参数化类型（如返回E）的方法，仅仅能通过Object接收，而形参为参数化类型的（如V v）方法，无法调用，编译报错（会被一个capture类型的入参占位，无法传入参数）

> 无界通配——？：参数和返回值为泛型的方法，不能使用  
> 子类限定（上限确定，？只能接收XXX或其子类）——？extends XXX：参数为泛型的方法不能使用【正三角】  
> 父类限定（下限确定，？只能接收XXX或其父类）——？super XXX返回值为泛型的方法不能使用【倒三角】

#### 泛型为什么会擦除
JVM里从来就没有过泛型信息，为了保证向后兼容兼容性，Java采取了折中的方法

想要实现真泛型，有如下两件事Java 必须要处理：

修改 JVM 源代码，让 JVM 能正确的的读取和校验泛型信息（之前的Java 是没有泛型这种概念的，所以需要修改）。
为了兼容老程序，需为原本不支持泛型的 API 平行添加一套泛型 API（主要是容器类型）。

### 自定义泛型类/方法

泛型类中，可以在成员变量上使用。也可以在方法中使用（返回值类型、形参类型、局部变量类型）

```java
    class ea<E>{
        E date ;
        public E a(E e){
            E i;
            return e;
        }
    }
```

new E()是不可以的，想想就知道，因为编译后E就会被擦除了，而创建对象时，new后面跟的构造函数的符号引用是需要保存在常量池中的。

```java
   public<E> E a(E e){
        return e;
    }
```

在访问修饰符后面声明泛型


### 思考：set、list、map接口

set、list、map是java提供的三个接口，同时他们也对应着相对的规范。其中set和list都是collection的子接口，是对集合行为进一步划分。set规范**不重复**、**不要求有序**的**集合**行为（实现类仍然可以基于有序实现，这里只是一个规范），list规范**允许重复**、**有序**的**线性表**行为。而map是一个映射接口，规范了**映射类型**应该具有的行为：一个键对应一个值，键是唯一的，值可以不唯一等。

> 提问对某个接口的理解，归根结底是要答出“它规范了哪种行为”

Set方法仅仅是继承了collection接口，并没有提供任何其他的方法。也就是说，**set和collection提供的方法都是一样的**。

这么来理解：collection可以看作对“元素容器”、“元素集合体”类型行为的一种规范，而这个“元素集合体”又可以进一步被解释为“集合”（不允许重复、不要求有序），而List则通过增加方法去进一步限定行为，包括indexOf、get、sort等“行为规范”，因此List的行为定义是（允许重复、有序，这里的序指的是我能够根据一个偏移量去拿到这个值即get(int i)和indexOf()）

Queue则是在collection的基础上提供了offer、poll、peek等方法，也就是说（允许重复、不关注顺序、更加关注首尾操作）


#### List、 Set 和 Map 的初始容量和加载因子
List
ArrayList 的初始容量是10，加载因子为0.5；扩容增量：原容量的 0.5倍+1；一次扩容后长度为16。
Vector 初始容量为10，加载因子1。扩容增量：原容量的1倍，一次扩容后的容量为20。

Set
HashSet，初始容量为16，加载因子为0.75；扩容增量：原容量的1.6倍；如 HAshSet 的容量为16，一次扩容后容量为32

Map
HashMap，初始容量16，加载因子0.75；扩容增量：原容量的1倍；如 HashMap 的容量为16，一次扩容后容量为 32

加载因子是表示Hsah表中元素的填满的程度。

若:加载因子越大,填满的元素越多,好处是,空间利用率高了,但:冲突的机会加大了。反之,加载因子越小,填满的元素越少,好处是:冲突的机会减小了,但:空间浪费多了。

冲突的机会越大,则查找的成本越高.反之,查找的成本越小.因而,查找时间就越小。

因此,必须在 "冲突的机会"与"空间利用率"之间寻找一种平衡与折衷. 这种平衡与折衷本质上是数据结构中有名的 **"时-空"矛盾** 的平衡与折衷。

### ArrayList和linkedList

ArrayList和linkedList都是list接口的实现类，因此他们都具有**线性表**的行为。其中ArrayList底层是基于数组实现的，而linkedList则是基于双向链表实现的。  
ArrayList是基于数组的，而一旦添加节点导致容量不够用就会触发扩容函数，ArrayList是基于创建新的数组并将原数据拷贝进新数组实现的扩容，需要新开辟一个比当前容量更大一些的数组空间（旧容量的1.5倍），空间复杂度大致为O（n），而复制函数时间复杂度也需要O（n）。（最大数组大小可以达到整型的最大值）  
ArrayList默认初始数组大小为10。  
而基于链表的linkedList可就省心多了。linkedList仅需要维护头节点和尾结点以及size（查询复杂度较低为O(1)），不需要考虑扩容，初始状态下头尾节点都指向空。而如果需要添加元素无法就是创建一个节点对象，然后将引入链入头尾节点维系的链表即可，理论上是无界的，除非没有足够的内存可以分配给节点对象使用了。

### 对比

【1】上面已经提到了，最基本的不同肯定还是底层数据结构不同。而且ArrayList需要扩容函数支持，而linkedList则是天生无界的。  
【2】ArrayList增删等涉及结构变动的操作底层都是基于复制实现的，时间复杂度O（n），但是支持随机访问。而linkedList涉及结构修改都是O（1），而且由于双向链表的特性，得到任意一个节点，节点本身、前驱、后驱都可以进行删除操作，但是链表不支持随机访问，因此如果需要访问某个指定位置的元素，时间复杂度是O（n）。  
【3】只看单个元素，ArrayList占用一个数组单元，而linkedList中则需要单独为该元素创建一个对象节点，因此linkedList占用空间更多。但是ArrayList很难避免存在冗余位置/空间，而linkedList每个节点都是具有意义的，更加“紧密”


### 选择双向链表还是单链表

linkedList双向链表的特性使得通过一个节点可以直接访问到当前、前驱、后驱三个节点，这一点对于删除操作是十分友好的，如果我们只有一个单链表节点，那么我们只能是删除后面的节点（当然了，你也可以“基于值”删除当前节点）。基于双向链表**很容易就可以实现栈和队列**——维护头尾指针，然后就可以进行任意的删除、添加组合达到对应效果。  
而如果为一个单链表维护一个尾指针，除了访问最后一个元素和标记结尾，恐怕没有别的意义了…

正在由于使用了双向链表作为底层数据结构，linkedList可以被用作一个栈或队列，而且linkedList也确实实现了deque接口，可以作为双端队列使用。

双向链表有什么缺点吗？  
linkedList使用者用的很爽，但是开发者需要维护一个节点的两个指针，编写代码的难度加倍。而且对象需要多维护一个指针的空间。同时，它只是对链表的访问方式，但是访问性能上和单链表没区别。

jdk的双向链表最早还是双向循环链表的，但是双向循环链表中循环的意义不大，不如直接使用头尾节点。最重要的是，头插尾插总是需要修改两个指针，这很麻烦，因此最佳方案还是使用无环双向链表。

> 细节补充：集合框架的底层结构大多使用transient修饰，那他们如何被序列化？
> 
> ArrayList在被序列化为文件、网络io等时，会调用被序列化类中的writeObject方法，找不到writeObject则调用工具类中defaultWriteFields方法，在ArrayList中writeObject私有的，序列化时使用**反射调用**。  
> 之所以不使用类中属性elementData直接来序列化，主要原因是elementData是一个缓存数组，为了性能考虑，它通常会预留一些容量，因此**可能有大量空间没有实际存储元素**。不直接序列化elementData可以保证**序列化实际有值的那些元素，而不是序列化整个数组**



## 线程安全方案

线程安全？如果使用数据库中的“事务”去思考，那么就很清晰了。我们把线程要完成的某项操作看出一个事务，事务的最重要的特点是原子性，也就是说线程的某个操作必须保证是原子的，不能够被其他线程打断。如果出现“打断”，那么这个事务就是失败的，也就是说发生了线程安全问题（写写冲突/读写冲突）  
java.util下诸如linkedList、ArrayList、hashMap等都是不保证线程安全的，大致可以有以下几个解决方案：  
【1】外部加锁，即通过同步块或者加锁使得线程互斥访问容器。  
【2】使用工具类collections提供的一些“同步化”方法，其实就是基于“装饰者”模式，collections内部定义了一些同步装饰器，而传入的容器作为被装饰对象，最终给你返回一个经过装饰的容器对象。  
【3】直接使用线程的线程安全容器vector、hashTable等。  
以上的方式虽然保证了线程安全，但是加锁粒度太大了，即使并发读操作也需要互斥读取，并发度不高

> vector默认大小10，每次扩容为旧容量二倍（ArrayList是1.5倍）

【4】copyOnWriteArrayList是java.util.concurrent包下提供的一种ArrayList的线程安全版本，而且并发度比vector高。（concurrentLinkedQueue可以看作linkedList的线程安全版本）



## CopyOnWriteArrayList

copyOnWriteArrayList从名字上就可以看出来，它的底层是基于数组的线性表结构，而且基于“写时复制”保证线程安全

### 理解copyOnWrite思想

多个调用者请求相同资源时，系统不会立即为他们分别创建资源，而是分配一个指向目标资源的指针/地址值，只有当调用者尝试修改资源时系统才会为其真正创建独立的资源。  
其实就是一个**延迟创建**、**读共享**的思想。  
适用于 **“读多写少”** 的场景  
linux的fork()调用就是copyOnWrite思想的一个典型案例。

### 简述原理

copyOnWriteArrayList底层数组指针使用volatile修饰，保证了可见性，一旦指针指向了别的对象，那么线程再次访问该指针时能够立即知道。  
copyOnWriteArrayList的读操作是不加锁的，而写操作需要加锁，而且每次进行写（增/删/改）操作都会创建/拷贝一个新的数组，并且使得指针重新指向。  
多个线程并发读的是同一个数组对象，但是其中一个线程写操作后，最终指针指向的数组对象会被替换掉。

> 线程读取的数组可能是一个已经被替换的数组，而且线程迭代的数组也是一个“快照数组”。这里通过copyOnWrite解决读写冲突——读和写不是同一个数组对象

### 特点

从上面的描述，应该可以知道了，每当copyOnWriteArrayList进行写操作都需要拷贝一个新数组，因此高并发下，内存中可能同时出现大量过期数组对象等待回收，这使得内存压力非常大。（因为每次写都是数组的赋值，因此无需考虑扩容问题，也不考虑初始容量问题，没有冗余空间）  
另一方面，copyOnWriteArrayList只能保证数据的最终一致性，而不能保证数据的实时一致性。（vector能够保证数据的实时一致性，代价就是并发度的降低）

> 你正在读的，和别人正在写的是两个独立的数组对象，解决了读写冲突——你读你的，我写我的，但是这个问题就是数据不是实时。而vector读写在同一个对象上，我正在读你就不能写，你写的时候我等着，也解决了读写冲突——互斥读写，而且是强一致性的

为啥读线程和写线程操作copyOnWriteArrayList可以不冲突？copyOnWriteArrayList只需要考虑写冲突即可，因为如果不同步写，A和B两个写线程同时更新数组指针，其中一个写线程的最新数据将被覆盖而造成更新丢失。而写线程并不会干扰读线程，因为读线程拿到数组引用的时候，这个数组可能已经“被抛弃”了，写线程先new一个空数组，然后进行数据拷贝，然后更新数组指针——也就是说，读线程和写线程在原数组上都是仅进行“读”操作，读线程和写线程不存在同时读写一个数组的情况。

## 快速失败和安全失败

快速失败和安全失败指的是**迭代器的错误处理方式**。  
如果在某个线程迭代的过程中，其他线程对集合做出了结构性的修改（或者当前线程使用非iterator提供的方法对集合进行了修改，从迭代器的角度看，这也是属于“未告知”的修改），此时迭代器在迭代的过程中就会抛出concurrentModificationException并发修改异常——这称为快速失败（一旦发现问题，就立即选择失败）。这种迭代器也称为强一致性迭代器。

> 实现上就是让容器和迭代器分别维护一个修改计数器modCount，每当进行结构性修改都将计数器自增，迭代的过程中总是需要比较两个计数器，如果值不相等就抛出异常

而并发容器一般是基于安全失败的，允许并发修改，因此即使迭代的过程中容器被其他线程修改也不会报错。对应的迭代器也称为弱一致性迭代器。比如copyOnWriteArrayList使用快照数组迭代器，而concurrentHashMap则是迭代底层数组，并且如果已经迭代过的内容出错不会引起异常，未迭代部分发生修改可能会反映出来。

> 不要一棒子打死加锁的方式，各有各的优点和缺点：内存占用、并发度、一致性等

## hashMap
>[从基础到实践，一文带你看懂HashMap - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/258347168)


hashMap是基于哈希表实现的散列类型，hashMap是Map的实现类，底层数据结构数组，更具体的说是哈希表，因为数组存放的是哈希表节点Node/entry，哈希表节点的键通过哈希函数可以计算出一个哈希值，根据哈希值可以对应一个数组索引，如果存在哈希冲突则会基于链表法解决冲突，当链表的节点达到阈值（默认8）后会重构为红黑树结构，当小于阈值（默认6）后又会重构为链表。

> 描述hashMap：是什么、底层结构

### 为什么数组长度为2的幂次方
当数组长度为2的幂次方时，可以使用位运算来计算元素在数组中的下标

HashMap是通过index=hash&(table.length-1)这条公式来计算元素在table数组中存放的下标，就是把元素的hash值和数组长度减1的值做一个与运算，即可求出该元素在数组中的下标，这条公式其实等价于hash%length，也就是对数组长度求模取余，只不过**只有当数组长度为2的幂次方时，hash&(length-1)才等价于hash%length**，使用位运算可以提高效率。



### hashMap 与redis 的负载因子

因为Redis是用键值对数量除以长度，而不是已使用位置的数量除以长度。

### 链表树化
为什么[链表](https://www.nowcoder.com/jump/super-jump/word?word=%E9%93%BE%E8%A1%A8)树化需要同时满足[链表](https://www.nowcoder.com/jump/super-jump/word?word=%E9%93%BE%E8%A1%A8)长度>=8和数组长度>=64两个条件

因为当 table 数组容量比较小时，键值对节点 hash 的碰撞率可能会比较高，进而导致链表长度较长。这个时候应该优先扩容，而不是立马树化。

为什么要大于等于8转化为红黑树，而不是7或9？
树节点的比普通节点更大，在链表较短时红黑树并未能明显体现性能优势，反而会浪费空间，在链表较短是采用链表而不是红黑树。在理论数学计算中（装载因子=0.75），链表的长度到达8的概率是百万分之一；把7作为分水岭，大于7转化为红黑树，小于7转化为链表。红黑树的出现是为了在某些极端的情况下，抗住大量的hash冲突，正常情况下使用链表是更加合适的。


如果 hashCode的分布离散良好的话，那么红黑树是很少会被用到的，因为各个值都均匀分布，很少出现链表很长的情况。在理想情况下，链表长度符合泊松分布，各个长度的命中概率依次递减，注释中给我们展示了1-8长度的具体命中概率，当长度为8的时候，概率概率仅为0.00000006，这么小的概率，HashMap的红黑树转换几乎不会发生，因为我们日常使用不会存储那么多的数据，你会存上千万个数据到HashMap中吗？

  

### hashCode（）与hash（）

hashCode()方法是一个本地方法，能够返回一个计算值，逻辑上代表对象的内存地址。该方法的最大作用就是**配合哈希结构的容器使用**如hashMap、hashSet等。  
该方法默认有jvm实现，当第一次调用后这个值会被保存到对象头的mark word中（对象会撤销偏向锁）。

> 计算hashCode时，经常使用到**乘以31进行移位操作**，它是一个奇数也是一个质数，31=2的5次方-1,31可以被JVM自动优化——31\*i = (i<<5)-i 。31可以使用移位替代乘法，使用位运算可以得到更好的性能。如果乘数是个偶数会造成信息丢失。（其实我感觉33应该也可以 i <<5 + i）

hash()是hashMap的一个内部方法，用于对hashCode进行再hash计算。其实直接使用hashCode取模就可以找到一个数组索引了（例如hashTable），这里可能是为了让散列值更加均匀。

```java
    private int hash(K key) {
        if(key==null)return 0;
        int hashCode=key.hashCode();
        int temp=hashCode>>>16;
        System.out.println("使用hashCode："+hashCode+"和hashCode>>>16 :"+temp+"做异或运算得到："+(hashCode^temp));
        return hashCode^temp;
    }
```

为了可读性，这里对代码进行改写  
hashMap的hash()使用hashCode的低16位和高16位进行了异或操作，其实就是一个扰动计算——让所有位都参与计算，这样每一位不同都可以对应一个新的hash计算值，降低hash冲突的概率（如果直接使用原始hashCode，可能出现过多高位相同低位不同的hash值，使得取模后存放过于集中）。说白了，就是通过**不同的高位影响相似的低位，让总体的hash值更加平均**。

每个对象都具有hashCode（），该方法定义在顶层基类object，因此所有对象都可以使用hash容器

### 二次幂

```java
int index=(table.length-1)&hash;
```

计算桶的索引就是一个取模操作，hashMap源码中写作位运算的形式（hash是一个很大的数，而数组的范围只有0到len-1），同时hashMap默认大小是16，默认的扩容因子是0.75。如果是外部传入初始大小总是会经过一个tableSizeFor函数转换为大于该值的最小的二次幂（传入15输出16，传入17输出32）

```java
     final int tableSizeFor(int cap) {//返回大于等于cap的最近的2次幂
        int n = cap - 1;
        n |= n >>> 1;
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
        if(n>=maxCap)return maxCap;
        if(n<0)return 1;
        return n+1;
    }
```

> 这个算法主要是作用于非二次幂的数，先做一个减一操作不会改变最高位。例如14（1110）减一变成1101,12（1100）减一变成1011.而对于二次幂，减一则会改变最高位。而|运算可以看作位运算中的加法，依次右移1、2…位进行“插入1”操作其实就是为了使得**低位布满1**  
> 例如14（1110）经过一系列移位和插入操作，最终变成1111的形式，在进行一个加一操作，就会变成10000（16）。而如果cap本身就是2的整数幂，那么该函数就没用了，调用了个寂寞。  
> 总结：**移位、低位通过|运算符插入1，最终使得低位全1，最后使用一个加一操作使得最终cap称为一个二的整数幂**。

> **为什么一开始要减一**？这是考虑二次幂的情况。这个**减一操作不是针对非二次幂的**，无论是1110还是1101经过一系列移位操作最终都能变成1111.而如果一开始就是二次幂如10，经过移位操作会变成11，如果加个1变成100，好家伙直接翻了一倍。  
> 因此,为了防止以上情况发生，针对2、4、8这种数一开始必须减个1，而这个减一操作并不是针对非二次幂的。

说白了，hashMap要求我们进去(len-1)&hash中的len是一个2的整数幂，因为2的整数幂写作二进制就是仅有一个1，其他位全是0如16对应1000，如果做一个减一操作那么低位就是像是**掩码**，如果低位不全是1，那么就会造成空间的浪费——1&hash可以将两个不同hash值分别映射到两个桶，而如果0&hash，两个不同的hash值只能放入同一个桶中，另一个桶“**无法寻址**”！浪费了

总结：长度是二次幂时，进行取模操作时可以保证数组的每一个桶都可以至少对应一个hash值，减少hash冲突概率，同时提升桶的利用率。

### 哈希函数

hash函数没什么特别的，也是由输入、输出、功能组成的。hash函数最大的作用就是将一个大范围映射到一个小的范围，可以节省空间，并且易于保存数据。  
以上提到的hashCode（）本质上就是一个hash函数，将对象的地址空间映射为一个整形值。而将hash值映射为数组索引其实也可以看作一个hash函数。

#### 解决哈希冲突的办法

两个不同的输入，经过hash函数得到同一个输出，我们需要解决这个冲突。  
【1】开发定址法  
当前位置已经被占用了，就继续向后面找，直到找到另外一个空位置。  
JDK的threadLocalMap就是这么解决hash冲突的，通过线性探测法解决。  
【2】链地址法  
最常见的，hashMap就是基于该方式  
【3】再哈希法  
再使用另外一个hash函数进行一次计算，那再冲突了呢？可能继续找新的hash函数，或者搭配另外一种方式，看具体实现吧  
【4】公共溢出区  
将哈希表分为基本表与溢出表，冲突数据往溢出区存放。小坑放不下扔进大坑

#### 哈希函数的其他实现

【1】取余。（最常用）  
【2】直接定址。（直接使用关键字，或进行线性计算）  
【3】随机数  
【4】取若干位数。

### hashCode() 和 equals()

从设计原则上考虑，hashCode()将一个对象的地址值映射为一个整形值，但是两个hashCode()返回值相同的对象并不一定是同一个对象，可能仅仅是产生hash冲突的对象，因此需要根据equals()方法返回值判断二者是否相同。  
因此：**hashCode相同的两对象，equals返回值不一定相同，但是equals返回值相同hashCode返回值一定相同**。

hashCode主要用于 **“支持散列容器”** 的使用，而equals使用更广。因此**如果没有使用散列容器的需求，仅使用equals则可以不理会hashCode方法，但是如果需要使用散列容器则必须同时重写equals和hashCode方法。**

如果希望自定义的类对象，占用不同内存但是内容确实一样的对象调用hashcode方法返回值也是一样的，则就必须自己重写hashcode方法。（String由官方重写了两个方法，可以当做范例）

《Effective Java》中提供了一种简单通用的hashCode算法。  
【1】初始化一个整形变量，为此变量赋予一个非零的常数值  
【2】选取equals方法中用于比较的所有域，然后针对每个域的属性进行计算：  
(1) 如果是boolean值，则计算f ? 1:0  
(2) 如果是bytecharshortint,则计算(int)f  
(3) 如果是long值，则计算(int)(f ^ (f >>> 32))  
(4) 如果是float值，则计算Float.floatToIntBits(f)  
(5) 如果是double值，则计算Double.doubleToLongBits(f)，然后返回的结果是long,再用规则(3)去处理long,得到int  
(6) 如果是对象应用，如果equals方法中采取递归调用的比较方式，那么hashCode中同样采取递归调用hashCode的方式。否则需要为这个域计算一个范式，比如当这个域的值为null的时候，那么hashCode 值为0  
(7) 如果是数组，那么需要为每个元素当做单独的域来处理。java.util.Arrays.hashCode方法包含了8种基本类型数组和引用数组的hashCode计算，算法同上。  
【3】最后，把每个域的散列码合并到对象的哈希码中

```java
int result;
long temp;
result = int_; 
result = 31 * result + (string_ != null ? string_.hashCode() : 0); 
result = 31 * result + (ref_ != null ? ref_.hashCode() : 0);
result = 31 * result + (f_ != +0.0f ? Float.floatToIntBits(f_) : 0); float
temp = Double.doubleToLongBits(d_); double先转换成long（都是64位）
result = 31 * result + (int) (temp ^ (temp >>> 32)); long再转换成double
result = 31 * result + Arrays.hashCode(arr); 数组
return result;
```

equals()的意义就是比较两个对象，object默认使用等号做了实现，如果是基本类型比较的就是内存保存的字面量，否则就是保存的对象地址。一般自定义对象都需要重写该方法。  
比较的时候，需要对两个字段的所有字段进行比较，基本类型就使用等号，引用类型就使用equals方法，数组就使用Arrays,equals方法。

> equals()需要满足的一些特性：  
> 自反性（reflexive）。对于任意不为null的引用值x，x.equals(x)一定是true  
> 对称性（symmetric）。对于任意不为null的引用值x和y，当且仅当x.equals(y)是true时，y.equals(x)也是true  
> 传递性（transitive）。对于任意不为null的引用值x、y和z，如果x.equals(y)是true，同时y.equals(z)是true，那么x.equals(z)一定是true  
> 一致性（consistent）。对于任意不为null的引用值x和y，如果用于equals比较的对象信息没有被修改的话，多次调用时x.equals(y)要么一致地返回true要么一致地返回false  
> 对于任意不为null的引用值x，x.equals(null)返回false；

### 扩容原理
[(58条消息) 八、JDK1.8中HashMap扩容机制_菠萝y的博客-CSDN博客_hashmap1.8扩容机制](https://blog.csdn.net/yueaini10000/article/details/109030129)
hashMap默认大小是16，默认扩容因子是0.75，因此一旦检测到节点数量达到12就会触发resize函数进行扩容，数组的新容量变成就容量的二倍（32），并且重新计算阈值。本质上是一个数组中的节点向另一个数组转移的过程。

1.7中，遍历旧数组中每一个节点，遍历的同时计算新数组的索引位置，并且**头插**进行新数组（因为只需要计算数组索引）

1.8中，不再是边遍历边移动了，而是使用两个辅助链表节点——维护两个链表（两对头尾节点），高位链表和低位链表，每一个桶都对应两个辅助链表。遍历旧桶的时候将节点放入高位链表或低位链表，当某一个桶被遍历完毕，就将这两个链表保存到新桶中、清空链表、然后重复这个过程直到所有的节点被移动完毕（低位链表最终保存在新数组的index，高位链表存入oldCap+index位置）。因为两个链表都是保存了尾结点的，因此节点插入是**尾插**的。

> 新容量大小 = oldCap + oldCap ，因此原桶中的元素实际被划分为了两部分，一部分存入【0，oldCap】的index，另一部分存入【oldCap,2oldCap】的oldCap+index中。

（1.7每个节点移动前都需要计算一次index。而1.8每个桶只计算一次index即可，更主要关注的是去往哪一个链表）

> 1.7是先判断扩容后插入，而1.8是先插入然后判断扩容。先扩容后插入其实是可以避免一定的空间浪费的（防止扩容后就不再使用了），这里为什么1.8先插入后扩容真的不知道，以后看能填上坑不能吧。

使用`e.hash & oldCap==0` 表示是低位链表，否则就是高位链表。

### jdk7死循环的产生
[jdk1.7中 hashmap为什么会发生死链？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/394039290)
jdk7在多线程环境下扩容可能会导致死循环，主要是由头插法导致元素在桶中的相对位置发送改变，破坏了稳定性。jdk1.8基于尾插，扩容完毕后元素的相对位置没有改变，不会造成死循环。

因为如果两个线程同时执行扩容，那么肯定都是各种拿着公共的元素往自己数组中放，假设某个链表A->B,其中一个线程完成扩容，且顺序变成B->A，而另一个线程醒来后局部变量e为A，next为B。A头插进入另一个线程开辟的数组newTable[i]，然后e迭代给next即e为B，下一轮循环重新为局部变量next赋值，而next=e.next，此时next又回到了A，这时如果再进行一次头插A将指向B，此时就已经成为环了。

### 阈值问题

loadfactor负载因子是hashMap扩容的一个参考因子，hashMap使用loadfactor和当前容量计算出扩容的阈值。存在阈值的原因是因为hashMap是基于hash值与数组容量取余来计算节点的数组索引，因此设置阈值可以减少hash冲突的产生。  
**设置阈值是空间换时间的考虑**。  
如果阈值设置太大，那么可能出现hash冲突，无法保证O（1）的访问时间复杂度，严重的情况下可能退化为链表。如果设置太小又会造成不必要的空间浪费，而且扩容的行为可能是否频繁，影响整体性能，同时扩容本身也带来了时延和内存占用（申请数组和移动元素）。  
0.75是一个经验值，是空间和时间上的折中。

> 根据源码注释，节点在桶中的位置遵循泊松分布，当加载因子为0.75时，桶中元素超过8的几率非常小。

jdk8之后的底层数据结构是数组+链表+红黑树。其中如果某个桶中的链表节点数量超过8个，则在插入第8个节点后进行树化操作。而节点数量小于等于6个时又会重新变成链表节点。其中7相当于是一个缓冲节点，防止节点类型频繁的转换。  
树节点比链表节点占用更多的空间，因为实际上树节点继承了linkedHashMap定义的entry节点，而这个entry节点又继承了Node节点

```java
static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> 
```

因此，这个树节点还是比较“重量”的。

### 红黑树性质

红黑树本质上就是一颗二叉树——特殊的平衡二叉树，通过维护红黑节点来进行平衡。如果使用二叉搜索树，极端情况下可能退化为O（n）的链表，而二叉平衡树可以将查询时间复杂度稳定在logN。  
【1】每个节点非黑即红  
【2】根节点总是黑的  
【3】如果当前节点是红的，子节点一定是黑的  
【4】每个叶子节点都是空节点  
**【5】从根节点到任意一个叶子节点的路径，必须包含相同的黑色节点。**

红黑树本质上是一颗2-3-4树（拥有2 3 4 节点的树），2表示一个节点两个指针，3表示两个个节点三个指针，4表示三个节点四个指针。黑节点具有支撑作用，一个黑节点就是一个2节点，3节点可以对应一颗黑节点+红节点的树，4节点中黑节点为根，两侧各一个红节点。  
**每次插入的都是红色节点，一旦插入就可能打破红黑树的性质，而旋转、变色的根本目的就是将红黑树调整为满足性质的情况**。

### put与get方法的实现

（这里以1.8为例）  
put和get实际上逻辑是非常简单的。  
put方法底层调用的是putVal方法，调用之前会使用hash()函数对hashCode进行二次哈希计算，得到一个计算值hash。hashMap的数组默认是懒创建的，因此一开始会先判断数组是否存在，不存在就创建。然后就拿到刚才计算的hash值，和数组长度取模得到当前键值对在数组中的索引位置。  
如果对应位置没有元素直接放入，如果存在元素则比较hash值（粗略当成hashCode也可以）和equals方法，只有二者都相同才会认为当前元素与待插入元素是同一个元素，这种情况进行节点覆盖，否则就接着往下判断。  
判断一下是否属于树节点，如果属于就委托插入树节点的方法去插入。如果不是树节点，说明存在哈希冲突。于是沿着当前元素这个链表往后遍历，边遍历边计数，计数结果超过7则进行树化后插入。否则继续找，最终只有两个结果：覆盖了某一个链表节点，或者尾插入链表。  
如果插入新节点会返回null，如果覆盖节点则会返回旧节点。1.7在插入前会判断扩容，而1.8则是先插入再判断扩容。

get就更简单了，不需要扩容判断，同样是根据hashCode进行二次哈希计算出hash值，然后与数组长度取模得到数组索引，根据hash值和key的equals方法进行对比，是就返回，没有就顺着链表向后找，没有找到就返回null，如果是一个树节点则委托查找树节点的函数去执行。

## 简述linkedHashMap与treeMap

linkedHashMap在之前的LRU文章已经详细介绍过了，这里做个总结。linkedHashMap继承了hashMap并且重写了若干父类留下的模板方法，linkedHashMap节点继承的父类定义的Node节点，即用于解决hash冲突，又起到维护顺序的作用。默认就是插入顺序，其中尾部代表新元素位置，访问顺序就是将最新访问到的元素移动到尾部。而且linkedHashMap预留了模板方法removeEldestEntry()，如果想要实现LRU缓存，只需要继承linkedHashMap（增加一个size字段）并且重写这个方法即可（控制什么时候移除最久未被访问元素）。

treeMap实现了sortedMap接口，具体排序映射的行为，传入需要通过构造函数传入一个自定义构造器comparator或者实现默认排序行为接口comparable的对象。**不允许null做key**。treeMap内部也是基于红黑树节点实现的，可以将时间复杂度降低为logN。（红黑树的增删改查时间复杂度约logN，因为红黑树本质上是弱平衡的一颗二叉搜索树）

> comparator接口对应的方法是两个参数的compara（），它指明的一种行为是：这是一个工具，他能提供一种规则，供两个传入对象比较。而comparable接口对应的方法是单个参数的compareTo()，它指明的一种行为是：实现了该接口的对象能够与另一个comparable对象进行比较（第零个参数其实就是this）。一般容器涉及comparable比较时都会先将两个对象转换为comparable类型对象，然后调用compareTo方法进行比较。

hashSet、treeSet不再赘述，底层都是基于Map实现的。

## hashTable

hashTable是线程安全的hashMap，但是锁的粒度比较大，是基于synchronized加锁的，锁对象就是全局的this，严格来说，应该是this对象头mark word锁指针指向monitor对象。（这里不考虑锁升级，如果考虑锁升级，这个“锁”可能是monitor、或者线程id、lock record，这里不展开了）。说白了和vector一样，全局共同使用一把锁。  
hashTable是不允许存放null值的，事实上所有并发容器都不允许存放null值，因为并发容器一开始就打算应用在并发环境，一个key如果是一个null，那么它到达一开始是个null，还是被其他线程remove了呢？

> hashTable和vector都是比较旧的容器，jdk1.0就有了，而ArrayList/HashMap/Colllecetion等都是jdk1.2才有的，因此hashTable和vector都具有一些历史遗留方法，例如elements()可以返回一个enumeration对象，这个相当于一个只读的迭代器（iterator是1.2才有的），也不存在什么快速失败问题（压根没有暴露读写的接口），可以定义一个适配器将enumeration转换为iterator接口（但是修改的功能可能仍然无法实现，该适配的目的顶多实现接口的转换或兼容）

hashTable是直接使用hashCode与数组长度取模计算索引位置的，默认大小是11，而扩容是2N+1的，扩容因子默认仍然为0.75.  
为什么是11？因为除以（近似的）质数求余数的分散效果更好，2N+1可以保证每次容量都是一个奇数（接近质数）。

## concurrentHashMap

concurrentHashMap是java.util.concurrent包下提供的线程安全hashMap。

### 简述原理

concurrentHashMap是基于分段加锁的思想的，不像hashTable使用一把全局锁。concurrentHashMap将底层数组分为多个部分，每部分由一把锁进行锁定，其中通过unsafe类提供的方法保证可见性。

### 1.7与1.8对比

jdk7和jdk8之间的改变很大，但是二者不变的仍然是分段加锁的思想。  
【1】jdk1.7默认创建16个segment数组，segment继承了reentrantLock，本质上就是一把锁，其中segment内部维护了hashEntry数组，可以说1.7中concurrentHashMap分别由16个segment维护的hashEntry数组组成，其中hashEntry就是键值对，基于链表解决冲突。  
也就是说，获取某一个成员需要先通过计算出这个成员在哪一个segment，拿到segment后再遍历segment维护的hashEntry数组，得到对应的hashEntry节点。不过concurrentHashMap的get操作是不加锁的。  
也就是说jdk7中**至少需要寻址两次**（偏移量寻址，也不算太慢，O（1））才能找到目标节点，如果存在hash冲突那么需要遍历链表  
jdk8使用数组+链表，取消了segment分段锁，而且链表可以在达到阈值后优化为红黑树存储。数组中存储的直接就是node节点，因此一次寻址即可定位node所在桶。  
【2】jdk7使用segment管理hashEntry数组，因此整体粒度和segment的数量直接有关。但是jdk8并发粒度大大增大，因为jdk8直接使用的就是synchronized块，包裹的是数组的每个首节点（每个桶中第一个节点），并发粒度和数组长度有关，相当于两个线程想要操作同一个hashEntry则需要竞争，而现在仅当两个线程想要操作“同一链表”元素时才会出现竞争！！！  
【3】由于1.7是成员是分散在segment维护的数组中的，因此如果某个segment维护的数组元素个数超过阈值，会引起单个segment的扩容，而不会影响其他segment。1.8中由于各个线程本质上操作的是同一个数组，因此如果涉及扩容操作必然需要锁住整个hashMap，但是1.8的设计者做出了优化：如果一个线程准备修改数组，并且根据状态变量发现concurrentHashMap正在扩容状态，那么将会协助它一起扩容。（分段扩容，一个线程负责一小段区域进行搬运工作，具体有几个线程可以加入并行扩容和CPU核数有关）

> 其实segment数组一开始只初始化了segment[0]（初始时segment[0]的容量就是1，阈值是0），后面的15个segment也都是延迟创建的（以segment[0]为模板），用户可以通过构造函数指定concurrentLevel，segment数组的个数是一个二次幂而且大于等于传入的concurrentLevel，而且hashEntry数组大小也是一个二次幂。

【4】jdk7使用的是reentrantLock，而jdk8使用CAS+synchronized。jdk7中的reentrantLock需要在jdk层面创建，而jdk8的synchronized会获得对象头关联的monitor。而且jdk6时synchronized已经得到很大的优化，锁升级使得monitor不总会被创建，而且synchronized重锁加锁失败后不会立即通过系统调用阻塞而是通过自适应自旋，等待获取锁的机会。jdk8的put操作中，在执行synchronized同步方法中，会首先尝试CAS插入（前提是当前桶中没有节点）

由于concurrentHashMap是基于CAS+synchronized实现的，即先通过CAS尝试插入，没有成功才synchronized同步插入，因此可以分成加锁和不加锁去讨论：  
**加锁后/同步块中**，可见性、有序性由jvm为读写volatile或synchronized添加的内存屏障保证，正确性由as-if-serial保证。  
**没加锁/同步块外**，可见性由unsafe类提供的getObjectVolatile、cas等方法保证。（因为数组指针是volatile，数组中的节点对象的value也是volatile的，但是不能保证节点对象本身是可见的，因此需要使用unsafe方法保证从数组中取出的对象节点总是最新的）

还有一些不同基本都是hashMap版本之间的差异，不再赘述。（concurrentHashMap说难是真的难，以上仅能算是原理的大概阐述，计数、扩容细节、状态量等都十分复杂）

### get与put方法简述

concurrentHashMap的get()方法不需要加锁，节点对象本身的可见性由unsafe的getObjectVolatile保证，而节点的成员都是volatile修饰的。

> hashTable的成员没有使用volatile修饰，因为hashTable是加锁读的，as-if-serial，synchronized可以保证它的可见性。volatile是一个轻量级的、可以用于实现线程通信的关键字。

两个版本的不同就是jdk7需要至少两次哈希寻址，而jdk8一次即可。

1.7的put方法中：  
需要先根据key的hashCode()二次哈希得到一个计算值，然后偏移量寻址拿到segment对象，如果没有segment就按segment数组的首元素为模板创建一个放入数组，之后就是上锁和插入节点。不过不会一开始就调用reentrantLock的lock方法，而是在循环中调用trylock()（这里其实也用到了CAS，不过这里是尝试CAS置位，取得锁变量），如果自旋超过阈值64才会调用lock()。插入成功后判断是否需要扩容，之后unlock()退出。

> jdk1.7并不是一开始就自旋tryLock()，则是先尝试一次tryLock()获取segment上锁，失败后才进行自旋tryLock。

1.8的put方法中：  
也是根据key的hashCode进行二次哈希，进入同步块前，如果目标桶没有节点，则会先尝试CAS插入Node节点，如果此时concurrentHashMap正在扩容，那么就帮助它一起扩容。同步块以目标桶的首节点（对应monitor）为锁对象，插入和判断基本都是hashMap的逻辑，最终插入成功后会进行是否需要扩容的判断。  
1.8的put上锁粒度更加下了，而且是乐观锁结合悲观锁

> jdk1.8没有使用将CAS自旋在API层面写出来，我的理解：synchronized重锁优化，在CAS修改monitor的owner失败后会进行自适应自旋，也就是说重试的操作在jvm层面进行，就没必要再次实现了。



## 深拷贝


## 异常
异常也是一种类型，它是JDK对“异常事件”的一种抽象。配合throw 关键字可以抛出一个异常对象，这个异常对象如果一直不能被捕获并处理，最终将会抛给JVM，JVM执行默认行为：在标准错误输出流system.err中打印堆栈信息。

> 所以，如果问我什么是异常，我会说：Java的异常是对非正常事件的一种抽象，**具体的异常信息通常都会创建一个异常实例，用于保存这异常的元信息**。

### 分类

异常的顶层父类是throwable。Throw关键字底层对应athrow命令，只能抛出throwable的实例。

Throwable有两大子类：  
1. error  
Error一般是系统相关的错误，例如OOM、Stack Overflow等  
2. exception  
异常又可以分为**运行时异常runtimeException**和**编译期异常**。  
runtimeException以及它的子类都是非受检异常，无论是主动抛出这个异常还是调用了声明该异常的方法。都可以不去处理，而交给JVM去处理。JVM会调用注册在线程上**未捕获异常处理器**（能抛给JVM异常处理器的异常一定是运行时异常）

```java
public static void main(String[] args) {
    Thread.currentThread().setUncaughtExceptionHandler((r,e)->{
        System.out.println("没事，抛者玩的");
        System.out.println(r.getName()+" "+e.getMessage());
    });
    throw new RuntimeException();
}
```

> 通过设置异常处理器，也可以实现子线程与主线程的通信，如错误报告。

除了runtimeException以及它的子类，其他的异常（Exeption类型）都是受检异常。必须进行try-catch处理或者throws向上抛出。（当然了，如果抛给了JVM则执行默认的处理器，标准错误输出流进行输出）

常见的受检异常包括SQL异常、IO异常、文件无法找到异常、EOF异常等。  
注意：Error类及其子类表示程序本身无法修复的错误，javac不会检查他们，当程序运行时出现这些异常，Java进程会直接终止——**Error是非受检的**。  
不过Error类型一般是JDK预设好的，用户一般不会主动扩展错误类型，而用户总是选择扩展RuntimeException类型。


### 异常处理机制

一个异常的执行顺序：  
【1】new一个异常对象  
【2】中止当前正在执行的程序  
【3】弹出异常对象的引用  
【4】异常处理机制接管被中止的程序  
【5】进入异常处理程序的catch代码块继续执行。

JVM使用**方法调用栈（method invocation stack）** 来跟踪每一个线程中一系列方法的调用过程。该栈保存了每个调用方法的本地信息（如方法的局部变量）。每个线程都有一个独立的方法调用栈。Java主线程中栈底方法是main()方法。每当一个新方法被调用时，JVM将描述该方法的栈结构放入栈顶，位于栈顶的方法就是正在执行的方法。

当一个方法正常执行完毕，JVM就会从调用栈中弹出该方法的栈结构（出栈），然后继续执行栈中下一个方法。  
如果在执行方法的过程中抛出了异常，则JVM必须能找到catch代码块，如果在当前方法找不到，JVM就会从调用栈中弹出该方法的栈结构，继续到下一个方法中查找合适的catch代码块。

> 每个方法调用栈的catch结构可以看到当前栈帧的异常处理器，如果找不到就会栈帧出栈，并寻找上一调用级别的异常处理器。最终main方法栈帧出栈后，交给JVM的未捕获异常处理器进行处理。如果没有设置则执行默认行为：  
> 【1】调用异常对象的**printStackTrace（）方法**，打印来自方法调用栈的异常信息  
> 【2】如果该线程不是主线程，则终止这个线程，其他线程继续正常运行。如果是主线程，那么整个应用程序被终止。

### finally

如果finally和try/catch都有返回语句，那么后者的return内容将会被覆盖掉。后者返回之前会执行finally的内容。  
Finally语句不被执行的唯一情况就是：执行了system.exit()方法——用于终止当前的Java进程

如果在try和catch进行return，首先这个return的值是赋给了一个局部变量，如果finally中不存在任何return语句，那么返回的就是这个局部变量。（字面量或者引用被赋值给一个局部变量）  
如果finally中存在return ，则最终返回的是finally中的return。Catch中的return X 相当于将X存放到了一个局部变量（如果X=a++也是会执行的）。

**return覆盖的情况：**

```java
static int fun(){
    int a =0;
    int b =1;
    try{
        return a++; //a++会被执行
    }finally {
        return a+b; //最终返回2
    }
}

    
```

**异常丢失的情况：**

```java
static int fun(){
    int a =0;
    int b =1;
    try{ 
	//异常对象仅仅是被保存起来，但是抛出异常之前就返回了
        throw new RuntimeException((a++)+" ");
    }finally {
        return a+b; //没有异常抛出，并返回
    }
}

    
```

局部变量是引用类型

```java
int[] a={1};
try{
    return a; //引用指向的数组内容被改变了
}finally {
    a[0]=33;
}

    
```

局部变量是字面量类型

```java
static int fun(){
    int[] a={1};
    try{
      return a[0]; //字面量已经被保存到了临时变量，最终返回值不变
    }finally {
        a[0]=33;
    }
}

    
```

总结：finally中不建议使用return，因为会造成“异常丢失”和“返回值内容被覆盖”

### throw和throws

Throw用于抛出一个异常，写在方法体内。而throws用于声明一个方法可能产生的所有异常。  
Throws更多是**提醒调用者“我这个方法可能抛出哪些异常”**。如果是受检异常，则必须处理，如果是运行时异常则可以不去处理。  
注意：如果我们拿到的是一个受检异常，我们必须try/catch进行处理，或者throws声明。而我们拿到一个非受检异常，也可以去处理或者抛出，但是不是必要的。

```java
    public static void a() throws IOException {

    }

    
```

throws 甚至可以加在一个空实现的方法上，但是如果另外一个方法b()调用了a()，a() ; 这行代码本身就会被视作一个异常，b()方法必须选择处理或者throws。而如果a()如果声明的是一个runtimeException则b()调用a()不需要进行额外处理。

换一个角度描述一下他们的关系：  
如果一个方法体内throw new XXException（） ，或是调用一个throws XXException的方法，他们（这一行代码）的效果相似。如果这是一个受检异常，调用方必须做出throws或try/catch。如果这是一个非受检异常，则调用方则不需要额外处理。

如果我们需要实现runnable接口对应的run()方法，则我们只能抛出运行时异常，而对应受检异常只能try/catch进行处理，因此**重写一个方法时不允许抛出更严格的异常**，而run方法没有throws任何异常，因此我们只剩下唯一一种选择：try/catch

```java
@Override
    public void run() {
        try {
            throw new IOException();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    
```

总结：异常也是java提供的一种类型，每个异常实例代表一种错误请求，异常可以被用于throws声明或者throw抛出。



### 常见异常

常见的RuntimeException：

1.  ClassCastException //类型转换异常
2.  IndexOutOfBoundsException //数组越界异常
3.  NullPointerException //空指针
4.  ArrayStoreException //数组存储异常
5.  NumberFormatException //数字格式化异常
6.  ArithmeticException //数算异常

unchecked Exception：

1.  NoSuchFieldException //反射异常，没有对应的字段
2.  ClassNotFoundException //类没有找到异常
3.  IllegalAccessException //安全权限异常，可能是反射时调用了private方法




## 序列化和反序列化


### 序列化理解
我们对序列化做一个最直观的理解，就是把有结构的对象去拉成一个无结构的序列或者某种特定编码的二进制，这个序列可以被用于保存在磁盘上，也可以通过网卡发送到另一台主机上。不管是持久化还是网络传输，我们最终的目标一定是一个字节流。因此序列号的目的就是把**有结构的对象转换为无结构的字节流**。java为我们提供了序列化和反序列化的抽象，即为objectOutputStream和objectInputStream。

### Java序列化

java的序列化非常简单，因为java仅仅为我们提供了两个类型和一个接口。objectOutputStream和objectInputStream就是java为我们提供的序列化和反序列化的工具，而我们如果想要对某一个对象进行序列化，只需要为这个对象标识serializable接口即可。  
serializable仅仅是一个起了标识作用的接口，它声明了一种可序列化的类型，而readObject中会做一个转型操作，将传入的对象统一转型为serializable类型。如果无法转型即实现Serializable接口的话，在序列化时就会抛**NotSerializableException**异常（不是能够序列化的）。  
（字符串、数组和枚举都是可序列化的）

> 基本Java中所有官方提供的对象都实现了serializable接口，因此如果使用serializable作为方法重载的入参，那么所有对象都能够被匹配。


### 版本号问题

这里还需要提到一个**序列化版本号**的东西，它可以被看作**对一个序列化模板的唯一标识**，可以这么理解，一个对象从序列化为一个无结构字节流，再到重新反序列化为原来的对象，这不是通过构造方法进行的，而JVM进行实现的，具体如何实现下面再讨论。  
反序列化时，JVM根据**字节流中的序列号id**与将要被反序列化成的**目标类的序列号ID**进行对比，只有一致才能支持反序列化。而反序列的过程其实一个对象深拷贝的过程。

> 我们当前的待反序列化的字节流中序列号为A，而我们希望最终生成一个目标对象，而这个对象的类的序列号是B，进行反序列化操作时，JVM会对两个序列号A和B进行对比，只有一致才能进行反序列化操作

这是一个**校验机制**，可以保证一个对象即使在网络或磁盘中停留过一次，仍保证数据的正确（能够正确地被还原为一个对象）。实现了类的一致性

序列化版本号JVM会帮我们默认生成，我们也可以自己指定或者使用IDE进行自动生成。推荐后者，如果我们让JVM为我们默认生成，如果我们对序列化对应的模板类进行更改，序列号也会随着发生改变。  
“改变”包括方法签名、修饰符、字段、类名、继承关系等结构上的变化，如果内容（方法的内容、属性的默认值等）、顺序（声明的顺序）、空格的修改并不会新生成序列号（已经经过实验）。这里我做一个基于个人的理解：只有当影响到class文件本身结构发生的变化的修改，才会使得生成一个新的版本号

### 序列化内容

序列化大致存放的就是三类：**对象本身的类型、对象成员字段的类型、当前对象各个成员的值**  
更细一点：**瞬态关键字修饰、静态关键字修饰（因为它不属于实例）、方法包括构造函数、final修饰的变量不会被序列化（会重新计算）**

> java序列化仅保存对象的属性值和类型，因为类是对象的模板，而为属性进行不同的赋值可以对应一个对象，而方法仅仅是一堆字节码指令而已，是不带状态的，方法代表本质上还是对象共用一套模板，是状态的。只有能够拿到某一个类型，classLoader将这个类加载到内存，很容易获得这个类里面有哪些方法。方法的签名等信息在JVM自动生成序列号的时候会进行一个参考

Transient 关键字的作用是控制变量的序列化——瞬态，在变量声明前加上该关键字，可以阻止该变量被序列化到文件中，在被反序列化后，transient 变量的值被设为初始值。

显式声明序列号，我们的反序列化便实现了**版本向上兼容**的功能，允许使用V1版本的应用访问了V2版本的对象，提高了代码的健壮性。此时虽然生产者和消费者对象的类版本不一样，但是显式声明的序列号相同，反序列化也是可以运行的，所带来的业务问题就是消费者不能读取到的新增加的业务属性（还原为零值）

序列化还存在父类与子类之间的问题。  
序列化和可以和clone()进行一个类别，如果不光当前对象是serializable，成员对象也需要是serializable的。同时，一个对象的成员不光是自己声明的，从父类继承的成员也属于它的一部分。因此，如果父类实现了序列化接口，那么子类也间接实现了这个接口。而如果子类实现了这个接口，但是**父类并没有实现这个接口，那么从父类继承下来从成员不会被序列化**。  
另外，**父类必须有无参构造函数**（除非父类没有实现serializable接口），因为反序列化时，往往是从超类对象开始构造，这时就会反射调用空参构造器先拿到一个空对象，然后再慢慢地为填充成员注入值（可以类比Spring Bean的创建过程）

注意：**final变量不会被保存到序列化流中，它的内容总是被重新计算的**。以下三种情况，Final变量不会被赋值：  
【1】通过构造方法为final变量赋值  
【2】通过方法返回值为final变量赋值  
【3】Final修饰的属性不是基本类型

> 反序列化的执行过程是这样的：反序列化的过程中，构造函数不会执行。JVM从数据流中获取一个Object对象，然后根据数据流中的类文件描述信息（例如Person类），查看发现是final变量（例如name），需要重新计算，于是引用了Person类中的name值，而此时JVM又发现name竟然没有赋值于是不会再初始化，保持原值状态

### Java序列化算法

【1】所有保存到磁盘的对象都有一个序列化版本号  
【2】当试图序列化一个对象时，会**先检查该对象是否被序列化过**，只有未被JVM序列化过的对象，才会将该对象序列化为字节序列保存起来  
【3】**如果该对象已经被序列化过，直接保存序列化编号即可**。例如A对象已经被序列化过了，而B对象的一个成员注入了对象A，那么当B序列化时直接保存成员A的序列号

> 该算法的出发点是节省磁盘空间，当同一个对象被连续序列化时，第二次仅仅会保存一份引用，而不是对元数据和数值进行再次存储。

这里也存在出现问题的风险：  
由于序列化算法不会重复序列化同一个对象，只会记录已序列化对象的编号。如果序列化一个可变对象（对象内的内容可更改）后，再次序列化，并不会再次将此对象转换为字节序列，而只是保存序列化编号（**编号对应仍是修改前对象的字节序列，因此当还原这个对象的时候仅仅是初始版本的对象**）

> 反序列化时，必须有序列化对象的class文件。  
> 数组不能显示的声明UID，因为它们始终有默认的计算值，但是对于数组类，无需匹配UID。  
> 如果一个类的成员不是基本类型或string类型，则成员必须实现序列化接口，否则该类无法序列化.

注意：持久化完毕的对象包含两部分：类描述信息和实例变量（类型、值），因此**一个持久化后的对象比class文件要大一些**。

### 重写readObject和writeObject方法

反序列化其实是一个隐式的对象构造过程，我们希望“受控”，则可以选择自行编写readObject函数（重写），用于对象的反序列化构造，从而提供约束性。readObject和writeObject方法会在进行反序列化和序列化时被分别通过反射调用，其中ArrayList就重写了自己的两个方法，并且使用瞬态关键字修饰了底层数组，防止过多不必要的空间被序列化。（也就是说，ArrayList告诉JVM：我不需要你赋值序列化，我自己来就行）

```java
    private void writeObject(ObjectOutputStream out) throws IOException {
        out.writeObject(this.name);
        out.writeInt(this.age);
    }
    private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {
        this.name=(String)in.readObject();
        this.age=in.readInt();
    }

    
```

（注意private void是写死的，是会被检查的，不能改变）  
通过重写writeObject()与readObject()方法，可选择哪些属性要序列化。如果writeObject使用了某种规则进行序列化，则readObject要使用相反的规则进行反序列化。我们往往会在重写的方法中加入加密解密的逻辑，

> JVM在序列化的时候首先会看看对象是否有writeObject()与readObject()方法，如果没有调用的是ObjectOutputStream的defaultWriteObject方法以及ObjectInputStream的defaultReadObject方法。

writeReplace()方法：在序列化前，会先调用该方法，然后再调用writeObject方法。此方法可以使用任意对象代替目标序列化对象。  
readResolve()方法：**替代反序列化输出的对象，反序列化出来的对象会被立即丢弃**，此方法在readObject()后调用  
单例类序列化，需要重写readResolve方法，否则会破坏单例原则。

### 防止对单例序列化的破坏

序列化和反序列化可以达到深拷贝的效果，因此若对于一个单例对象进行该操作，将打破单例的语义。

```java
class Singleton implements Serializable{
    private volatile static Singleton singleton;
    private Singleton (){}
    public static Singleton getSingleton() {
        if (singleton == null) {
            synchronized (Singleton.class) {
                if (singleton == null) {
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }

    private Object readResolve() {
        return singleton;
    }
}


    
```

假如有其他人通过反序列化视图得到一个新的对象，当创建完毕一个对象后会调用readResolve接口，最终将生成的对象丢弃掉，重新返回单例对象。

### Externalizable接口

将对象进行序列化还可以实现**Externalizable接口**，实现了该接口的类，必须实现readExternal(ObjectInput in)和writeExternal(ObjectOutput out)方法  
Externalizable是serializable的子接口，并且提供了readExternal(ObjectInput in)和writeExternal(ObjectOutput out)两个方法，此时你必须提供两个类似writeObject()与readObject()的实现，而不是走默认实现——ObjectOutputStream的defaultWriteObject方法以及ObjectInputStream的defaultReadObject方法。

而且实现了Externalizable接口的类型必须提供默认构造方法，否则反序列化会报错，因为在反序列化时会默认调用无参构造实例化对象，如果没有此无参构造，则运行时将会出现异常。而serializable则不要求一定提供空参构造器。但是采用Externalizable接口的方案无序提供序列化版本号。

> 由于Serializable对象完全以它存储的二进制位为基础来构造，并不会调用任何构造函数，因此Serializable类无需默认构造函数。一种情况除外：父类没有实现serializable但是子类实现了，此时字节流中是没有存放任何父类信息的，但是创建对象时必须拿到父类继承下来的方法、成员。因此反序列化时会调用父类的默认构造方法拿到这部分（字节流里拿不到），如果此时父类如果没有定义默认构造函数，就会报错。  
> 而Externalizable接口方式中，是基于默认构造函数创建对象的，因此必须提供声明为public的构造函数（必须是public，会单独对修饰符modifier进行判断）

### 其他的序列化方式

java的序列化方式性能比较差、只能作用于Java对象，无法实现跨语言。更加推荐使用JSON、protobuf、thrift等方式进行序列化。  
序列化也是实现PRC框架的基础，因为命令总是需要在网络中进行传输的，而选用一种性能高、序列化体积小的方式就能节省网络流量、减少传输使用的时间。


### Java序列化原理

Java序列化的顺序首先按照从子类到父类的顺序，将类型的元信息、属性类型的元信息进行序列化，然后按照从父类到子类的顺序，将成员的字面量进行序列化。如果遇到引用类型，则会进入新的层次的递归。直到所有字面量数据被保存起来。  
这也为我们理解深拷贝打下了基础。序列化流中本质上是没有保存任何引用数据的，都是字面量数据。因此当进行反序列化化时，其实本质上是为空对象进行字面量赋值，如果涉及引用变量则递归进行字面量赋值。

### 总结

序列化/反序列化、clone()实现深拷贝的本质就是“**保存所有的引用对应的字面量，恢复的时候直接进行字面量的赋值，而不是引用/指针**”，如果成员是引用类型，则要求它重写clone()并且在当前类的clone()方法中，递归地调用成员的clone()。或者要求它也是serializable的，原理其实和clone()类似。


