## 高性能IO模型
上来就问：redis单线程为什么快？

先讲下：Redis 是单线程，**主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程**。 但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执 行的。

有I/O操作时用多线程，因为整个程序如果是单线程的话，I/O操作会阻塞住，阻塞时CPU就是空闲的。

redis在数据读写这一个功能下，是不需要I/O的，如果用多线程，涉及到线程切换和线程调度，并没有提高效率，反而造成额外的性能开销。（eg：系统中通常会存在被多线程同时访问的 共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，**为了保证共享资源的正确性**，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开 销，**如锁的开销，上下文切换的开销**。拿 Redis 来说，在上节课中，我提到过，Redis 有 List 的数据类型，并提供出队（LPOP） 和入队（LPUSH）操作。假设 Redis 采用多线程设计，如下图所示，现在有两个线程 A 和 B，线程 A 对一个 List 做 LPUSH 操作，并对队列长度加 1。同时，线程 B 对该 List 执行 LPOP 操作，并对队列长度减 1。为了保证队列长度的正确性，Redis 需要让线程 A 和 B 的 LPUSH 和 LPOP 串行执行，这样一来，Redis 可以无误地记录它们对 List 长度的修 改。否则，我们可能就会得到错误的长度结果。这就是多线程编程模式面临的共享资源的 并发访问控制问题。）

理清了为什么用单线程，下面讲讲其网络的基本IO模型和潜在的阻塞点

一方面，Redis 的**大部分操作在内存上完成**，再加上它采用了**高效的数据结构**，例如哈希表和跳表，这是它实现高性能的一个重要原因。另一方面，就是 Redis 采用了**多路复用机制**，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。

以 Get 请求为例，SimpleKV 为了处理一个 Get 请求，需要监听客户端请求 （bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析 客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结 果，即向 socket 中写回数据（send）。 下图显示了这一过程，其中，bind/listen、accept、recv、parse 和 send 属于网络 IO 处 理，而 get 属于键值数据操作。
![[Pasted image 20220206134348.png]]
在这里的网络 IO 操作中，有潜在的阻塞点，分别是 accept() 和 recv()。当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这 里，导致其他客户端无法和 Redis 建立连接。类似的，当 Redis 通过 recv() 从一个客户端 读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。
**这就导致 Redis 整个线程阻塞，无法处理其他客户端请求，效率很低。不过，幸运的是， socket 网络模型本身支持非阻塞模式。**

非阻塞模式
Socket 网络模型的非阻塞模式设置，主要体现在三个关键的函数调用上

在 socket 模型中，不同操作调用后会返回不同的套接字类型。socket() 方法会返回主动套 接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户 端的连接请求。最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。
![[Pasted image 20220206134420.png]]
bind 和 listen 都不会阻塞，调用accept和send，recv都会阻塞，那现在既要等待后续请求，又要返回处理其他操作并在有数据达到时通知 Redis。 这样才能保证 Redis 线程，既不会像基本 IO 模型中一直在阻塞点等待，也不会导致 Redis 无法处理实际到达的连接请求或数据。

所以引入 **Linux 中的 IO 多路复用机制**

**基于多路复用的高性能 I/O 模型**

Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，**该机制允许内核中，同 时存在多个监听套接字和已连接套接字**。内核会一直监听这些套接字上的连接请求或数据 请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。
![[Pasted image 20220206134822.png]]

为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针 对不同事件的发生，调用相应的处理函数。

那么，回调机制是怎么工作的呢？其实，select/epoll 一旦监测到 FD 上有请求到达时，就 会触发相应的事件。

**这些事件会被放进一个事件队列**，Redis 单线程对该事件队列不断进行处理。这样一来， Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时， Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件 的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。

eg:这两个请求分别对应 Accept 事件和 Read 事件，Redis 分别对这两个事件注册 accept 和 get 回调函数。当 Linux 内核监听到有连接请求或读数据请求时，就会触发 Accept 事件 和 Read 事件，此时，内核就会回调 Redis 相应的 accept 和 get 函数进行处理。



## 持久化机制
### RDB

什么是RDB?

记录redis某一时刻的数据的文件,相当于redis某一时刻数据的快照

阻塞点:

-   当我们使用save命令时,主线程去执行rdb文件的写入,所以会阻塞
    
-   当我们使用bgsave命令时,又会有哪些阻塞点

```markdown
1.fork本身这个操作执行时,内核需要给子进程拷贝一份父进程的页表,通过页表映射子进程能读取到主进程的原始数据.如果主进程的内存大,页表也相应大,拷贝页表的耗时就会长,这是主线程阻塞的时间就变长

2.在bgsave保存rdb时,如果有写请求到来,主线程会把新数据或修改后的数据写到新的物理内存地址上,并修改主线程自己的页表映射.主线程阻塞的点是 申请内存空间以及原本数据页数据的拷贝

第2点为什么要这么做捏?
因为是为了保证数据的完整性,如果主线程直接修改的话,那么就有可能破坏 **快照完整性**, 所以才利用操作系统提供的 写时复制技术(COW)来解决这个问题

那么子进程在写rdb文件时不可以对数据加锁吗?
如果这样做,虽然能保证 快照完整性, 但会降低redis并发性能, 此时主线程只能处理读请求,而写请求将会阻塞
```


**如何尽量保证数据不丢失?**

先讲阻塞点,然后为了提高效率与数据的可靠性,我们既要避免通过频繁bgsave来保证数据不丢失,又要避免频繁bgsave带来的主线程阻塞问题, 所以要尽量避免 全量快照, redis4.0 使用混合 AOF日志和 内存快照的方法, 两次快照, 使用 AOF日志来记录这期间的写操作.

一方面是避免频繁 bgsave 带来的主线程阻塞问题, 另一方面也可以避免 AOF文件过大导致需要重写而消耗一定性能的问题



### AOF

AOF通过保存redis服务器所执行的写命令来记录数据库状态，类似于mysql binlog的statement格式。被写入redis的命令按照请求协议格式保存，是**纯文本格式**的，可读性较高（命令传输的时候也是按照这个格式，命令传播一定程度上也通过AOF实现）。  
AOF功能默认是关闭的，需要append only yes进行开启。

AOF日志记录的是对数据进行新增或修改的操作命令,是写后日志(这点要与MySQL区分)

为什么是日志是写后才记录的

因为 为了**避免额外的检查开销**,redis**在向AOF里面记录日志的时候并不会对这些命令进行语法检查**,所以如果先记录日志再执行命令的话,日志中就可能记录了错误的命令,redis在使用日志恢复数据时就可能出错

写后日志好处和潜在问题
```markdown
好处 : 
1.不会阻塞当前操作

潜在问题:
1.写日志之前宕机了,造成数据丢失
2.AOF虽然不会阻塞当前线程, 但会有阻塞下一个操作的风险. AOF日志是由 ** 主线程 ** 执行的,如果把日志文件写入磁盘时,磁盘读写压力大,那么就会导致写盘很慢,影响到下一个操作
```

对于以上两个潜在问题,核心问题就是 **AOF写回磁盘的时机**

AOF三种写回策略, appendfsync三个可选值:Always，Everysec，No

除了写回策略,AOF还有哪些注意事项
```markdown
1.AOF日志是追加的方式记录写命令
   这就导致了AOF文件可能过大,那文件过大会出现什么问题?
   		1. 无法保存过大文件,文件系统本身对文件大小有限制
   		2. 效率变低,如果文件太大,再往里面追加命令记录的话就会导致效率变低
   		3. 数据恢复过程慢,如果redis宕机了,恢复数据时要一条条执行AOF日志中的命令记录.
   如何解决?
   		本质就是AOF文件过大,所以目的很明确,减少AOF日志文件大小,引入 AOF重写 来解决这个问题
   AOF重写过程
   		AOF重写是由子进程bgrewriteaof来完成的，不用主线程参与,所以子进程的执行不阻塞主线程
   		一处拷贝,两处日志
   		拷贝指的是子进程拷贝父进程的页表
   		两处日志: 1.当前正在使用的AOF日志
   				 2. 新的AOF重写日志
   		如果有新的写操作命令到来时,既会被写到当前AOF日志缓冲区,也会被写到重写AOF日志的缓冲区
   		
   		为什么AOF日志缓冲区要两份呢?
   		首先明确一点就是 AOF重写过程中,AOF日志还是依据我们的策略照常写回磁盘,当写回磁盘后 AOF缓冲区将会清空
   		这就是为什么缓冲区要两份的原因,如果只有一份,那么AOF重写就会丢失部分写操作命令
   		
   		子线程重新AOF日志完成时会向主线程发送信号处理函数，会完成 （1）将AOF重写缓冲区的内容写入到新的AOF文件中。（2）将新的AOF文件改名，原子地替换现有的AOF文件。完成以后才会重新处理客户端请求。
   		
   		为什么不复用AOF原本的日志文件?
   		AOF重写不复用AOF本身的日志，一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。二是如果AOF重写过程中失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可。
```

```markdown
2.AOF重写阻塞点有哪些
	1. fork主进程,页表越大,阻塞时间越长
	2. 在AOF重写时,由于主线程正常处理请求,如果有写请求到来并且要修改的key原本就已经存在,那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。
```

>Huge page。这个特性大家在使用Redis也要注意。Huge page对提升TLB命中率比较友好，因为在相同的内存容量下，使用huge page可以减少页表项，TLB就可以缓存更 多的页表项，能减少TLB miss的开销
>
>但是，这个机制对于Redis这种喜欢用fork的系统来说，的确不太友好，尤其是在Redis的写入请 求比较多的情况下。因为fork后，父进程修改数据采用写时复制，复制的粒度为一个内存页。如 果只是修改一个256B的数据，**父进程需要读原来的内存页，然后再映射到新的物理地址写入**。一 读一写会造成读写放大。如果内存页越大（例如2MB的大页），那么读写放大也就越严重，对Redis性能造成影响。 Huge page在实际使用Redis时是建议关掉的



## 主从集群
为了实现redis高可靠第二点: 尽量减少服务中断的时间,我们就需要增加冗余副本到不同机器,采取主从集群,读写分离的模式来达到目标,但会触发一个多实例数据同步问题

为什么要采取读写分离?
```markdown
因为如果对数据的写操作发给不同的redis实例,那么就会导致一个数据不一致的问题。
如果对数据的写操作都发给主库，由主库将写操作同步给从库，这样就可以大大减少客户端读取到的数据与实际数据不一致的概率
```


### 主从集群的同步过程

第一次同步过程
```markdown
启动多个redis实例，通过 replicaof（redis5.0之前使用 slaveof）命令形成主库和从库的关系

经过三个阶段后完成数据的第一次同步
1. 建立连接，协商同步
2. 主库同步数据给从库
主库执行bgsave生成RDB文件，将其发送给从库。在这段时间内的写操作命令，主库都会在内存中用专门的replication buffer记录
从库清空现有数据,加载RDB
3. 主库发送同步期间新的写命令给从库
当主库完成RDB文件发送后，就会将此时replication buffer中的修改操作发送给从库，从库再执行这些操作，这样一来主从库就实现同步
从库执行加载repl buffer
```

![[Pasted image 20220206133824.png]]


**主从库间网络断了**
redis2.8之前，如果主从库在命令传播时出现网络闪断，那么从库就会和主库重新进行一次全量复制

redis2.8开始，网络断了之后，主从库会尝试使用 **增量复制** 的方式继续同步
>增量复制就是只会把主从库网络断连期间主库收到的写命令同步给从库

增量复制如何实现的？
```markdown
为了找到主从数据差异，主库通过 repl_backlog_buffer 这个环形缓冲区 来判断是否能找到从库断开的位置

repl_backlog_buffer：
主库的写命令除了传播给从库外，还会在这个数据结构中记录一份，缓存起来，只有预先缓存了这些命令，当从库断连后，从库发送自己的id和offset，主库才能通过offset找到从库断开的位置，将offset之后的增量数据发送给从库即可。若找不到offset的位置，则进行全量复制

每个从库会记录自己的slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，**从库会通过psync命令把自己记录的slave_repl_offset发给主库** ，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制。
```


**主从全量同步使用RDB而不用AOF的原因**
```markdown
1.RDB文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。在主从全量数据同步时，传输RDB文件可以尽量降低对主库机器网络带宽的消耗，从库在加载RDB文件时，一是文件小，读取整个文件的速度会很快，二是因为RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量同步的成本最低。

2.假设要使用AOF做全量同步，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量同步数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。
```


**区分repl_backlog_buffer 和 replication buffer**
```markdown
1、repl_backlog_buffer：就是上面我解释到的，它是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量同步带来的性能开销。如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量同步，所以repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量同步的概率。而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer。

2、replication buffer：Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互，客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的：Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer。

3、再延伸一下，既然有这个内存buffer存在，那么这个buffer有没有限制呢？如果主从在传播命令时，因为某些原因从库处理得非常慢，那么主库上的这个buffer就会持续增长，消耗大量的内存资源，甚至OOM。所以Redis提供了client-output-buffer-limit参数限制这个buffer的大小，如果超过限制，主库会强制断开这个client的连接，也就是说从库处理慢导致主库内存buffer的积压达到限制后，主库会强制断开从库的连接，此时主从复制会中断，中断后如果从库再次发起复制请求，那么此时可能会导致恶性循环，引发复制风暴，这种情况需要格外注意。


1. repl_backlog_buffer用于主从间的增量同步。主节点只有一个repl_backlog_buffer缓冲区，各个从节点的offset偏移量都是相对该缓冲区而言的。
2. replication buffer用于主节点与各个从节点间 数据的批量交互。主节点为各个从节点分别创建一个缓冲区，由于各个从节点的处理能力差异，各个缓冲区数据可能不同。

repl_backlog_buffer这个缓冲只在主从重连时才起作用，在主从连接正常时，即使master覆盖了slave的数据也没关系，应为数据都在replication_buffer里，只要replication_buffer没溢出，等slave消费完了replication_buffer，slave_offset也追上去了，只有等到主从重连时才会用到repl_backlog_buffer做判断，正常情况下repl_backlog_buffer只是一直循环写

而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer。
这句话的意思是：先在backlog里通过offset差异，找到差异数据，然后将这部分差异数据同步到replication buffer后，replication buffer才专门的将这部分数据发送给从库，达到增量同步的目的

只要有从节点连接上，在主节点就会有一个repl_backlog_buffer，并且无论从节点是否断开连接，主节点都会把收到的命令写入repl_backlog_buffer，如果从节点连接正常，主节点直接走replication buffer，如果从节点断开连接，等再次连接上时判断offset是否被覆盖，没有被覆盖把slave offset和master offset之间的数据通过replication buffer传输，如果被覆盖则再次RDB走replication buffer全量同步.
如果一个slave都没有了，那backlog buffer也会释放了。
```


**环形缓冲期很大导致数据不同步怎么处理？比方说，一个从库长断网以后，长时间没有联网处理。**
```markdown
没错，环形缓冲区再大，在某些时候，就如你所说的从库长期断网时，也会出问题。

其实从库正常情况下会每秒给主库发送一个replconf ack命令，主库会根据这个命令的达到时间判断和从库的连网情况。如果距离最后一次ack命令收到的时间已经超过了repl_timeout时间，就会和从库断开连接了。

从库再和主库连接时，会发送自己的复制进度，如果要复制内容在缓冲区中已经被覆盖了，那么就不再做增量复制了，而是进行全量复制。
```


疑惑就是同步数据这个过程主线程执行的还是别的线程执行
```markdown
repl_backlog_size这个参数很重要，因为如果满了，就需要重新全量复制，默认是1M，所以之前网上就流传1个段子，如果一个公司说自己体量如何大，技术多么牛，要是repl_backlog_size参数是默认值，基本可以认为要不业务体量吹牛逼了，要不就没有真正的技术牛人。

主从复制的另一种方式：基于硬盘和无盘复制
可以通过这个参数设置
repl-diskless-sync
复制集同步策略：磁盘或者socket
新slave连接或者老slave重新连接时候不能只接收不同，得做一个全同步。需要一个新的RDB文件dump出来，然后从master传到slave。可以有两种情况：
 1）基于硬盘（disk-backed）：master创建一个新进程dump RDB，完事儿之后由父进程（即主进程）增量传给slaves。
 2）基于socket（diskless）：master创建一个新进程直接dump RDB到slave的socket，不经过主进程，不经过硬盘。

当基于 disk-backed 复制时，当 RDB 文件生成完毕，多个 replicas 通过排队来同步 RDB 文件。

当基于diskless的时候，master等待一个repl-diskless-sync-delay的秒数，如果没slave来的话，就直接传，后来的得排队等了。否则就可以一起传。适用于disk较慢，并且网络较快的时候，可以用diskless。（默认用disk-based）


回答下课后问题：
    1、RDB读取快，这样从库可以尽快完成RDB的读取，然后入去消费replication buffer的数据。如果是AOF的话，AOF体积大，读取慢，需要更大的replication buffer，如果一个主节点的从节点多的话，就需要更大的内存去处理；
    2、AOF文件是append追加模式，同时读写需要考虑并发安全问题，并且AOF是文本文件，体积较大，浪费网络带宽。

最后问老师个问题哈，就是bgsave生成的rdb文件什么时候“过期”，或者有过期的说法吗？比如我2个从节点执行replicaof（或者slaveof），主节点是同一个，这中情况下，rdb生成1次还是2次？

A从节点向主节点申请全量同步，
在主节点创建完成RDB文件之前，如果B从节点也向主及诶点申请全量同步的话，RDB只会生成一次。
在主节点创建完成RDB文件之后，如果B从节点也向主及诶点申请全量同步的话，主节点会在完成A节点的RDB文件同步之后，再重新创建RDB文件给B节点的同步。
```


## 哨兵
首先为什么要引入哨兵?

引入哨兵的最终目的是 当前主库挂了，但还是能不间断服务



怎么做到这点？

将一个从库切换为主库



这种方式会涉及哪些问题？

1. 主库真的挂了吗？ 
2. 该选择哪个从库作为主库？ 
3. 怎么把新主库的相关信息通知给从库和客户端呢


在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机 制，它有效地解决了**主从复制模式下故障转移**的这三个问题


### 哨兵机制
#### 基本流程
哨兵机制，它是实现 Redis 不间断服务的重要保证。具体来说， 主从集群的数据同步，是数据可靠的基础保证；而在主库发生故障时，自动的主从切换是服务不间断的关键支撑。

哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。

我们先看监控。监控是指哨兵进程在运行时，周期性地给所有的主从库发送 PING 命令， 检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“下线状态”；如果主库也没有在规定时间内响应哨兵的 PING 命令，如果是单哨兵模式情况下,哨兵会直接标记主库为主观下线,然后开始新主库的选举工作, 若是部署的是哨兵集群,则会先标记主库主观下线，再进行客观下线的判定，若通过则开始自动切换主库的流程。

这个流程首先是执行哨兵的第二个任务，选主。主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。

然后，哨兵会执行最后一个任务：通知。在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时， 哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。

![[Pasted image 20220203195116.png]]
**哨兵需要做出的两个决策：**

1.  在监控任务中，哨兵需要判断主从库是否处于下线状态；
    
2.  在选主任务中，哨兵也要决定选择哪个从库实例作为主库。


##### 监控

哨兵存在误判的情况，若是哨兵误判后启动主从切换，则后续的选主和通知操作都会带来额外的计算和通信开销

**什么是误判？**

主库实际并没有下线，但是哨兵误以为它下线 了。误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况 下。

**误判带来的影响？**

一旦哨兵判断主库下线了，就会开始选择新主库，并让从库和新主库进行数据同步，这个过程本身就会有开销，例如，哨兵要花时间选出新主库，从库也需要花时间和新主库同 步。而在误判的情况下，主库本身根本就不需要进行切换的，所以这个过程的开销是没有价值的。正因为这样，我们需要判断是否有误判，以及减少误判。

**如何减少误判**

概括：集群，少数服从多数

通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。

在判断主库是否下线时，不能由一个哨兵说了算，只有大多数的哨兵实例，都判断主库已 经“主观下线”了，主库才会被标记为“客观下线”，这个叫法也是表明主库下线成为一 个客观事实了。这个判断原则就是：少数服从多数。同时，这会进一步触发哨兵开始主从切换流程。

**客观下线的标准**

“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判 断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判 的概率，也能避免误判带来的无谓的主从库切换。（当然，有多少个实例做出“主观下线”的判断才可以，可以由 Redis 管理员自行设定）

##### 选主

一般来说，我把哨兵选择新主库的过程称为“筛选 + 打分”。简单来说，我们在多个从库 中，先按照**一定的筛选条件**，把不符合条件的从库去掉。然后，我们再按照**一定的规则**， 给剩下的从库逐个打分，将得分最高的从库选为新主库，如下图所示：
![[Pasted image 20220203200104.png]]

**过滤**

在选主时，**除了要检查从库的当前在线状态，还要判断它之前的网络连接状态**

具体怎么判断呢？你使用配置项 down-after-milliseconds * 10。其中，down-after-milliseconds 是我们认定主从库断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连 了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。

就过滤掉了不适合做主库的从库，完成了筛选工作。

**打分**

接下来就要给剩余的从库打分了。我们可以分别按照三个规则依次进行三轮打分，这三个 规则分别是从库优先级、从库复制进度以及从库 ID 号。**只要在某一轮中，有从库得分最高，那么它就是主库了**，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。

**第一轮：优先级最高的从库得分高。**

用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如，你有两个从 库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时， 哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如 果从库的优先级都一样，那么哨兵开始第二轮打分。

**第二轮：和旧主库同步程度最接近的从库得分高。**

这个规则的依据是，如果选择和旧主库同步最接近的那个从库作为主库，那么，这个新主 库上就有最新的数据。

如何判断从库和旧主库间的同步进度呢？

主从库同步时有个命令传播的过程。在这个过程中，主库会用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会 用 slave_repl_offset 这个值记录当前的复制进度

此时，我们想要找的从库，它的 slave_repl_offset 需要最接近 master_repl_offset。如果 在所有从库中，有从库的 slave_repl_offset 最接近 master_repl_offset，那么它的得分就 最高，可以作为新主库。

如果有两个从库的 slave_repl_offset 值大小是一样的（例如，从库 1 和从库 2 的 slave_repl_offset 值都是 990），我们就需要给它们进行第三轮打分了。

**第三轮：ID 号小的从库得分高。**

每个实例都会有一个 ID，这个 ID 就类似于这里的从库的编号。目前，Redis 在选主库 时，有一个默认的规定：在优先级和复制进度都相同的情况下，ID 号最小的从库得分最 高，会被选为新主库。到这里，新主库就被选出来了，“选主”这个过程就完成了。


##### 通知
从本质上说，哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。
![[Pasted image 20220204132806.png]]
知道了这些频道之后，你就可以让客户端从哨兵这里订阅消息了。具体的操作步骤是，客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，我们可以在客户端执行订阅命令，来获取不同的事件消息。

当哨兵把新主库选择出来后，客户端就会看到下面的 switch-master 事件。这个事件表示主库已经切换了，新主库的 IP 地址和端口信息已经有了。这个时候，客户端就可以用这里面的新主库地址和端口进行通信了。

有了这些事件通知，客户端不仅可以在主从切换后得到新主库的连接信息，还可以监控到主从库切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。

有了 pub/sub 机制，哨兵和哨兵之间、哨兵和从库之间、哨兵和客户端之间就都能建立起连接了，再加上我们上节课介绍主库下线判断和选主依据，哨兵集群的监控、选主和通知三个任务就基本可以正常工作了

#### 主从切换由哨兵集群中的哪一个进行实际的主从切换
**“客观下线”具体的判断过程**

任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。
![[Pasted image 20220204132858.png]]


一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的。例如，现在有 5 个哨兵，quorum 配置的是 3，那么，一个哨兵需要 3 张赞成票，就可以标记主库为“客观下线”了。这 3 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。

此时，**这个哨兵**就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“Leader 选举”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader。

在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。以 3 个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。

这轮投票没有产生 Leader的话，哨兵集群会等待一段时间（也就是哨兵故障转移超时时间的 2 倍），再重新选举。这是因为，哨兵集群能够进行成功投票，很大程度上依赖于选举命令的正常网络传播。如果网络压力较大或有短时堵塞，就可能导致没有一个哨兵能拿到半数以上的赞成票。所以，等到网络拥塞好转之后，再进行投票选举，成功的概率就会增加。

需要注意的是，如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，**必须获得 2 票**，而不是 1 票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置 3 个哨兵实例。这一点很重要，你在实际应用时可不能忽略了。

**要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds**。我们曾经就踩过一个“坑”。当时，在我们的项目中，因为这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库形成共识，也就没有及时切换主库，最终的结果就是集群服务不稳定。所以，你一定不要忽略这条看似简单的经验。


#### 思考
通过哨兵机制，可以实现主从库的自动 切换，这是实现服务不间断的关键支撑，同时，我也提到了主从库切换是需要一定时间 的。所以，请你考虑下，在这个切换过程中，客户端能否正常地进行请求操作呢？如果想 要应用程序不感知服务的中断，还需要哨兵或需要客户端再做些什么吗？

```markdown
如果客户端使用了读写分离，那么读请求可以在从库上正常执行，不会受到影响。但是由于此时主库已经挂了，而且哨兵还没有选出新的主库，所以在这期间写请求会失败，失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库的时间。

如果不想让业务感知到异常，客户端只能把写失败的请求先缓存起来或写入消息队列中间件中，等哨兵切换完主从后，再把这些写请求发给新的主库，但这种场景只适合对写入请求返回值不敏感的业务，而且还需要业务层做适配，另外主从切换时间过长，也会导致客户端或消息队列中间件缓存写请求过多，切换完成之后重放这些请求的时间变长。

哨兵检测主库多久没有响应就提升从库为新的主库，这个时间是可以配置的（down-after-milliseconds参数）。配置的时间越短，哨兵越敏感，哨兵集群认为主库在短时间内连不上就会发起主从切换，这种配置很可能因为网络拥塞但主库正常而发生不必要的切换，当然，当主库真正故障时，因为切换得及时，对业务的影响最小。如果配置的时间比较长，哨兵越保守，这种情况可以减少哨兵误判的概率，但是主库故障发生时，业务写失败的时间也会比较久，缓存写请求数据量越多。

应用程序不感知服务的中断，还需要哨兵和客户端做些什么？当哨兵完成主从切换后，客户端需要及时感知到主库发生了变更，然后把缓存的写请求写入到新库中，保证后续写请求不会再受到影响，具体做法如下：

哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于哨兵主动通知客户端。

如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，客户端也需要支持主动去获取最新主从的地址进行访问。

所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址。

一般Redis的SDK都提供了通过哨兵拿到实例地址，再访问实例的方式，我们直接使用即可，不需要自己实现这些逻辑。当然，对于只有主从实例的情况，客户端需要和哨兵配合使用，而在分片集群模式下，这些逻辑都可以做在proxy层，这样客户端也不需要关心这些逻辑了，Codis就是这么做的。

另外再简单回答下哨兵相关的问题：

1、哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？

这个属于分布式系统领域的问题了，指的是在分布式系统中，如果存在故障节点，整个集群是否还可以提供服务？而且提供的服务是正确的？

这是一个分布式系统容错问题，这方面最著名的就是分布式领域中的“拜占庭将军”问题了，“拜占庭将军问题”不仅解决了容错问题，还可以解决错误节点的问题，虽然比较复杂，但还是值得研究的，有兴趣的同学可以去了解下。

简单说结论：存在故障节点时，只要集群中大多数节点状态正常，集群依旧可以对外提供服务。具体推导过程细节很多，大家去查前面的资料了解就好。

2、哨兵集群多数实例达成共识，判断出主库“客观下线”后，由哪个实例来执行主从切换呢？

哨兵集群判断出主库“主观下线”后，会选出一个“哨兵领导者”，之后整个过程由它来完成主从切换。

但是如何选出“哨兵领导者”？这个问题也是一个分布式系统中的问题，就是我们经常听说的共识算法，指的是集群中多个节点如何就一个问题达成共识。共识算法有很多种，例如Paxos、Raft，这里哨兵集群采用的类似于Raft的共识算法。

简单来说就是每个哨兵设置一个随机超时时间，超时后每个哨兵会请求其他哨兵为自己投票，其他哨兵节点对收到的第一个请求进行投票确认，一轮投票下来后，首先达到多数选票的哨兵节点成为“哨兵领导者”，如果没有达到多数选票的哨兵节点，那么会重新选举，直到能够成功选出“哨兵领导者”。




环形缓冲区的位置偏移量是单调递增的。主库的被称为：master_repl_offset，从库的被称为：slave_repl_offset，其实两者本质是相同的，叫不同的名字只是为了区分



master_repl_offset是单调增加的，它的值可以大于repl_backlog_size。Redis会用一个名为repl_backlog_idx的值记录在环形缓冲区中的最新写入位置。
举个例子，例如写入len的数据，那么
master_repl_offset += len
repl_backlog_idx += len
但是，如果repl_backlog_idx等于repl_backlog_size时，repl_backlog_idx会被置为0，表示从环形缓冲区开始位置继续写入。

而在实际的选主代码层面，sentinel是直接比较从库的slave_repl_offset，来选择和主库最接近的从库。
```



### 哨兵集群
如果有哨兵实例在运行时发生了故障，主从库还能正常切换吗？

实际上，一旦多个实例组成了哨兵集群，即使有哨兵实例出现故障挂掉了，其他哨兵还能继续协作完成主从库切换的工作，包括判定主库是不是处于下线状态，选择新主库，以及通知从库和客户端。

如果你部署过哨兵集群的话就会知道，在配置哨兵的信息时，我们只需要用到下面的这个配置项，设置**主库的 IP** 和**端口**，并没有配置其他哨兵的连接信息。

`sentinel monitor <master-name> <ip> <redis-port> <quorum>`

这些哨兵实例既然都不知道彼此的地址，又是怎么组成集群的呢？要弄明白这个问题，我们就需要学习一下哨兵集群的组成和运行机制了。

#### 基于 pub/sub 机制的哨兵集群组成

哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。

哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。

除了哨兵实例，我们自己编写的应用程序也可以通过 Redis 进行消息的发布和订阅。所以，为了区分不同应用的消息，Redis 会以**频道**的形式，对这些消息进行分门别类的管理。所谓的频道，实际上就是消息的类别。当消息类别相同时，它们就属于同一个频道。反之，就属于不同的频道。**只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。**

在主从集群中，主库上有一个名为“__sentinel__:hello”的频道，不同哨兵就是通过它来相互发现，实现互相通信的。
>我来举个例子，具体说明一下。在下图中，哨兵 1 把自己的 IP（172.16.19.3）和端口（26579）发布到“**sentinel**:hello”频道上，哨兵 2 和 3 订阅了该频道。那么此时，哨兵 2 和 3 就可以从这个频道直接获取哨兵 1 的 IP 地址和端口号。然后，哨兵 2、3 可以和哨兵 1 建立网络连接。通过这个方式，哨兵 2 和 3 也可以建立网络连接，这样一来，哨兵集群就形成了。它们相互间可以通过网络连接进行通信，比如说对主库有没有下线这件事儿进行判断和协商![[Pasted image 20220204133149.png]]

**哨兵除了彼此之间建立起连接形成集群外，还需要和从库建立连接。这是因为，在哨兵的监控任务中，它需要对主从库都进行心跳判断，而且在主从库切换完成后，它还需要通知从库，让它们和新主库进行同步**。

**哨兵是如何知道从库的 IP 地址和端口的呢？**
这是由哨兵向主库发送 INFO 命令来完成的。就像下图所示，哨兵 2 给主库发送 INFO 命令，主库接受到这个命令后，就会把**从库列表返回**给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。哨兵 1 和 3 可以通过相同的方法和从库建立连接。
![[Pasted image 20220204133225.png]]

通过 pub/sub 机制，哨兵之间可以组成集群，同时，哨兵又通过 INFO 命令，获得了从库连接信息，也能和从库建立连接，并进行监控了。

但是，哨兵不能只和主、从库连接。因为，主从库切换后，客户端也需要知道新主库的连接信息，才能向新主库发送请求操作。所以，哨兵还需要完成把新主库的信息告诉客户端这个任务。

在实际使用哨兵时，我们有时会遇到这样的问题：如何在客户端通过监控了解哨兵进行主从切换的过程呢？比如说，主从切换进行到哪一步了？这其实就是要求，客户端能够获取到哨兵集群在监控、选主、切换这个过程中发生的各种事件。

我们仍然可以依赖 pub/sub 机制，来帮助我们完成哨兵和客户端间的信息同步

#### 思考
假设有一个 Redis 集群，是“一主四从”，同时配置了包含 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？此外，哨兵实例是不是越多越好呢，如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处呢？
```markdown
1、哨兵集群可以判定主库“主观下线”。由于quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，哨兵集群可以判定主库为“客观下线”。

2、但哨兵不能完成主从切换。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5/2+1=3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到多数选票的结果。

但是投票选举过程的细节并不是大家认为的：每个哨兵各自1票，这个情况是不一定的。下面具体说一下：

场景a：哨兵A先判定主库“主观下线”，然后马上询问哨兵B（注意，此时哨兵B只是被动接受询问，并没有去询问哨兵A，也就是它还没有进入判定“客观下线”的流程），哨兵B回复主库已“主观下线”，达到quorum=2后哨兵A此时可以判定主库“客观下线”。此时，哨兵A马上可以向其他哨兵发起成为“哨兵领导者”的投票，哨兵B收到投票请求后，由于自己还没有询问哨兵A进入判定“客观下线”的流程，所以哨兵B是可以给哨兵A投票确认的，这样哨兵A就已经拿到2票了。等稍后哨兵B也判定“客观下线”后想成为领导者时，因为它已经给别人投过票了，所以这一轮自己就不能再成为领导者了。

场景b：哨兵A和哨兵B同时判定主库“主观下线”，然后同时询问对方后都得到可以“客观下线”的结论，此时它们各自给自己投上1票后，然后向其他哨兵发起投票请求，但是因为各自都给自己投过票了，因此各自都拒绝了对方的投票请求，这样2个哨兵各自持有1票。

场景a是1个哨兵拿到2票，场景b是2个哨兵各自有1票，这2种情况都不满足大多数选票(3票)的结果，因此无法完成主从切换。

经过测试发现，场景b发生的概率非常小，只有2个哨兵同时进入判定“主观下线”的流程时才可以发生。我测试几次后发现，都是复现的场景a。

哨兵实例是不是越多越好？

并不是，我们也看到了，哨兵在判定“主观下线”和选举“哨兵领导者”时，都需要和其他节点进行通信，交换信息，哨兵实例越多，通信的次数也就越多，而且部署多个哨兵时，会分布在不同机器上，节点越多带来的机器故障风险也会越大，这些问题都会影响到哨兵的通信和选举，出问题时也就意味着选举时间会变长，切换主从的时间变久。

调大down-after-milliseconds值，对减少误判是不是有好处？

是有好处的，适当调大down-after-milliseconds值，当哨兵与主库之间网络存在短时波动时，可以降低误判的概率。但是调大down-after-milliseconds值也意味着主从切换的时间会变长，对业务的影响时间越久，我们需要根据实际场景进行权衡，设置合理的阈值。



图示哨兵选举过程中，选举的结果取决于S2的投票，如果S2也投给自己，并且每轮投票都是只投给自己，岂不是无法选出“Leader”，是不是这个过程从了死循环呢？投票投给谁，依据是什么？
1.文章中的例子里，要发生S1、S2和S3同时同自己投票的情况，这需要这三个哨兵基本同时判定了主库客观下线。但是，不同哨兵的网络连接、系统压力不完全一样，接收到下线协商消息的时间也可能不同，所以，它们同时做出主库客观下线判定的概率较小，一般都有个先后关系。文章中的例子，就是S1、S3先判定，S2一直没有判定。

其次，哨兵对主从库进行的在线状态检查等操作，是属于一种时间事件，用一个定时器来完成，一般来说每100ms执行一次这些事件。每个哨兵的定时器执行周期都会加上一个小小的随机时间偏移，目的是让每个哨兵执行上述操作的时间能稍微错开些，也是为了避免它们都同时判定主库下线，同时选举Leader。

最后，即使出现了都投给自己一票的情况，导致无法选出Leader，哨兵会停一段时间（一般是故障转移超时时间failover_timeout的2倍），然后再可以进行下一轮投票。

2.哨兵如果没有给自己投票，就会把票投给第一个给它发送投票请求的哨兵。后续再有投票请求来，哨兵就拒接投票了。




[(53条消息) Redis Sentinel 模式最少几个Sentinel节点_程序袁小黑-CSDN博客_redis哨兵最少几台](https://blog.csdn.net/ydonghao2/article/details/97639095)
一般节点和sentinel都用奇数个节点，有利于防止脑裂。
```


## 切片集群
切片集群或者分片集群，用来存储大量数据的。为什么redis要使用它呢？redis的Master-Slave集群不行吗？这个也可以很简单的理解，因为后者是主备存储，前者是集群存储。

主备存储目的就是两个，一个就是防止主从任意一个节点挂掉而导致服务不可用；另一个作用就是缓解读写压力，所有的读取数据的操作不但master可以承担，所有的从节点也可以去承担，这样对于读多写少的场景非常适合，所有的写可以直接写入master节点，然后通过rdb和buffer模式同步给从节点，这样保证整个主备集群数据都是一致的。

但是主备有个缺陷就是无法保存大量数据，因为一旦Master数据超过几十G之后，那么不管是主从集群rdb同步还是命令写入都是非常高危的，严重的情况下会导致主备集群直接不可用，因此为了解决这个问题，redis官方引入了Redis Cluster，它完全可以解决大量数据存储问题。

不过，在只使用单个实例的时候，数据存在哪儿，客户端访问哪儿，都是非常明确的，但是，切片集群不可避免地涉及到多个实例的分布式管理问题。要想把切片集群用起来，我们就需要解决两大问题：

-   数据切片后，在多个实例之间如何分布？
    
-   客户端怎么确定想要访问的数据在哪个实例上？



#### 1. Redis Cluster的目标
分布式的。

高性能和线性扩展，上线可水平扩展到1000个节点。

没有代理，使用异步复制(gossip协议)，也没有对值执行合并操作。

那些与大多数节点相连的客户端所做的写入操作，系统尝试全部都保存下来。不过公认的，还是会有小部分写入会丢失。

绝大多数的主节点是可达的，并且对于每一个不可达的主节点都至少有一个它的从节点可达的情况下，Redis 集群仍能进行分区(hash slot)操作。

#### 2. Redis Cluster的命令集
Redis Cluster实现了所有在非分布式Redis版本(单机或者主备)中出现的处理单一键值的命令。

那些使用多个键值的复杂操作，比如set里的并集（unions）和交集（intersections）操作，就没有实现。

Redis Cluster不像单机版本的Redis那样支持多个数据库，集群只有数据库0，而且也不支持SELECT命令。
#### 3. Redis Cluster 通信协议
在 Redis Cluster中，节点负责存储数据、记录集群的状态（包括键值对到正确节点的映射）。集群节点同样能自动发现其他节点，检测出没正常工作的节点，并且在需要的时候在从节点中选出主节点。

为了执行这些任务，所有的集群节点都通过TCP连接和一个二进制协议（集群连接，cluster bus）建立通信。这样每一个节点都通过集群连接（cluster bus）与集群上的其余每个节点连接起来。连接上之后所有节点使用一个**gossip协议**来传播集群的信息，这样可以：发现新的节点、 发送ping包（用来确保所有节点都在正常工作中）、在特定情况发生时发送集群消息。集群连接也用于在集群中发布或订阅消息。
由于集群节点不能代理请求，客户端可能被重定向到其他节点使用重定向错误-MOVED和-ASK。从理论上讲，客户端可以自由地向集群中的所有节点发送请求，并在需要时被重定向，因此客户端不需要保存集群的状态。然而，能够缓存键和节点之间的映射的客户端可以提高处理请求性能。
#### 4. Redis Cluster key如何存储
Redis Cluster方案采用哈希槽（Hash Slot）来处理数据和实例之间的映射关系。在Redis Cluster方案中，一个切片集群共有16384个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的key被映射到一个哈希槽中。

具体的映射过程分为两大步：首先根据键值对的key按照CRC16算法计算一个16bit的值；然后再用这个16bit值对16384取模，得到0~16383范围内的模数，每个模数代表一个相应编号的哈希槽。

那么，这些哈希槽又是如何被映射到具体的Redis实例上的呢？

我们在部署Redis Cluster方案时，可以使用cluster create命令创建集群，此时Redis会自动把这些槽平均分布在集群实例上。例如，如果集群中有N个实例，那么每个实例上的槽个数为16384/N个。当然我们也可以使用cluster meet命令手动建立实例间的连接，形成集群，再使用cluster addslots命令，指定每个实例上的哈希槽个数。
```redis
redis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1
redis-cli -h 172.16.19.4 –p 6379 cluster addslots 2,3
redis-cli -h 172.16.19.5 –p 6379 cluster addslots 4
```
在集群运行的过程中，key1和key2计算完CRC16值后，对哈希槽总个数5取模，再根据各自的模数结果，就可以被映射到对应的实例1和实例3上了。另外，在手动分配哈希槽时，需要把16384个槽都分配完，否则Redis集群无法正常工作。


#### 5. 客户端如何定位数据
在定位键值对数据时，它所处的哈希槽是可以通过计算得到的，这个计算可以在客户端发送请求时来执行。但是，要进一步定位到实例，**还需要知道哈希槽分布在哪个实例上。**
客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端

但是，在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个:
-   在集群中，实例有新增或删除，Redis 需要重新分配哈希槽；
    
-   为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。

实例之间还可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。这就会导致，它缓存的分配信息和最新的分配信息就不一致了，那该怎么办呢？

Redis Cluster 方案提供了一种重定向机制，所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。
那客户端又是怎么知道重定向时的新实例的访问地址呢？当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址。

![[Pasted image 20220204130242.png]]

需要注意的是，在上图中，当客户端给实例 2 发送命令时，Slot 2 中的数据已经全部迁移到了实例 3。在实际应用时，如果 Slot 2 中的数据比较多，就可能会出现一种情况：客户端向实例 2 发送请求，但此时，Slot 2 中的数据只有一部分迁移到了实例 3，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息，如下所示：
![[Pasted image 20220204130440.png]]

这个结果中的 ASK 命令就表示，客户端请求的键值对所在的哈希槽 13320，在 172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5 这个实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 GET 命令，以读取数据。

ASK 命令表示两层含义：第一，表明 Slot 数据还在迁移中；第二，ASK 命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 ASKING 命令，然后再发送操作命令。
和 MOVED 命令不同，ASK 命令并不会更新客户端缓存的哈希槽分配信息。所以，在上图中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。这也就是说，ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。

#### 思考
Redis Cluster 方案通过哈希槽的方式把键值对分配到不同的实例上，这个过程需要对键值对的 key 做 CRC 计算，然后再和哈希槽做映射，这样做有什么好处吗？如果用一个表直接把键值对和实例的对应关系记录下来（例如键值对 1 在实例 2 上，键值对 2 在实例 1 上），这样就不用计算 key 和哈希槽的对应关系了，只用查表就行了，Redis 为什么不这么做呢？
```markdown
1、整个集群存储key的数量是无法预估的，key的数量非常多时，直接记录每个key对应的实例映射关系，这个映射表会非常庞大，这个映射表无论是存储在服务端还是客户端都占用了非常大的内存空间。

2、Redis Cluster采用无中心化的模式（无proxy，客户端与服务端直连），客户端在某个节点访问一个key，如果这个key不在这个节点上，这个节点需要有纠正客户端路由到正确节点的能力（MOVED响应），这就需要节点之间互相交换路由表，每个节点拥有整个集群完整的路由关系。如果存储的都是key与实例的对应关系，节点之间交换信息也会变得非常庞大，消耗过多的网络资源，而且就算交换完成，相当于每个节点都需要额外存储其他节点的路由表，内存占用过大造成资源浪费。

3、当集群在扩容、缩容、数据均衡时，节点之间会发生数据迁移，迁移时需要修改每个key的映射关系，维护成本高。

4、而在中间增加一层哈希槽，可以把数据和节点解耦，key通过Hash计算，只需要关心映射到了哪个哈希槽，然后再通过哈希槽和节点的映射表找到节点，相当于消耗了很少的CPU资源，不但让数据分布更均匀，还可以让这个映射表变得很小，利于客户端和服务端保存，节点之间交换信息时也变得轻量。

5、当集群在扩容、缩容、数据均衡时，节点之间的操作例如数据迁移，都以哈希槽为基本单位进行操作，简化了节点扩容、缩容的难度，便于集群的维护和管理。

另外，我想补充一下Redis集群相关的知识，以及我的理解：

Redis使用集群方案就是为了解决单个节点数据量大、写入量大产生的性能瓶颈的问题。多个节点组成一个集群，可以提高集群的性能和可靠性，但随之而来的就是集群的管理问题，最核心问题有2个：请求路由、数据迁移（扩容/缩容/数据平衡）。

1、请求路由：一般都是采用哈希槽的映射关系表找到指定节点，然后在这个节点上操作的方案。

Redis Cluster在每个节点记录完整的映射关系(便于纠正客户端的错误路由请求)，同时也发给客户端让客户端缓存一份，便于客户端直接找到指定节点，客户端与服务端配合完成数据的路由，这需要业务在使用Redis Cluster时，必须升级为集群版的SDK才支持客户端和服务端的协议交互。

其他Redis集群化方案例如Twemproxy、Codis都是中心化模式（增加Proxy层），客户端通过Proxy对整个集群进行操作，Proxy后面可以挂N多个Redis实例，Proxy层维护了路由的转发逻辑。操作Proxy就像是操作一个普通Redis一样，客户端也不需要更换SDK，而Redis Cluster是把这些路由逻辑做在了SDK中。当然，增加一层Proxy也会带来一定的性能损耗。

2、数据迁移：当集群节点不足以支撑业务需求时，就需要扩容节点，扩容就意味着节点之间的数据需要做迁移，而迁移过程中是否会影响到业务，这也是判定一个集群方案是否成熟的标准。

Twemproxy不支持在线扩容，它只解决了请求路由的问题，扩容时需要停机做数据重新分配。而Redis Cluster和Codis都做到了在线扩容（不影响业务或对业务的影响非常小），重点就是在数据迁移过程中，客户端对于正在迁移的key进行操作时，集群如何处理？还要保证响应正确的结果？

Redis Cluster和Codis都需要服务端和客户端/Proxy层互相配合，迁移过程中，服务端针对正在迁移的key，需要让客户端或Proxy去新节点访问（重定向），这个过程就是为了保证业务在访问这些key时依旧不受影响，而且可以得到正确的结果。由于重定向的存在，所以这个期间的访问延迟会变大。等迁移完成之后，Redis Cluster每个节点会更新路由映射表，同时也会让客户端感知到，更新客户端缓存。Codis会在Proxy层更新路由表，客户端在整个过程中无感知。

除了访问正确的节点之外，数据迁移过程中还需要解决异常情况（迁移超时、迁移失败）、性能问题（如何让数据迁移更快、bigkey如何处理），这个过程中的细节也很多。

Redis Cluster的数据迁移是同步的，迁移一个key会同时阻塞源节点和目标节点，迁移过程中会有性能问题。而Codis提供了异步迁移数据的方案，迁移速度更快，对性能影响最小，当然，实现方案也比较复杂。
    
```

##### 一致性hash和哈希槽
请问下redis集群模式为什么不采用一致性hash，而是用这种槽的方式？
Redis Cluster does not use consistent hashing, but a different form of sharding where every key is conceptually part of what we call a hash slot.
```markdown
一致性hash通常用来解决当集群节点数变化时，大量缓存无法命中的情况，因为hashcode/节点数，节点数的变化使得大部分计算结果都发生了变化。一致性hash可以保证同一个key在节点数变化的时候，大部分“hashcode/节点数”仍然能计算出相同结果。
而redis的槽设计，将节点数设定为16384，每个节点分配一定的槽数，客户端也可以缓存槽与节点的对应关系，节点与节点之间也知道槽与节点的对应关系。槽的设计就像是客户端与redis集群的一个中间层，它将集群中存储空间的分配具象化了。你可以让节点A多分配几个槽，以增大节点A承受的压力，也可以对节点B少分配几个槽，以降低节点B承受的压力，当然，一致性hash也可以实现，但没有槽来得这么具体。
想象一下没有槽的设计，客户端需要去服务器获取一个key，首先需要计算key的hash值，然后获取hash环，定位key所在的redis节点（如果需要增加平衡度，可能还需要引入虚拟节点，根据虚拟节点再找真实节点）。在这个过程中，槽比hash环的设计，性能是更高的，同时在压力分配问题上也更加灵活。

我的结论是：都可以，但槽更加合适。不管是性能上，还是可维护性，灵活性都更高。
    
还一个原因，用映射表可能会导致数据分布不均匀。
因为如果要分布均匀，有三种方案：
一个是取余放入，一个是先哈希hash再取余放入（目前redis用此方案），还一个是随机放入，
因为字符串的存在，无法直接取余，而随机放入的效果不如hash取余稳定。

1.引入哈希槽，将key的分布与具体的Redis实例解耦，有利于Redis数据的均衡分布。
2.不采用哈希槽的话，Redis实例的扩容和缩容，需要针对无规则的key进行处理，实现数据迁移。此外，需要引入负载均衡中间件来协调各个Redis实例的均衡响应，确保数据的均匀分布；中间件需要保存key的分布状态，保证key的查询能够得到响应。
增加了Redis系统的复杂性 与 可维护性。


hash槽里面会存储什么吗，比如说会存keys吗，移动槽的时候怎么知道有哪些数据要迁移呢？或者说每个slot在内存中有一个固定区域吗
每个哈希槽会记录自己处理（占有）哪些槽 slots，还有一个 slots_to_keys 跳跃表记录了槽和键之间的关系（score是槽号，member是键），这样就能找到这个槽/数据库对应的所有数据



这么说一个Redis集群，最多只能有16384个实例，达到这个上限后就不能水平扩容了。16384这个数字是怎么定出来的？
因为集群中每个节点需要交换各自的路由信息，也就是槽位信息，Redis也需要考虑交换的成本，占用的网络资源。
过多的槽位在交换信息时也会变得很重，所以Redis作者在设计时做了权衡，尽量使用少的内存完成信息交换，在设计内存存储时定的16384，作者预估一个集群不会超过1000个实例。github上作者有解释，你可以查一下。


一致性哈希算法对于容错性和扩展性有非常好的支持。但一致性哈希算法也有一个严重的问题，就是数据倾斜。
如果在分片的集群中，节点太少，并且分布不均，一致性哈希算法就会出现部分节点数据太多，部分节点数据太少。也就是说无法控制节点存储数据的分配。
```

##### 若发生切片集群中某节点下线
我看《redis设计与实现》中说，如果集群中某个节点下线了，这个节点负责槽会给它的从节点。如果它没有从节点，这些槽会怎么办呢？自动顺时针迁移给下一个节点吗？
还有如果在集群中新增一个节点，是要手动全部重写分配槽，还是怎么样呢？
```markdown
没有从节点，那这个节点就相当于故障了，内存数据会丢失，只能从RDB或AOF文件中恢复数据，不会自动转移到下一个节点。
新增节点，可以选择只迁移某一个节点的数据，也可以选择自动平衡数据，每个节点都迁移一部分到新节点，这是可配置的。
```







## 场景题
### 海量数据情况下如何选择合适的集合
[12 | 有一亿个keys要统计，应该用哪种集合？ (geekbang.org)](https://time.geekbang.org/column/article/280680)

四种统计模式，包括聚合统计、排序统计、二值状态统计和基数统计

聚合统计，就是指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（**交集**统计）；把两个集合相比，统计其中一个集合独有的元素（**差集**统计）；统计多个集合的所有元素（**并集**统计）。

Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。所以，我给你分享一个小建议：你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。

排序统计,要求集合类型能对元素保序，也就是说，集合中的元素可以按序排列，这种对元素保序的集合类型叫作有序集合。在 Redis 常用的 4 个集合类型中（List、Hash、Set、Sorted Set），List 和 Sorted Set 就属于有序集合。

二值状态统计.这里的二值状态就是指集合元素的取值就只有 0 和 1 两种。在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态

基数统计.基数统计就是指统计一个集合中不重复的元素个数。对应到我们刚才介绍的场景中，就是统计网页的 UV。网页 UV 的统计有个独特的地方，就是需要去重，一个用户一天内的多次访问只能算作一次。

HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。
![[Pasted image 20220204180850.png]]


### Redis为什么变慢了？
[Redis为什么变慢了？一文讲透如何排查Redis性能问题 | 万字长文 (qq.com)](https://mp.weixin.qq.com/s?__biz=MzIyOTYxNDI5OA==&mid=2247484679&idx=1&sn=3273e2c9083e8307c87d13a441a267d7&chksm=e8beb2b2dfc93ba4c28c95fdcb62eefc529d6a4ca2b4971ad0493319adbf8348b318224bd3d9&scene=178&cur_album_id=1699766580538032128#rd)

![[Pasted image 20220206143955.png]]


## redis当作旁路缓存


## 数据结构
### String类型如何保存数据
当你保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数，这种保存方式通常也叫作 int 编码方式。
但是，当你保存的数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存
在 SDS 中，buf 保存实际数据，而 len 和 alloc 本身其实是 SDS 结构体的额外开销。另外，对于 String 类型来说，除了 SDS 的额外开销，还有一个来自于 RedisObject 结构体的开销。
因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据。
一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向 String 类型的 SDS 结构所在的内存地址
![[Pasted image 20220204184825.png]]

**为了节省内存空间**，Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计。
一方面，当保存的是 Long 类型整数时，**RedisObject 中的指针就直接赋值为整数数据了**，这样就不用额外的指针再指向整数了，节省了指针的空间开销。
另一方面，当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式。
当然，当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。

>为什么是44字节？
>原因: 新版的sds做了优化，len、cap以及新增的flag使用的都是int8类型，只占用1个字节，这样64-16（ReadObj头部）-3（sds头部）-1（buf末尾\0）= 44。
>
>用64字节来减是因为cpu cache line是64吗？
>是 因为 sdshdr8 这个结构体 能够使用的最大字节为8\*8=64字节
>
>3.2 版本（3.2~6.0）引入了 5 种 sdshdr类型，根据实际长度判断应该选择什么类型的sdshdr
>还有个flags字段表明用什么sdshdr类型，1个字节



全局哈希表 #redis全局哈希表
Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节，如下图所示：
![[Pasted image 20220204200137.png]]
但是，这三个指针只有 24 字节，为什么会占用了 32 字节呢？这就要提到 Redis 使用的内存分配库 jemalloc 了。
jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。

好了，到这儿，你应该就能理解，为什么用 String 类型保存图片 ID 和图片存储对象 ID 时需要用 64 个字节了。



### SDS
![[Pasted image 20220204183658.png]]
**(老版本)**
* buf：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\0”，这就会额外占用 1 个字节的开销。
* len：占 4 个字节，表示 buf 的已用长度。
* alloc：也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。





### 压缩列表
Redis 有一种底层数据结构，叫压缩列表（ziplist），这是一种非常节省内存的结构。
list、hash、sorted_set在数据量比较少的时候使用的ziplist，这种数据结构没有指针的开销

压缩列表的构成：表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 zlend，表示列表结束。
压缩列表之所以能节省内存，就在于它是用一系列连续的 entry 保存数据。每个 entry 的元数据包括下面几部分。
* prev_len，表示前一个 entry 的长度。prev_len 有两种取值情况：1 字节或 5 字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1 字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是 255，因此，就默认用 255 表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时，prev_len 取值为 1 字节，否则，就取值为 5 字节。
* len：表示自身长度，4 字节；
* encoding：表示编码方式，1 字节；
* content：保存实际数据。

这些 entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间。
>entry挨个放在内存中，扩容时是不是很麻烦
>这个结构有规则的 key个数512限制 每个值64kb限制



## 过期键删除策略和内存淘汰策略
通过expire或pexpire（precise）命令，客户端可以以秒或者毫秒精度为数据库中的某个键设置生存时间（TTL）。当到底过期时间后，会达到一个逻辑删除的效果——**键不会被立刻删除，而是由定时事件处理器serverCron进行异步删除，但是在获取的时候会“视而不见”**。  
通过TTL或PTTL命令可以查询这个键还有多少时间过期。

> setex time就是将set k v 和 expire k time 合成了一个原子命令，但是只能对字符串使用。

RedisDb结构的expire字典保存了数据库中所有键的过期时间，称为过期字典。键空间的键和过期字典的键都是**指针类型，他们共同指向同一个对象（RedisObject结构体），因此不会造成空间的浪费**。  
当expire命令执行成功后，数据库中的目标键就会被关联上一个过期时间。（persist命令可以解除过期时间，尤其是检测到某些数据是当前热点数据）


### 过期键删除策略
redis的每个对象都是RedisObject结构体的实例，而删除一个键其实就是将这个对象close掉

Redis 同时使用了两种策略来删除过期的数据，分别是惰性删除策略和定期删除策略。

先说惰性删除策略。当一个数据的过期时间到了以后，并不会立即删除数据，而是等到再有请求来读写这个数据时，对数据进行检查，如果发现数据已经过期了，再删除这个数据。

这个策略的好处是尽量减少删除操作对 CPU 资源的使用，**对于用不到的数据，就不再浪费时间进行检查和删除了**。但是，**这个策略会导致大量已经过期的数据留存在内存中，占用较多的内存资源**。所以，Redis 在使用这个策略的同时，还使用了第二种策略：定期删除策略。

惰性删除的引入，其中就是在**命令真正执行之前多加了一层判断，判断当前的键是否过期或者存在**。而定时删除没有这个判断,这就是定时删除会读到过期数据的原因

定期删除策略是指，Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除，这样就可以及时释放一些内存。定时删除操作由**时间函数serverCron**负责，它会在规定的时间内分多次遍历服务器的各个数据库，从数据库的过期字典中**随机检查一部分键**的过期时间，并删除其中的过期键。

>为了保证软实时并没有遍历检查所有的key，而是随机抽取若干个key进行检查，并且删除其中过期的key。这是因为redis可以存储成千上万个key，每次都遍历所有的key是不现实的，更加难以实现软实时。



**清楚了这两个删除策略，我们再来看看它们为什么会导致读取到过期数据。**

首先，虽然定期删除策略可以释放一些内存，但是，Redis 为了避免过多删除操作对性能产生影响，每次随机检查数据的数量并不多。如果过期数据很多，并且一直没有再被访问的话，这些数据就会留存在 Redis 实例中。业务应用之所以会读到过期数据，这些留存数据就是一个重要因素。

其次，惰性删除策略实现后，数据只有被再次访问时，才会被实际删除。如果客户端从主库上读取留存的过期数据，主库会触发删除操作，此时，客户端并不会读到过期数据。**但是，从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。那么，从库会给客户端返回过期数据吗？**

**这就和你使用的 Redis 版本有关了。如果你使用的是 Redis 3.2 之前的版本，那么，从库在服务读请求时，并不会判断数据是否过期，而是会返回过期数据。在 3.2 版本后，Redis 做了改进，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值，这就避免了客户端读到过期数据**。所以，在应用主从集群时，尽量使用 Redis 3.2 及以上版本。

你可能会问，**只要使用了 Redis 3.2 后的版本，就不会读到过期数据了吗？其实还是会的。**

为啥会这样呢？这跟 Redis 用于设置过期时间的命令有关系，有些命令给数据设置的过期时间在从库上可能会被延后，导致应该过期的数据又在从库上被读取到了，我来给你具体解释下。

我先给你介绍下这些命令。设置数据过期时间的命令一共有 4 个，我们可以把它们分成两类：

-   EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；
    
-   EXPIREAT 和 PEXPIREAT：它们会直接把数据的过期时间设置为具体的一个时间点。
    

![image-20220129143556830](file://D:\java-daily\redis\images\redis\image-20220129143556830.png?lastModify=1647066678)

为了避免这种情况，我给你的建议是，在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据。


生成RDB文件的时候，已经过期的键不会被保存到新建的RDB文件中。如果服务器开启了AOF功能，但是写入AOF文件后这个键才过期，程序会向AOF文件追加一条DEL命令来显示删除目标键。已经过期的键也不会被保存到重写后的AOF文件。  
当启动服务器并载入RDB文件的时候，如果是主服务器，RDB文件中过期的键会被直接忽略。如果服务器以从服务器的模式运行，载入RDB文件的时候过期的键也会被保存到数据库中，不过在数据同步的时候，过期键就会被清除掉。（命令传播阶段会收到主服务器传递的DEL命令）

> 在一主多从模式下，无法达到实时一致性，只能达到最终一致性。这是C（一致性）A（可用性）P（分区容错性）选择后两者的权衡


### 内存淘汰策略

不管是惰性删除还是定时删除，都无法精确的删除所有过期键，并且不考虑过期键，redis本身也是有上限的（在开始maxMemory之后）。因此必须考虑内存淘汰（过期键导致的内存泄露以及内存不够用导致的内存溢出）的场景。

内存淘汰策略基本就是**各种“删除类型”以及“删除算法”的组合**

首先，**默认的策略**就是内存超过maxMemory的时候**直接抛出异常/返回错误**。  
删除范围包括：所有键allkeys、**配置了过期时间的键volatile**。  
删除算法包括：LRU最近的长时间未使用的、LFU最近的使用频率最小的、ttl马上过期的、random随机删除


Redis 4.0 之前一共实现了 6 种内存淘汰策略，在 4.0 之后，又增加了 2 种策略。我们可以按照是否会进行数据淘汰把它们分成两类：

* 不进行数据淘汰的策略，只有 noeviction 这一种。
* 会进行淘汰的 7 种其他策略。

会进行淘汰的 7 种策略，我们可以再进一步根据淘汰候选数据集的范围把它们分成两类：

* 在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis 4.0 后新增）四种。

* 在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）三种。

默认情况下，Redis 在使用的内存空间超过 maxmemory 值时，并不会淘汰数据，也就是设定的 noeviction 策略。对应到 Redis 缓存，也就是指，一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。Redis 用作缓存时，实际的数据集通常都是大于缓存容量的，总会有新的数据要写入缓存，这个策略本身不淘汰数据，也就不会腾出新的缓存空间，我们不把它用在 Redis 缓存中。

我们再分析下 volatile-random、volatile-ttl、volatile-lru 和 volatile-lfu 这四种淘汰策略。它们筛选的候选数据范围，被限制在已经设置了过期时间的键值对上。也正因为此，即使缓存没有写满，这些数据如果过期了，也会被删除。

例如，我们使用 EXPIRE 命令对一批键值对设置了过期时间后，无论是这些键值对的过期时间是快到了，还是 Redis 的内存使用量达到了 maxmemory 阈值，Redis 都会进一步按照 volatile-ttl、volatile-random、volatile-lru、volatile-lfu 这四种策略的具体筛选规则进行淘汰。(两种情况出现一种即可触发)



LRU 算法在实际实现时，需要用链表管理所有的缓存数据，这会带来额外的空间开销。而且，当有数据被访问时，需要在链表上把该数据移动到 MRU 端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。**

所以，在 Redis 中，LRU 算法被做了简化，以**减轻数据淘汰对缓存性能的影响**。**具体来说，Redis 默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构 RedisObject 中的 lru 字段记录）。然后，Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。**

Redis 提供了一个配置参数 maxmemory-samples，这个参数就是 Redis 选出的数据个数 N。例如，我们执行如下命令，可以让 Redis 选出 100 个数据作为候选数据集：`CONFIG SET maxmemory-samples 100`

当需要再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。**这儿的挑选标准是：能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值**。当有新数据进入候选数据集后，如果候选数据集中的数据个数达到了 maxmemory-samples，Redis 就把候选数据集中 lru 字段值最小的数据淘汰出去。

这样一来，**Redis 缓存不用为所有的数据维护一个大链表，也不用在每次数据访问时都移动链表项，提升了缓存的性能。**


到这里，我们就学完了除了使用 LFU 算法以外的 5 种缓存淘汰策略，我再给你三个使用建议。

-   优先使用 allkeys-lru 策略。这样，可以充分利用 LRU 这一经典缓存算法的优势，把最近最常访问的数据留在缓存中，提升应用的访问性能。
    
-   如果你的业务数据中有明显的冷热数据区分，我建议你使用 allkeys-lru 策略。如果业务应用中的数据访问频率相差不大，没有明显的冷热数据区分，建议使用 allkeys-random 策略，随机选择淘汰的数据就行。
    
-   如果你的业务中有置顶的需求，比如置顶新闻、置顶视频，那么，可以使用 volatile-lru 策略，同时不给这些置顶数据设置过期时间。这样一来，这些需要置顶的数据一直不会被删除，而其他数据会在过期时根据 LRU 规则进行筛选。



```markdown
Redis在用作缓存时，使用只读缓存或读写缓存的哪种模式？

1、只读缓存模式：每次修改直接写入后端数据库，如果Redis缓存不命中，则什么都不用操作，如果Redis缓存命中，则删除缓存中的数据，待下次读取时从后端数据库中加载最新值到缓存中。

2、读写缓存模式+同步直写策略：由于Redis在淘汰数据时，直接在内部删除键值对，外部无法介入处理脏数据写回数据库，所以使用Redis作读写缓存时，只能采用同步直写策略，修改缓存的同时也要写入到后端数据库中，从而保证修改操作不被丢失。但这种方案在并发场景下会导致数据库和缓存的不一致，需要在特定业务场景下或者配合分布式锁使用。

当一个系统引入缓存时，需要面临最大的问题就是，如何保证缓存和后端数据库的一致性问题，最常见的3个解决方案分别是Cache Aside、Read/Write Throught和Write Back缓存更新策略。

1、Cache Aside策略：就是文章所讲的只读缓存模式。读操作命中缓存直接返回，否则从后端数据库加载到缓存再返回。写操作直接更新数据库，然后删除缓存。这种策略的优点是一切以后端数据库为准，可以保证缓存和数据库的一致性。缺点是写操作会让缓存失效，再次读取时需要从数据库中加载。这种策略是我们在开发软件时最常用的，在使用Memcached或Redis时一般都采用这种方案。

2、Read/Write Throught策略：应用层读写只需要操作缓存，不需要关心后端数据库。应用层在操作缓存时，缓存层会自动从数据库中加载或写回到数据库中，这种策略的优点是，对于应用层的使用非常友好，只需要操作缓存即可，缺点是需要缓存层支持和后端数据库的联动。

3、Write Back策略：类似于文章所讲的读写缓存模式+异步写回策略。写操作只写缓存，比较简单。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，在加载之前，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库中，再把对应的数据放入到缓存中。这种策略的优点是，写操作飞快（只写缓存），缺点是如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。这种策略经常使用在操作系统Page Cache中，或者应对大量写操作的数据库引擎中。

除了以上提到的缓存和数据库的更新策略之外，还有一个问题就是操作缓存或数据库发生异常时如何处理？例如缓存操作成功，数据库操作失败，或者反过来，还是有可能会产生不一致的情况。

比较简单的解决方案是，根据业务设计好更新缓存和数据库的先后顺序来降低影响，或者给缓存设置较短的有效期来降低不一致的时间。如果需要严格保证缓存和数据库的一致性，即保证两者操作的原子性，这就涉及到分布式事务问题了，常见的解决方案就是我们经常听到的两阶段提交（2PC）、三阶段提交（3PC）、TCC、消息队列等方式来保证了，方案也会比较复杂，一般用在对于一致性要求较高的业务场景中。




我发现一个问题，在淘汰策略上，我的记忆中，他一直是默认volatile-lru，而且在百度上搜索，大多数也都是默认volatile-lru。而我在前几周也看到与你有相同的说法，默认是noeviction，所以我查看了多个版本的配置文件，从中了解到，在redis3.0之前，默认是volatile-lru；在redis3.0之后（包括3.0），默认淘汰策略则是noeviction。所以这个地方需要强调一下。



能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值。
感觉这句话有问题，如果能进入候选集合的数据的lru字段值都小于候选集合中的最小的lru值的话，每次淘汰的肯定是刚进入候选集合的这条数据啊，这样这条被选择进行候选集合的数据就没有必要再进入候选集合了啊，直接删除就可以了吧????
在实际运行时，每次往候选集中插入的数据可能不止一个，而在淘汰数据时，也是会根据使用内存量超过maxmemory的情况，来决定要淘汰的数据量，所以可能也不止一个数据被淘汰。候选集的作用是先把符合条件（lru值小）的数据准备好。候选集本身是会按照lru值大小排序的，等待要淘汰时，会根据要淘汰的量，从候选集中淘汰数据。所以，并不是刚进入候选集就立马就淘汰了。准备候选集和淘汰数据实际是两个解耦的逻辑操作。



能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值。
这里有个疑问，请教老师，这样第二次及后续进入的备选淘汰集合中的数据lru都小于第一次的，淘汰的也是lru最小的，那第一次进入淘汰集合的数据这样不就不会被选中淘汰了呢?
是有这种可能的，第一次进入候选集合的数据是随机选取的，数据的lru值可能大可能小。第二次及后续再进入候选集的数据的lru值需要小于候选集中的最小lru值。
同时，候选集的实现是一个链表，数据是按照lru值排序的，链表头是lru值最大的，链表尾是lru值最小的。当第二次及后续进入候选集的数据lru更小，但是候选集中已经没有空位置时，候选集链表头的数据会被移出候选集，把位置空出来，给新进入的数据。这样的话，这个被移出的数据就不会作为被淘汰的候选数据了。
```


## 缓存异常

### 如何解决缓存和数据库的数据不一致问题？

存和数据库的数据不一致是如何发生的？

首先，我们得清楚“**数据的一致性”具体是啥意思。其实，这里的“一致性”包含了两种情况：**
-   缓存中有数据，那么，缓存的数据值需要和数据库中的值相同；
-   缓存中本身没有数据，那么，数据库中的值必须是最新值。
    
不符合这两种情况的，就属于缓存和数据库的数据不一致问题了。不过，当缓存的读写模式不同时，缓存数据不一致的发生情况不一样，我们的应对方法也会有所不同，所以，我们先按照缓存读写模式，来分别了解下不同模式下的缓存不一致情况。我在第 23 讲中讲过，根据是否接收写请求，我们可以把**缓存分成读写缓存和只读缓存。**

对于读写缓存来说，如果要对数据进行增删改，就需要在缓存中进行，同时还要根据采取的写回策略，决定是否同步写回到数据库中。
-   同步直写策略：写缓存时，也同步写数据库，缓存和数据库中的数据一致；
-   异步写回策略：写缓存时不同步写数据库，等到数据从缓存中淘汰时，再写回数据库。使用这种策略时，如果数据还没有写回数据库，缓存就发生了故障，那么，此时，数据库就没有最新的数据了。
    
所以，对于读写缓存来说，要想保证缓存和数据库中的数据一致，就要采用同步直写策略。不过，需要注意的是，如果采用这种策略，就**需要同时更新缓存和数据库。所以，我们要在业务应用中使用事务机制，来保证缓存和数据库的更新具有原子性**，也就是说，两者要不一起更新，要不都不更新，返回错误信息，进行重试。否则，我们就无法实现同步直写。

当然，在有些场景下，我们对数据一致性的要求可能不是那么高，比如说缓存的是电商商品的非关键属性或者短视频的创建或修改时间等，那么，我们可以使用异步写回策略。

下面我们再来说说只读缓存。对于只读缓存来说，如果有数据新增，会直接写入数据库；而有数据删改时，就需要把只读缓存中的数据标记为无效。这样一来，应用后续再访问这些增删改的数据时，因为缓存中没有相应的数据，就会发生缓存缺失。此时，应用再从数据库中把数据读入缓存，这样后续再访问数据时，就能够直接从缓存中读取了。

**如何解决数据不一致问题？**

首先，我给你介绍一种方法：重试机制。
具体来说，可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。
如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致了。否则的话，我们还需要再次进行重试。如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。

刚刚说的是在更新数据库和删除缓存值的过程中，其中一个操作失败的情况，实际上，即使这两个操作第一次执行时都没有失败，当有大量并发请求时，应用还是有可能读到不一致的数据。

同样，我们按照不同的删除和更新顺序，分成两种情况来看。在这两种情况下，我们的解决方法也有所不同。
1. 先db后删
2. 先删后db


**缓存和数据库的数据不一致一般是由两个原因导致的**，我给你提供了相应的解决方案。
-   删除缓存值或更新数据库失败而导致数据不一致，你可以使用重试机制确保删除或更新操作成功。
-   在删除缓存值、更新数据库的这两步操作中，有其他线程的并发读操作，导致其他线程读取到旧值，应对方案是延迟双删。


只读缓存
![[Pasted image 20220312151109.png]]


**在大多数业务场景下，我们会把 Redis 作为只读缓存使用。针对只读缓存来说，我们既可以先删除缓存值再更新数据库，也可以先更新数据库再删除缓存。我的建议是，优先使用先更新数据库再删除缓存的方法，原因主要有两个：**

1.  先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力；
    
2.  如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。
    

不过，**当使用先更新数据库再删除缓存时，也有个地方需要注意，如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在 Redis 缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性**。**如果是强一致性的业务要求，只能暂存请求**


```markdown
数据在删改操作时，如果不是删除缓存值，而是直接更新缓存的值，你觉得和删除缓存值相比，有什么好处和不足？

这种情况相当于把Redis当做读写缓存使用，删改操作同时操作数据库和缓存。

1、先更新数据库，再更新缓存：如果更新数据库成功，但缓存更新失败，此时数据库中是最新值，但缓存中是旧值，后续的读请求会直接命中缓存，得到的是旧值。

2、先更新缓存，再更新数据库：如果更新缓存成功，但数据库更新失败，此时缓存中是最新值，数据库中是旧值，后续读请求会直接命中缓存，但得到的是最新值，短期对业务影响不大。但是，一旦缓存过期或者满容后被淘汰，读请求就会从数据库中重新加载旧值到缓存中，之后的读请求会从缓存中得到旧值，对业务产生影响。

同样地，针对这种其中一个操作可能失败的情况，也可以使用重试机制解决，把第二步操作放入到消息队列中，消费者从消息队列取出消息，再更新缓存或数据库，成功后把消息从消息队列删除，否则进行重试，以此达到数据库和缓存的最终一致。

以上是没有并发请求的情况。如果存在并发读写，也会产生不一致，分为以下4种场景。

1、先更新数据库，再更新缓存，写+读并发：线程A先更新数据库，之后线程B读取数据，此时线程B会命中缓存，读取到旧值，之后线程A更新缓存成功，后续的读请求会命中缓存得到最新值。这种场景下，线程A未更新完缓存之前，在这期间的读请求会短暂读到旧值，对业务短暂影响。

2、先更新缓存，再更新数据库，写+读并发：线程A先更新缓存成功，之后线程B读取数据，此时线程B命中缓存，读取到最新值后返回，之后线程A更新数据库成功。这种场景下，虽然线程A还未更新完数据库，数据库会与缓存存在短暂不一致，但在这之前进来的读请求都能直接命中缓存，获取到最新值，所以对业务没影响。

3、先更新数据库，再更新缓存，写+写并发：线程A和线程B同时更新同一条数据，更新数据库的顺序是先A后B，但更新缓存时顺序是先B后A，这会导致数据库和缓存的不一致。

4、先更新缓存，再更新数据库，写+写并发：与场景3类似，线程A和线程B同时更新同一条数据，更新缓存的顺序是先A后B，但是更新数据库的顺序是先B后A，这也会导致数据库和缓存的不一致。

场景1和2对业务影响较小，场景3和4会造成数据库和缓存不一致，影响较大。也就是说，在读写缓存模式下，写+读并发对业务的影响较小，而写+写并发时，会造成数据库和缓存的不一致。

针对场景3和4的解决方案是，对于写请求，需要配合分布式锁使用。写请求进来时，针对同一个资源的修改操作，先加分布式锁，这样同一时间只允许一个线程去更新数据库和缓存，没有拿到锁的线程把操作放入到队列中，延时处理。用这种方式保证多个线程操作同一资源的顺序性，以此保证一致性。

综上，使用读写缓存同时操作数据库和缓存时，因为其中一个操作失败导致不一致的问题，同样可以通过消息队列重试来解决。而在并发的场景下，读+写并发对业务没有影响或者影响较小，而写+写并发时需要配合分布式锁的使用，才能保证缓存和数据库的一致性。

另外，读写缓存模式由于会同时更新数据库和缓存，优点是，缓存中一直会有数据，如果更新操作后会立即再次访问，可以直接命中缓存，能够降低读请求对于数据库的压力（没有了只读缓存的删除缓存导致缓存缺失和再加载的过程）。缺点是，如果更新后的数据，之后很少再被访问到，会导致缓存中保留的不是最热的数据，缓存利用率不高（只读缓存中保留的都是热数据），所以读写缓存比较适合用于读写相当的业务场景。

```



### 缓存穿透
缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。此时，应用也无法从数据库中读取数据再写入缓存，来服务后续请求，这样一来，缓存也就成了“摆设”，如果应用持续有大量请求访问数据，就会同时给缓存和数据库带来巨大压力

那么，缓存穿透会发生在什么时候呢？一般来说，有两种情况。

-   业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；
    
-   恶意攻击：专门访问数据库中没有的数据。
    

为了避免缓存穿透的影响，我来给你提供三种应对方案。

**第一种方案是，缓存空值或缺省值。**

一旦发生缓存穿透，我们就可以针对查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值（例如，库存的缺省值可以设为 0）。紧接着，应用发送的后续请求再进行查询时，就可以直接从 Redis 中读取空值或缺省值，返回给业务应用了，避免了把大量请求发送给数据库处理，保持了数据库的正常运行。

**第二种方案是，使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。**

正是基于布隆过滤器的快速检测特性，我们可以在把数据写入数据库时，使用布隆过滤器做个标记。当缓存缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。如果不存在，就不用再去数据库中查询了。这样一来，即使发生缓存穿透了，大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。布隆过滤器可以使用 Redis 实现，本身就能承担较大的并发访问压力。

**最后一种方案是，在请求入口的前端进行请求检测**。

缓存穿透的一个原因是有大量的恶意请求访问不存在的数据，所以，一个有效的应对方案是在请求入口前端，对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库。这样一来，也就不会出现缓存穿透问题了。



### 缓存击穿
缓存击穿是指，**针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理**，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时

为了避免缓存击穿给数据库带来的激增压力，我们的解决方法也比较直接，对于访问特别频繁的热点数据，我们就不设置过期时间了。这样一来，对热点数据的访问请求，都可以在缓存中进行处理，而 Redis 数万级别的高吞吐量可以很好地应对大量的并发请求访问。

好了，到这里，你了解了缓存雪崩和缓存击穿问题，以及它们的应对方案。当发生缓存雪崩或击穿时，数据库中还是保存了应用要访问的数据。接下来，我向你介绍的缓存穿透问题，和雪崩、击穿问题不一样，缓存穿透发生时，数据也不在数据库中，这会同时给缓存和数据库带来访问压力，那该怎么办呢？我们来具体看下。

缓存击穿，个人感觉跟缓存雪崩概念很像，击穿应该算雪崩的一个子集吧。血崩是大量内容redis无法处理【key过期（redis中一片经常访问的内容没有了）、实例挂了】，击穿是redis中没有所需的热点数据（某几个key过期导致“击穿”，而redis还能用）。两者都是没有内容导致数据库访问激增，具体表现不同，所以处理方式也不同：击穿只需要针对热点不设置过期时间，而雪崩需要合理的key过期时间、高可用集群的和服务降级、熔断和限流等技术解决。

### 缓存雪崩
缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。

缓存雪崩一般是由两个原因导致的，应对方案也有所不同，我们一个个来看。

第一个原因是：缓存中有大量数据同时过期，导致大量请求无法得到处理。(亲身经历的一个场景就是：to b 办公工具，在长假过后，缓存大量失效，到假期结束后，db 的压力上升。)

具体来说，当数据保存在缓存中，并且设置了过期时间时，如果在某一个时刻，大量数据同时过期，此时，应用再访问这些数据的话，就会发生缓存缺失。紧接着，应用就会把请求发送给数据库，从数据库中读取数据。如果应用的并发请求量很大，那么数据库的压力也就很大，这会进一步影响到数据库的其他正常业务请求处理

针对大量数据同时失效带来的缓存雪崩问题，我给你提供两种解决方案。
-   当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；
-   当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。

这样一来，只有部分过期数据的请求会发送到数据库，数据库的压力就没有那么大了


**除了大量数据同时失效会导致缓存雪崩，还有一种情况也会发生缓存雪崩，那就是，Redis 缓存实例发生故障宕机了，无法处理请求，这就会导致大量请求一下子积压到数据库层，从而发生缓存雪崩。**

一般来说，一个 Redis 实例可以支持数万级别的请求处理吞吐量，而单个数据库可能只能支持数千级别的请求处理吞吐量，它们两个的处理能力可能相差了近十倍。由于缓存雪崩，Redis 缓存失效，所以，数据库就可能要承受近十倍的请求压力，从而因为压力过大而崩溃。

此时，**因为 Redis 实例发生了宕机，我们需要通过其他方法来应对缓存雪崩了。我给你提供两个建议。**

**第一个建议，是在业务系统中实现服务熔断或请求限流机制。**

所谓的服务熔断，是指在发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，我们暂停业务应用对缓存系统的接口访问。再具体点说，就是业务应用调用缓存接口时，缓存客户端并不把请求发给 Redis 缓存实例，而是直接返回，等到 Redis 缓存实例重新恢复服务后，再允许应用请求发送到缓存系统。这样一来，我们就避免了大量请求因缓存缺失，而积压到数据库系统，保证了数据库系统的正常运行。

在业务系统运行时，我们可以监测 Redis 缓存所在机器和数据库所在机器的负载指标，例如每秒请求数、CPU 利用率、内存利用率等。如果我们发现 Redis 缓存实例宕机了，而数据库所在机器的负载压力突然增加（例如每秒请求数激增），此时，就发生缓存雪崩了。大量请求被发送到数据库进行处理。我们可以启动服务熔断机制，暂停业务应用对缓存服务的访问，从而降低对数据库的访问压力


服务熔断虽然可以保证数据库的正常运行，但是暂停了整个缓存系统的访问，对业务应用的影响范围大。为了尽可能减少这种影响，我们也可以进行请求限流。这里说的请求限流，就是指，我们在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。

我给你举个例子。假设业务系统正常运行时，请求入口前端允许每秒进入系统的请求是 1 万个，其中，9000 个请求都能在缓存系统中进行处理，只有 1000 个请求会被应用发送到数据库进行处理。一旦发生了缓存雪崩，数据库的每秒请求数突然增加到每秒 1 万个，此时，我们就可以启动请求限流机制，在请求入口前端只允许每秒进入系统的请求数为 1000 个，再多的请求就会在入口前端被直接拒绝服务。所以，使用了请求限流，就可以避免大量并发请求压力传递到数据库层。

使用服务熔断或是请求限流机制，来应对 Redis 实例宕机导致的缓存雪崩问题，是属于“事后诸葛亮”，也就是已经发生缓存雪崩了，**我们使用这两个机制，来降低雪崩对数据库和整个业务系统的影响。**

当一段时间间隔内，多次发生访问redis失败，就进入熔断状态。一段时间之后允许少量请求通过，如果请求都执行成功，则退出熔断状态，如果请求仍旧失败，在下一个时间段，再次允许少量请求通过，试探服务是否恢复。

**我给你的第二个建议就是事前预防。**

通过主从节点的方式构建 Redis 缓存高可靠集群。如果 Redis 缓存的主节点故障宕机了，从节点还可以切换成为主节点，继续提供缓存服务，避免了由于缓存实例宕机而导致的缓存雪崩问题。

缓存雪崩是发生在大量数据同时失效的场景下，缓存击穿，是发生在某个热点数据失效的场景下。


```markdown
是否可以采用服务熔断、服务降级、请求限流的方法来应对缓存穿透问题？

我觉得需要区分场景来看。

如果缓存穿透的原因是恶意攻击，攻击者故意访问数据库中不存在的数据。这种情况可以先使用服务熔断、服务降级、请求限流的方式，对缓存和数据库层增加保护，防止大量恶意请求把缓存和数据库压垮。在这期间可以对攻击者进行防护，例如封禁IP等操作。

如果缓存穿透的原因是，业务层误操作把数据从缓存和数据库都删除了，如果误删除的数据很少，不会导致大量请求压到数据库的情况，那么快速恢复误删的数据就好了，不需要使用服务熔断、服务降级、请求限流。如果误操作删除的数据范围比较广，导致大量请求压到数据库层，此时使用服务熔断、服务降级、请求限流的方法来应对是有帮助的，使用这些方法先把缓存和数据库保护起来，然后使用备份库快速恢复数据，在数据恢复期间，这些保护方法可以为数据库恢复提供保障。

还有一种缓存穿透的场景，我们平时会遇到的，和大家分享一下。

对于一个刚上线的新业务模块，如果还没有用户在这个模块内产生业务数据，当用户需要查询这个业务模块自己的数据时，由于缓存和数据库都没有这个用户的数据，此时也会产生缓存穿透，但这种场景不像误删数据和恶意攻击那样，而是属于正常的用户行为。

这种场景采用服务熔断、服务降级、请求限流的方式就没有任何意义了，反而会影响正常用户的访问。这种场景只能使用缓存回种空值、布隆过滤器来解决。

可见，服务熔断、服务降级、请求限流的作用是，当系统内部发生故障或潜在问题时，为了防止系统内部的问题进一步恶化，所以会采用这些方式对系统增加保护，待系统内部故障恢复后，可以依旧继续对外提供服务，这些方法属于服务治理的范畴，在任何可能导致系统故障的场景下，都可以选择性配合使用。

另外，关于文章所讲的由于“Redis缓存实例发生故障宕机”导致缓存雪崩的问题，我觉得一个可以优化的方案是，当Redis实例故障宕机后，业务请求可以直接返回错误，没必要再去请求数据库了，这样就不会导致数据库层压力变大。当然，最好的方式还是Redis部署主从集群+哨兵，主节点宕机后，哨兵可以及时把从节点提升为主，继续提供服务。

关于布隆过滤器的使用，还有几点和大家分享。

1、布隆过滤器会有误判：由于采用固定bit的数组，使用多个哈希函数映射到多个bit上，有可能会导致两个不同的值都映射到相同的一组bit上。虽然有误判，但对于业务没有影响，无非就是还存在一些穿透而已，但整体上已经过滤了大多数无效穿透请求。

2、布隆过滤器误判率和空间使用的计算：误判本质是因为哈希冲突，降低误判的方法是增加哈希函数 + 扩大整个bit数组的长度，但增加哈希函数意味着影响性能，扩大数组长度意味着空间占用变大，所以使用布隆过滤器，需要在误判率和性能、空间作一个平衡，具体的误判率是有一个计算公式可以推导出来的（比较复杂）。但我们在使用开源的布隆过滤器时比较简单，通常会提供2个参数：预估存入的数据量大小、要求的误判率，输入这些参数后，布隆过滤器会有自动计算出最佳的哈希函数数量和数组占用的空间大小，直接使用即可。

3、布隆过滤器可以放在缓存和数据库的最前面：把Redis当作布隆过滤器时（4.0提供了布隆过滤器模块，4.0以下需要引入第三方库），当用户产生业务数据写入缓存和数据库后，同时也写入布隆过滤器，之后当用户访问自己的业务数据时，先检查布隆过滤器，如果过滤器不存在，就不需要查询缓存和数据库了，可以同时降低缓存和数据库的压力。

4、Redis实现的布隆过滤器bigkey问题：Redis布隆过滤器是使用String类型实现的，存储的方式是一个bigkey，建议使用时单独部署一个实例，专门存放布隆过滤器的数据，不要和业务数据混用，否则在集群环境下，数据迁移时会导致Redis阻塞问题。




1）、缓存雪崩还有一个场景，是一致性hash环的集群特性导致的。集群中 某个主从节点挂掉了，请求分散到其他集群，但是量极大，把其他集群也都冲垮了。
解决办法，如果场景是热的极热 冷的极冷，不建议使用 一致性hash环的集群玩法，直接使用逻辑分组，挂掉的就暂时挂掉，后续人工恢复。 总比打垮整个系统的好

2）、缓存击穿 不只有不写过期时间，也可以对读数据做预判，例如主动给某些热的数据做 过期时间延期操作。

3）、布隆过滤器介绍 最后一部分 关于命中这部分缺少了，如果都是1 那么结果返回 存在，但是真正存在吗？ 不一定，可能是由于其他value的hash函数填充的，所以 对于 布隆过滤器 返回存在的，我们要穿透到缓存与db中查询。
像一个极端情况，如果 整个bit数组 都是1 或者大部分都是1的场景，这说明什么？ 说明布隆过期已经基本被填满了，也说明超出了布隆过滤器 一开始预期的大小，没错 布隆过滤器是需要事先预知 总容量大小与误判率预期的，否则就会出现 误判率极高 基本等于 没有作用的情况

4）、redis实现布隆过滤器 是bigKey，但是是string 的数据结构，整体而言 问题不是特别大，从redis4.0 lazy-free 删除string结构 并不是在子线程而主线程直接删除就能看出来，网上也有很多实现 string的删除耗时并没有随着value大小增加而增加太多，当然 如果能单独创建实例最好。

5）、布隆过期率场景应用很常见，例如 hbase的MemStore读之前一定会先查询布隆过滤器。再举一个实际的业务场景，微博 微信 每一条数据都要展示，你是否对某个数据赞过，这点 明显用布隆过滤器 比传统的缓存+db 好多了。因为绝大部分信息你都没有点过赞




建议使用时部署一个实例，是指部署一个redis实例还是指部署布隆过滤器的实例？集群环境下迁移数据为何会导致redis阻塞？是因为数据迁移时，redis缓存无法进行？小白一枚，望指点
布隆过滤器的实例单独部署，不和业务实例混用。

集群多个节点之间迁移一个key会同时阻塞这两个节点，直到这个key迁移完成，如果是bigkey阻塞时间会更久，影响业务。




我觉得并没有必要：采用服务熔断、服务降级、请求限流的方法来应对缓存穿透的场景；
        因为缓存穿透的场景实质上是因为查询到了Redis和数据库中没有的数据。
        熔断、降级、限流，本质上是为了解决Redis实例没有起到缓存层作用这种情况；在损失业务吞吐量的代价下，在时间的作用下，随着过期key慢慢填充，Redis实例可以自行恢复缓存层作用。
        而缓存穿透的场景，是因为用户要让Redis和数据库提供一个它没有的东西。这种场景下，如果没有人工介入，不论时间过去多久，都不太可能会自然恢复。
        采用这种有损业务吞吐量的行为，会拖慢系统响应、降低用户体验、给公司一种系统“勉强能用”的错觉；但对问题的解决没有帮助。
        最好的办法是事前拦截，降低这种类型的请求打到系统上的可能。布隆过滤器虽然判别数据存在可能有误判的情况，但判别数据不存在不会误判。可以降低数据库无效的访问。

```


## 缓存污染
我们应用 Redis 缓存时，如果能缓存会被反复访问的数据，那就能**加速业务应用的访问**。但是，如果发生了缓存污染，那么，缓存对业务应用的加速作用就减少了。

那什么是缓存污染呢？在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。

当缓存污染不严重时，只有少量数据占据缓存空间，此时，对缓存系统的影响不大。但是，缓存污染一旦变得严重后，就会有大量不再访问的数据滞留在缓存中。如果这时数据占满了缓存空间，我们再往缓存中写入新数据时，就需要先把这些数据逐步淘汰出缓存，这就会引入额外的操作时间开销，进而会影响应用的性能。


**如何解决**

要解决缓存污染，我们也能很容易想到解决方案，那就是得把不会再被访问的数据筛选出来并淘汰掉。这样就不用等到缓存被写满以后，再逐一淘汰旧数据之后，才能写入新数据了。而哪些数据能留存在缓存中，是由缓存的淘汰策略决定的。

在这 8 种策略中，noeviction 策略是不会进行数据淘汰的。所以，它肯定不能用来解决缓存污染问题。其他的 7 种策略，都会按照一定的规则来淘汰数据。这里有个关键词是“一定的规则”，那么问题来了，不同的规则对于解决缓存污染问题，是否都有效呢？

首先，我们看下 volatile-random 和 allkeys-random 这两种策略。它们都是采用随机挑选数据的方式，来筛选即将被淘汰的数据。

既然是随机挑选，那么 Redis 就不会根据数据的访问情况来筛选数据。如果被淘汰的数据又被访问了，就会发生缓存缺失。也就是说，应用需要到后端数据库中访问这些数据，降低了应用的请求响应速度。所以，volatile-random 和 allkeys-random 策略，在避免缓存污染这个问题上的效果非常有限。

虽然 volatile-ttl 策略不再是随机选择淘汰数据了，但是剩余存活时间并不能直接反映数据再次访问的情况。所以，按照 volatile-ttl 策略淘汰数据，和按随机方式淘汰数据类似，也可能出现数据被淘汰后，被再次访问导致的缓存缺失问题。

这时，你可能会想到一种例外的情况：业务应用在给数据设置过期时间的时候，就明确知道数据被再次访问的情况，并根据访问情况设置过期时间。此时，Redis 按照数据的剩余最短存活时间进行筛选，是可以把不会再被访问的数据筛选出来的，进而避免缓存污染。例如，业务部门知道数据被访问的时长就是一个小时，并把数据的过期时间设置为一个小时后。这样一来，被淘汰的数据的确是不会再被访问了。

讲到这里，我们先小结下。**除了在明确知道数据被再次访问的情况下，volatile-ttl 可以有效避免缓存污染。在其他情况下，volatile-random、allkeys-random、volatile-ttl 这三种策略并不能应对缓存污染问题**。

接下来，我们再分别分析下 LRU 策略，以及 Redis 4.0 后实现的 LFU 策略。LRU 策略会按照数据访问的时效性，来筛选即将被淘汰的数据，应用非常广泛。在第 24 讲，我们已经学习了 Redis 是如何实现 LRU 策略的，所以接下来我们就重点看下它在解决缓存污染问题上的效果。

**LRU 缓存策略**

我们先复习下 LRU 策略的核心思想：如果一个数据刚刚被访问，那么这个数据肯定是热数据，还会被再次访问。按照这个核心思想，Redis 中的 LRU 策略，会在每个数据对应的 RedisObject 结构体中设置一个 lru 字段，用来记录数据的访问时间戳。在进行数据淘汰时，LRU 策略会在候选数据集中淘汰掉 lru 字段值最小的数据（也就是访问时间最久的数据）。

所以，在数据被频繁访问的业务场景中，LRU 策略的确能有效留存访问时间最近的数据。而且，因为留存的这些数据还会被再次访问，所以又可以提升业务应用的访问速度。

但是，也正是**因为只看数据的访问时间，使用 LRU 策略在处理扫描式单次查询操作时，无法解决缓存污染**。**(Mysql中通过对lru分为两段来规避遍历造成的冷数据污染)**。所谓的扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 lru 字段值都很大。

在使用 LRU 策略淘汰数据时，这些数据会留存在缓存中很长一段时间，造成缓存污染。如果查询的数据量很大，这些数据占满了缓存空间，却又不会服务新的缓存请求，此时，再有新数据要写入缓存的话，还是需要先把这些旧数据替换出缓存才行，这会影响缓存的性能。

所以，对于采用了 LRU 策略的 Redis 缓存来说，扫描式单次查询会造成缓存污染。**为了应对这类缓存污染问题，Redis 从 4.0 版本开始增加了 LFU 淘汰策略**。

**与 LRU 策略相比，LFU 策略中会从两个维度来筛选并淘汰数据**：一是，数据访问的时效性（访问时间离当前时间的远近）；二是，数据的被访问次数。

**LFU 缓存策略的优化**

LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。

为了避免操作链表的开销，Redis 在实现 LRU 策略时使用了两个近似方法：

-   Redis 是用 RedisObject 结构来保存数据的，RedisObject 结构中设置了一个 lru 字段，用来记录数据的访问时间戳；
    
-   Redis 并没有为所有的数据维护一个全局的链表，而是通过随机采样方式，选取一定数量（例如 10 个）的数据放入候选集合，后续在候选集合中根据 lru 字段值的大小进行筛选。
    

**在此基础上，Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分**。

1.  ldt 值：lru 字段的前 16bit，表示数据的访问时间戳；
    
2.  counter 值：lru 字段的后 8bit，表示数据的访问次数。
    

总结一下：当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的**后 8bit 选择访问次数最少的数据进行淘汰**。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。

到这里，还没结束，Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255，这样可以吗？

在实际应用中，一个数据可能会被访问成千上万次。如果每被访问一次，counter 值就加 1 的话，那么，只要访问次数超过了 255，数据的 counter 值就一样了。在进行数据淘汰时，LFU 策略就无法很好地区分并筛选这些数据，反而还可能会把不怎么访问的数据留存在了缓存中。

在实现 LFU 策略时，Redis 并没有采用数据每被访问一次，就给对应的 counter 值加 1 的计数规则，而是采用了一个更优化的计数规则。

简单来说，LFU 策略实现的计数规则是：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。

下面这段 Redis 的部分源码，显示了 LFU 策略增加计数器值的计算逻辑。其中，baseval 是计数器当前的值。计数器的初始值默认是 5（由代码中的 LFU_INIT_VAL 常量设置），而不是 0，这样可以**避免数据刚被写入缓存，就因为访问次数少而被立即淘汰**。

使用了这种计算规则后，我们可以通过设置不同的 lfu_log_factor 配置项，来控制计数器值增加的速度，避免 counter 值很快就到 255 了。

可以看到，当 lfu_log_factor 取值为 1 时，实际访问次数为 100K 后，counter 值就达到 255 了，无法再区分实际访问次数更多的数据了。而当 lfu_log_factor 取值为 100 时，当实际访问次数为 10M 时，counter 值才达到 255，此时，实际访问次数小于 10M 的不同数据都可以通过 counter 值区分出来。

正是因为使用了**非线性递增的计数器方法**，**即使缓存数据的访问次数成千上万，LFU 策略也可以有效地区分不同的访问次数，从而进行合理的数据筛选**。从刚才的表中，我们可以看到，当 lfu_log_factor 取值为 10 时，百、千、十万级别的访问次数对应的 counter 值已经有明显的区分了，所以，我们在应用 LFU 策略时，一般可以将 lfu_log_factor 取值为 10。

前面我们也提到了，应用负载的情况是很复杂的。**在一些场景下，有些数据在短时间内被大量访问后就不会再被访问了**。那么再**按照访问次数来筛选的话，这些数据会被留存在缓存中，但不会提升缓存命中率。为此，Redis 在实现 LFU 策略时，还设计了一个 counter 值的衰减机制。**

简单来说，**LFU 策略使用衰减因子配置项 lfu_decay_time 来控制访问次数的衰减**。**LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。**

简单举个例子，假设 lfu_decay_time 取值为 1，如果数据在 N 分钟内没有被访问，那么它的访问次数就要减 N。如果 lfu_decay_time 取值更大，那么相应的衰减值会变小，衰减效果也会减弱。所以，如果业务应用中有短时高频访问的数据的话，建议把 lfu_decay_time 值设置为 1，这样一来，LFU 策略在它们不再被访问后，会较快地衰减它们的访问次数，尽早把它们从缓存中淘汰出去，避免缓存污染。







**总结**
缓存污染问题指的是留存在缓存中的数据，实际不会被再次访问了，但是又占据了缓存空间。如果这样的数据体量很大，甚至占满了缓存，每次有新数据写入缓存时，还需要把这些数据逐步淘汰出缓存，就会增加缓存操作的时间开销。

因此，要解决缓存污染问题，最关键的技术点就是能识别出这些只访问一次或是访问次数很少的数据，在淘汰数据时，优先把它们筛选出来并淘汰掉。因为 noviction 策略不涉及数据淘汰，所以这节课，我们就从能否有效解决缓存污染这个维度，分析了 Redis 的其他 7 种数据淘汰策略。

volatile-random 和 allkeys-random 是随机选择数据进行淘汰，无法把不再访问的数据筛选出来，可能会造成缓存污染。如果业务层明确知道数据的访问时长，可以给数据设置合理的过期时间，再设置 Redis 缓存使用 volatile-ttl 策略。当缓存写满时，剩余存活时间最短的数据就会被淘汰出缓存，避免滞留在缓存中，造成污染。

当我们使用 LRU 策略时，由于 LRU 策略只考虑数据的访问时效，对于只访问一次的数据来说，LRU 策略无法很快将其筛选出来。而 LFU 策略在 LRU 策略基础上进行了优化，在筛选数据时，首先会筛选并淘汰访问次数少的数据，然后针对访问次数相同的数据，再筛选并淘汰访问时间最久远的数据。

在具体实现上，相对于 LRU 策略，Redis 只是把原来 24bit 大小的 lru 字段，又进一步拆分成了 16bit 的 ldt 和 8bit 的 counter，分别用来表示数据的访问时间戳和访问次数。为了避开 8bit 最大只能记录 255 的限制，LFU 策略设计使用非线性增长的计数器来表示数据的访问次数。

在实际业务应用中，LRU 和 LFU 两个策略都有应用。**LRU 和 LFU 两个策略关注的数据访问特征各有侧重，LRU 策略更加关注数据的时效性，而 LFU 策略更加关注数据的访问频次**。**通常情况下，实际应用的负载具有较好的时间局部性，所以 LRU 策略的应用会更加广泛。但是，在扫描式查询的应用场景中，LFU 策略就可以很好地应对缓存污染问题了，建议你优先使用**。

```markdown
使用了 LFU 策略后，缓存还会被污染吗？

我觉得还是有被污染的可能性，被污染的概率取决于LFU的配置，也就是lfu-log-factor和lfu-decay-time参数。

1、根据LRU counter计数规则可以得出，counter递增的概率取决于2个因素：

a) counter值越大，递增概率越低
b) lfu-log-factor设置越大，递增概率越低

所以当访问次数counter越来越大时，或者lfu-log-factor参数配置过大时，counter递增的概率都会越来越低，这种情况下可能会导致一些key虽然访问次数较高，但是counter值却递增困难，进而导致这些访问频次较高的key却优先被淘汰掉了。

另外由于counter在递增时，有随机数比较的逻辑，这也会存在一定概率导致访问频次低的key的counter反而大于访问频次高的key的counter情况出现。

2、如果lfu-decay-time配置过大，则counter衰减会变慢，也会导致数据淘汰发生推迟的情况。

3、另外，由于LRU的ldt字段只采用了16位存储，其精度是分钟级别的，在counter衰减时可能会产生同一分钟内，后访问的key比先访问的key的counter值优先衰减，进而先被淘汰掉的情况。

可见，Redis实现的LFU策略，也是近似的LFU算法。Redis在实现时，权衡了内存使用、性能开销、LFU的正确性，通过复用并拆分lru字段的方式，配合算法策略来实现近似的结果，虽然会有一定概率的偏差，但在内存数据库这种场景下，已经做得足够好了。


缓存淘汰是在每次请求时同步去计算这些淘汰机制吗？
是的，达到maxmemory后，请求进来，先淘汰数据，再写入数据。


还有一种情况，淘汰的效率比较慢，比新增的数据速度慢，也会导致缓存被污染



班长你好，请问下衰减因子策略是在主线程执行的还是子线程扫描执行的？
主线程，请求到的key才会触发计算。


请问为了count可以支持更大的值，lfu_log_factor岂不是越大越好，直接设置100不就行了，为什么作者要建议设置10
lfu-log-factor设置过大会使counter递增概率过低，导致counter递增困难，在访问量不高的场景下，很难区分出频次高和频次低的key


这个衰减，是有专门的定时机制进行处理吗？
请求过来，先判断内存是否超过了maxmemory,如果超了，就触发淘汰机制，淘汰机制是采样到待淘汰集合，计算后进行淘汰删除

```

## redis事务

redis事务更像是一个**打包**的命令，把一组客户端的命令进行打包，然后放入队列，再进行执行。执行期间依次顺序执行命令，每条指令是独立的，单条指令出错不会影响其他指令。打包后的命令可以看作一条指令，因此执行“队列”中的命令时，和其他单条命令或打包命令串行执行。

开启事务对应multi命令（感觉是声明多条指令），然后客户端再发送指令后，这些指令不会立即执行，而是入队（每天指令都需要和服务器进行交互），当调用exec时才会真正执行任务。使用discard会舍弃任务。redis事务不支持回滚。

```
127.0.0.1:6379> multi 
OK
127.0.0.1:6379> set k1 v1
QUEUED	
127.0.0.1:6379> set k2 v2
QUEUED
127.0.0.1:6379> exec 
1) OK
2) OK

    
```

> 如果代码出现语法问题如使用了不存在的命令，那么事务中的所有命令都不会执行，如果运行时出现错误，那么出错的指令不会影响其他的指令。这是一部分人或书籍对redis原子性的解释，但是这些“这些不是应该的吗？”，我认为redis没有原子性。
>第二种情况和第一种情况不同的是，事务操作入队时，**命令和操作的数据类型不匹配**，但 Redis 实例没有检查出错误。但是，在执行完 EXEC 命令以后，Redis 实际执行这些事务操作时，就会报错。不过，需要注意的是，**虽然 Redis 会对错误命令报错，但还是会把正确的命令执行完**。在这种情况下，事务的原子性就无法得到保证了。

redis事务还有watch和unwatch指令，**在exec命令执行之前，会监视任意数量的数据库键，如果在exec执行时，至少一个被监视的键值被修改，那么服务器拒绝执行队列中的命令**。

每个redis数据库（RedisServer的db成员结构体）都会保存一个watched_key字典，**如果某个客户端对某个key进行watch调用，那么表示该客户端的对象将被加入到watched_key对应key所在的链表**。  
一旦某个key被修改，那么redis服务器依次将对应客户端的redis_dirty_cas成员置位，标识事务已经破坏，如果该客户端向服务器发送exec指令，那么服务器检查该标志后将拒绝执行命令。

### 对redis事务ACID的思考

Redis的事务和关系型数据库的事务不一样，它不保证原子性，也不支持回滚，也没有隔离级别的概念。

【1】没有隔离级别  
隔离性在关系型数据库中，指的是**即使数据库中有多个事务并发执行，各个事务之间也不会互相影响，并发状态下执行的事务和串行执行的事务产生的结果完全相同**。但是关系式数据库考虑到并发性能，并没有使用统一的串行化，而是根据隔离程度划分了隔离级别。

事务期间的命令放入队列，但是没有执行，只有当提交的时候命令才按照顺序执行。也就是说**redis的事务本质上是将一组指令入队，并且这组指令是一次性执行完的，但是提交之前仍然是会执行其他指令的**。并且如果存在其他的事务（或者说打包命令），那么他们是串行化被执行的。

> 这里强调的至少“打包”命令的执行与其他命令的执行是串行的，但是“入队”的过程，其他命令是会被立刻执行的、

【2】残缺的原子性  
队列中指令的执行是一次性执行完的，中途不会执行其他客户端的命令。但是一旦出现错误是不提供回滚的。也就是说**不能保证“要么成功要么失败”**，即使事务队列中的某个命令在执行期间出现了错误，整个事务也会继续执行下去，直到将队列中的命令执行完毕。  
【3】几乎没有持久性  
如果没有开启持久化则不具有持久性。如果在RDB模式下运行，也不具备（因为生成RDB文件总是和时间事件有关，是异步的。包括非always的AOF也无法保证持久性）。**只有当基于always的AOF模式下，才能保证持久性**（也可以考虑提交事务前，在队列中加入一个save命令，不过比较低效）  
【4】没有一致性的概念  
一致性应该是建立在以上三个性质的，即使书上说它可以通过错误检测和简单设计保证一致性，但是我认为它的一致性还是比较残缺的。这取决于它原子性的缺失。另一方面，关系式数据库的一致性还依赖应用层去进行约束数据的正确性，但是redis更多的是作为一个缓存区使用，没有所谓的“约束”。

### 总结

**redis的事务更像是一个命令打包、一次批量执行的命令，并且在执行的过程中不会转去执行其他命令**。命令入队的时候总是需要和服务器进行交换，增加带宽。

如果我们真正想要去一次性执行多个redis命令，应该将redis多条命令封装为一个**lua脚本**即多条指令变成一条指令去执行。

redis事务本质上还是多条指令包括开启、入队和执行，这期间是会被其他客户端影响的。而且lua脚本可以做到redis事务做不到的事——使用逻辑关系运算如if/else等。（不过使用该方式也是不能支持回滚的，除非自己写补偿的代码）

> 使用LUA脚本的好处：  
> 【1】相对redis事务，减少请求的带宽  
> 【**2】原子操作，redis将脚本作为一个整体执行，中间不会被其他客户端的命令进行插入**。（凡是多条redis需要捆绑在一起执行的原子操作，都需要使用LUA脚本进行实现）  
> 【3】脚本相当于是一个存储过程，可以被复用

换一种思路思考的话，redis只是完成了“它所指代”的事务。  
【1】redis认为的原子性——事务队列中的每个指令是独立的，每个指令要么成功，要么失败，整体的执行是不被中断的  
【2】一定程度上的持久性  
【3】每个“队列命令”之间的执行都是串行化的，即他们之间的执行是隔离的。（没有隔离级别概念，因为总是串行化执行的）



# 待整理
## 为什么Redis会设计redisObject对象

在redis的命令中，用于对键进行处理的命令占了很大一部分，而对于键所保存的值的类型（键的类型），键能执行的命令又各不相同。如：LPUSH 和 LLEN 只能用于列表键, 而 SADD 和 SRANDMEMBER 只能用于集合键, 等等; 另外一些命令, 比如 DEL、 TTL 和 TYPE, 可以用于任何类型的键；但是要正确实现这些命令, 必须为不同类型的键设置不同的处理方式: 比如说, 删除一个列表键和删除一个字符串键的操作过程就不太一样。

  

**以上的描述说明, Redis 必须让每个键都带有类型信息, 使得程序可以检查键的类型, 并为它选择合适的处理方式.**

比如说， 集合类型就可以由字典和整数集合两种不同的数据结构实现， 但是， 当用户执行 ZADD 命令时， 他/她应该不必关心集合使用的是什么编码， 只要 Redis 能按照 ZADD 命令的指示， 将新元素添加到集合就可以了。

这说明, **操作数据类型的命令除了要对键的类型进行检查之外, 还需要根据数据类型的不同编码进行多态处理.**

为了解决以上问题, Redis 构建了自己的类型系统：

1.类型检查实现  

**类型检查是通过redisObject结构的type属性来实现的**：

-   在执行一个命令之前，服务器会检查输入数据库键的值对象是否为执行命令所需的类型，如果是的话，服务器就对键执行指定的命令；
    
-   否则，服务器将拒绝命令，并向客户端返回一个类型错误；
    

![图片](https://mmbiz.qpic.cn/mmbiz_png/SNiaXKPlfx8RyXEvByGhapBEHRWvBtYn5sOyVOS4Y7YA6NOibuUQrwApLrZTSaQb0l8RamPAlr94GJa4EdvFAKPg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

  

2.多态命令的实现

**Redis除了会根据对象的类型来判断键是否能够执行指定命令之外，还会根据值对象的编码方式，选择正确的命令实现代码来执行命令**

![图片](https://mmbiz.qpic.cn/mmbiz_png/SNiaXKPlfx8RyXEvByGhapBEHRWvBtYn5BXInibYJrBwWvsVicWXu3hMicGQOoaxqsCvbHCbRr5CFEJh46MocLib2cQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

  

3.内存回收  

redisObject中有refcount属性，是对象的引用计数，显然计数0那么就是可以回收。

-   每个redisObject结构都带有一个refcount属性，指示这个对象被引用了多少次；
    
-   当新创建一个对象时，它的refcount属性被设置为1；
    
-   当对一个对象进行共享时，redis将这个对象的refcount加一；
    
-   当使用完一个对象后，或者消除对一个对象的引用之后，程序将对象的refcount减一；
    
-   当对象的refcount降至0 时，这个RedisObject结构，以及它引用的数据结构的内存都会被释放。
    

  

4.对象共享  

除了用于实现引用计数内存回收机制外，对象的引用计数属性还带有对象共享的作用。

Redis在初始化服务器时，会创建一万个字符串对象（0~9999的字符串对象），当服务器需要用到这些值对象时，服务器会使用这些共享对象，而不是创建新对象；

  

假设键A创建了一个包含整数值100的字符串对象作为值对象，如果此时键B也要创建一个包含整数值100的字符串对象作为值对象，那么键A和键B将共享同一个字符串对象。

![图片](https://mmbiz.qpic.cn/mmbiz_png/SNiaXKPlfx8RyXEvByGhapBEHRWvBtYn5DMSCoRibqc1pfAbcWFLat9RWk3qpkPMAZEiasDkU0D1gESbJnnKj2Elw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

在Redis中，让多个键共享同一个值对象只需要两个步骤：

1）将数据库键的值指针指向一个现有的值对象；  

2）将被共享的值对象引用计数加一；

  

为什么Redis不共享包含字符串的对象？

当服务器考虑将一个共享对象设置为键的值对象时，程序需要先检查给定的共享对象和键想创建的目标对象是否完全相同，一个共享对象保存的值越复杂，验证的时间复杂度就越高，消耗CPU时间也就越多：

-   如果共享对象是保存字符串对象，那么验证操作的复杂度为O(1)；
    
-   如果共享对象是保存字符串值的字符串对象，那么验证操作的复杂度为O(N);
    
-   如果共享对象是包含多个值的对象，其中值本身又是字符串对象，即其它对象中嵌套了字符串对象，比如列表对象、哈希对象，那么验证操作的复杂度将会是O(N^2);
    

  
5.对象的空转时间

redisObject结构里有个lru属性，记录对象最后一次被命令程序访问的时间；

![图片](https://mmbiz.qpic.cn/mmbiz_png/SNiaXKPlfx8RyXEvByGhapBEHRWvBtYn5yxbxfH51SpWhCYBUkticyxGzqmApcopibBzd88qojovXhyth6wEpaGyQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

如果服务器打开`maxmemory`选项，并且回收内存的算法为`volatile-lru`或`allkeys-lru`，那么当服务器占用的内存数超过`maxmemory`选项设置的上限值是，空转时间较高的键会优先被服务器释放，回收内存。（空转时间是由当前时间减去值对象的lru时间计算出来的）

![[Pasted image 20220312002944.png]]

![[Pasted image 20220312002951.png]]


```markdown

redis为数据结构抽象出了一种对象系统，如集合对象，既可以通过哈希表实现也可以通过线性表实现，类似Java的接口与实现类之间的多态关系  
同时redis基于**引用计数**的方式回收不被使用的对象。  
redis的对象带有标识访问时间记录的属性，在内存不够用的时候将会优先回收空转时间过长的对象。  
当在redis中创建一个键值对的时候，至少会创建两个对象，每个对象由一个结构体标识RedisObject，type成员指明它是一个什么类型的对象，encoding指明它底层是基于实现的，而ptr指针指向底层的数据结构。

redis的命令可以分为两种，一种可以在**任意类型的键**执行如del 、 type 、 expire等。另一种只能对**特定类型的键**执行如set、hset等。其中是**基于类型（type）的多态**，而后者是**基于编码（encoding）的多态**。

对象的引用计数属性还可以实现对象共享，而redis仅共享保存**整数值的字符串**对象（0-9999一万个），因为这只需要O（1）复杂度的验证。



字符串对象: 
    编码: 字符串对象的编码可以是int，raw或者embstr。
    int 编码：保存的是可以用 long 类型表示的整数值。
    embstr 编码：保存长度小于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）。
    raw 编码：保存长度大于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）。
    
	int 编码是用来保存整数值，而embstr是用来保存短字符串，raw编码是用来保存长字符串。

	raw 和 embstr 的区别:
    

	其实 embstr 编码是专门用来保存短字符串的一种优化编码，raw 和 embstr 的区别：
	
		embstr与raw都使用redisObject和sds保存数据
		
		区别在于，embstr的使用只分配一次内存空间（因此redisObject和sds是连续的），而raw需要分配两次内存空间（分别为redisObject和sds分配空间）。因此与raw相比，embstr的好处在于创建时少分配一次空间，删除时少释放一次空间，以及对象的所有数据连在一起，寻找方便。
		
		而embstr的坏处也很明显，如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，因此redis中的embstr实现为只读,一旦涉及修改操作就会升级为raw编码
		
		ps：Redis中对于浮点数类型也是作为字符串保存的，在需要的时候再将其转换成浮点数类型。

  

	编码的转换:
	    当 int 编码保存的值不再是整数，或大小超过了long的范围时，自动转化为raw。
	    对于 embstr 编码，由于 Redis 没有对其编写任何的修改程序（embstr 是只读的），在对embstr对象进行修改时，都会先转化为raw再进行修改，因此，只要是修改embstr对象，修改后的对象一定是raw的，无论是否达到了44个字节



列表对象:
	list 列表，它是简单的字符串列表，按照插入顺序排序，你可以添加一个元素到列表的头部（左边）或者尾部（右边），它的底层实际上是个链表结构。
	
	编码:
		列表对象的编码是quicklist。 
		
		（1）（Redis 3.2 版本前）列表对象底层实现的方式，压缩列表（ziplist）与双端链表（linkedlist）存在转换
		
		（2）（Redis 3.2 版本）考虑到 Redis 的空间存储效率和时间效率，引入了 quicklist（快速列表）作为 list 的底层实现


	为什么Redis  3.2版本要引入快速列表呢？
		
		为了解决 linkedlist 的双向指针占用内存过多，以及 ziplist 数据量太大性能就变差的问题（连锁更新），结合他们两个产出了新的数据结构，也就是 quicklist.
		
		它将多个 ziplist 通过前后节点的指针连接起来，在一定程度上解决了上面的问题，提高了 Redis 的响应速度。

		ziplist 由于是一整块连续内存，所以存储效率很高。但是，它不利于修改操作，每次数据变动都会引发一次内存的**重分配**。特别是当 ziplist 长度很长的时候，一次 重分配可能会导致大批量的数据拷贝（Redis在特殊情况下产生的连续多次空间拓展操作称之为连锁更新），进一步降低性能。




哈希对象:
	哈希对象编码可以是ziplist或hashtable；
    使用ziplist编码的条件：
    键和值的字符串长度小于64字节；
    键值对数量少于512个；

	在前面介绍压缩列表时，我们介绍过压缩列表是Redis为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，相对于字典数据结构，压缩列表用于元素个数少、元素长度小的场景。其优势在于集中存储，节省空间。

集合对象:
	集合对象的编码可以是 intset 或者 hashtable; 
    底层实现有两种, 分别是intset和dict。

	显然当使用**intset**作为底层实现的数据结构时, 集合中存储的只能是数值数据, 且必须是整数; 而当使用**dict**作为集合对象的底层实现时, 是将数据全部存储于dict的键中, 值字段闲置不用.
	
	使用inset编码的条件：
	
		所有元素为整数值；
	    保存的元素不超过512个


有序集合对象:
	有序集合的编码可以是**ziplist**或 **skiplist**，**dict**；
    压缩列表内的集合元素按分值从小到大排列；

	使用ziplist编码的条件：
		元素数量少于128个；
	    元素长度小于64字节；
	    使用skiplist编码时，使用zset结构作为底层实现；


为什么有序集合需要同时使用跳跃表和字典来实现？  

	当只使用字典来实现，可以以O(1)的时间复杂度获取成员的分值，但是由于字典是无序的，当需要进行范围性操作的时候，需要对字典中的所有元素进行排序，这个时间复杂度至少需要 O(nlogn)。
	    
	当只使用跳跃表来实现，可以在O(logn)的时间进行范围排序操作，但是如果要获取到某个元素的分值，时间复杂度也是O(logn)。
	    
	因此，将字典和跳跃表结合进行使用，可以在O(1)的时间复杂度下完成查询分值操作，而对一些范围操作使用跳跃表可以达到O(logn)的时间复杂度。
```

## 基础数据结构

```markdown
简单动态字符串SDS:
	主要包含三成员: 1. 字符串长度len 2. 底层的字符数组char[] 3. 记录字符数组中未使用的字节数

	len的好处是 1.获取长度时间复杂度为O(1) 2.避免了遇到'\0'就返回问题,读到len才返回(c数组最后一个元素是'\0',不会出现将某个值误认为结束标志)

	底层的字符数组是基于预分配和延迟释放的,因此字符串长度不等于底层字符长度,并且空间预分配和延迟释放策略可以避免内存分配函数被频繁调用,对内存分配操作涉及到系统调用,而redis是一个内存数据库,频繁的系统调用将极大影响性能



字典:
	组成: 1. 哈希表数组,有两个,一般只用其中一个. 哈希表底层就是哈希表结点的数组,哈希表结点是一个键值对,该结点还保存了next指针用于解决哈希冲突 2.rehash索引,当rehash = -1 表示当前没有在扩容

	解决hash冲突的还是链地址法,随着链表的增长,查询时间增加,解决办法就是rehash,过程分为3步: 
	1.给 ht[1] 分配空间，一般会比 ht[0] 大 2 倍； 
	2.将 ht[0] 的数据迁移到 ht[1] 中； 
	3.迁移完成后，ht[0] 的空间会被释放，并把 ht[1] 设置为 ht[0]，然后在 ht[1] 新创建一个空白的哈希表，为下次 rehash 做准备。
	第二步很有问题，如果 ht[0] 的数据量非常大，那么在迁移至 ht[1]  的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求。
	为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了渐进式 rehash，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。
	
	渐进式hash:
	1.为 h[1] 开辟空间，字典同时持有 h[0] 和 h[1]
	    
	2.字典中的 rehashidx 维护了 rehash 的进度，设置为 0 的时候，开始 rehash
	    
	3.字典每次增删改查的时候，除了完成指定操作之外，还会顺带把 rehashidx 上的整条链表迁移到 h[1] 中。迁移完之后 rehashidx + 1
	    
	4.随着字典的不断读取、操作，最终 h[0] 上的所有键值对都会迁移到 h[1] 中。全部迁移完成之后 rehashidx = -1

	redis会定时触发时间事件，也会推进rehash

	在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。
	
	比如，查找一个 key 的值的话，先会在 ht[0] 里面进行查找，如果没找到，就会继续到 ht[1]  里面进行找到。
	
	另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到 ht[1] 中，而 ht[0]  则不再进行任何添加操作，这样保证了 ht[0] 的 key-value 数量只会减少，随着 rehash 操作的完成，最终 ht[0] 就会变成空表。

	渐进式rehash避免了集中式rehash带来的巨大计算量，但是也存在一些问题：
	1.整个扩容期间，一直会存在两张哈希表，占用一定空间  
	2.增删改一般需要查询两张表，效率比较低 
	3.redis使用内存临近最大内存时（并设置了驱逐策略的情况下），执行rehash可能使得内存占用超过最大内存，从而触发驱逐操作，使得主从服务器出现不一致的情况。



跳表:
	1.跳表是可以实现二分查找的有序链表；
    2.每个元素插入时随机生成它的level；
	3.最底层包含所有的元素；
	4.如果一个元素出现在level(x)，那么它肯定出现在x以下的level中；
	5.每个索引节点包含两个指针，一个向下，一个向右；各种跳表源码实现包括Redis 的zset 都没有向下的指针，那怎么从二级索引跳到一级索引呢？
	6.跳表查询、插入、删除的时间复杂度为O(log n)，与平衡二叉树接近；


	为什么使用跳跃表，而不是平衡树等用来做有序元素的查找
	1. 跳跃表的时间复杂度和红黑树是一样的，而且实现简单
	2. 在并发的情况下，红黑树在插入删除的时候可能需要做rebalance的操作，这样的操作可能会涉及到整个树的其他部分；而链表的操作就会相对局部，只需要关注插入删除的位置即可，只要多个线程操作的地方不一样，就不会产生冲突
	3.有序集合经常会进行 zrange 或 zrevrange 这样的范围查找，跳表里的双向链表可以十分方便的进行这操作
	
	跳跃表中的节点按照分值大小进行排序，当分值相同时， 节点按照成员对象的大小进行排序。这一点也是redis针对跳表这个结构做出的优化之一。具体的优化点为：
	1.允许重复分值，即多个节点允许相同的分值，但是每个节点的成员对象必须是唯一的
	2.比较的时候不仅仅是分值，还有整个对象，即分值相同，按照成员对象大小排序
	3.在第一层有一个back指针，适用于 ZREVRANGE 方法，允许从尾部到头部来遍历列表


	每次创建一个新的跳跃表节点时，程序都会根据幂次定理随机生成一个介于1和32之间的值，作为level数组的大小，这个大小就是高度。

整数集合:
	整数集合不会出现重复元素，而且是有序的，是redis用于保存整数值的集合抽象数据结构，可以保存16位、32位和64位的整数值，底层数组是什么类型取决于最大的数是什么类型。如果一开始插入一个16位可以装下的数，那么数组此时就是int16_t的，如果某个放入的元素只能使用64位表示，那么数组就会**升级**为int64_t的。
	升级：重新分配内存空间、数组中的元素转型，高位补零、将新元素放入数组中。引发升级的元素要么大于所有现有的元素，要么小于所有现有的元素
	升级操作可以实现一个懒类型转换的效果，并不一开始就申请一个能够容纳64位元素的连续数组，而是当有一个64位元素将放入的时候才进行升级。  
	整数集合不支持降级操作。主要还是减少开销的权衡。


压缩列表:
	当一个列表键只包含少量列表项，并且都是小的整数值或者短字符串，那么它便适合使用压缩列表进行实现，因此压缩列表的一个特点就是节约内存

	列表列表由一系列特殊编码的连续内存块组成。压缩列表的组成：整个列表占用的字节数、表尾节点到起始地址的偏移量（快速拿到表尾节点）、节点数量、各个节点、用于标识末尾的标志符号。  
	其中，节点由三个部分组成：前一个节点的长度、节点编码、节点值
	
	如果前一个节点小于254字节，preLen占1字节，否则占用5字节，这5字节中的第一个表示这是一个5字节长度的preLen属性，后4字节存储前一个节点的实际长度。通过这种存储方式，可以实现从表尾到表头的遍历。
	
	preLen属性本身也算作节点的长度，因此添加、删除一个元素，都可能使得后面的元素指向连锁更新。（连续多次内存扩展或调整），不过并不多见，最坏复杂度是N^2
```


# 设计：跳表

[力扣1206：设计跳表](https://leetcode-cn.com/problems/design-skiplist/)

```
    static class Entry {
        Entry[] next;
        int val;
        int count;
        int level;

        public Entry(int val, int level) {
            this.val = val;
            this.count = 1;
            this.level = level;
            this.next = new Entry[level];
        }
    }

    
```

每个跳表节点有一个前进数组的成员，val保存对应的值，level保存前进指针的数量（前进指针数组的对象），**count用于保存元素的数量（重复元素使用count进行逻辑存储，没有重复元素count等于1）**。其中**level值是通过随机数生成的**。  
**其中层数越高，能够跳动的跨度越大**，例如第一层的前进指针总是执行直接相邻的节点1->2->3->4->5->null，而更高层的跳表指针可能是1->3->5->null，如果我们想要查找6，如果按照最底层查找就相当于退化为了链表，而如果**自高向低**进行查找，查找效率就会大大提升，如果想要查找4，只需要先和3比较，再和5比较，最后确定范围是（3,5），于是在指针3的下一层进行更小范围的跳跃，最终达到4，跳表的层数越高，跳跃的范围越大。

因此，由于高层节点的存在，不再需要逐一比较每个节点，需要比较的节点大概只有原来的一半。跳表的本质就是就是**多层链表**，每一层链表的节点个数大致都是下一层节点个数的一半，但是这种关系很容易被插入删除等更改结构的操作打破，为了避免这个问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数。  
由于每一层的层数都是随机处理的，因此新插入一个节点不会影响其他节点的层数，**插入操作只需要修改插入节点前后的指针**，这降低了插入和修改维护的复杂度。

跳表和平衡树具有相似的查询效率（查找当个键，时间复杂度都为logN），但是比平衡树更容易实现，而且维护开销更小。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。

> 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势

```
    private static final int MAX_LEVEL = 64;

    private Entry head;
    private Random random;

    
```

跳表结构维护一个头结点，和一个用于生成随机数的对象。其中头结点就是一个哨兵节点

```
    public Skiplist() {
        this.head = new Entry(Integer.MIN_VALUE, MAX_LEVEL);
        this.random = new Random();
    }

    
```

## 随机层数

redis的大致实现：  
一个节点最少有一层指针，它具有下一层指针的概率是p（redis中取1/4），以下函数的逻辑就是，循环每轮执行的概率都是1/4，1/4的概率增加一层，最大增加到max_level（可以根据数据规模取，一般取2的整数倍）。假设产生了4层，那么这个概率就是pow(1/4,3)

```
    private int randomLevel() {
        int level = 1;
        while(random.nextInt(100) < 25) {
            level++;
            if(level == MAX_LEVEL) {
                break;
            }
        }
        return level;
    }

    
```

## search

我们从头结点开始搜索，而且从最高层开始搜索（这里的实现没有维护maxLevel而是每次从最高层开始向下搜索，有优化空间），如果在某一层发现存在不为空的指针，就横向跳跃直到当前指针cur的相邻指针cur.next指向的对象大于等于目标对象target。每当内层循环退出时，当前层已经成功划定了一个范围cur以及cur.next[i]所在节点，二者之间可能存在一其他节点（层数小于二者），然后 i - - 层数下降，重复以上过程、  
最终cur下降到第1层即i=0，这时cur.next[0].val可能大于等于target，cur.next[0]也可能为空。做一个后处理即可  
其中外循环是常量级别的，内循环相当于做二分操作，总体时间复杂度在logN 。

```
    public boolean search(int target) {
        Entry cur = head;
        //从最高层往下搜索，和相邻指向的元素最比较
        for(int i = MAX_LEVEL - 1; i >= 0; i--) {//纵向
            while(cur.next[i] != null && cur.next[i].val < target) {//横向
                cur = cur.next[i];
            }
        }
        //此时next可能>=target或者为null
        cur = cur.next[0];
        if(cur == null) {
            return false;
        }
        return cur.val == target;
    }

    
```

## add

```
    private Entry newEntry(int num) {
        int level = randomLevel();
        return new Entry(num, level);
    }

    
```

插入一个节点（值为num），我们依然从头结点开始搜索，同时我们还需要一个专门用于**映射指针**的辅助节点数组，例如我们需要在54367中的3和6直接插入一个9（数字均代表层数），插入的实现，需要将5 4 3的指针指向9，同时9这个节点还需要继承他们指向 3 6 7的指针（想象成一堵墙立在中间）。

每当内循环退出，说明当前层cur < num且cur.next[i] >= num，使用辅助节点数组prev在第i层保存cur（相当于cur和cur.next[i]全部拿到了）。从上到下依次对prev进行填充，最终prev被初始化完毕

> prev数组是用于实现节点接替的，如果只有一层链表我们直接遍历到目标节点，完成接替并返回即可，但是现在是多层链表，因此需要使用一个临时数组保存接替节点，最后再依次接替

cur最终会走到第一层，其中cur.val和cur.next[i].val将num夹住，如果cur.next[0]等于num则直接逻辑添加并返回。  
否则，创建新节点，然后借助prev数组依次实现指针变换操作。

```
    public void add(int num) {
        Entry[] prev = new Entry[MAX_LEVEL];//prev将小于num的level保存起来
        Entry cur = head;
        //prev的每一个元素，记录了“preV元素”对应的引用
        for(int i = MAX_LEVEL - 1; i >= 0; i--) {
            while(cur.next[i] != null && cur.next[i].val < num) {
                cur = cur.next[i];
            }
            //当前cur<num且cur.next[i]>=num
            prev[i] = cur;
        }
        //已存在的元素则只需要逻辑上添加
        if(cur.next[0] != null && cur.next[0].val == num) {
            cur.next[0].count += 1;
            return;
        }

        Entry newEntry = newEntry(num);
        int newLevel = newEntry.level;
        //prev-newEntry-prevNext 
        for(int i = newLevel - 1; i >= 0; i--) {
            newEntry.next[i] = prev[i].next[i];
            prev[i].next[i] = newEntry;
        }
    }


    
```

## erase

删除操作和添加操作实现思路基本一致，也是通过辅助数组prev记录哪些指针需要修改。最后的后处理将两个指针关系重新连接即可。

```
    public boolean erase(int num) {
        Entry[] prev = new Entry[MAX_LEVEL];
        Entry cur = head;
        for(int i = MAX_LEVEL - 1; i >= 0; i--) {
            while(cur.next[i] != null && cur.next[i].val < num) {
                cur = cur.next[i];
            }
            //此时满足 cur > num >= cur.next[i]
            prev[i] = cur;
        }
        cur = cur.next[0];
        //从来没有添加过该值
        if(cur == null || cur.val != num) {
            return false;
        }
        //存在多个该值
        if(cur.count > 1) {
            cur.count -= 1;
        } else {
            //移除该值对应结构
            int level = cur.level;
            //prev - beDeleted - prevNext
            for(int i = level - 1; i >= 0; i--) {
                prev[i].next[i] = cur.next[i];
            }
        }
        return true;
    }


    
```



# 总结redis持久化、服务处理模型、redis事务
## 服务模型

redis服务器可以与多个客户端建立连接，客户端将命令请求通过网络传输给服务器。redis服务器从在相应的数据库上执行读写操作。

redis服务是通过**单线程单进程**的方式处理客户端的请求。当一个redis客户端与redis服务器建立连接之后，服务器为客户端在服务器内部维护一个**结构体RedisClient**表示客户端状态，这个结构体用于保存**当前客户的上下文信息**。主要就是与客户端建立连接的**套接字描述符**、输入/输出缓冲区等与客户端有关的信息。

> 套接字描述符属性记录了客户端正在使用的套接字描述符。而输入缓存区用于保存redis客户端向redis服务器发送的命令，输出缓冲区用于保存redis服务器执行完毕命令，待回写到redis客户端的命令。

redis服务器可以一次性服务多个用户，这些用户使用链表结构组织起来。redis本质上就是一个**事件驱动程序**，可以处理文件事件和时间时间。**文件事件就是服务器对套接字操作的抽象**，因为send和receive本身就可以看作特殊的文件接口，而对端的socket输入缓冲区就是打开的文件。时间时间是需要在给定时间点执行的事件，是**服务器定时操作的抽象**。  
redis的文件处理器是reactor模型，基于事件驱动的。文件事件处理器使用I/O多路复用程序可以同时监听多个套接字，并且注册感兴趣的事件，包括accept（连接建立事件）、read（读事件）、write（写事件）、close（关闭事件）、slaveof（主从复制）等

Redis单进程线程的架构意思是：从网络IO到实际处理读写事件、时间事件等都是有单个线程基于I/O复用完成的。并不是整个redis中只有一个主线程和单一进程。  
Redis 6支持多线程技术，**仅针对处理网络请求的过程采用了多线程，而数据的读写命令仍然采用单线程进行处理**。这里使用多线程IO的原因是在**等待网络IO的时候最大化利用CPU资源**。

> 多路复用的IO模型，处理网络请求的时候，select()调用是阻塞的。如果并发量很高的情况下，可能成为瓶颈。多线程可以利用CPU多核的优势，使得多个线程并行。当select()调用返回的时候，请求依次交给多个线程去处理，充分利用CPU多核的优势。

但是处理事件（执行事件处理器）本身是很快的，不存在CPU瓶颈。而且可以避免线程安全问题。  
虽然多线程模型执行读写事件能够提升并发性能，但是引入了多线程会**使得程序的执行具有不确定性，还会造成额外的切换开销**

> redis基于内存数据库，本身在执行上不存在CPU瓶颈。如果采用多线程反而会增加上下文切换带来的开销，以及线程安全问题，为程序的执行带来不确定性。redis采用I/O多路复用模型，使得它可以同时响应多个事件，这极大地提升了I/O利用率。另外redis的对象底层根据不同的场景，会使用不同的数据结构进行实现，优化了性能。  
> **redis真正的瓶颈在于网络带宽和机器内存大小**。

（redis4.0也支持了多线程技术，主要是用于后台处理包括对象回收、过期键回收等redis服务器部分的时间事件的功能）

## 文件事件

文件事件处理器由四个部分组成：**套接字、I/O多路复用程序、文件事件分派器（dispatcher）、事件处理器（controller）**  
【1】redis客户端与redis服务器建立连接后，redis服务器就会在内存中维护一个redis客户端的对象，并且将redis客户端的套接字注册在I/O多路复用程序上  
【2】I/O多路复用程序监听这些套接字，一旦有感兴趣的事件发生，就会传输产生了事件的套接字给文件事件分派器（他们通过队列通信，I/O复用程序将套接字同步有序的放入**队列**，而分派器则从队列中取出，类似基于生产者消费者模型的阻塞队列）  
【3】分派器根据文件事件的种类，调用相应的事件处理器接口（事件处理函数，例如连接应答、命令请求、命令回复）（可以类比springMVC中的dispatcherSerlet和controller）

其中I/O多路复用程序底层依赖/O复用类库如select、epoll等。

## 时间事件

时间事件主要分为定时事件和周期事件，一个事件是定时事件还是周期事件取决于时间事件处理器的返回值（redis内部定义的常量值）。服务器会将所有的时间事件存入一个无序的链表。**当时间事件执行器运行的时候，他就遍历整个链表，找到所有已达到的时间事件，并调用相应的事件处理器**。redis作为内存数据库，遍历链表的操作是可以达到常量级别的。  
redis服务器需要定时对自身的资源和状态进行检查和调整，这些定时操作由serverCron函数负责，包括**定期清理过期键值对**、更新记账信息、与从服务器定期同步、**定期持久化操作**等。**正常模式下，redis服务器只运行serverCron一个时间事件，并且是周期事件**。

> serverCron默认每隔100毫秒执行一次，负责管理服务器的资源。包括更新LRU时钟、更新服务器每秒执行命令的次数、更新服务器内存峰值记录、处理kill （15即sig term） 的信号、检查持久化操作的运行状态。  
> serverCron函数每次执行的时候，都会调用clientsCron函数管理客户端资源，以及调用databasesCron函数，管理数据库资源

文件事件和时间时间都是**原子、有序、同步**地执行的，它们都会尽可能少地减少程序的阻塞时间，并且在有需要的时候主动让出执行权。如果执行时间、数据大小超过预设的阈值，通常会留在下一轮事件循环中执行。它们之间是合作关系，服务器会轮流执行这两个事件，并且执行过程不会互相抢占。

## 一次请求过程

【1】当redis客户端向redis服务器发送一个命令请求时，这个命令会以某种格式（自解释协议），通过连接传输到对端的套接字。当命令成功传输到对端后，服务器对应该客户端的连接套接字变得可读，该套接字经由分派器转发到对应的**读处理器**进行处理——将请求保存到输入缓冲区，将请求命令与参数进行解析并保存到客户端状态中。

> 客户端的命令传输到服务器后，服务器将命令保存在客户端状态的**输入缓冲区**，并按照协议解析出**命令**和**命令参数**。服务器会搜索命令表（一个KV结构，命令标识->命令实现函数），并找到为命令的抽象出的对象RedisCommand（结构体），并且将保存在服务器的客户端状态中的cmd属性指向RedisCommand对象。接着服务器就可以执行这个命令请求，并向客户端返回结果。

【2】调用命令执行器的接口，执行命令。命令执行器根据请求的命令标识在命令表中查找命令对象RedisCommand，并且保存到客户端状态的cmd属性（RedisClient对象的RedisCommand成员cmd指向目标RedisCommand对象）。在命令正式执行之前还会做一些校验工作包括检查执行权限、参数校验、检查内存空间等。  
【3】RedisCommand的proc属性是一个函数指针，指向命令的实现函数。服务器执行命令就是回调RedisClient的cmd成员指向的RedisCommand对象的proc回调函数。最终的调用结果将会保存在客户端状态的输出缓冲区。此时连接套接字的状态变为可写，分派器则将套接字分派给**命令回复处理器**进行处理。（当redis客户端收到命令，它会将信息转换为可读性更高的格式输出到终端）  
【4】最后就是一些记账相关的操作，例如记录慢查询日志、保存到AOF缓冲区、命令传播给从服务器、更新RedisCommand对象的执行耗时milliseconds和调用计数器calls属性



## 持久化

redis的**数据库状态**使用**RedisDb结构体**定义，RedisServer维护RedisDb的数组，为了将数据库状态保存起来可以使用redis的持久化功能。



## AOF

AOF通过保存redis服务器所执行的写命令来记录数据库状态，类似于mysql binlog的statement格式。被写入redis的命令按照请求协议格式保存，是**纯文本格式**的，可读性较高（命令传输的时候也是按照这个格式，命令传播一定程度上也通过AOF实现）。  
AOF功能默认是关闭的，需要append only yes进行开启。

AOF的实现分为三个部分：  
【1】服务器执行完一个（写）命令后，会以协议格式追加到服务器状态（RedisServer）的缓冲区中（就是一个sds字符串）  
【2】每一个redis服务器的事件循环的末尾，都会考虑是否将内存缓冲区的内容不同到文件中（**每次都会将redis缓冲区的内容复制到操作系统的page cache，但是刷盘事件根据配置文件的参数而定**）。

> 可以在redis.conf配置文件中配置三种选择：每个操作都同步always、每秒everysec（默认）、仅仅复制到操作系统的page cache，刷盘时机取决于操作系统 no。

如果redis突然掉电，需要分情况讨论：如果使用AOF的配置对每一条指令同步磁盘，则不会丢失数据。**如果是定时sync，如每N秒syn一次，则最多丢失N秒内的数据**。

> Redis 是先执行写操作，在将记录保存在AOF日志中的，好处：  
> 【1】避免额外的检查开销（只有当该命令执行成功时，才会将命令记录在AOF日志中，不需要额外的检查开销，保证AOF日志中的命令一定是正确的）  
> 【2】不会阻塞当前写操作命令的执行  
> 风险：掉电后，AOF日志可能会丢失至少一次事件循环的操作

当载入AOF持久化文件的时候，会创建一个**本地客户端（伪客户端）**，伪客户端从本地AOF文件中读取指令并发送给redis服务器执行命令。

AOF由于记录的是命令，并且是基于文本格式的，为了**防止AOF文件体积膨胀过大**的问题（本质上是为了缩短数据恢复的时间），redis提供了AOF文件重写的功能。redis会创建一个新的AOF文件去替换原来的文件，并且体积小很多。该功能通过读取当前服务器状态进行实现——**从数据库中读取键值，使用一条命令去记录键值对，替代原来的记录该键值的多条命令**。  
一般常用AOF后台重写的功能，通过为了保证当前数据库状态和重写后的AOF文件保存的数据库状态是一致的，redis额外设置了AOF重写缓冲区，服务器创建子进程之后开始使用。

当redis服务器执行完一个写命令之后，他会同时将这个命令发送给AOF缓冲区和AOF重写缓冲区  
，当AOF重写任务执行完毕后，子进程向父进程发送信号，父进程调用事件处理函数，**将AOF重写缓冲区的内容保存进一个新的AOF文件中，并原子地覆盖旧的AOF文件。**

> 重写缓冲区不是一次申请好的，而是边用边申请的，当无法继续申请时打印一条日志后进程退出，

**为什么bgsave和AOF重写日志的时候通常创建子进程，而不是子线程**  
因为如果创建的是线程，多个线程之间会共享内存，那么访问执行快照生成或AOF缓冲区访问的时候必须先**申请锁**（如果主线程要执行写，还可能会被阻塞），这会降低性能。  
而采用子进程时，基于COW，子进程即可以不加锁地读取原副本，一旦父进程的主线程（进程）执行写操作，生成独立数据副本，减少锁的开销。

## 总结

RDB持久化本质上是数据快照，而AOF持久化本质上是记录增量指令。

RDB适合做**冷备份**和**灾难恢复** ，它会生成多个数据文件，每个数据文件代表某一时刻redis里面的数据。如果服务挂了，可以拷贝前若干分钟的数据。同时，RDB对redis的性能影响非常小，因为同步数据的时候，redis会fork一个子进程进行持久化，而它在进行大数据量恢复的情况下，速度也快于AOF。  
由于RDB是快照文件，不宜频繁的生成，默认五分钟生成一次快照文件。而且如果生成的文件很大可能会使得客户端的正常请求收到影响。

AOF比RDB更加可靠，默认AOF一秒一次（everysec）去通过一个后台线程fsync操作，最多丢失一秒钟的数据，而且AOF文件的可读性更高。性能上，AOF将每个增量命令追加到内存缓冲区，并通过异步的方式进行磁盘文件同步，不会造成主线程的阻塞。适合进行**热备份**  
但是，同样的数据，AOF文件往往比RDB更加大，加载持久化文件的时候执行速度也慢一些。AOF开启后，redis的QPS（每秒查询次数）比基于RDB持久化更低，因为每秒都需要额外去异步刷新日志，相当于窃取了CPU时间。

两种机制全部开启的时候，redis在重启的时候会默认使用AOF去重新构建数据，因为**AOF的数据比RDB更加完整**

选择：先使用RDB数据恢复（快），然后使用AOF做数据补全（出事瞬间，数据丢失少）  
RDB做镜像全量持久化，AOF做增量持久化。RDB会耗费较长时间，不够实时，而且宕机时可能丢失大量数据，需要AOF配合。

在redis实例重启的时候，会使用RDB持久化文件构建基础的数据库状态，然后使用AOF重放最近的操作指令，来完整恢复重启之前的状态。



## redis变慢大分析
